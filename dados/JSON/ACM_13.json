{
    "exportedDoiLength": 101,
    "fileName": "acm",
    "style": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<style xmlns=\"http://purl.org/net/xbiblio/csl\" class=\"in-text\" version=\"1.0\" demote-non-dropping-particle=\"sort-only\" default-locale=\"en-US\">\n    <!-- This style was edited with the Visual CSL Editor (http://editor.citationstyles.org/visualEditor/) -->\n    <info>\n        <title>BibTeX ACM citation style</title>\n        <id>http://www.zotero.org/styles/bibtex-acm-citation-style</id>\n        <link href=\"http://www.zotero.org/styles/bibtex-acm-citation-style\" rel=\"self\"/>\n        <link href=\"http://www.bibtex.org/\" rel=\"documentation\"/>\n        <author>\n            <name>Markus Schaffner</name>\n        </author>\n        <contributor>\n            <name>Richard Karnesky</name>\n            <email>karnesky+zotero@gmail.com</email>\n            <uri>http://arc.nucapt.northwestern.edu/Richard_Karnesky</uri>\n        </contributor>\n        <category citation-format=\"author-date\"/>\n        <category field=\"generic-base\"/>\n        <updated>2018-06-11T10:52:49+00:00</updated>\n        <rights license=\"http://creativecommons.org/licenses/by-sa/3.0/\">This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 License</rights>\n    </info>\n    <macro name=\"zotero2bibtexType\">\n        <choose>\n            <if type=\"BILL BOOK GRAPHIC LEGAL_CASE LEGISLATION MOTION_PICTURE SONG\" match=\"any\">\n                <choose>\n                    <if genre=\"rfc\"  match=\"any\">\n                       <text value=\"rfc\"/>\n                    </if>\n                     <else-if  genre=\"bibliography\" match=\"any\">\n                        <text value=\"bibliography\"/>\n                    </else-if>\n                    <else-if  genre=\"play_drama\" match=\"any\">\n                        <text value=\"playdrama\"/>\n                    </else-if>\n                    <else-if  genre=\"proceeding\" match=\"any\">\n                        <text value=\"proceedings\"/>\n                    </else-if>\n                    <else-if  genre=\"tech_brief\" match=\"any\">\n                        <text value=\"tech-brief\"/>\n                    </else-if>\n                    <else>\n                       <text value=\"book\"/>\n                    </else>\n                </choose>\n            </if>\n            <else-if type=\"CHAPTER\" match=\"any\">\n                <text value=\"inbook\"/>\n            </else-if>\n            <else-if type=\"ARTICLE ARTICLE_JOURNAL ARTICLE_MAGAZINE ARTICLE_NEWSPAPER\" match=\"any\">\n                <text value=\"article\"/>\n            </else-if>\n            <else-if type=\"THESIS\" match=\"any\">\n                <choose>\n                    <if variable=\"genre\">\n                        <text variable=\"genre\" text-case=\"lowercase\" strip-periods=\"true\"/>\n                    </if>\n                </choose>\n                <text value=\"thesis\"/>\n            </else-if>\n            <else-if type=\"PAPER_CONFERENCE\" match=\"any\">\n                <text value=\"inproceedings\"/>\n            </else-if>\n            <else-if type=\"REPORT\" match=\"any\">\n                <text value=\"techreport\"/>\n            </else-if>\n            <else-if type=\"DATASET\" match=\"any\">\n                <choose>\n                    <if genre=\"software\"  match=\"any\">\n                       <text value=\"software\"/>\n                    </if>\n                    <else>\n                       <text value=\"dataset\"/>\n                    </else>\n                </choose>\n            </else-if>\n            <else>\n                <text value=\"misc\"/>\n            </else>\n        </choose>\n    </macro>\n    <macro name=\"citeKey\">\n           <text variable=\"call-number\"/>\n    </macro>\n    <macro name=\"editor-short\">\n        <names variable=\"editor\">\n            <name form=\"short\" delimiter=\":\" delimiter-precedes-last=\"always\"/>\n        </names>\n    </macro>\n    <macro name=\"author-short\">\n        <names variable=\"author\">\n            <name form=\"short\" delimiter=\":\" delimiter-precedes-last=\"always\"/>\n        </names>\n    </macro>\n    <macro name=\"issued-year\">\n        <date variable=\"issued\">\n            <date-part name=\"year\"/>\n        </date>\n    </macro>\n    <macro name=\"issued-month\">\n        <choose>\n            <if type=\"ARTICLE\" match=\"any\">\n                <date variable=\"issued\">\n                    <date-part name=\"month\" form=\"short\" strip-periods=\"true\" text-case=\"lowercase\"/>\n                </date>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"issue-date\">\n        <choose>\n            <if type=\"ARTICLE ARTICLE_JOURNAL\" match=\"any\">\n                <choose>\n                    <if variable=\"note\" match=\"none\">\n                        <choose>\n                            <if variable=\"source\">\n                                 <text variable=\"source\"/>\n                            </if>\n                               <else>\n                                 <date date-parts=\"year-month\" form=\"text\" variable=\"issued\"/>\n                               </else>\n                        </choose>\n                    </if>\n                </choose>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"author\">\n        <names variable=\"author\">\n            <name sort-separator=\", \" delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n            <label form=\"long\" text-case=\"capitalize-first\"/>\n        </names>\n    </macro>\n    <macro name=\"editor-translator\">\n        <names variable=\"editor translator\" delimiter=\", \">\n            <name sort-separator=\", \" delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n            <label form=\"long\" text-case=\"capitalize-first\"/>\n        </names>\n    </macro>\n    <macro name=\"title\">\n        <choose>\n            <if genre=\"proceeding\" match=\"any\">\n                <text variable=\"container-title-short\" suffix=\": \"/>\n                <text variable=\"title\" text-case=\"title\"/>\n            </if>\n            <else-if type=\"ARTICLE_JOURNAL\" match=\"none\">\n                <text variable=\"title\" text-case=\"title\"/>\n            </else-if>\n        </choose>\n    </macro>\n    <macro name=\"volume\">\n        <choose>\n            <if type=\"ARTICLE BOOK ARTICLE_JOURNAL\" match=\"any\">\n                <text variable=\"volume\" prefix=\"volume = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"DOI\">\n        <choose>\n            <if type=\"ARTICLE PAPER_CONFERENCE\" match=\"any\">\n                <text variable=\"DOI\" prefix=\"doi = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"abstract\">\n        <if match=\"any\" variable=\"abstract\">\n            <text variable=\"abstract\"/>\n        </if>\n    </macro>\n    <macro name=\"URL\">\n        <text variable=\"URL\" prefix=\"url = {\" suffix=\"}\"/>\n    </macro>\n    <macro name=\"container-title\">\n        <choose>\n            <if type=\"CHAPTER PAPER_CONFERENCE\" match=\"any\">\n                <text variable=\"container-title\" prefix=\"booktitle = {\" suffix=\"}\" text-case=\"title\"/>\n            </if>\n            <else-if type=\"ARTICLE ARTICLE_JOURNAL\" match=\"any\">\n                <text variable=\"container-title\" prefix=\"journal = {\" suffix=\"}\" text-case=\"title\"/>\n            </else-if>\n        </choose>\n    </macro>\n    <macro name=\"pages\">\n        <group delimiter=\",&#10;\">\n            <choose>\n                <if match=\"any\" variable=\"collection-number\">\n                    <text variable=\"collection-number\" prefix=\"articleno = {\" suffix=\"}\"/>\n                </if>\n                <else>\n                    <text variable=\"page\" prefix=\"pages = {\" suffix=\"}\"/>\n                </else>\n            </choose>\n            <text variable=\"number-of-pages\" prefix=\"numpages = {\" suffix=\"}\"/>\n        </group>\n    </macro>\n    <macro name=\"edition\">\n        <text variable=\"edition\"/>\n    </macro>\n    <macro name=\"editor\">\n        <choose>\n            <if match=\"any\" type=\"THESIS\">\n                <names variable=\"editor\" delimiter=\", \" prefix=\"advisor = {\" suffix=\"}\">\n                    <name delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n                </names>\n            </if>\n            <else>\n               <names variable=\"editor\" delimiter=\", \" prefix=\"editor = {\" suffix=\"}\">\n                   <name delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n               </names>\n            </else>\n        </choose>\n    </macro>\n    <macro name=\"keyword\">\n        <choose>\n            <if type=\"ARTICLE PAPER_CONFERENCE DATASET\" match=\"any\">\n                <text variable=\"keyword\" prefix=\"keywords = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <citation et-al-min=\"11\" et-al-use-first=\"10\" disambiguate-add-year-suffix=\"true\" disambiguate-add-names=\"false\" disambiguate-add-givenname=\"false\" collapse=\"year\">\n        <layout delimiter=\"_\">\n            <text macro=\"citeKey\"/>\n        </layout>\n    </citation>\n    <bibliography hanging-indent=\"false\">\n        <layout>\n            <group display=\"right-inline\">\n                <text macro=\"zotero2bibtexType\" prefix=\"@\"/>\n                <group prefix=\"{\" suffix=\"&#10;}\" delimiter=\",&#10;\">\n                    <text macro=\"citeKey\"/>\n                    <text macro=\"author\" prefix=\"author = {\" suffix=\"}\"/>\n                    <text macro=\"editor\"/>\n                    <text macro=\"title\" prefix=\"title = {\" suffix=\"}\"/>\n                    <text macro=\"issued-year\" prefix=\"year = {\" suffix=\"}\"/>\n                    <text macro=\"issue-date\" prefix=\"issue_date = {\" suffix=\"}\"/>\n                    <text variable=\"ISBN\" prefix=\"isbn = {\" suffix=\"}\"/>\n                    <text variable=\"publisher\" prefix=\"publisher = {\" suffix=\"}\"/>\n                    <text variable=\"publisher-place\" prefix=\"address = {\" suffix=\"}\"/>\n                    <text variable=\"chapter-number\" prefix=\"chapter = {\" suffix=\"}\"/>\n                    <text macro=\"edition\" prefix=\"edition = {\" suffix=\"}\"/>\n                    <text macro=\"volume\"/>\n                    <text variable=\"issue\" prefix=\"number = {\" suffix=\"}\"/>\n                    <text variable=\"ISSN\" prefix=\"issn = {\" suffix=\"}\"/>\n                    <text variable=\"archive_location\" prefix=\"archiveLocation = {\" suffix=\"}\"/>\n                    <text macro=\"URL\"/>\n                    <text macro=\"DOI\"/>\n                    <text macro=\"abstract\" prefix=\"abstract = {\" suffix=\"}\"/>\n                    <text variable=\"note\" prefix=\"note = {\" suffix=\"}\"/>\n                    <text macro=\"container-title\"/>\n                    <text macro=\"issued-month\" prefix=\"month = {\" suffix=\"}\"/>\n                    <text macro=\"pages\"/>\n                    <text macro=\"keyword\"/>\n                    <text variable=\"event-place\" prefix=\"location = {\" suffix=\"}\"/>\n                    <choose>\n                        <if type=\"PAPER_CONFERENCE\" match=\"any\">\n                            <text variable=\"collection-title\" prefix=\"series = {\" suffix=\"}\"/>\n                        </if>\n                        <else>\n                            <text variable=\"collection-title\" prefix=\"collection = {\" suffix=\"}\"/>\n                        </else>\n                    </choose>\n                </group>\n            </group>\n        </layout>\n    </bibliography>\n</style>\n",
    "suffix": "bib",
    "locale": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<locale xmlns=\"http://purl.org/net/xbiblio/csl\" version=\"1.0\" xml:lang=\"en-US\">\n  <info>\n    <rights license=\"http://creativecommons.org/licenses/by-sa/3.0/\">This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 License</rights>\n    <updated>2012-07-04T23:31:02+00:00</updated>\n  </info>\n  <style-options punctuation-in-quote=\"true\"\n                 leading-noise-words=\"a,an,the\"\n                 name-as-sort-order=\"ja zh kr my hu vi\"\n                 name-never-short=\"ja zh kr my hu vi\"/>\n  <date form=\"text\">\n    <date-part name=\"month\" suffix=\" \"/>\n    <date-part name=\"day\" suffix=\", \"/>\n    <date-part name=\"year\"/>\n  </date>\n  <date form=\"numeric\">\n    <date-part name=\"month\" form=\"numeric-leading-zeros\" suffix=\"/\"/>\n    <date-part name=\"day\" form=\"numeric-leading-zeros\" suffix=\"/\"/>\n    <date-part name=\"year\"/>\n  </date>\n  <terms>\n    <term name=\"radio-broadcast\">radio broadcast</term>\n    <term name=\"television-broadcast\">television broadcast</term>\n    <term name=\"podcast\">podcast</term>\n    <term name=\"instant-message\">instant message</term>\n    <term name=\"email\">email</term>\n    <term name=\"number-of-volumes\">\n      <single>volume</single>\n      <multiple>volumes</multiple>\n    </term>\n    <term name=\"accessed\">accessed</term>\n    <term name=\"and\">and</term>\n    <term name=\"and\" form=\"symbol\">&amp;</term>\n    <term name=\"and others\">and others</term>\n    <term name=\"anonymous\">anonymous</term>\n    <term name=\"anonymous\" form=\"short\">anon.</term>\n    <term name=\"at\">at</term>\n    <term name=\"available at\">available at</term>\n    <term name=\"by\">by</term>\n    <term name=\"circa\">circa</term>\n    <term name=\"circa\" form=\"short\">c.</term>\n    <term name=\"cited\">cited</term>\n    <term name=\"edition\">\n      <single>edition</single>\n      <multiple>editions</multiple>\n    </term>\n    <term name=\"edition\" form=\"short\">ed.</term>\n    <term name=\"et-al\">et al.</term>\n    <term name=\"forthcoming\">forthcoming</term>\n    <term name=\"from\">from</term>\n    <term name=\"ibid\">ibid.</term>\n    <term name=\"in\">in</term>\n    <term name=\"in press\">in press</term>\n    <term name=\"internet\">internet</term>\n    <term name=\"interview\">interview</term>\n    <term name=\"letter\">letter</term>\n    <term name=\"no date\">no date</term>\n    <term name=\"no date\" form=\"short\">n.d.</term>\n    <term name=\"online\">online</term>\n    <term name=\"presented at\">presented at the</term>\n    <term name=\"reference\">\n      <single>reference</single>\n      <multiple>references</multiple>\n    </term>\n    <term name=\"reference\" form=\"short\">\n      <single>ref.</single>\n      <multiple>refs.</multiple>\n    </term>\n    <term name=\"retrieved\">retrieved</term>\n    <term name=\"scale\">scale</term>\n    <term name=\"version\">version</term>\n\n    <!-- ANNO DOMINI; BEFORE CHRIST -->\n    <term name=\"ad\">AD</term>\n    <term name=\"bc\">BC</term>\n\n    <!-- PUNCTUATION -->\n    <term name=\"open-quote\">“</term>\n    <term name=\"close-quote\">”</term>\n    <term name=\"open-inner-quote\">‘</term>\n    <term name=\"close-inner-quote\">’</term>\n    <term name=\"page-range-delimiter\">–</term>\n\n    <!-- ORDINALS -->\n    <term name=\"ordinal\">th</term>\n    <term name=\"ordinal-01\">st</term>\n    <term name=\"ordinal-02\">nd</term>\n    <term name=\"ordinal-03\">rd</term>\n    <term name=\"ordinal-11\">th</term>\n    <term name=\"ordinal-12\">th</term>\n    <term name=\"ordinal-13\">th</term>\n\n    <!-- LONG ORDINALS -->\n    <term name=\"long-ordinal-01\">first</term>\n    <term name=\"long-ordinal-02\">second</term>\n    <term name=\"long-ordinal-03\">third</term>\n    <term name=\"long-ordinal-04\">fourth</term>\n    <term name=\"long-ordinal-05\">fifth</term>\n    <term name=\"long-ordinal-06\">sixth</term>\n    <term name=\"long-ordinal-07\">seventh</term>\n    <term name=\"long-ordinal-08\">eighth</term>\n    <term name=\"long-ordinal-09\">ninth</term>\n    <term name=\"long-ordinal-10\">tenth</term>\n\n    <!-- LONG LOCATOR FORMS -->\n    <term name=\"book\">\n      <single>book</single>\n      <multiple>books</multiple>\n    </term>\n    <term name=\"chapter\">\n      <single>chapter</single>\n      <multiple>chapters</multiple>\n    </term>\n    <term name=\"column\">\n      <single>column</single>\n      <multiple>columns</multiple>\n    </term>\n    <term name=\"figure\">\n      <single>figure</single>\n      <multiple>figures</multiple>\n    </term>\n    <term name=\"folio\">\n      <single>folio</single>\n      <multiple>folios</multiple>\n    </term>\n    <term name=\"issue\">\n      <single>number</single>\n      <multiple>numbers</multiple>\n    </term>\n    <term name=\"line\">\n      <single>line</single>\n      <multiple>lines</multiple>\n    </term>\n    <term name=\"note\">\n      <single>note</single>\n      <multiple>notes</multiple>\n    </term>\n    <term name=\"opus\">\n      <single>opus</single>\n      <multiple>opera</multiple>\n    </term>\n    <term name=\"page\">\n      <single>page</single>\n      <multiple>pages</multiple>\n    </term>\n    <term name=\"paragraph\">\n      <single>paragraph</single>\n      <multiple>paragraph</multiple>\n    </term>\n    <term name=\"part\">\n      <single>part</single>\n      <multiple>parts</multiple>\n    </term>\n    <term name=\"section\">\n      <single>section</single>\n      <multiple>sections</multiple>\n    </term>\n    <term name=\"sub verbo\">\n      <single>sub verbo</single>\n      <multiple>sub verbis</multiple>\n    </term>\n    <term name=\"verse\">\n      <single>verse</single>\n      <multiple>verses</multiple>\n    </term>\n    <term name=\"volume\">\n      <single>volume</single>\n      <multiple>volumes</multiple>\n    </term>\n\n    <!-- SHORT LOCATOR FORMS -->\n    <term name=\"book\" form=\"short\">bk.</term>\n    <term name=\"chapter\" form=\"short\">chap.</term>\n    <term name=\"column\" form=\"short\">col.</term>\n    <term name=\"figure\" form=\"short\">fig.</term>\n    <term name=\"folio\" form=\"short\">f.</term>\n    <term name=\"issue\" form=\"short\">no.</term>\n    <term name=\"line\" form=\"short\">l.</term>\n    <term name=\"note\" form=\"short\">n.</term>\n    <term name=\"opus\" form=\"short\">op.</term>\n    <term name=\"page\" form=\"short\">\n      <single>p.</single>\n      <multiple>pp.</multiple>\n    </term>\n    <term name=\"paragraph\" form=\"short\">para.</term>\n    <term name=\"part\" form=\"short\">pt.</term>\n    <term name=\"section\" form=\"short\">sec.</term>\n    <term name=\"sub verbo\" form=\"short\">\n      <single>s.v.</single>\n      <multiple>s.vv.</multiple>\n    </term>\n    <term name=\"verse\" form=\"short\">\n      <single>v.</single>\n      <multiple>vv.</multiple>\n    </term>\n    <term name=\"volume\" form=\"short\">\n      <single>vol.</single>\n      <multiple>vols.</multiple>\n    </term>\n\n    <!-- SYMBOL LOCATOR FORMS -->\n    <term name=\"paragraph\" form=\"symbol\">\n      <single>¶</single>\n      <multiple>¶¶</multiple>\n    </term>\n    <term name=\"section\" form=\"symbol\">\n      <single>§</single>\n      <multiple>§§</multiple>\n    </term>\n\n    <!-- LONG ROLE FORMS -->\n    <term name=\"director\">\n      <single>director</single>\n      <multiple>directors</multiple>\n    </term>\n    <term name=\"editor\">\n      <single>editor</single>\n      <multiple>editors</multiple>\n    </term>\n    <term name=\"editorial-director\">\n      <single>editor</single>\n      <multiple>editors</multiple>\n    </term>\n    <term name=\"illustrator\">\n      <single>illustrator</single>\n      <multiple>illustrators</multiple>\n    </term>\n    <term name=\"translator\">\n      <single>translator</single>\n      <multiple>translators</multiple>\n    </term>\n    <term name=\"editortranslator\">\n      <single>editor &amp; translator</single>\n      <multiple>editors &amp; translators</multiple>\n    </term>\n\n    <!-- SHORT ROLE FORMS -->\n    <term name=\"director\" form=\"short\">\n      <single>dir.</single>\n      <multiple>dirs.</multiple>\n    </term>\n    <term name=\"editor\" form=\"short\">\n      <single>ed.</single>\n      <multiple>eds.</multiple>\n    </term>\n    <term name=\"editorial-director\" form=\"short\">\n      <single>ed.</single>\n      <multiple>eds.</multiple>\n    </term>\n    <term name=\"illustrator\" form=\"short\">\n      <single>ill.</single>\n      <multiple>ills.</multiple>\n    </term>\n    <term name=\"translator\" form=\"short\">\n      <single>tran.</single>\n      <multiple>trans.</multiple>\n    </term>\n    <term name=\"editortranslator\" form=\"short\">\n      <single>ed. &amp; tran.</single>\n      <multiple>eds. &amp; trans.</multiple>\n    </term>\n\n    <!-- VERB ROLE FORMS -->\n    <term name=\"director\" form=\"verb\">directed by</term>\n    <term name=\"editor\" form=\"verb\">edited by</term>\n    <term name=\"editorial-director\" form=\"verb\">edited by</term>\n    <term name=\"illustrator\" form=\"verb\">illustrated by</term>\n    <term name=\"interviewer\" form=\"verb\">interview by</term>\n    <term name=\"recipient\" form=\"verb\">to</term>\n    <term name=\"reviewed-author\" form=\"verb\">by</term>\n    <term name=\"translator\" form=\"verb\">translated by</term>\n    <term name=\"editortranslator\" form=\"verb\">edited &amp; translated by</term>\n\n    <!-- SHORT VERB ROLE FORMS -->\n    <term name=\"container-author\" form=\"verb-short\">by</term>\n    <term name=\"director\" form=\"verb-short\">dir.</term>\n    <term name=\"editor\" form=\"verb-short\">ed.</term>\n    <term name=\"editorial-director\" form=\"verb-short\">ed.</term>\n    <term name=\"illustrator\" form=\"verb-short\">illus.</term>\n    <term name=\"translator\" form=\"verb-short\">trans.</term>\n    <term name=\"editortranslator\" form=\"verb-short\">ed. &amp; trans.</term>\n\n    <!-- LONG MONTH FORMS -->\n    <term name=\"month-01\">January</term>\n    <term name=\"month-02\">February</term>\n    <term name=\"month-03\">March</term>\n    <term name=\"month-04\">April</term>\n    <term name=\"month-05\">May</term>\n    <term name=\"month-06\">June</term>\n    <term name=\"month-07\">July</term>\n    <term name=\"month-08\">August</term>\n    <term name=\"month-09\">September</term>\n    <term name=\"month-10\">October</term>\n    <term name=\"month-11\">November</term>\n    <term name=\"month-12\">December</term>\n\n    <!-- SHORT MONTH FORMS -->\n    <term name=\"month-01\" form=\"short\">Jan.</term>\n    <term name=\"month-02\" form=\"short\">Feb.</term>\n    <term name=\"month-03\" form=\"short\">Mar.</term>\n    <term name=\"month-04\" form=\"short\">Apr.</term>\n    <term name=\"month-05\" form=\"short\">May</term>\n    <term name=\"month-06\" form=\"short\">Jun.</term>\n    <term name=\"month-07\" form=\"short\">Jul.</term>\n    <term name=\"month-08\" form=\"short\">Aug.</term>\n    <term name=\"month-09\" form=\"short\">Sep.</term>\n    <term name=\"month-10\" form=\"short\">Oct.</term>\n    <term name=\"month-11\" form=\"short\">Nov.</term>\n    <term name=\"month-12\" form=\"short\">Dec.</term>\n\n    <!-- SEASONS -->\n    <term name=\"season-01\">Spring</term>\n    <term name=\"season-02\">Summer</term>\n    <term name=\"season-03\">Autumn</term>\n    <term name=\"season-04\">Winter</term>\n  </terms>\n</locale>\n",
    "contentType": "Application/x-bibtex",
    "items": [
        {
            "10.1145/3209914.3234637": {
                "id": "10.1145/3209914.3234637",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Hua",
                        "given": "Zhao"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            4,
                            27
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            4,
                            27
                        ]
                    ]
                },
                "abstract": "With the rapid development of Internet and the communication technology, the construction of smart tourism is no longer a slogan that can not be realized. The construction of smart tourism in tourist destinations conforms to the strategic goal of tourism industry development in China. Based on the background of big data, this paper elaborated the connotation of big data and smart tourism, and built a large data platform to realize the forecast and feedback of smart tourism through the analysis of tourism development. The platform could be divided into government tourism platform, tourists platform, tourism enterprises platform and community residents platform relying on big data do their own duty. Eventually this paper put forward a construction model and path to realize the smart tourism platform.",
                "call-number": "10.1145/3209914.3234637",
                "collection-title": "ICISS '18",
                "container-title": "Proceedings of the 2018 International Conference on Information Science and System",
                "DOI": "10.1145/3209914.3234637",
                "event-place": "Jeju, Republic of Korea",
                "ISBN": "9781450364218",
                "keyword": "management model, smart tourism, Big data",
                "number-of-pages": "5",
                "page": "102–106",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A Study on the Management Model of Smart Tourism Industry under the Era of Big Data",
                "URL": "https://doi.org/10.1145/3209914.3234637"
            }
        },
        {
            "10.1145/3374749": {
                "id": "10.1145/3374749",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Tian",
                        "given": "Zhihong"
                    },
                    {
                        "family": "Luo",
                        "given": "Chaochao"
                    },
                    {
                        "family": "Lu",
                        "given": "Hui"
                    },
                    {
                        "family": "Su",
                        "given": "Shen"
                    },
                    {
                        "family": "Sun",
                        "given": "Yanbin"
                    },
                    {
                        "family": "Zhang",
                        "given": "Man"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            9,
                            25
                        ]
                    ]
                },
                "abstract": "Recently, the urban network infrastructure has undergone a rapid expansion that is increasingly generating a large quantity of data and transforming our cities into smart cities. However, serious security problems arise with this development with more and more smart devices collecting private information under smart city scenario. In this article, we investigate the task of detecting insiders’ anomalous behaviors to prevent urban big data leakage. Specifically, we characterize a user's daily activities from four perspectives and use several deep learning algorithms (long short-term memory (LSTM) and convolutional LSTM (convLSTM)) to calculate deviations between realistic actions and normalcy of daily behaviors and use multilayer perceptron (MLP) to identify abnormal behaviors according to those deviations. To evaluate the proposed multimodel-based system (MBS), we conducted experiments on the CERT (United States Computer Emergency Readiness Team) dataset. The experimental results show that our proposed MBS has a remarkable ability to learn the normal pattern of users’ daily activities and detect anomalous behaviors.",
                "call-number": "10.1145/3374749",
                "collection-number": "16",
                "container-title": "ACM/IMS Trans. Data Sci.",
                "DOI": "10.1145/3374749",
                "ISSN": "2691-1922",
                "issue": "3",
                "keyword": "deep learning, UEBA, anomaly detection, security",
                "number": "Article 16",
                "number-of-pages": "19",
                "page": "1–19",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "August 2020",
                "title": "User and Entity Behavior Analysis under Urban Big Data",
                "URL": "https://doi.org/10.1145/3374749",
                "volume": "1"
            }
        },
        {
            "10.1145/3449052": {
                "id": "10.1145/3449052",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Aljawarneh",
                        "given": "Shadi"
                    },
                    {
                        "family": "Lara",
                        "given": "Juan A."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            5,
                            6
                        ]
                    ]
                },
                "call-number": "10.1145/3449052",
                "collection-number": "6",
                "container-title": "J. Data and Information Quality",
                "DOI": "10.1145/3449052",
                "ISSN": "1936-1955",
                "issue": "2",
                "keyword": "quality management, big data, Quality assessment",
                "number": "Article 6",
                "number-of-pages": "3",
                "page": "1–3",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "June 2021",
                "title": "Editorial: Special Issue on Quality Assessment and Management in Big Data—Part I",
                "URL": "https://doi.org/10.1145/3449052",
                "volume": "13"
            }
        },
        {
            "10.1145/3449056": {
                "id": "10.1145/3449056",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Aljawarneh",
                        "given": "Shadi"
                    },
                    {
                        "family": "Lara",
                        "given": "Juan A."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            5,
                            6
                        ]
                    ]
                },
                "call-number": "10.1145/3449056",
                "collection-number": "13",
                "container-title": "J. Data and Information Quality",
                "DOI": "10.1145/3449056",
                "ISSN": "1936-1955",
                "issue": "3",
                "keyword": "Quality assessment, quality management, big data",
                "number": "Article 13",
                "number-of-pages": "3",
                "page": "1–3",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "September 2021",
                "title": "Editorial: Special Issue on Quality Assessment and Management in Big Data—Part II",
                "URL": "https://doi.org/10.1145/3449056",
                "volume": "13"
            }
        },
        {
            "10.1145/2537148.2537159": {
                "id": "10.1145/2537148.2537159",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Soran",
                        "given": "Ahmet"
                    },
                    {
                        "family": "Akdemir",
                        "given": "Furkan Mustafa"
                    },
                    {
                        "family": "Yuksel",
                        "given": "Murat"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            12,
                            9
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            12,
                            9
                        ]
                    ]
                },
                "abstract": "Over the last several years, the deployment of multi-core routers has grown rapidly. However, big data transfers are not leveraging the powerful multi-core routers to the extent possible, particularly in the key function of routing. Our main goal is to find a way to use these cores more effectively and efficiently in routing the big data transfers. We propose a novel approach to parallelize data transfers by using each core in the routers to calculate a separate shortest path. For each core, we generate a different \"substrate\" topology in order to allow shortest path calculations to find a different end-to-end (e2e) path. By abstracting a different topology for each core, we indirectly steer each core to calculate a different e2e path in parallel to each other. The e2e big data transfers can use these shortest paths obtained from each substrate topology to increase the total throughput. We present an initial evaluation of the concept.",
                "call-number": "10.1145/2537148.2537159",
                "collection-title": "CoNEXT Student Workhop '13",
                "container-title": "Proceedings of the 2013 workshop on Student workhop",
                "DOI": "10.1145/2537148.2537159",
                "event-place": "Santa Barbara, California, USA",
                "ISBN": "9781450325752",
                "keyword": "multi-path routing, load balancing, multi-core routers",
                "number-of-pages": "4",
                "page": "35–38",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Parallel routing on multi-core routers for big data transfers",
                "URL": "https://doi.org/10.1145/2537148.2537159"
            }
        },
        {
            "10.1145/3006299.3006320": {
                "id": "10.1145/3006299.3006320",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Cavallo",
                        "given": "Marco"
                    },
                    {
                        "family": "Polito",
                        "given": "Carmelo"
                    },
                    {
                        "family": "Modica",
                        "given": "Giuseppe Di"
                    },
                    {
                        "family": "Tomarchio",
                        "given": "Orazio"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            12,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            12,
                            6
                        ]
                    ]
                },
                "abstract": "Big data analysis requires adequate infrastructure and programming paradigms capable of processing large amount of data. Hadoop, the most known open-source implementation of the MapReduce paradigm, is widely employed in big data analysis frameworks. However, in many recent application scenarios data are natively distributed over different geographic regions in data centers which are inter-connected through network links with very lower bandwidth than those of the computing environments where traditionally Hadoop deployments are supposed to work. In such a context, Hadoop applications perform very poorly. To cope with these issues, we developed a Hierarchical Hadoop Framework (H2F) specifically designed to work on geodistributed data. In this work, we compare the performance of H2F with that of a plain Hadoop implementation. First results show that for very large amount of data the H2F solution performs better than the Hadoop.",
                "call-number": "10.1145/3006299.3006320",
                "collection-title": "BDCAT '16",
                "container-title": "Proceedings of the 3rd IEEE/ACM International Conference on Big Data Computing, Applications and Technologies",
                "DOI": "10.1145/3006299.3006320",
                "event-place": "Shanghai, China",
                "ISBN": "9781450346177",
                "keyword": "geographical computing environment, application profiling, mapreduce, hierarchical hadoop, big data",
                "number-of-pages": "9",
                "page": "27–35",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "H2F: a hierarchical hadoop framework for big data processing in geo-distributed environments",
                "URL": "https://doi.org/10.1145/3006299.3006320"
            }
        },
        {
            "10.5555/2693848.2693981": {
                "id": "10.5555/2693848.2693981",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "He",
                        "given": "Miao"
                    },
                    {
                        "family": "Ji",
                        "given": "Hao"
                    },
                    {
                        "family": "Wang",
                        "given": "Qinhua"
                    },
                    {
                        "family": "Ren",
                        "given": "Changrui"
                    },
                    {
                        "family": "Lougee",
                        "given": "Robin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            12,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            12,
                            7
                        ]
                    ]
                },
                "abstract": "Supplier risks jeopardize on-time or complete delivery of supply in a supply chain. Traditionally, a company can merely do an ex-post evaluation of a supplier's performance, and handles emergencies in a reactive rather than a proactive way. We propose an agile process management framework to monitor and manage supply risks. The innovation is two fold - Firstly, a business process is established to make sure that the right data, the right insights, and the right decision-makers are in place at the right time. Secondly, we install a big data analytics component, a simulation component and an optimization component into the business process. The big data analytics component senses and predicts supply disruptions with internally (operational) and external (environmental) data. The simulation component supports risk evaluation to convert predicted risk severity to key performance indices (KPIs) such as cost and stockout percentage. The optimization component assists the risk-hedging decision-making.",
                "call-number": "10.5555/2693848.2693981",
                "collection-title": "WSC '14",
                "container-title": "Proceedings of the 2014 Winter Simulation Conference",
                "event-place": "Savannah, Georgia",
                "number-of-pages": "9",
                "page": "1005–1013",
                "publisher": "IEEE Press",
                "title": "Big data fueled process management of supply risks: sensing, prediction, evaluation and mitigation"
            }
        },
        {
            "10.14778/2994509.2994519": {
                "id": "10.14778/2994509.2994519",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Liu",
                        "given": "Hai"
                    },
                    {
                        "family": "Xiao",
                        "given": "Dongqing"
                    },
                    {
                        "family": "Didwania",
                        "given": "Pankaj"
                    },
                    {
                        "family": "Eltabakh",
                        "given": "Mohamed Y."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            8,
                            1
                        ]
                    ]
                },
                "abstract": "Big data infrastructures are increasingly supporting datasets that are relatively structured. These datasets are full of correlations among their attributes, which if managed in systematic ways would enable optimization opportunities that otherwise will be missed. Unlike relational databases in which discovering and exploiting the correlations in query optimization have been extensively studied, in big data infrastructures, such important data properties and their utilization have been mostly abandoned. The key reason is that domain experts may know many correlations but with a degree of uncertainty (fuzziness or softness). Since the data is big, it is very challenging to validate such correlations, judge their worthiness, and put strategies for utilizing them in query optimization. Existing techniques for exploiting soft correlations in RDBMSs, e.g., BHUNT, CORDS, and CM, are heavily tailored towards optimizing factors inherent in relational databases, e.g., predicate selectivity and random I/O accesses of secondary indexes, which are issues not applicable to big data infrastructures, e.g., Hadoop.In this paper, we propose the EXORD system to fill in this gap by exploiting the data's correlations in big data query optimization. EXORD supports two types of correlations; hard correlations---which are guaranteed to hold for all data records, and soft correlations---which are expected to hold for most, but not all, data records. We introduce a new three-phase approach for (1) Validating and judging the worthiness of soft correlations, (2) Selecting and preparing the soft correlations for deployment by specially handling the violating data records, and (3) Deploying and exploiting the correlations in query optimization. We propose a novel cost-benefit model for adaptively selecting the most beneficial soft correlations w.r.t a given query workload while minimizing the introduced overhead. We show the complexity of this problem (NP-Hard), and propose a heuristic to efficiently solve it in a polynomial time. EXORD can be integrated with various state-of-art big data query optimization techniques, e.g., indexing and partitioning. EXORD prototype is implemented as an extension to the Hive engine on top of Hadoop. The experimental evaluation shows the potential of EXORD in achieving more than 10x speedup while introducing minimal storage overheads.",
                "call-number": "10.14778/2994509.2994519",
                "container-title": "Proc. VLDB Endow.",
                "DOI": "10.14778/2994509.2994519",
                "ISSN": "2150-8097",
                "issue": "12",
                "number-of-pages": "12",
                "page": "1005–1016",
                "publisher": "VLDB Endowment",
                "source": "August 2016",
                "title": "Exploiting soft and hard correlations in big data query optimization",
                "URL": "https://doi.org/10.14778/2994509.2994519",
                "volume": "9"
            }
        },
        {
            "10.1145/2910896.2925435": {
                "id": "10.1145/2910896.2925435",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Wang",
                        "given": "Wei"
                    },
                    {
                        "family": "Liu",
                        "given": "Jiaying"
                    },
                    {
                        "family": "Yu",
                        "given": "Shuo"
                    },
                    {
                        "family": "Zhang",
                        "given": "Chenxin"
                    },
                    {
                        "family": "Xu",
                        "given": "Zhenzhen"
                    },
                    {
                        "family": "Xia",
                        "given": "Feng"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            6,
                            19
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            6,
                            19
                        ]
                    ]
                },
                "abstract": "Mining advisor-advisee relationships can benefit many interesting applications such as advisor recommendation and protege performance analysis. Based on the hypothesis that, advisor-advisee relationships among researchers are hidden in scholarly big data, we propose in this work a deep learning based advisor-advisee relationship identification method which considers the personal properties and network characteristics with a stacked autoencoder model. To the best of our knowledge, this is the first time that a deep learning model is utilized to represent coauthor network features for relationships identification. Moreover, experiments demonstrate that the proposed method has better performance compared with other state-of-the-art methods.",
                "call-number": "10.1145/2910896.2925435",
                "collection-title": "JCDL '16",
                "container-title": "Proceedings of the 16th ACM/IEEE-CS on Joint Conference on Digital Libraries",
                "DOI": "10.1145/2910896.2925435",
                "event-place": "Newark, New Jersey, USA",
                "ISBN": "9781450342292",
                "keyword": "deep learning, stacked autoencoders, relationship mining",
                "number-of-pages": "2",
                "page": "209–210",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Mining Advisor-Advisee Relationships in Scholarly Big Data: A Deep Learning Approach",
                "URL": "https://doi.org/10.1145/2910896.2925435"
            }
        },
        {
            "10.1145/3301551.3301610": {
                "id": "10.1145/3301551.3301610",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Yonghong"
                    },
                    {
                        "family": "Zhang",
                        "given": "Shuwen"
                    },
                    {
                        "family": "Jia",
                        "given": "Nan"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            12,
                            29
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            12,
                            29
                        ]
                    ]
                },
                "abstract": "With the emergence of a new generation of information technology, big data has become an important driving force for current social development. Digitalization has become the main direction of the transformation and upgrading of traditional industries. As the product of current informatization, big data includes data quantity, data quality and data analysis ability. It is used as two different ways to interpret the value creation of big data, making it clear that it can promote the transformation and upgrading of traditional industries through value creation. Then, it puts forward the traditional industrial transformation and upgrading path from the perspective of big data, namely the linear path of \"traditional industry + digital\" and the transitional non-linear \"digital + traditional industry\". Its path selection will be analyzed by combining external and internal factors.",
                "call-number": "10.1145/3301551.3301610",
                "collection-title": "ICIT 2018",
                "container-title": "Proceedings of the 6th International Conference on Information Technology: IoT and Smart City",
                "DOI": "10.1145/3301551.3301610",
                "event-place": "Hong Kong, Hong Kong",
                "ISBN": "9781450366298",
                "keyword": "Transformation and upgrading, Big data, The path, Traditional industries",
                "number-of-pages": "6",
                "page": "54–59",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on the Transformation and Upgrading Path and Selection of Traditional Industries from the Perspective of Big Data",
                "URL": "https://doi.org/10.1145/3301551.3301610"
            }
        },
        {
            "10.1145/3404649.3404656": {
                "id": "10.1145/3404649.3404656",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yao",
                        "given": "Xiaolin"
                    },
                    {
                        "family": "Wei",
                        "given": "Qi"
                    },
                    {
                        "family": "Zhang",
                        "given": "Qisong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            6,
                            5
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            6,
                            5
                        ]
                    ]
                },
                "abstract": "The fast development of a new generation of information technology represented by artificial intelligence has brought a far-reaching impact to the financial management activities in enterprises. In the future, big data, artificial intelligence and robot process automation will be widely applied, these promoted the transformation of traditional financial management into intelligent financial management [1]. How to meet the demand of financial management transformation in the big data era is an important issue that all universities and colleges should consider. By integrating OBE educational concept and CDIO engineering education mode, this paper reforms the curriculum system and teaching contents of financial management major of undergraduate education in order to improve students' ability of big data analysis. With the help of school-enterprise cooperation resources and technological advantages, the undergraduate education can cultivate compound and intelligent financial management talents to meet the needs of enterprises in the era of big data",
                "call-number": "10.1145/3404649.3404656",
                "collection-title": "ICEBT '20",
                "container-title": "Proceedings of the 2020 4th International Conference on E-Education, E-Business and E-Technology",
                "DOI": "10.1145/3404649.3404656",
                "event-place": "Shanghai, China",
                "ISBN": "9781450387781",
                "keyword": "OBE-CDIO Mode, Robot Process Automation, Big data, Artificial Intelligence",
                "number-of-pages": "7",
                "page": "43–49",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Innovation of Undergraduate Education Mode of the Financial Management Major in Big Data Era",
                "URL": "https://doi.org/10.1145/3404649.3404656"
            }
        },
        {
            "10.1145/3230744.3230753": {
                "id": "10.1145/3230744.3230753",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Prophet",
                        "given": "Jane"
                    },
                    {
                        "family": "Kow",
                        "given": "Yong Ming"
                    },
                    {
                        "family": "Hurry",
                        "given": "Mark"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            8,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            8,
                            12
                        ]
                    ]
                },
                "abstract": "Our prototype app, Pocket Penjing, built using Unity3D, takes its name from the Chinese \"Penjing.\" These tray plantings of miniature trees pre-date bonsai, often including miniature benches or figures to allude to people's relationship to the tree. App users choose a species, then create and name their tree. Swiping rotates a 3D globe showing flagged locations. Each flag represents a live online air quality monitoring station data stream that the app can scrape. Data is pulled in from the selected station and the AR window loads. The AR tree grows in real-time 3D. Its L-Systems form is determined by the selected live air quality data. We used this prototype as the basis of a two-part formative participatory design workshop with 63 participants.",
                "call-number": "10.1145/3230744.3230753",
                "collection-number": "16",
                "collection-title": "SIGGRAPH '18",
                "container-title": "ACM SIGGRAPH 2018 Posters",
                "DOI": "10.1145/3230744.3230753",
                "event-place": "Vancouver, British Columbia, Canada",
                "ISBN": "9781450358170",
                "keyword": "augmented reality, polyaesthetics, gamification",
                "number": "Article 16",
                "number-of-pages": "2",
                "page": "1–2",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Small trees, big data: augmented reality model of air quality data via the chinese art of \"artificial\" tray planting",
                "URL": "https://doi.org/10.1145/3230744.3230753"
            }
        },
        {
            "10.1145/3539781.3539795": {
                "id": "10.1145/3539781.3539795",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Satheesan",
                        "given": "Sandeep Puthanveetil"
                    },
                    {
                        "family": "Bhavya"
                    },
                    {
                        "family": "Davies",
                        "given": "Adam"
                    },
                    {
                        "family": "Craig",
                        "given": "Alan B."
                    },
                    {
                        "family": "Zhang",
                        "given": "Yu"
                    },
                    {
                        "family": "Zhai",
                        "given": "ChengXiang"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            6,
                            27
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            6,
                            27
                        ]
                    ]
                },
                "abstract": "The availability and generation of digitized newspaper collections have provided researchers in several domains with a powerful tool to advance their research. More specifically, digitized historical newspapers give us a magnifying glass into the past. In this paper, we propose a scalable and customizable big data analysis system that enables researchers to study complex questions about our society as depicted in news media for the past few centuries by applying cutting-edge text analysis tools to large historical newspaper collections. We discuss our experience with building a preliminary version of such a system, including how we have addressed the following challenges: processing millions of digitized newspaper pages from various publications worldwide, which amount to hundreds of terabytes of data; applying article segmentation and Optical Character Recognition (OCR) to historical newspapers, which vary between and within publications over time; retrieving relevant information to answer research questions from such data collections by applying human-in-the-loop machine learning; and enabling users to analyze topic evolution and semantic dynamics with multiple compatible analysis operators. We also present some preliminary results of using the proposed system to study the social construction of juvenile delinquency in the United States and discuss important remaining challenges to be tackled in the future.",
                "call-number": "10.1145/3539781.3539795",
                "collection-number": "12",
                "collection-title": "PASC '22",
                "container-title": "Proceedings of the Platform for Advanced Scientific Computing Conference",
                "DOI": "10.1145/3539781.3539795",
                "event-place": "Basel, Switzerland",
                "ISBN": "9781450394109",
                "keyword": "data visualization, juvenile delinquency, historical newspapers, image analysis, social construction, social science research, big data analysis system, natural language processing, text analysis, information retrieval, newspaper article segmentation",
                "number": "Article 12",
                "number-of-pages": "11",
                "page": "1–11",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Toward a big data analysis system for historical newspaper collections research",
                "URL": "https://doi.org/10.1145/3539781.3539795"
            }
        },
        {
            "10.1145/1077501.1077503": {
                "id": "10.1145/1077501.1077503",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Garcia-Molina",
                        "given": "Hector"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2005,
                            6,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2005,
                            6,
                            17
                        ]
                    ]
                },
                "abstract": "Entity resolution (ER) is a problem that arises in many information integration scenarios: We have two or more sources containing records on the same set of real-world entities (e.g., customers).However, there are no unique identifiers that tell us what records from one source correspond to those in the other sources.Furthermore, the records representing the same entity may have differing information, e.g., one record may have the address misspelled, another record may be missing some fields.An ER algorithm attempts to identify the matching records from multiple sources (i.e., those corresponding to the same real-world entity), and merges the matching records as best it can.In many ER applications the input data has data quality or uncertainty values associated with it. Furthermore, the ER process itself introduces additional uncertainties, e.g., we may only be 90% confident that two given records actually correspond to the same real-world entity.In this talk Hector Garcia-Molina will discuss the challenges in representing quality/uncertainty/confidences in a way that is useful for the ER process.He will also present some preliminary ideas on how to perform ER with uncertain data. (This work is joint with Omar Benjelloun, David Menestrina, Qi Su, and Jennifer Widom).",
                "call-number": "10.1145/1077501.1077503",
                "collection-title": "IQIS '05",
                "container-title": "Proceedings of the 2nd international workshop on Information quality in information systems",
                "DOI": "10.1145/1077501.1077503",
                "event-place": "Baltimore, Maryland",
                "ISBN": "1595931600",
                "number-of-pages": "1",
                "page": "1",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Handling data quality in entity resolution",
                "URL": "https://doi.org/10.1145/1077501.1077503"
            }
        },
        {
            "10.1145/3453187.3453341": {
                "id": "10.1145/3453187.3453341",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chen",
                        "given": "Sisi"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            12,
                            5
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            12,
                            5
                        ]
                    ]
                },
                "abstract": "Nowadays, the industry of network live broadcasting platform is developing rapidly, which attracts people's attention. And in the network live broadcast, live with goods or network anchor recommended goods and other behavior has been common. Especially after the epidemic, through the network live marketing, has become an important means to promote economic recovery. However, the level of product quality in live network broadcasting is not uniform, and the problem that consumers' rights and interests cannot be protected is gradually revealed. Therefore, this paper discusses the role of e-commerce law based on big data on live network. In the discussion, this paper first analyzes the e-commerce law to clarify the applicability of the e-commerce law in the live network; secondly, through the investigation of the network anchor and fans, analyzes the business behavior in the network live broadcast; finally, analyzes the role of the e-commerce law based on big data on the network live broadcast. The results show that the e-commerce law based on big data has a good regulatory effect on webcast, which can promote the healthy development of webcast.",
                "call-number": "10.1145/3453187.3453341",
                "collection-title": "EBIMCS 2020",
                "container-title": "Proceedings of the 2020 3rd International Conference on E-Business, Information Management and Computer Science",
                "DOI": "10.1145/3453187.3453341",
                "event-place": "Wuhan, China",
                "ISBN": "9781450389099",
                "keyword": "E-Commerce Law, Big Data, Live Streaming, Live Sales",
                "number-of-pages": "4",
                "page": "234–237",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Analysis of the Role of E-Commerce Law Based on Big Data on Live Network",
                "URL": "https://doi.org/10.1145/3453187.3453341"
            }
        },
        {
            "10.1145/3349567.3351720": {
                "id": "10.1145/3349567.3351720",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhan",
                        "given": "Jinyu"
                    },
                    {
                        "family": "Li",
                        "given": "Ying"
                    },
                    {
                        "family": "Jiang",
                        "given": "Wei"
                    },
                    {
                        "family": "Wu",
                        "given": "Junting"
                    },
                    {
                        "family": "Zhu",
                        "given": "Jianping"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            13
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            13
                        ]
                    ]
                },
                "abstract": "In this paper we approach to accelerate the data processing of storage and computing separated big data systems. We propose an improved Network Interface Card with Query Filter (NIC-QF), implemented by FPGA on storage nodes, to accelerate the data queries, which can also reduce the workload and communication overhead on computing nodes. NIC-QF is designed with query filtering accelerator and Network Interface Card (NIC) communicator, which can filter the original data on storage nodes as an implicit coprocessor and directly send the filtered data to computing nodes of big data systems. Filter units in NIC-QF can perform multiple SQL tasks in parallel, and each filter unit is internally pipelined, which can further speed up the data processing. Experiments with two benchmarks demonstrate the efficiency of our approach, which can achieve average up to 65.56% faster than the traditional approach.",
                "call-number": "10.1145/3349567.3351720",
                "collection-number": "19",
                "collection-title": "CODES/ISSS '19",
                "container-title": "Proceedings of the International Conference on Hardware/Software Codesign and System Synthesis Companion",
                "DOI": "10.1145/3349567.3351720",
                "event-place": "New York, New York",
                "ISBN": "9781450369237",
                "keyword": "network interface card, storage and computing separated big data systems, query filter, FPGA",
                "number": "Article 19",
                "number-of-pages": "2",
                "page": "1–2",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "An improved network interface card with query filter for big data systems: work-in-progress",
                "URL": "https://doi.org/10.1145/3349567.3351720"
            }
        },
        {
            "10.1145/3352411.3352417": {
                "id": "10.1145/3352411.3352417",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yahya",
                        "given": "Farashazillah"
                    },
                    {
                        "family": "Fazli",
                        "given": "Bashirah Mohd"
                    },
                    {
                        "family": "Abdullah",
                        "given": "Mohd Fikri"
                    },
                    {
                        "family": "Zulkifli",
                        "given": "Harlisa"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            7,
                            19
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            7,
                            19
                        ]
                    ]
                },
                "abstract": "With the rise of heterogeneous large spatial and non-spatial data, systems are developed to manage these data sets. Big data emphasizes heterogeneity among systems leading to data integration issues due to the nature of big data which includes volume, variety and velocity. MyLake is a National Lake Database to manage information and knowledge sharing on lakes in Malaysia. At the moment, data are uploaded by each agency using MyLake as a platform. Nevertheless, this is carried out manually and require timely human effort. Each agency does one-to-one data integration (in-silo) where the integration is developed according to the agency-specific needs resulting from a possibility of integration issue across agencies. Therefore, this paper introduces a big data integration approach that extends the MyLake repository. The big data integration platform is a preliminary idea of how data can be shared, integrated, retrieved, and disseminated within a reliable and authenticated environment. The proposed centralized platform consisting of a set of standards, tools, repository and registry that enable multiple integrations between different agencies. The platform offers the potential to provide a reliable platform that acts as data retriever and disseminator.",
                "call-number": "10.1145/3352411.3352417",
                "collection-title": "DSIT 2019",
                "container-title": "Proceedings of the 2019 2nd International Conference on Data Science and Information Technology",
                "DOI": "10.1145/3352411.3352417",
                "event-place": "Seoul, Republic of Korea",
                "ISBN": "9781450371414",
                "keyword": "Database, Big Data, Lake, Big Data Integration, National Lake, Data Integration",
                "number-of-pages": "6",
                "page": "30–35",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Extending the National Lake Database of Malaysia (MyLake) as a Central Data Exchange using Big Data Integration",
                "URL": "https://doi.org/10.1145/3352411.3352417"
            }
        },
        {
            "10.1145/3484622.3484626": {
                "id": "10.1145/3484622.3484626",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Doulkeridis",
                        "given": "Christos"
                    },
                    {
                        "family": "Vlachou",
                        "given": "Akrivi"
                    },
                    {
                        "family": "Pelekis",
                        "given": "Nikos"
                    },
                    {
                        "family": "Theodoridis",
                        "given": "Yannis"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            8,
                            31
                        ]
                    ]
                },
                "abstract": "In the current era of big spatial data, the vast amount of produced mobility data (by sensors, GPS-equipped devices, surveillance networks, radars, etc.) poses new challenges related to mobility analytics. A cornerstone facilitator for performing mobility analytics at scale is the availability of big data processing frameworks and techniques tailored for spatial and spatio-temporal data. Motivated by this pressing need, in this paper, we provide a survey of big data processing frameworks for mobility analytics. Particular focus is put on the underlying techniques; indexing, partitioning, query processing are essential for enabling efficient and scalable data management. In this way, this report serves as a useful guide of state-of-the-art methods and modern techniques for scalable mobility data management and analytics.",
                "call-number": "10.1145/3484622.3484626",
                "container-title": "SIGMOD Rec.",
                "DOI": "10.1145/3484622.3484626",
                "ISSN": "0163-5808",
                "issue": "2",
                "number-of-pages": "12",
                "page": "18–29",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "June 2021",
                "title": "A Survey on Big Data Processing Frameworks for Mobility Analytics",
                "URL": "https://doi.org/10.1145/3484622.3484626",
                "volume": "50"
            }
        },
        {
            "10.5555/3021955.3021960": {
                "id": "10.5555/3021955.3021960",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Paiva",
                        "given": "Eduardo"
                    },
                    {
                        "family": "Revoredo",
                        "given": "Kate"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            5,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            5,
                            17
                        ]
                    ]
                },
                "abstract": "Nowadays all government entity must maintain transparency portals that shows the all revenue and expenditure carried out daily. However, the mere availability of such information in government portals does not ensure an effective increase in the degree of transparency of these entities, because the large volume of data combined with the lack of standards makes it impossible any systematic monitoring of such data. This paper suggests the application of parallel programming techniques based on mapreduce programming paradigm to the identification of a predetermined set of products purchased by the Public Administration. It also proposes a way to consolidate this information to make easy viewing of disparities found in the large volume of data presented. The proposed solution was tested in a case study performed in the Transparency Portal of the Federal Government. The results suggest that the presented techniques constitute a promising approach to issues related to transparency areas, which normally handles large volumes of data, but it does not always provide quality information.",
                "call-number": "10.5555/3021955.3021960",
                "collection-title": "SBSI 2016",
                "container-title": "Proceedings of the XII Brazilian Symposium on Information Systems on Brazilian Symposium on Information Systems: Information Systems in the Cloud Computing Era - Volume 1",
                "event-place": "Florianopolis, Santa Catarina, Brazil",
                "ISBN": "9788576693178",
                "keyword": "text mining, Public transparency, Big data",
                "number-of-pages": "8",
                "page": "25–32",
                "publisher": "Brazilian Computer Society",
                "publisher-place": "Porto Alegre, BRA",
                "title": "Big Data and Transparency: Using MapReduce functions to increase Public Expenditure transparency"
            }
        },
        {
            "10.1145/3460179.3460180": {
                "id": "10.1145/3460179.3460180",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Dai",
                        "given": "Yibo"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            2,
                            25
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            2,
                            25
                        ]
                    ]
                },
                "abstract": "In order to accurately estimate the sports injury risk of athletes during sports training, this paper divides the sports injury risk into three levels, designs the sports injury estimation index, selects RBF neural network as the model framework, and uses big data analysis technology to construct the sports injury estimation model. Bayesian model and Lagrange model are selected as the control group to test the accuracy and efficiency of this model in sports injury estimation. The test results show that compared with other models, this model can improve the accuracy and efficiency of sports injury estimation significantly, and can be used as a sports injury estimation tool.",
                "call-number": "10.1145/3460179.3460180",
                "collection-title": "ICIIT '21",
                "container-title": "2021 6th International Conference on Intelligent Information Technology",
                "DOI": "10.1145/3460179.3460180",
                "event-place": "Ho Chi Minh, Viet Nam",
                "ISBN": "9781450388948",
                "keyword": "sports injury, big data analysis technology, RBF neural network, estimation model",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on the Design of Sports Injury Estimation Model based on Big Data",
                "URL": "https://doi.org/10.1145/3460179.3460180"
            }
        },
        {
            "10.1145/3373086": {
                "id": "10.1145/3373086",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Guo",
                        "given": "Yuan"
                    },
                    {
                        "family": "Sun",
                        "given": "Yu"
                    },
                    {
                        "family": "Wu",
                        "given": "Kai"
                    },
                    {
                        "family": "Jiang",
                        "given": "Kerong"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            2,
                            18
                        ]
                    ]
                },
                "abstract": "Under big data, the integrated system of case-based reasoning and Bayesian network has exhibited great advantage in implementing the intelligence of engineering application in many domains. To further improve the performance of the hybrid system, this article proposes Probability Change Measurement of Solution Parameters (PCMSP)–Half-Division-Cross (HDC) method, which includes two algorithms, namely PCMSP and HDC algorithm. PCMSP algorithm can select principal problem features according to their effects upon all solution features measured by calculating the weighted relative probability (RP) change of all solution features caused by each problem feature. PCMSP algorithm can perfectly work under big data no matter how complex the data types are and how huge the data size is. HDC algorithm is used to assign the computation task of big data to enhance the efficiency of the integrated system. HDC algorithm assigns big data by grouping all the problem parameters into many small sub-groups and then distributing the data which covers the same sub-group of problem parameters to a slave node. HDC algorithm can guarantee enough efficiency of the integrated system under big data no matter how large the number of problem parameters is. Finally, lots of experiments are executed to validate the proposed method.",
                "call-number": "10.1145/3373086",
                "collection-number": "23",
                "container-title": "ACM Trans. Knowl. Discov. Data",
                "DOI": "10.1145/3373086",
                "ISSN": "1556-4681",
                "issue": "2",
                "keyword": "big data, CBR, integrated system, Feature selection",
                "number": "Article 23",
                "number-of-pages": "20",
                "page": "1–20",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "April 2020",
                "title": "New Algorithms of Feature Selection and Big Data Assignment for CBR System Integrated by Bayesian Network",
                "URL": "https://doi.org/10.1145/3373086",
                "volume": "14"
            }
        },
        {
            "10.1145/3507485.3507494": {
                "id": "10.1145/3507485.3507494",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "LYU",
                        "given": "Xiaoyong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            12,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            12,
                            3
                        ]
                    ]
                },
                "abstract": "With the rapid development of Internet technology, the collection and application of user data is becoming more and more of a concern for Internet companies. At the same time, enterprises have gained extremely high revenue due to the application of big data technology. The field of e-commerce is greatly influenced by the rapid development of big data technology. E-commerce enterprises can reform and innovate their business models based on their own platform advantages and with the power of big data technology in order to promote the good development of e-commerce enterprises. Therefore, the innovation of business models is first briefly introduced in this paper. Then, the important value of the application of big data to the innovation of business models of e-commerce enterprises is analyzed. Finally, the innovation path of the business model of e-commerce enterprises influenced by big data is presented.",
                "call-number": "10.1145/3507485.3507494",
                "collection-title": "ICSEB 2021",
                "container-title": "2021 5th International Conference on Software and e-Business (ICSEB)",
                "DOI": "10.1145/3507485.3507494",
                "event-place": "Osaka, Japan",
                "ISBN": "9781450385831",
                "keyword": "E-Commerce Companies, Innovation, Business Models, Big Data",
                "number-of-pages": "4",
                "page": "51–54",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on the Innovation Path of Business Model of E-Commerce Enterprises Affected by Big Data",
                "URL": "https://doi.org/10.1145/3507485.3507494"
            }
        },
        {
            "10.1145/2479787.2479806": {
                "id": "10.1145/2479787.2479806",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Hu",
                        "given": "Yuh-Jong"
                    },
                    {
                        "family": "Cheng",
                        "given": "Kua-Ping"
                    },
                    {
                        "family": "Huang",
                        "given": "Ya-Ling"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            12
                        ]
                    ]
                },
                "abstract": "Structured big data of Personal Identifiable Information (PII) are acquired from everywhere and stored as microdata in a statistical database. Given a statistical disclosure control method, big data analysis and protection are enacted for outsourcing data sources. We flexibly glean the data utility to achieve effective data-driven decision-making. However, we still comply with the privacy protection principles while applying data analysis. In this paper, we propose three types of semantics-enabled policies for controlling access, handling data, and releasing data to craft a balance between data utility and protection. Structured big data are tagged with semantic metadata to enable semantics-enabled policy's direct processing and interpretation. Finally, we demonstrate how to craft a balance between data utility and protection with these types of semantics-enabled policies, combined with various statistical disclosure control methods.",
                "call-number": "10.1145/2479787.2479806",
                "collection-number": "18",
                "collection-title": "WIMS '13",
                "container-title": "Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics",
                "DOI": "10.1145/2479787.2479806",
                "event-place": "Madrid, Spain",
                "ISBN": "9781450318501",
                "keyword": "semantic data cloud, data utility, data protection, world wide web, statistical disclosure control, big data, semantics-enabled policy",
                "number": "Article 18",
                "number-of-pages": "12",
                "page": "1–12",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Crafting a balance between big data utility and protection in the semantic data cloud",
                "URL": "https://doi.org/10.1145/2479787.2479806"
            }
        },
        {
            "10.1145/2632168.2638835": {
                "id": "10.1145/2632168.2638835",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Xu",
                        "given": "Guoqing"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            7,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            7,
                            22
                        ]
                    ]
                },
                "abstract": "Modern computing has entered the era of Big Data. Analyzing data from Twitter, Google, Facebook, Wikipedia, or the Human Genome Project requires the development of scalable platforms that can quickly extract useful information from an ocean of records collected from customers, clinical trial participants, program execution logs, or the Internet. Most of the existing Big Data applications, including Hadoop, Giraph, Hive, Pig, Mahout, or Hyracks are written managed, object-oriented languages such as Java. While the use of such languages simplifies development tasks, the (memory and execution) inefficiencies inherent in these languages can have large impact on the application performance and scalability. When object-orientation meets Big Data, performance problems are significantly magnified, making data-intensive computing systems fail to scale to large datasets. I will talk about several projects we are currently working on to scale Big Data applications by reducing the cost of a managed runtime. Particularly, I will talk about Facade, a compiler and runtime system we have developed to transform a Big Data application into an almost object-bounded application which has been shown to be much more efficient and scale to much larger datasets. I will also briefly mention two other projects, one attempting to provide a memory-oblivious programming model for developers to allow them to write a program without worrying about how to create threads and use memory, and second aiming to trim a big dataset with probabilistic guarantees to facilitate debugging/testing of a Big Data application.",
                "call-number": "10.1145/2632168.2638835",
                "collection-title": "WODA+PERTEA 2014",
                "container-title": "Proceedings of the 2014 Joint International Workshop on Dynamic Analysis (WODA) and Software and System Performance Testing, Debugging, and Analytics (PERTEA)",
                "DOI": "10.1145/2632168.2638835",
                "event-place": "San Jose, CA, USA",
                "ISBN": "9781450329347",
                "keyword": "Highly Scalable Big Data Application, System Support",
                "number-of-pages": "1",
                "page": "13",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Language, compiler, and runtime system support towards highly scalable big data application (invited talk abstract)",
                "URL": "https://doi.org/10.1145/2632168.2638835"
            }
        },
        {
            "10.1145/2851613.2852015": {
                "id": "10.1145/2851613.2852015",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Ahmad",
                        "given": "Awais"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            4,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            4,
                            4
                        ]
                    ]
                },
                "abstract": "As we delve deeper into the Internet of Things (IoT), we are observing the intensive interaction and heterogeneous communication among different social objects over the Internet. Such knowledge gives us the concept of Social Internet of Things (SIoT). SIoT comprises billions of interconnected objects that generate massive volume of heterogeneous, multisource, dynamic, and sparse data, which lead a system towards a major computational challenges, such as processing, analyzing, and storing data in an efficient manner. To address this problem, we propose a system architecture for processing a stream of Big Data with the enhanced features of parallel processing techniques. The proposed architecture consists of three functional domains, i.e., object domain, SIoT server domain, and application domain. The performance of the system architecture is tested on Hadoop using UBUNTU 14.04 LTS core™i5 machine with 3.2 GHz processor and 4 GB memory. The analysis and discussion show that the performance of the proposed system architecture fulfills the required desires if we increase the size of the datasets.",
                "call-number": "10.1145/2851613.2852015",
                "collection-title": "SAC '16",
                "container-title": "Proceedings of the 31st Annual ACM Symposium on Applied Computing",
                "DOI": "10.1145/2851613.2852015",
                "event-place": "Pisa, Italy",
                "ISBN": "9781450337397",
                "number-of-pages": "2",
                "page": "216–217",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Social element of big data analytics: integrating social network with the internet of things: student research abstract",
                "URL": "https://doi.org/10.1145/2851613.2852015"
            }
        },
        {
            "10.1145/3278229.3278235": {
                "id": "10.1145/3278229.3278235",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Hui"
                    },
                    {
                        "family": "Cheng",
                        "given": "Yibo"
                    },
                    {
                        "family": "Li",
                        "given": "Yinghui"
                    },
                    {
                        "family": "Ma",
                        "given": "Xiaochang"
                    },
                    {
                        "family": "Li",
                        "given": "Delong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            8,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            8,
                            22
                        ]
                    ]
                },
                "abstract": "This paper develops a health management and assessment system named Jinluo Kangbao Health Management System, which is based on big data analysis of meridian potential value. The main purpose is to achieve fast and low-cost diagnosis of disease, and to alleviate problems like unequal distribution of medical resources. The system contains three major modules, the meridian detector, the client software and the central database. During test process, the electrode of meridian detector contacts 24 acupuncture points of the body in particular order, and collects potential value of each acupuncture point. By constructing a calculation matrix, the potential values are corresponded to certain regions of a 24-dimensional space. Within this space, the positions are used to judge the status of the client's health condition, including at low-risk, at medium-risk, at high risk, in subclinical state or in clinical state. The collected data are analyzed by the central database, which also provides reliable medical advice. In this paper, we use Jinluo Kangbao system to check a client. We list the detailed results concerning major aspects of his health condition, and give him relevant medical advice. The output of this system shows high accuracy compared to the results provided by hospital.",
                "call-number": "10.1145/3278229.3278235",
                "collection-title": "ICBIP '18",
                "container-title": "Proceedings of the 3rd International Conference on Biomedical Signal and Image Processing",
                "DOI": "10.1145/3278229.3278235",
                "event-place": "Seoul, Republic of Korea",
                "ISBN": "9781450364362",
                "keyword": "Medical advice, Meridian detector, Big data analysis, Health assessment system, Acupuncture point",
                "number-of-pages": "6",
                "page": "75–80",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Health Assessment System Based on Big Data Analysis of Meridian Electrical Potential",
                "URL": "https://doi.org/10.1145/3278229.3278235"
            }
        },
        {
            "10.1145/3331453.3362042": {
                "id": "10.1145/3331453.3362042",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Lin",
                        "given": "Ching-Lung"
                    },
                    {
                        "family": "Lin",
                        "given": "Huang-Liang"
                    },
                    {
                        "family": "Lin",
                        "given": "Shu-Chi"
                    },
                    {
                        "family": "Liu",
                        "given": "Yung-Te"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            22
                        ]
                    ]
                },
                "abstract": "This paper proposes an elder care system that develops a multi-solution for Taiwan's current Long-Term Care 2.0. The system is designed by using the Internet of Things, Big data, cloud database, application of various sensors, and the integration of the experiences of the Long-Term Care Centers. We find a way to create the maximum effectiveness with the least resources, so that elders in long-term care centers can keep their ability of daily living activities (ADLs) and instrumental activities of daily living (IADLs), and it alleviates internal pressures and costs inside country under the continuing aging society.",
                "call-number": "10.1145/3331453.3362042",
                "collection-number": "18",
                "collection-title": "CSAE 2019",
                "container-title": "Proceedings of the 3rd International Conference on Computer Science and Application Engineering",
                "DOI": "10.1145/3331453.3362042",
                "event-place": "Sanya, China",
                "ISBN": "9781450362948",
                "keyword": "Long Term Healthcare 2.0, Internet of Things, Big Data, Aging country",
                "number": "Article 18",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Long Term Healthcare System for Elders by Using Internet of Things with Big Data",
                "URL": "https://doi.org/10.1145/3331453.3362042"
            }
        },
        {
            "10.1145/3495018.3495345": {
                "id": "10.1145/3495018.3495345",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chen",
                        "given": "Xin"
                    },
                    {
                        "family": "Yang",
                        "given": "Lirong"
                    },
                    {
                        "family": "Sun",
                        "given": "Yanzhi"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            23
                        ]
                    ]
                },
                "abstract": "The era of big data has quietly arrived, which is a revolution that determines the development and future destiny of enterprises. Any enterprises that are not ready for this revolution will be eliminated by the era. This paper mainly studies the construction, analysis and management of human resource system in the era of big data. Based on the actual needs, this paper analyzes the business process and functional requirements of human resource management, completes the system architecture design, function module design, database design, realizes the system function module, and completes the test of the system function. The functional modules realized in this paper include: core personnel management, salary management and comprehensive inquiry. The human resource information system designed in this paper ensures the scientific nature, security, availability and portability of the system, meets the demand of data sharing, and plays a positive role in the whole human resource management cycle.",
                "call-number": "10.1145/3495018.3495345",
                "collection-title": "AIAM2021",
                "container-title": "2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture",
                "DOI": "10.1145/3495018.3495345",
                "event-place": "Manchester, United Kingdom",
                "ISBN": "9781450385046",
                "number-of-pages": "5",
                "page": "1107–1111",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Human Resource Information System Performance Test under Big Data Technology",
                "URL": "https://doi.org/10.1145/3495018.3495345"
            }
        },
        {
            "10.14778/2536360.2536368": {
                "id": "10.14778/2536360.2536368",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Fan",
                        "given": "Wenfei"
                    },
                    {
                        "family": "Geerts",
                        "given": "Floris"
                    },
                    {
                        "family": "Neven",
                        "given": "Frank"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            7,
                            1
                        ]
                    ]
                },
                "abstract": "A query class is traditionally considered tractable if there exists a polynomial-time (PTIME) algorithm to answer its queries. When it comes to big data, however, PTIME algorithms often become infeasible in practice. A traditional and effective approach to coping with this is to preprocess data off-line, so that queries in the class can be subsequently evaluated on the data efficiently. This paper aims to provide a formal foundation for this approach in terms of computational complexity. (1) We propose a set of Π-tractable queries, denoted by ΠTQ0, to characterize classes of queries that can be answered in parallel poly-logarithmic time (NC) after PTIME preprocessing. (2) We show that several natural query classes are Π-tractable and are feasible on big data. (3) We also study a set ΠTQ of query classes that can be effectively converted to Π-tractable queries by refactorizing its data and queries for preprocessing. We introduce a form of NC reductions to characterize such conversions. (4) We show that a natural query class is complete for ΠTQ. (5) We also show that ΠTQ0 ⊂ P unless P = NC, i.e., the set ΠTQ0 of all Π-tractable queries is properly contained in the set P of all PTIME queries. Nonetheless, ΠTQ = P, i.e., all PTIME query classes can be made Π-tractable via proper refactorizations. This work is a step towards understanding the tractability of queries in the context of big data.",
                "call-number": "10.14778/2536360.2536368",
                "container-title": "Proc. VLDB Endow.",
                "DOI": "10.14778/2536360.2536368",
                "ISSN": "2150-8097",
                "issue": "9",
                "number-of-pages": "12",
                "page": "685–696",
                "publisher": "VLDB Endowment",
                "source": "July 2013",
                "title": "Making queries tractable on big data with preprocessing: through the eyes of complexity theory",
                "URL": "https://doi.org/10.14778/2536360.2536368",
                "volume": "6"
            }
        },
        {
            "10.1145/2627770.2627774": {
                "id": "10.1145/2627770.2627774",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Loebman",
                        "given": "Sarah"
                    },
                    {
                        "family": "Ortiz",
                        "given": "Jennifer"
                    },
                    {
                        "family": "Choo",
                        "given": "Lee Lee"
                    },
                    {
                        "family": "Orr",
                        "given": "Laurel"
                    },
                    {
                        "family": "Anderson",
                        "given": "Lauren"
                    },
                    {
                        "family": "Halperin",
                        "given": "Daniel"
                    },
                    {
                        "family": "Balazinska",
                        "given": "Magdalena"
                    },
                    {
                        "family": "Quinn",
                        "given": "Thomas"
                    },
                    {
                        "family": "Governato",
                        "given": "Fabio"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            22
                        ]
                    ]
                },
                "abstract": "We present the motivation, design, implementation, and preliminary evaluation for a service that enables astronomers to study the growth history of galaxies by following their `merger trees' in large-scale astrophysical simulations. The service uses the Myria parallel data management system as back-end and the D3 data visualization library within its graphical front-end. We demonstrate the service at the workshop on a ~5TB dataset.",
                "call-number": "10.1145/2627770.2627774",
                "collection-title": "DanaC'14",
                "container-title": "Proceedings of Workshop on Data analytics in the Cloud",
                "DOI": "10.1145/2627770.2627774",
                "event-place": "Snowbird, UT, USA",
                "ISBN": "9781450329972",
                "keyword": "parallel data management, Myria, astronomy, Cloud service",
                "number-of-pages": "4",
                "page": "1–4",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big-Data Management Use-Case: A Cloud Service for Creating and Analyzing Galactic Merger Trees",
                "URL": "https://doi.org/10.1145/2627770.2627774"
            }
        },
        {
            "10.1145/3459930.3470855": {
                "id": "10.1145/3459930.3470855",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Mohammad",
                        "given": "Umair"
                    },
                    {
                        "family": "Saeed",
                        "given": "Fahad"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            8,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            8,
                            1
                        ]
                    ]
                },
                "abstract": "Making large-scale Mass Spectrometry (MS) data FAIR (Findable, Accessible, Interoperable, Reusable) and democratizing access for the omics research community requires advance access and reuse mechanisms. In this work, we proposed a novel distributed data access infrastructure and developed a simulation test-bed to show the feasibility of this solution. In contrast to existing centralized approaches, participating nodes are relied upon to execute the search algorithm and search based on the comparison of raw spectra is supported as opposed to simple meta-data based searches. Simulation results using networking, stochastic modelling, and queuing theory, illustrated that search times were reduced by up-to 600 times for up-to a total of fifty billion spectra. Proteomics is vital because of the importance proteins to life and their role in state-of-the-art medicine such as custom drug delivery and cancer treatment. MS-based proteomics involves the fragmentation of proteins into peptide ions to generate raw MS spectra. Traditionally, scientists have relied on meta-data based searches of centralized repositories followed by complex database searches and protein sequencing. Though useful, this technique may result in missed datasets because of poor meta-data or sheer amount of effort and computational time needed. Recently, direct raw spectra search has been proposed with the development of centralized tools such as PeptideAtlas. However, PeptideAtlas hosts 13,000 spectra whereas systems supporting billions of spectra are needed. Let us assume users can submit one or more query spectra for search to a central controller. In the proposed novel distributed paradigm, the controller will forward the queries to several nodes hosting a total of multiple MS/MS datasets, where each of the nodes will run the search algorithm against against each spectrum in their local MS/MS dataset, and send the results as URLs/pointers and associated scores back to the controller. The controller will then collate the results and transmit them back to the users. To simulate the system performance, we focused on the distributed process between the controller and the participating nodes. We modeled the the nodes using computational devices present in typical research labs, communication links as the average achievable by combined fiber/Ethernet links, and data loads based on typical storage sizes of spectra and URLs. By running Monte Carlo simulations, we were able to obtain the response time to a single query for various scenarios and assuming an M/M/1 queue, we simulated the time degradation due to multiple requests by compounding over the number of requests with a load degradation factor. Testing results for fifty billion spectra indicated that using 500 distributed nodes can provide search results in 10s and 2000 nodes in 5s, a reduction by 100 and 200 times, respectively, compared to a centralized approach which requires 1000s. Considering typical capabilities of modern day servers and computers, a load factor of 0.001% was tested and indicated that the system provided constant time performance up-to 10k concurrent queries. Lastly, accounting for communication link degradation demonstrated that a trade-off can be achieved between performance and number of nodes. Therefore, it is worth investigating the implementation of a distributed big-data access infrastructure for proteomics.",
                "call-number": "10.1145/3459930.3470855",
                "collection-number": "85",
                "collection-title": "BCB '21",
                "container-title": "Proceedings of the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics",
                "DOI": "10.1145/3459930.3470855",
                "event-place": "Gainesville, Florida",
                "ISBN": "9781450384506",
                "keyword": "proteomics, modelling and simulation, big omics data, distributed infrastructure, spectral search, networked database, mass spectrometry",
                "number": "Article 85",
                "number-of-pages": "1",
                "page": "1",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Search feasibility in distributed MS-proteomics big data",
                "URL": "https://doi.org/10.1145/3459930.3470855"
            }
        },
        {
            "10.1145/1891879.1891881": {
                "id": "10.1145/1891879.1891881",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Blake",
                        "given": "Roger"
                    },
                    {
                        "family": "Mangiameli",
                        "given": "Paul"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2011,
                            2,
                            1
                        ]
                    ]
                },
                "abstract": "Data quality remains a persistent problem in practice and a challenge for research. In this study we focus on the four dimensions of data quality noted as the most important to information consumers, namely accuracy, completeness, consistency, and timeliness. These dimensions are of particular concern for operational systems, and most importantly for data warehouses, which are often used as the primary data source for analyses such as classification, a general type of data mining. However, the definitions and conceptual models of these dimensions have not been collectively considered with respect to data mining in general or classification in particular. Nor have they been considered for problem complexity. Conversely, these four dimensions of data quality have only been indirectly addressed by data mining research. Using definitions and constructs of data quality dimensions, our research evaluates the effects of both data quality and problem complexity on generated data and tests the results in a real-world case. Six different classification outcomes selected from the spectrum of classification algorithms show that data quality and problem complexity have significant main and interaction effects. From the findings of significant effects, the economics of higher data quality are evaluated for a frequent application of classification and illustrated by the real-world case.",
                "call-number": "10.1145/1891879.1891881",
                "collection-number": "8",
                "container-title": "J. Data and Information Quality",
                "DOI": "10.1145/1891879.1891881",
                "ISSN": "1936-1955",
                "issue": "2",
                "keyword": "information quality, data mining, Data quality, data quality metrics and measurements",
                "number": "Article 8",
                "number-of-pages": "28",
                "page": "1–28",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "February 2011",
                "title": "The Effects and Interactions of Data Quality and Problem Complexity on Classification",
                "URL": "https://doi.org/10.1145/1891879.1891881",
                "volume": "2"
            }
        },
        {
            "10.1145/3417188.3417214": {
                "id": "10.1145/3417188.3417214",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Shu",
                        "given": "Wei"
                    },
                    {
                        "family": "Sun",
                        "given": "Fuliang"
                    },
                    {
                        "family": "Li",
                        "given": "Yueen"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            7,
                            10
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            7,
                            10
                        ]
                    ]
                },
                "abstract": "Traditional design methods are inspired by introverted self-salvation or creativity-driven design. In the era of big data, they are gradually driven by vast data. Design innovation without data is increasingly lacking in persuasion. The design of data participation increasingly faces market risks. Moreover, with the progress of artificial intelligence, such a technological innovation will eventually deconstruct the existing field of design innovation, its impact will continue, and it may fundamentally spawn new design ideas and methods.",
                "call-number": "10.1145/3417188.3417214",
                "collection-title": "ICDLT 2020",
                "container-title": "Proceedings of the 2020 4th International Conference on Deep Learning Technologies (ICDLT)",
                "DOI": "10.1145/3417188.3417214",
                "event-place": "Beijing, China",
                "ISBN": "9781450375481",
                "keyword": "big data, design methodology, innovation, Artificial intelligence",
                "number-of-pages": "5",
                "page": "104–108",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The Development Trend of Design Methodology under the Influence of Artificial Intelligence and Big Data",
                "URL": "https://doi.org/10.1145/3417188.3417214"
            }
        },
        {
            "10.1145/3127479.3129248": {
                "id": "10.1145/3127479.3129248",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sikdar",
                        "given": "Sourav"
                    },
                    {
                        "family": "Teymourian",
                        "given": "Kia"
                    },
                    {
                        "family": "Jermaine",
                        "given": "Chris"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            9,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            9,
                            24
                        ]
                    ]
                },
                "abstract": "Many cloud-based data management and analytics systems support complex objects. Dataflow platforms such as Spark and Flink allow programmers to manipulate sets consisting of objects from a host programming language (often Java). Document databases such as MongoDB make use of hierarchical interchange formats---most popularly JSON---which embody a data model where individual records can themselves contain sets of records. Systems such as Dremel and AsterixDB allow complex nesting of data structures.Clearly, no system designer would expect a system that stores JSON objects as text to perform at the same level as a system based upon a custom-built physical data model. The question we ask is: How significant is the performance hit associated with choosing a particular physical implementation? Is the choice going to result in a negligible performance cost, or one that is debilitating? Unfortunately, there does not exist a scientific study of the effect of physical complex model implementation on system performance in the literature. Hence it is difficult for a system designer to fully understand performance implications of such choices. This paper is an attempt to remedy that.",
                "call-number": "10.1145/3127479.3129248",
                "collection-title": "SoCC '17",
                "container-title": "Proceedings of the 2017 Symposium on Cloud Computing",
                "DOI": "10.1145/3127479.3129248",
                "event-place": "Santa Clara, California",
                "ISBN": "9781450350280",
                "keyword": "big data management, experimental comparison, complex objects implementation, data serialization",
                "number-of-pages": "13",
                "page": "432–444",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "An experimental comparison of complex object implementations for big data systems",
                "URL": "https://doi.org/10.1145/3127479.3129248"
            }
        },
        {
            "10.1145/3373376.3380611": {
                "id": "10.1145/3373376.3380611",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kaplan",
                        "given": "Frédéric"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            3,
                            9
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            3,
                            9
                        ]
                    ]
                },
                "abstract": "In 2012, the Ecole Polytechnique Fédérale de Lausanne (EPFL) and the University Ca'Foscari launched a program called the Venice Time Machine, whose goal was to develop a large-scale digitisation program to transform Venice's heritage into 'Big Data of the Past'. Millions of register pages and photographs have been scanned at the State Archive in Venice and at the Fondazione Giorgio Cini. These documents were analysed using the deep-learning artificial-intelligence methods developed at EPFL's Digital Humanities Laboratory in order to extract their textual and iconographic content and to make the data accessible via a search engine. The project has now expand to a European scale, including more than 500 institutions and 20 new cities jointly constructing a distributed digital information system mapping the social, cultural and geographical evolution of Europe. The project build upon existing platforms such as Europeana, and accelerate their development. While Europeana drives transformation throughout the cultural heritage sector with innovative standards, infrastructure and networks, Time Machine aims to design and implement advanced new digitisation and artificial intelligence technologies to mine Europe's vast cultural heritage, providing fair and free access to information that will support future scientific and technological developments in Europe.",
                "call-number": "10.1145/3373376.3380611",
                "collection-title": "ASPLOS '20",
                "container-title": "Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems",
                "DOI": "10.1145/3373376.3380611",
                "event-place": "Lausanne, Switzerland",
                "ISBN": "9781450371025",
                "number-of-pages": "1",
                "page": "1",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data of the Past, from Venice to Europe",
                "URL": "https://doi.org/10.1145/3373376.3380611"
            }
        },
        {
            "10.1145/2818869.2818898": {
                "id": "10.1145/2818869.2818898",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Tang",
                        "given": "Bo"
                    },
                    {
                        "family": "Chen",
                        "given": "Zhen"
                    },
                    {
                        "family": "Hefferman",
                        "given": "Gerald"
                    },
                    {
                        "family": "Wei",
                        "given": "Tao"
                    },
                    {
                        "family": "He",
                        "given": "Haibo"
                    },
                    {
                        "family": "Yang",
                        "given": "Qing"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            7
                        ]
                    ]
                },
                "abstract": "The ubiquitous deployment of various kinds of sensors in smart cities requires a new computing paradigm to support Internet of Things (IoT) services and applications, and big data analysis. Fog Computing, which extends Cloud Computing to the edge of network, fits this need. In this paper, we present a hierarchical distributed Fog Computing architecture to support the integration of massive number of infrastructure components and services in future smart cities. To secure future communities, it is necessary to build large-scale, geospatial sensing networks, perform big data analysis, identify anomalous and hazardous events, and offer optimal responses in real-time. We analyze case studies using a smart pipeline monitoring system based on fiber optic sensors and sequential learning algorithms to detect events threatening pipeline safety. A working prototype was constructed to experimentally evaluate event detection performance of the recognition of 12 distinct events. These experimental results demonstrate the feasibility of the system's city-wide implementation in the future.",
                "call-number": "10.1145/2818869.2818898",
                "collection-number": "28",
                "collection-title": "ASE BD&amp;SI '15",
                "container-title": "Proceedings of the ASE BigData & SocialInformatics 2015",
                "DOI": "10.1145/2818869.2818898",
                "event-place": "Kaohsiung, Taiwan",
                "ISBN": "9781450337359",
                "keyword": "distributed computing architecture, smart city, Fog computing, big data analysis, pipeline safety monitoring",
                "number": "Article 28",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A Hierarchical Distributed Fog Computing Architecture for Big Data Analysis in Smart Cities",
                "URL": "https://doi.org/10.1145/2818869.2818898"
            }
        },
        {
            "10.1145/3416921.3416944": {
                "id": "10.1145/3416921.3416944",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Cuzzocrea",
                        "given": "Alfredo"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            8,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            8,
                            26
                        ]
                    ]
                },
                "abstract": "Nowadays, a great deal of attention is devoted to the relevant problem of supporting big data analytics from social systems (e.g., social networks, smart city applications, skill management platforms, and so forth). Following this innovative trend, the opportunity of adopting advanced OLAP-based tools for supporting the knowledge extraction phase from big social data represents the new frontiers for big social data computing. Indeed, the well-known features of multidimensional data analysis are able to support a \"rich\" extraction of actionable knowledge, beyond actual limitations of alternative procedural approaches. In line with this emerging research challenge, this paper explores benefits, limitations and challenges of OLAP-based big data analytics tools over (big) social data.",
                "call-number": "10.1145/3416921.3416944",
                "collection-title": "ICCBDC '20",
                "container-title": "Proceedings of the 2020 4th International Conference on Cloud and Big Data Computing",
                "DOI": "10.1145/3416921.3416944",
                "event-place": "Virtual, United Kingdom",
                "ISBN": "9781450375382",
                "keyword": "Big social data, Big data analytics, Big social data computing, OLAPing big social data",
                "number-of-pages": "5",
                "page": "15–19",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "OLAPing Big Social Data: Multidimensional Big Data Analytics over Big Social Data Repositories",
                "URL": "https://doi.org/10.1145/3416921.3416944"
            }
        },
        {
            "10.5555/2888619.2888976": {
                "id": "10.5555/2888619.2888976",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Taylor",
                        "given": "Siman J. E."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            12,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            12,
                            6
                        ]
                    ]
                },
                "abstract": "Driven by innovations such as mass customisation, complex supply chains, smart cities and emerging cyber-physical and Internet of Things systems, Big Data is presenting a fascinating range of challenges to Analytics. New fields are emerging such as Big Data Analytics and Data Science. Modeling & Simulation (M&S) is core to Analytics. Arguably, contemporary M&S practices cannot deal with the demands of Big Data. The implication of this is that M&S may not feature in the Big Data Analytics techniques and tools of the future. Based on recent experiences from the i4MS FP7 European Cloud-based Simulation platform for Manufacturing and Engineering (CloudSME) and associated industrial projects, this talk will outline the key challenges that Big Data has to M&S and strongly argue that M&S has to get \"Big\" to meet these challenges. Exciting opportunities lie ahead for multi-disciplinary teams of practitioners and researchers from OR/MS, Computer Science and domain specific fields. Indeed \"Big\" Simulation presents its own possibilities and the talk will conclude with thoughts on the potential for \"Big\" Simulation Analytics to move beyond Big Data into future Dynamic Data Driven Application Systems.",
                "call-number": "10.5555/2888619.2888976",
                "collection-title": "WSC '15",
                "container-title": "Proceedings of the 2015 Winter Simulation Conference",
                "event-place": "Huntington Beach, California",
                "ISBN": "9781467397414",
                "number-of-pages": "1",
                "page": "3085",
                "publisher": "IEEE Press",
                "title": "The impact of big data on M&S: do we need to get \"big\"?"
            }
        },
        {
            "10.1145/3371158.3371161": {
                "id": "10.1145/3371158.3371161",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Maivizhi",
                        "given": "Radhakrishnan"
                    },
                    {
                        "family": "Yogesh",
                        "given": "Palanichamy"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            1,
                            5
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            1,
                            5
                        ]
                    ]
                },
                "abstract": "Wireless sensor networks (WSNs) deployed in a plethora of applications produce a significant portion of big data. Handling these huge volume of data is a critical challenge in a resource constrained wireless sensor networks. Data aggregation is the most practical and important paradigm in big data wireless sensor networks. It reduces the huge volume of data by combining the similar data and eliminating data redundancy and reduces thereby the resource consumption. However preserving data confidentiality and integrity along with en-route aggregation is a great challenge. In this paper, we propose a novel Concealed Multidimensional Data Aggregation (CMDA) protocol for big data wireless sensor networks. CMDA integrates super-increasing sequence and homomorphic encryption to structure the multidimensional data and protect the data privacy and a homomorphic signature to check the integrity of data. In addition, the proposed protocol filters false data packets and achieves data freshness. Security analysis reveals that the proposed protocol achieves end-to-end security and performance evaluation shows that CMDA incurs less communication overhead and consequently reduces energy consumption which enhances the lifetime of sensor networks. To the best of our knowledge, this is the first work that achieves end-to-end security in multidimensional data aggregation.",
                "call-number": "10.1145/3371158.3371161",
                "collection-title": "CoDS COMAD 2020",
                "container-title": "Proceedings of the 7th ACM IKDD CoDS and 25th COMAD",
                "DOI": "10.1145/3371158.3371161",
                "event-place": "Hyderabad, India",
                "ISBN": "9781450377386",
                "keyword": "multidimensional data, wireless sensor networks, privacy homomorphism, concealed data aggregation, energy efficiency",
                "number-of-pages": "9",
                "page": "19–27",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Concealed Multidimensional Data Aggregation in Big Data Wireless Sensor Networks",
                "URL": "https://doi.org/10.1145/3371158.3371161"
            }
        },
        {
            "10.1145/2978570": {
                "id": "10.1145/2978570",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Wu",
                        "given": "Dapeng"
                    },
                    {
                        "family": "Yang",
                        "given": "Boran"
                    },
                    {
                        "family": "Wang",
                        "given": "Honggang"
                    },
                    {
                        "family": "Wang",
                        "given": "Chonggang"
                    },
                    {
                        "family": "Wang",
                        "given": "Ruyan"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            9,
                            15
                        ]
                    ]
                },
                "abstract": "To preserve the privacy of multimedia big data and achieve the efficient data aggregation in wireless multimedia sensor networks (WMSNs), a distributed compressed sensing--based privacy-preserving data aggregation (DCSPDA) approach is proposed in this article. First, in this approach, the original multimedia sensor data are compressed and measured by distributed compressed sensing (DCS) and the compressed data measurements are uploaded to the sink, by which the inherent characteristics between sensor data can be obtained. Second, the original multimedia data are jointly recovered and the common and innovation sparse components are obtained through solving the optimization problem and linear equations at the sink. Third, through least squares support vector machine (LSSVM) learning of the sparse components, the sparse position configuration can be determined and disseminated for each node to conduct the privacy-preserving data configuration. After receiving the configuration message, original multimedia sensor data are accordingly customized, compressed, and measured by the common measurement matrix, aggregated at the cluster heads, and transmitted to the sink. Finally, the aggregated multimedia sensor data are recovered by the sink according to the data configuration to achieve the privacy-preserving data aggregation and transmission. Our comparative simulation results validate the efficiency and scalability of DCSPDA and demonstrate that the proposed approach can effectively reduce the communication overheads and provide reliable privacy-preserving with low computational complexity for WMSNs.",
                "call-number": "10.1145/2978570",
                "collection-number": "60",
                "container-title": "ACM Trans. Multimedia Comput. Commun. Appl.",
                "DOI": "10.1145/2978570",
                "ISSN": "1551-6857",
                "issue": "4s",
                "keyword": "Wireless multimedia sensor networks, data aggregation, distributed compressed sensing, privacy-preserving method",
                "number": "Article 60",
                "number-of-pages": "19",
                "page": "1–19",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "November 2016",
                "title": "Privacy-Preserving Multimedia Big Data Aggregation in Large-Scale Wireless Sensor Networks",
                "URL": "https://doi.org/10.1145/2978570",
                "volume": "12"
            }
        },
        {
            "10.1145/3274572": {
                "id": "10.1145/3274572",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Hourcade",
                        "given": "Juan Pablo"
                    },
                    {
                        "family": "Antle",
                        "given": "Alissa N."
                    },
                    {
                        "family": "Anthony",
                        "given": "Lisa"
                    },
                    {
                        "family": "Fails",
                        "given": "Jerry Alan"
                    },
                    {
                        "family": "Iversen",
                        "given": "Ole Sejer"
                    },
                    {
                        "family": "Rubegni",
                        "given": "Elisa"
                    },
                    {
                        "family": "Skov",
                        "given": "Mikael"
                    },
                    {
                        "family": "Slovak",
                        "given": "Petr"
                    },
                    {
                        "family": "Walsh",
                        "given": "Greg"
                    },
                    {
                        "family": "Zeising",
                        "given": "Anja"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            25
                        ]
                    ]
                },
                "abstract": "In this forum we celebrate research that helps to successfully bring the benefits of computing technologies to children, older adults, people with disabilities, and other populations that are often ignored in the design of mass-marketed products. --- Juan Pablo Hourcade, Editor",
                "call-number": "10.1145/3274572",
                "container-title": "interactions",
                "DOI": "10.1145/3274572",
                "ISSN": "1072-5520",
                "issue": "6",
                "number-of-pages": "4",
                "page": "78–81",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "November - December 2018",
                "title": "Child-computer interaction, ubiquitous technologies, and big data",
                "URL": "https://doi.org/10.1145/3274572",
                "volume": "25"
            }
        },
        {
            "10.1145/3282278.3282282": {
                "id": "10.1145/3282278.3282282",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Casado-Vara",
                        "given": "Roberto"
                    },
                    {
                        "family": "de la Prieta",
                        "given": "Fernando"
                    },
                    {
                        "family": "Prieto",
                        "given": "Javier"
                    },
                    {
                        "family": "Corchado",
                        "given": "Juan M."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            11,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            11,
                            4
                        ]
                    ]
                },
                "abstract": "Smart home presents a challenge in control and monitoring of its wireless sensors networks (WSN) and the internet of things (IoT) devices which form it. The current IoT architectures are centralized, complex, with poor security in its communications and with upstream communication channels mainly. As a result, there are problems with data reliability. These problems include data missing, malicious data inserted, communications network overload, and overload of computing power at the central node. In this paper a new architecture is presented. This architecture based in blockchain introduce the edge computing layer and a new algorithm to improve data quality and false data detection.",
                "call-number": "10.1145/3282278.3282282",
                "collection-title": "BlockSys'18",
                "container-title": "Proceedings of the 1st Workshop on Blockchain-enabled Networked Sensor Systems",
                "DOI": "10.1145/3282278.3282282",
                "event-place": "Shenzhen, China",
                "ISBN": "9781450360500",
                "keyword": "Blockchain, edge computing, non linear control, data quality false data detection, WSN, IoT",
                "number-of-pages": "6",
                "page": "19–24",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Blockchain framework for IoT data quality via edge computing",
                "URL": "https://doi.org/10.1145/3282278.3282282"
            }
        },
        {
            "10.1145/3465631.3465807": {
                "id": "10.1145/3465631.3465807",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Liao",
                        "given": "Wenhao"
                    },
                    {
                        "family": "Ren",
                        "given": "Yumei"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            8,
                            19
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            8,
                            19
                        ]
                    ]
                },
                "abstract": "NOTICE OF RETRACTION: While investigating potential publication-related misconduct in connection with the ICIMTech 2021 Conference Proceedings, serious concerns were raised that cast doubt on the integrity of the peer-review process and all papers published in the Proceedings of this Conference. The integrity of the entire Conference has been called into question. As a result, of its investigation, ACM has decided to retract the Entire Conference Proceedings and all related papers from the ACM Digital Library.None of the papers from this Proceeding should be cited in the literature because of the questionable integrity of the peer review process for this Conference.",
                "call-number": "10.1145/3465631.3465807",
                "collection-number": "137",
                "collection-title": "ICIMTECH 21",
                "container-title": "The Sixth International Conference on Information Management and Technology",
                "DOI": "10.1145/3465631.3465807",
                "event-place": "Jakarta, Indonesia",
                "ISBN": "9781450385015",
                "number": "Article 137",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "New Sports Fitness Space Based on Big Data",
                "URL": "https://doi.org/10.1145/3465631.3465807"
            }
        },
        {
            "10.1145/3037697.3037699": {
                "id": "10.1145/3037697.3037699",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhou",
                        "given": "Jingren"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            4,
                            4
                        ]
                    ]
                },
                "call-number": "10.1145/3037697.3037699",
                "collection-title": "ASPLOS '17",
                "container-title": "Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems",
                "DOI": "10.1145/3037697.3037699",
                "event-place": "Xi&apos;an, China",
                "ISBN": "9781450344654",
                "page": "",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data Analytics and Intelligence at Alibaba Cloud",
                "URL": "https://doi.org/10.1145/3037697.3037699"
            }
        },
        {
            "10.1145/3037699": {
                "id": "10.1145/3037699",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Zhou",
                        "given": "Jingren"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            11
                        ]
                    ]
                },
                "call-number": "10.1145/3037699",
                "container-title": "SIGARCH Comput. Archit. News",
                "DOI": "10.1145/3037699",
                "ISSN": "0163-5964",
                "issue": "1",
                "number-of-pages": "1",
                "page": "",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "March 2017",
                "title": "Big Data Analytics and Intelligence at Alibaba Cloud",
                "URL": "https://doi.org/10.1145/3037699",
                "volume": "45"
            }
        },
        {
            "10.1145/3040934": {
                "id": "10.1145/3040934",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Ji",
                        "given": "Rongrong"
                    },
                    {
                        "family": "Liu",
                        "given": "Wei"
                    },
                    {
                        "family": "Xie",
                        "given": "Xing"
                    },
                    {
                        "family": "Chen",
                        "given": "Yiqiang"
                    },
                    {
                        "family": "Luo",
                        "given": "Jiebo"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            4,
                            14
                        ]
                    ]
                },
                "call-number": "10.1145/3040934",
                "collection-number": "34",
                "container-title": "ACM Trans. Intell. Syst. Technol.",
                "DOI": "10.1145/3040934",
                "ISSN": "2157-6904",
                "issue": "3",
                "number": "Article 34",
                "number-of-pages": "3",
                "page": "1–3",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "May 2017",
                "title": "Mobile Social Multimedia Analytics in the Big Data Era: An Introduction to the Special Issue",
                "URL": "https://doi.org/10.1145/3040934",
                "volume": "8"
            }
        },
        {
            "10.1109/CCGrid.2015.139": {
                "id": "10.1109/CCGrid.2015.139",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Rosà",
                        "given": "Andrea"
                    },
                    {
                        "family": "Chen",
                        "given": "Lydia Y."
                    },
                    {
                        "family": "Binder",
                        "given": "Walter"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            5,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            5,
                            4
                        ]
                    ]
                },
                "abstract": "In large-scale datacenters, software and hardware failures are frequent, resulting in failures of job executions that may cause significant resource waste and performance deterioration. To proactively minimize the resource inefficiency due to job failures, it is important to identify them in advance using key job attributes. However, so far, prevailing research on datacenter workload characterization has overlooked job failures, including their patterns, root causes, and impact. In this paper, we aim to develop prediction models and mitigation policies for unsuccessful jobs, so as to reduce the resource waste in big datacenters. In particular, we base our analysis on Google cluster traces, consisting of a large number of big-data jobs with a high task fanout. We first identify the time-varying patterns of failed jobs and the contributing system features. Based on our characterization study, we develop an on-line predictive model for job failures by applying various statistical learning techniques, namely Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), and Logistic Regression (LR). Furthermore, we propose a delay-based mitigation policy which, after a certain grace period, proactively terminates the execution of jobs that are predicted to fail. The particular objective of postponing job terminations is to strike a good tradeoff between resource waste and false prediction of successful jobs. Our evaluation results show that the proposed method is able to significantly reduce the resource waste by 41.9% on average, and keep false terminations of jobs low, i.e., only 1%.",
                "call-number": "10.1109/CCGrid.2015.139",
                "collection-title": "CCGRID '15",
                "container-title": "Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing",
                "DOI": "10.1109/CCGrid.2015.139",
                "event-place": "Shenzhen, China",
                "ISBN": "9781479980062",
                "number-of-pages": "10",
                "page": "221–230",
                "publisher": "IEEE Press",
                "title": "Predicting and mitigating jobs failures in big data clusters",
                "URL": "https://doi.org/10.1109/CCGrid.2015.139"
            }
        },
        {
            "10.1145/2788516": {
                "id": "10.1145/2788516",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Sachs",
                        "given": "Karen"
                    },
                    {
                        "family": "Chen",
                        "given": "Tiffany"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            7,
                            27
                        ]
                    ]
                },
                "abstract": "Single-cell data creates computational opportunities for discovery in disease and human health.",
                "call-number": "10.1145/2788516",
                "container-title": "XRDS",
                "DOI": "10.1145/2788516",
                "ISSN": "1528-4972",
                "issue": "4",
                "number-of-pages": "6",
                "page": "54–59",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "Summer 2015",
                "title": "Big data comes in tiny packages: single-cell driven science and health",
                "URL": "https://doi.org/10.1145/2788516",
                "volume": "21"
            }
        },
        {
            "10.1145/3349614.3356026": {
                "id": "10.1145/3349614.3356026",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Jiang",
                        "given": "Junchen"
                    },
                    {
                        "family": "Zhou",
                        "given": "Yuhao"
                    },
                    {
                        "family": "Ananthanarayanan",
                        "given": "Ganesh"
                    },
                    {
                        "family": "Shu",
                        "given": "Yuanchao"
                    },
                    {
                        "family": "Chien",
                        "given": "Andrew A."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            7
                        ]
                    ]
                },
                "abstract": "The increasing complexity of deep learning and massive deployment of cameras at the edge have drastically increased the resource demand of edge data analytics. Compared to traditional Internet web applications, such resource demand (in computing, storage and networking) is not limited by millions of human users, but rather the continuous activities of billions of sensors. This paper presents the abstraction of camera cluster as an attempt to address this challenge in the context of video analytics. We envision a novel analytics stack that orchestrates the computing resource of massive networked cameras to enable efficient edge video analytics.",
                "call-number": "10.1145/3349614.3356026",
                "collection-title": "HotEdgeVideo'19",
                "container-title": "Proceedings of the 2019 Workshop on Hot Topics in Video Analytics and Intelligent Edges",
                "DOI": "10.1145/3349614.3356026",
                "event-place": "Los Cabos, Mexico",
                "ISBN": "9781450369282",
                "keyword": "camera cluster, video analytics, edge",
                "number-of-pages": "7",
                "page": "1–7",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Networked Cameras Are the New Big Data Clusters",
                "URL": "https://doi.org/10.1145/3349614.3356026"
            }
        },
        {
            "10.1145/3400934.3400996": {
                "id": "10.1145/3400934.3400996",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Amalia",
                        "given": "Sarah Sholihatul"
                    },
                    {
                        "family": "Sommeng",
                        "given": "Andy Noorsaman"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            6,
                            16
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            6,
                            16
                        ]
                    ]
                },
                "abstract": "Process safety is related to leak prevention, oil spills, monitoring of equipment damage, overpressure, excess temperature, corrosion, metal fatigue, and other similar conditions. Besides, operations are related to productivity and risk management, so it is essential to monitor the process in depth. This paper is focusing on risk management of the downstream segment on the priority element of Process Safety Management (PSM). Based on research, Mechanical Integrity is the most critical element in PSM that have to be focused. The aspect of essential reliability of equipment, in this case, the compressor becomes vital to prevent shutdown/trip and unplanned maintenance, which will have an impact on oil and gas production. Historical failure data and support that include structured and unstructured data from the reciprocating compressor approximately from 2014 until 2019 will be collected. It will use to identify the damage patterns and reliability rates of the equipment. The regression value will be calculated by R as Big Data Analytics Software to determine whether Weibull distribution is sufficient. By using Weibull analysis, we can conclude that it will be more useful to use preventive maintenance as the first barrier from getting fail.",
                "call-number": "10.1145/3400934.3400996",
                "collection-title": "APCORISE 2020",
                "container-title": "Proceedings of the 3rd Asia Pacific Conference on Research in Industrial and Systems Engineering 2020",
                "DOI": "10.1145/3400934.3400996",
                "event-place": "Depok, Indonesia",
                "ISBN": "9781450376006",
                "keyword": "Maintenance, R Software, Reliability, Risk Management, Big Data, Compressor",
                "number-of-pages": "5",
                "page": "339–343",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Process Safety Management (PSM) and Reliability for Compressor Inspection Using Big Data Analytics: A Conceptual Study",
                "URL": "https://doi.org/10.1145/3400934.3400996"
            }
        },
        {
            "10.1145/3490395": {
                "id": "10.1145/3490395",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Guangrui (Kayla)"
                    },
                    {
                        "family": "So",
                        "given": "Mike K. P."
                    },
                    {
                        "family": "Tam",
                        "given": "Kar Yan"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            3,
                            10
                        ]
                    ]
                },
                "abstract": "The prevalence of big data has raised significant epistemological concerns in information systems research. This study addresses two of them—the deflated p-value problem and the role of explanation and prediction. To address the deflated p-value problem, we propose a multivariate effect size method that uses the log-likelihood ratio test. This method measures the joint effect of all variables used to operationalize one factor, thus overcoming the drawback of the traditional effect size method (θ), which can only be applied at the single variable level. However, because factors can be operationalized as different numbers of variables, direct comparison of multivariate effect size is not possible. A quantile-matching method is proposed to address this issue. This method provides consistent comparison results with the classic quantile method. But it is more flexible and can be applied to scenarios where the quantile method fails. Furthermore, an absolute multivariate effect size statistic is developed to facilitate concluding without comparison. We have tested our method using three different datasets and have found that it can effectively differentiate factors with various effect sizes. We have also compared it with prediction analysis and found consistent results: explanatorily influential factors are usually also predictively influential in a large sample scenario.",
                "call-number": "10.1145/3490395",
                "collection-number": "19",
                "container-title": "ACM Trans. Manage. Inf. Syst.",
                "DOI": "10.1145/3490395",
                "ISSN": "2158-656X",
                "issue": "2",
                "keyword": "multivariate effect size, prediction analysis, Big data, deflated p-value, quantile matching",
                "number": "Article 19",
                "number-of-pages": "30",
                "page": "1–30",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "June 2022",
                "title": "Identifying the Big Shots—A Quantile-Matching Way in the Big Data Context",
                "URL": "https://doi.org/10.1145/3490395",
                "volume": "13"
            }
        },
        {
            "10.1145/3286606.3286788": {
                "id": "10.1145/3286606.3286788",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bibri",
                        "given": "Simon Elias"
                    },
                    {
                        "family": "Krogstie",
                        "given": "John"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            10
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            10
                        ]
                    ]
                },
                "abstract": "There has recently been much enthusiasm about the possibilities created by the big data deluge to better understand, monitor, analyze, and plan modern cities to improve their contribution to the goals of sustainable development. Indeed, much of our knowledge of urban sustainability has been gleaned from studies that are characterized by data scarcity. Therefore, this paper endeavors to develop a systematic framework for urban sustainability analytics based on a cross-industry standard process for data mining. The intention is to enable well-informed decision-making and enhanced insights in relation to diverse urban domains. We argue that there is tremendous potential to transform and advance the knowledge of smart sustainable cities through the creation of a big data deluge that seeks to provide much more sophisticated, wider-scale, finer-grained, real-time understanding, and control of various aspects of urbanity in the undoubtedly upcoming Exabyte Age.",
                "call-number": "10.1145/3286606.3286788",
                "collection-number": "11",
                "collection-title": "SCA '18",
                "container-title": "Proceedings of the 3rd International Conference on Smart City Applications",
                "DOI": "10.1145/3286606.3286788",
                "event-place": "Tetouan, Morocco",
                "ISBN": "9781450365628",
                "keyword": "Smart sustainable cities, data mining, big data analytics",
                "number": "Article 11",
                "number-of-pages": "10",
                "page": "1–10",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The Big Data Deluge for Transforming the Knowledge of Smart Sustainable Cities: A Data Mining Framework for Urban Analytics",
                "URL": "https://doi.org/10.1145/3286606.3286788"
            }
        },
        {
            "10.1109/UCC.2014.46": {
                "id": "10.1109/UCC.2014.46",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bellavista",
                        "given": "Paolo"
                    },
                    {
                        "family": "Corradi",
                        "given": "Antonio"
                    },
                    {
                        "family": "Reale",
                        "given": "Andrea"
                    },
                    {
                        "family": "Ticca",
                        "given": "Nicola"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            12,
                            8
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            12,
                            8
                        ]
                    ]
                },
                "abstract": "Distributed Stream Processing Systems (DSPSs) are attracting increasing industrial and academic interest as flexible tools to implement scalable and cost-effective on-line analytics applications over Big Data streams. Often hosted in private/public cloud deployment environments, DSPSs offer data stream processing services that transparently exploit the distributed computing resources made available to them at runtime. Given the volume of data of interest, possible (hard/soft) real-time processing requirements, and the time-variable characteristics of input data streams, it is very important for DSPSs to use smart and innovative scheduling techniques that allocate computing resources properly and avoid static over-provisioning. In this paper, we originally investigate the suitability of exploiting application-level indications about differentiated priorities of different stream processing tasks to enable application-specific DSPS resource scheduling, e.g., Capable of re-shaping processing resources in order to dynamically follow input data peaks of prioritized tasks, with no static over-provisioning. We originally propose a general and simple technique to design and implement priority-based resource scheduling in flow-graph-based DSPSs, by allowing application developers to augment DSPS graphs with priority metadata and by introducing an extensible set of priority schemas to be automatically handled by the extended DSPS. In addition, we show the effectiveness of our approach via its implementation and integration in our Quasit DSPS and through experimental evaluation of this prototype on a real-world stream processing application of Big Data vehicular traffic analysis.",
                "call-number": "10.1109/UCC.2014.46",
                "collection-title": "UCC '14",
                "container-title": "Proceedings of the 2014 IEEE/ACM 7th International Conference on Utility and Cloud Computing",
                "DOI": "10.1109/UCC.2014.46",
                "ISBN": "9781479978816",
                "keyword": "Distributed Stream Processing, Big Data, Cloud Computing Optimization, Application-level and Application-specific Scheduling, Vehicular Traffic Analysis, Priority-based Resource Scheduling",
                "number-of-pages": "8",
                "page": "363–370",
                "publisher": "IEEE Computer Society",
                "publisher-place": "USA",
                "title": "Priority-Based Resource Scheduling in Distributed Stream Processing Systems for Big Data Applications",
                "URL": "https://doi.org/10.1109/UCC.2014.46"
            }
        },
        {
            "10.1145/3510858.3510971": {
                "id": "10.1145/3510858.3510971",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhang",
                        "given": "Guoming"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            12,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            12,
                            18
                        ]
                    ]
                },
                "abstract": "With the rapid development of big data and multimedia communication technology, modern multimedia communication terminal technology has made human life more and more convenient, enabling distance learning, TV program broadcasting, video conferencing, etc. The long-term development of multimedia communication terminal technology must conform to the corresponding system specifications in order to promote the sound development of multimedia communication. This article aims to study the development of multimedia communication terminal technology under big data technology. Taking the representative video conference in multimedia communication terminal technology as an example, combined with echo cancellation algorithms, a video conference system is designed and implemented. Performance was tested. The test results show that the system can meet the basic needs of video conferencing and can provide reliable real-time communication.",
                "call-number": "10.1145/3510858.3510971",
                "collection-title": "ICASIT 2021",
                "container-title": "2021 International Conference on Aviation Safety and Information Technology",
                "DOI": "10.1145/3510858.3510971",
                "event-place": "Changsha, China",
                "ISBN": "9781450390422",
                "number-of-pages": "5",
                "page": "384–388",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Development of Multimedia Communication Terminal Technology under Big Data Technology",
                "URL": "https://doi.org/10.1145/3510858.3510971"
            }
        },
        {
            "10.1145/3473714.3473825": {
                "id": "10.1145/3473714.3473825",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Meng",
                        "given": "Hainie"
                    },
                    {
                        "family": "Cheng",
                        "given": "Yunli"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            6,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            6,
                            18
                        ]
                    ]
                },
                "abstract": "The information education mode supported by emerging technologies such as big data technology, cloud computing, communication and the Internet of Things is called intelligent education. The purpose of promoting intelligent education is to make use of developed countries and emerging technological means to create intelligent, effective and accurate education methods and adopt correct talent training methods based on the results of big data calculation, thus laying a good foundation for the cultivation of high quality technology and technical talents. Intelligent education platform is a new way of education communication which is constantly improved and developed along with the Internet and education digitization and information. On the one hand, it brings students great convenience, but also provides a new way of learning; On the other hand, it also proposes a solution to the phenomenon of \"information overload\" caused by the rapid increment of learning resources. Secondly, students who have no basic knowledge of courses will have more choices in choosing courses and learning paths.",
                "call-number": "10.1145/3473714.3473825",
                "collection-title": "ICCIR 2021",
                "container-title": "Proceedings of the 2021 International Conference on Control and Intelligent Robotics",
                "DOI": "10.1145/3473714.3473825",
                "event-place": "Guangzhou, China",
                "ISBN": "9781450390231",
                "keyword": "Intelligent education system, Big data, collaborative filtering, course recommendation algorithm",
                "number-of-pages": "8",
                "page": "638–645",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on Key Technologies of Intelligent Recommendation Based Online Education Platform in Big Data Environment",
                "URL": "https://doi.org/10.1145/3473714.3473825"
            }
        },
        {
            "10.5555/2814058.2814137": {
                "id": "10.5555/2814058.2814137",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Attorre",
                        "given": "Brunno F. M."
                    },
                    {
                        "family": "Silva",
                        "given": "Leandro A."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            5,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            5,
                            26
                        ]
                    ]
                },
                "abstract": "As the volume of data on the web continue to increase, it is getting more challenging for the search mechanism to find with a high precision rate what the users want to find. As a solution to improve these results, the development of a recommender engine, based on the content of the documents, would prove itself very useful. In this context, this research has the objective to show how the current search and indexing tools could be improved with recommendation, Machine Learning and textual analysis algorithms. The idea behind these project would be to, based on the content of the documents recovered in the search, find similar documents using most of the Open Source technology we have available right now.",
                "call-number": "10.5555/2814058.2814137",
                "collection-title": "SBSI 2015",
                "container-title": "Proceedings of the annual conference on Brazilian Symposium on Information Systems: Information Systems: A Computer Socio-Technical Perspective - Volume 1",
                "event-place": "Goiania, Goias, Brazil",
                "keyword": "Machine Learning Tools, Machine Learning, Index tools, big data",
                "number-of-pages": "6",
                "page": "487–492",
                "publisher": "Brazilian Computer Society",
                "publisher-place": "Porto Alegre, BRA",
                "title": "Open Source Tools Applied to Text Data Recovery in Big Data Environments"
            }
        },
        {
            "10.1145/2663876.2663885": {
                "id": "10.1145/2663876.2663885",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Freudiger",
                        "given": "Julien"
                    },
                    {
                        "family": "Rane",
                        "given": "Shantanu"
                    },
                    {
                        "family": "Brito",
                        "given": "Alejandro E."
                    },
                    {
                        "family": "Uzun",
                        "given": "Ersin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            11,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            11,
                            3
                        ]
                    ]
                },
                "abstract": "In a data-driven economy that struggles to cope with the volume and diversity of information, data quality assessment has become a necessary precursor to data analytics. Real-world data often contains inconsistencies, conflicts and errors. Such dirty data increases processing costs and has a negative impact on analytics. Assessing the quality of a dataset is especially important when a party is considering acquisition of data held by an untrusted entity. In this scenario, it is necessary to consider privacy risks of the stakeholders.This paper examines challenges in privacy-preserving data quality assessment. A two-party scenario is considered, consisting of a client that wishes to test data quality and a server that holds the dataset. Privacy-preserving protocols are presented for testing important data quality metrics: completeness, consistency, uniqueness, timeliness and validity. For semi-honest parties, the protocols ensure that the client does not discover any information about the data other than the value of the quality metric. The server does not discover the parameters of the client's query, the specific attributes being tested and the computed value of the data quality metric. The proposed protocols employ additively homomorphic encryption in conjunction with condensed data representations such as counting hash tables and histograms, serving as efficient alternatives to solutions based on private set intersection.",
                "call-number": "10.1145/2663876.2663885",
                "collection-title": "WISCS '14",
                "container-title": "Proceedings of the 2014 ACM Workshop on Information Sharing & Collaborative Security",
                "DOI": "10.1145/2663876.2663885",
                "event-place": "Scottsdale, Arizona, USA",
                "ISBN": "9781450331517",
                "keyword": "data quality assessment, privacy and confidentiality, cryptographic protocols",
                "number-of-pages": "9",
                "page": "21–29",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Privacy Preserving Data Quality Assessment for High-Fidelity Data Sharing",
                "URL": "https://doi.org/10.1145/2663876.2663885"
            }
        },
        {
            "10.1145/27544.27546": {
                "id": "10.1145/27544.27546",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Ballou",
                        "given": "Donald P."
                    },
                    {
                        "family": "Pazer",
                        "given": "Harold L."
                    },
                    {
                        "family": "Belardo",
                        "given": "Salvatore"
                    },
                    {
                        "family": "Klein",
                        "given": "Barbara"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            1987,
                            3,
                            1
                        ]
                    ]
                },
                "abstract": "This paper examines the impact of deficiencies in data quality on the results generated for spreadsheet applications. The purpose is to describe a framework which can be systematically used to determine the relative importance of potential errors in operational and judgmental data. Special emphasis is placed on analyzing the implications of deficiencies in data quality on projected spreadsheet results.",
                "call-number": "10.1145/27544.27546",
                "container-title": "SIGMIS Database",
                "DOI": "10.1145/27544.27546",
                "ISSN": "0095-0033",
                "issue": "3",
                "number-of-pages": "7",
                "page": "13–19",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "March 1987",
                "title": "Implications of data quality for spreadsheet analysis",
                "URL": "https://doi.org/10.1145/27544.27546",
                "volume": "18"
            }
        },
        {
            "10.1145/1563821.1563874": {
                "id": "10.1145/1563821.1563874",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Jacobs",
                        "given": "Adam"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2009,
                            7,
                            1
                        ]
                    ]
                },
                "abstract": "What is \"big data\" anyway? Gigabytes? Terabytes? Petabytes? A brief personal memory may provide some perspective. In the late 1980s at Columbia University I had the chance to play around with what at the time was a truly enormous \"disk\": the IBM 3850 MSS (Mass Storage System). The MSS was actually a fully automatic robotic tape library and associated staging disks to make random access, if not exactly instantaneous, at least fully transparent. In Columbia’s configuration, it stored a total of around 100 GB. It was already on its way out by the time I got my hands on it, but in its heyday, the early to mid-1980s, it had been used to support access by social scientists to what was unquestionably \"big data\" at the time: the entire 1980 U.S. Census database.",
                "call-number": "10.1145/1563821.1563874",
                "container-title": "Queue",
                "DOI": "10.1145/1563821.1563874",
                "ISSN": "1542-7730",
                "issue": "6",
                "number-of-pages": "10",
                "page": "10–19",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "July 2009",
                "title": "The Pathologies of Big Data: Scale up your datasets enough and all your apps will come undone. What are the typical problems and where do the bottlenecks generally surface?",
                "URL": "https://doi.org/10.1145/1563821.1563874",
                "volume": "7"
            }
        },
        {
            "10.1145/3540200": {
                "id": "10.1145/3540200",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Yin",
                        "given": "Fei"
                    },
                    {
                        "family": "Shi",
                        "given": "Feng"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            5,
                            25
                        ]
                    ]
                },
                "abstract": "For the heterogeneous big data parallel computing model, two levels of parallelism between nodes are not considered, resulting in low efficiency of heterogeneous big data parallel computing and bandwidth to send and receive information, high communication overhead, long model running time and small computational volume. In the paper, we propose an optimization model of heterogeneous big data parallel computing based on a hybrid Multi Point Interface (MPI)/Open Multi-Processing (OpenMP) and Sensor Networks. First, the processor characteristics of heterogeneous big data architecture is analyzed, the parallel tasks among processors are divided, collect the heterogeneous big data to be computed and cluster them, and use the processing results as the input items of the model. Then, a parallel load balancing mechanism is established to optimally divide the parallel computing load of heterogeneous big data, and a parallel computing optimization program is written by combining the hybrid programming mode of MPI and OpenMP and using the hybrid MPI/OpenMP, and finally, the parallel computing optimization of heterogeneous big data is realized by optimizing the parallel communication and determining the model parameters. The results show that the proposed model has a communication bandwidth of 510Mbps, a computational volume of 1.16GB, a model runtime of 24s, and an improved network bandwidth utilization of 93%, which can effectively reduce the communication overhead, and improve the efficiency of parallel computing and bandwidth sending and receiving information in sensor networks, and shorten the model running time.",
                "call-number": "10.1145/3540200",
                "container-title": "ACM Trans. Sen. Netw.",
                "DOI": "10.1145/3540200",
                "ISSN": "1550-4859",
                "keyword": "Machine Learning, Heterogeneous big data, MPI/OpenMP hybrid, Reservoir computing, Sensor Networks, Parallel computing",
                "note": "Just Accepted",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Heterogeneous Big Data Parallel Computing Optimization Model using MPI/OpenMP Hybrid and Sensor Networks",
                "URL": "https://doi.org/10.1145/3540200"
            }
        },
        {
            "10.1109/TCBB.2019.2951555": {
                "id": "10.1109/TCBB.2019.2951555",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Yan",
                        "given": "Lu"
                    },
                    {
                        "family": "Huang",
                        "given": "Weihong"
                    },
                    {
                        "family": "Wang",
                        "given": "Liming"
                    },
                    {
                        "family": "Feng",
                        "given": "Song"
                    },
                    {
                        "family": "Peng",
                        "given": "Yonghong"
                    },
                    {
                        "family": "Peng",
                        "given": "Jie"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            5,
                            1
                        ]
                    ]
                },
                "abstract": "This paper presents a big data analystics platform for clinical research and practice in the Gastroenterology Department of Xiangya Hospital at Central South University in China. This platform features a comprehensive and systematic support of big data in digestive medicine including geneneral health management, clinical gastroenterology practice, and related genomics research, which is proven to be helpful in real world clinical practices. A typical use case of integrated analysis based on electronic medical records and colonoscopy data was presented and discussed, the analaystic report on risk factors of colorectal diseases shows a reasonable recommendation about the age when people should start to screen the colorectal cancer, which could be very useful to individual and group health management for the general population in China.",
                "call-number": "10.1109/TCBB.2019.2951555",
                "container-title": "IEEE/ACM Trans. Comput. Biol. Bioinformatics",
                "DOI": "10.1109/TCBB.2019.2951555",
                "ISSN": "1545-5963",
                "issue": "3",
                "number-of-pages": "10",
                "page": "922–931",
                "publisher": "IEEE Computer Society Press",
                "publisher-place": "Washington, DC, USA",
                "source": "May-June 2021",
                "title": "Data-Enabled Digestive Medicine: A New Big Data Analytics Platform",
                "URL": "https://doi.org/10.1109/TCBB.2019.2951555",
                "volume": "18"
            }
        },
        {
            "10.14778/3352063.3352130": {
                "id": "10.14778/3352063.3352130",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Kandula",
                        "given": "Srikanth"
                    },
                    {
                        "family": "Lee",
                        "given": "Kukjin"
                    },
                    {
                        "family": "Chaudhuri",
                        "given": "Surajit"
                    },
                    {
                        "family": "Friedman",
                        "given": "Marc"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            1
                        ]
                    ]
                },
                "abstract": "With the rapidly growing volume of data, it is more attractive than ever to leverage approximations to answer analytic queries. Sampling is a powerful technique which has been studied extensively from the point of view of facilitating approximation. Yet, there has been no large-scale study of effectiveness of sampling techniques in big data systems. In this paper, we describe an in-depth study of the sampling-based approximation techniques that we have deployed in Microsoft's big data clusters. We explain the choices we made to implement approximation, identify the usage cases, and study detailed data that sheds insight on the usefulness of doing sampling based approximation.",
                "call-number": "10.14778/3352063.3352130",
                "container-title": "Proc. VLDB Endow.",
                "DOI": "10.14778/3352063.3352130",
                "ISSN": "2150-8097",
                "issue": "12",
                "number-of-pages": "12",
                "page": "2131–2142",
                "publisher": "VLDB Endowment",
                "source": "August 2019",
                "title": "Experiences with approximating queries in Microsoft's production big-data clusters",
                "URL": "https://doi.org/10.14778/3352063.3352130",
                "volume": "12"
            }
        },
        {
            "10.1145/1882291.1882293": {
                "id": "10.1145/1882291.1882293",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Eagle",
                        "given": "Nathan"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2010,
                            11,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2010,
                            11,
                            7
                        ]
                    ]
                },
                "abstract": "Petabytes of data about human movements, transactions, and communication patterns are continuously being generated by everyday technologies such as mobile phones and credit cards. In collaboration with the mobile phone, internet, and credit card industries, Eagle and colleagues are aggregating and analyzing behavioral data from over 250 million people from North and South America, Europe, Asia and Africa. Eagle discusses projects arising from these collaborations that involve inferring behavioral dynamics on a broad spectrum of scales from risky behavior in a group of MIT freshman to population-level behavioral signatures, including cholera outbreaks in Rwanda and wealth in the UK. The research group is developing a range of large-scale network analysis and machine learning algorithms that will provide deeper insight into human behavior.",
                "call-number": "10.1145/1882291.1882293",
                "collection-title": "FSE '10",
                "container-title": "Proceedings of the eighteenth ACM SIGSOFT international symposium on Foundations of software engineering",
                "DOI": "10.1145/1882291.1882293",
                "event-place": "Santa Fe, New Mexico, USA",
                "ISBN": "9781605587912",
                "keyword": "behavioral dynamics, network analysis, machine learning, data analysis",
                "number-of-pages": "2",
                "page": "3–4",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data, global development, and complex social systems",
                "URL": "https://doi.org/10.1145/1882291.1882293"
            }
        },
        {
            "10.1145/2382416.2382425": {
                "id": "10.1145/2382416.2382425",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Mell",
                        "given": "Peter"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            10,
                            15
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            10,
                            15
                        ]
                    ]
                },
                "call-number": "10.1145/2382416.2382425",
                "collection-title": "BADGERS '12",
                "container-title": "Proceedings of the 2012 ACM Workshop on Building analysis datasets and gathering experience returns for security",
                "DOI": "10.1145/2382416.2382425",
                "event-place": "Raleigh, North Carolina, USA",
                "ISBN": "9781450316613",
                "number-of-pages": "2",
                "page": "15–16",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data technology and implications for security research",
                "URL": "https://doi.org/10.1145/2382416.2382425"
            }
        },
        {
            "10.1145/3512353.3512376": {
                "id": "10.1145/3512353.3512376",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Ji",
                        "given": "Wenjun"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            1,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            1,
                            14
                        ]
                    ]
                },
                "abstract": "With the continuous development of the world economy, the information communication industry is developing extremely rapidly. Under the condition of the rapid development of the information and communication industry, the information and communication face serious network security problems because the relevant systems and equipment cannot meet the needs of the Internet information development. At the same time, with the continuous development of Internet technology, the current society has entered the era of big data. In the era of big data, information communication and network security have become extremely important. In order to scientifically avoid the security risks of network communication, the article deeply analyzes the communication network hardware equipment, data storage, data communication and communication network system, and proposes the strategy for relevant security management.",
                "call-number": "10.1145/3512353.3512376",
                "collection-title": "APIT 2022",
                "container-title": "2022 4th Asia Pacific Information Technology Conference",
                "DOI": "10.1145/3512353.3512376",
                "event-place": "Virtual Event, Thailand",
                "ISBN": "9781450395571",
                "keyword": "Strategic Analysis and research, Big data area, Network Communication Security",
                "number-of-pages": "5",
                "page": "155–159",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Strategic Analysis and Research of Network Communication Security in the Age of Big Data",
                "URL": "https://doi.org/10.1145/3512353.3512376"
            }
        },
        {
            "10.1145/3167486.3167565": {
                "id": "10.1145/3167486.3167565",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Mohammed",
                        "given": "Zouiten"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            11,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            11,
                            14
                        ]
                    ]
                },
                "abstract": "Two-dimensional arrays of bi-component structures made of cobalt and permalloy elliptical dots with thickness of 25 nm, length 1 m and width of 225 nm, have been prepared by a self-aligned shadow deposition technique. Brillouin light scattering has been exploited to study the frequency dependence of thermally excited magnetic eigenmodes on the intensity of the external magnetic field, applied along the easy axis of the elements. Our work is part of user-centered healthcare decision-making systems based on a process of predicting cancer distribution. This process should lead to a set of knowledge in Datamining, Ontologies and Geographical Information Systems. It is in the same time iterative and interactive. Therefore, it seems essential to take into account principles and methods of Human-Machine Interaction in the development of such systems. In this respect, development of interactive decision-making systems is currently being approached using two opposing approaches. In the first one, technology is fundamental; the second one is user centered placing the human actors in a central position. Although the first approach is still present in healthcare organizations, the current trend is definitely the user centric. In our framework we propose an approach that aims to integrate the steps of the predicting future from data process into a development model enriched from human-machine interactions. Our application context is the fight against breast cancer in hospitals. We demonstrate that medical decision can be based on a spatial analysis of the geographical distribution of many cancers. Several factors explain our choice of datamining for assistance of health decision-makers for learning in the CART algorithm about patients who are future actors of suspicion.",
                "call-number": "10.1145/3167486.3167565",
                "collection-number": "76",
                "collection-title": "ICCWCS'17",
                "container-title": "Proceedings of the 2nd International Conference on Computing and Wireless Communication Systems",
                "DOI": "10.1145/3167486.3167565",
                "event-place": "Larache, Morocco",
                "ISBN": "9781450353069",
                "keyword": "datamining, Redundancy, Machine learning, GIS health, CART",
                "number": "Article 76",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Machine learning algorithms for oncology big data treatment",
                "URL": "https://doi.org/10.1145/3167486.3167565"
            }
        },
        {
            "10.1145/2534921.2534924": {
                "id": "10.1145/2534921.2534924",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chen",
                        "given": "Jiaoyan"
                    },
                    {
                        "family": "Chen",
                        "given": "Huajun"
                    },
                    {
                        "family": "Pan",
                        "given": "Jeff Z."
                    },
                    {
                        "family": "Wu",
                        "given": "Ming"
                    },
                    {
                        "family": "Zhang",
                        "given": "Ningyu"
                    },
                    {
                        "family": "Zheng",
                        "given": "Guozhou"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            11,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            11,
                            4
                        ]
                    ]
                },
                "abstract": "Recently, the appearing disaster of severe smog has been attacking many cities in China such as the capital Beijing. The chief culprit of China smog, namely PM2.5, is affected by various factors including air pollutants, weather, climate, geographical location, urbanization, etc. To analyze the factors, we collect about 35,000,000 air quality records and about 30,000,000 weather records from the sensors in 77 China's cities in 2013. Moreover, two big data sets named Geoname and DBPedia are also combined for the data of climate, geographical location and urbanization. To deal with big spatio-temporal data for big smog analysis, we propose a MapReduce-based framework named BigSmog. It mainly conducts parallel correlation analysis of the factors and scalable training of artificial neural networks for spatio-temporal approximation of the concentration of PM2.5. In the experiments, BigSmog displays high scalability for big smog analysis with big spatio-temporal data. The analysis result shows that the air pollutants influence the short-term concentration of PM2.5 more than the weather and the factors of geographical location and climate rather than urbanization play a major role in determining a city's long-term pollution level of PM2.5. Moreover, the trained ANNs can accurately approximate the concentration of PM2.5.",
                "call-number": "10.1145/2534921.2534924",
                "collection-title": "BigSpatial '13",
                "container-title": "Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Analytics for Big Geospatial Data",
                "DOI": "10.1145/2534921.2534924",
                "event-place": "Orlando, Florida",
                "ISBN": "9781450325349",
                "keyword": "correlation analysis, MapReduce, artificial neural network, PM2.5, China smog, spatio-temporal",
                "number-of-pages": "10",
                "page": "13–22",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "When big data meets big smog: a big spatio-temporal data framework for China severe smog analysis",
                "URL": "https://doi.org/10.1145/2534921.2534924"
            }
        },
        {
            "10.1145/2483574.2483579": {
                "id": "10.1145/2483574.2483579",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Rupprecht",
                        "given": "Lukas"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            23
                        ]
                    ]
                },
                "abstract": "Data processing systems face the task of efficiently storing and processing data at petabyte scale, with the amount set to increase in the future. To meet such a requirement, highly scalable, shared-nothing systems, e.g. Google's BigTable [6] or Facebook's Cassandra [14], are built to partition data and process it in parallel on distributed nodes in a cluster. This allows the handling of data at scale but introduces new challenges due to the distribution of data. Running queries involves a high network overhead because data has to be exchanged between cluster nodes and hence, the network becomes a critical part of the system. To avoid the network bottleneck, it is essential for distributed data processing systems (DDPS) to be aware of the network rather than treating it as a black box.We propose in-network processing as a way of achieving network-awareness to decrease bandwidth usage by custom routing, redundancy elimination, and on-path data reduction. Thereby, we can increase the query throughput of a DDPS. The challenges of an in-network processing system range from design issues, such as performance and transparency, to the integration with query optimisation and deployment in data centres. We formulate these challenges as possible research directions and provide a prototype implementation. Our preliminary results suggest that we can significantly improve query throughput in a DDPS by performing partial data reduction within the network.",
                "call-number": "10.1145/2483574.2483579",
                "collection-title": "SIGMOD'13 PhD Symposium",
                "container-title": "Proceedings of the 2013 SIGMOD/PODS Ph.D. symposium",
                "DOI": "10.1145/2483574.2483579",
                "event-place": "New York, New York, USA",
                "ISBN": "9781450321556",
                "keyword": "nosql, scale-out, date centres, network-awareness",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Exploiting in-network processing for big data management",
                "URL": "https://doi.org/10.1145/2483574.2483579"
            }
        },
        {
            "10.1145/2809793": {
                "id": "10.1145/2809793",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Dopplick",
                        "given": "Renee"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            8,
                            14
                        ]
                    ]
                },
                "call-number": "10.1145/2809793",
                "container-title": "ACM Inroads",
                "DOI": "10.1145/2809793",
                "ISSN": "2153-2184",
                "issue": "3",
                "number-of-pages": "1",
                "page": "88",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "September 2015",
                "title": "Expanding minds to big data and data sciences",
                "URL": "https://doi.org/10.1145/2809793",
                "volume": "6"
            }
        },
        {
            "10.1145/2925686.2925691": {
                "id": "10.1145/2925686.2925691",
                "type": "ARTICLE",
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            4,
                            14
                        ]
                    ]
                },
                "abstract": "SIGHPC is expanding its \"virtual chapter\" offerings through two new chapters: one focused on topics at the intersection of HPC and Big Data (SIGHPC-BigData), and the other on developing cyberinfrastructure and workforce development in resourceconstrained environments (SIGHPC-RCE). These join SIGHPC's first virtual chapter on Education in HPC (SIGHPC-Edu).",
                "call-number": "10.1145/2925686.2925691",
                "container-title": "ACM SIGHPC Connect",
                "DOI": "10.1145/2925686.2925691",
                "issue": "2",
                "number-of-pages": "2",
                "page": "7–8",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "February 2016",
                "title": "New chapters focus on big data and resource-constrained environments",
                "URL": "https://doi.org/10.1145/2925686.2925691",
                "volume": "4"
            }
        },
        {
            "10.1145/3340531.3412182": {
                "id": "10.1145/3340531.3412182",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Berns",
                        "given": "Fabian"
                    },
                    {
                        "family": "Beecks",
                        "given": "Christian"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            10,
                            19
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            10,
                            19
                        ]
                    ]
                },
                "abstract": "Gaussian Process Models (GPMs) are widely regarded as a prominent tool for capturing the inherent characteristics of data. These bayesian machine learning models allow for data analysis tasks such as regression and classification. Usually a process of automatic GPM retrieval is needed to find an optimal model for a given dataset, despite prevailing default instantiations and existing prior knowledge in some scenarios, which both shortcut the way to an optimal GPM. Since non-approximative Gaussian Processes only allow for processing small datasets with low statistical versatility, we propose a new approach that allows to efficiently and automatically retrieve GPMs for large-scale data. The resulting model is composed of independent statistical representations for non-overlapping segments of the given data. Our performance evaluation of the new approach demonstrates the quality of resulting models, which clearly outperform default GPM instantiations, while maintaining reasonable model training time.",
                "call-number": "10.1145/3340531.3412182",
                "collection-title": "CIKM '20",
                "container-title": "Proceedings of the 29th ACM International Conference on Information & Knowledge Management",
                "DOI": "10.1145/3340531.3412182",
                "event-place": "Virtual Event, Ireland",
                "ISBN": "9781450368599",
                "keyword": "information retrieval, regression, gaussian processes, performance evaluation, bayesian machine learning",
                "number-of-pages": "4",
                "page": "1965–1968",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Automatic Gaussian Process Model Retrieval for Big Data",
                "URL": "https://doi.org/10.1145/3340531.3412182"
            }
        },
        {
            "10.1145/3277139.3277144": {
                "id": "10.1145/3277139.3277144",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Pu",
                        "given": "Guoli"
                    },
                    {
                        "family": "Li",
                        "given": "Yuanyuan"
                    },
                    {
                        "family": "Bai",
                        "given": "Ju"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            8,
                            25
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            8,
                            25
                        ]
                    ]
                },
                "abstract": "How can firms achieve sustainable competitive advantage of quality (SCAQ)? Some typical cases show that big data analytics is a possible approach. Based on the theory of dynamic capability, this paper constructs a theoretical framework and possible hypotheses of big data analytics (BDA) in the supply chain field that influences the firms SCAQ. The theoretical framework includes: (1) the definition and the dimensions of big data supply chain analytic (BDSCA) and SCAQ; (2) the internal and external factors that influence the use of BDSCA based on the TOE framework; (3) the path and effect of BDSCA on SCQR; (4) moderating effects of industry characters and environmental uncertainty. The research contributes to define the connotation and characteristics of BDSCA from the perspective of management, clarify the impact mechanism of BDSCA on SCAQ, and seek ways to improve the firms SCAQ in the area of big data.",
                "call-number": "10.1145/3277139.3277144",
                "collection-title": "IMMS '18",
                "container-title": "Proceedings of the 2018 International Conference on Information Management & Management Science",
                "DOI": "10.1145/3277139.3277144",
                "event-place": "Chengdu, China",
                "ISBN": "9781450364867",
                "keyword": "TOE framework, sustainable competitive advantage of quality, industry characters, big data analytics, environmental uncertainty",
                "number-of-pages": "5",
                "page": "33–37",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The effect of big data analytics on firms sustainable competitive advantage of quality: a theory framework",
                "URL": "https://doi.org/10.1145/3277139.3277144"
            }
        },
        {
            "10.1145/3425709": {
                "id": "10.1145/3425709",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Shah",
                        "given": "Syed Iftikhar Hussain"
                    },
                    {
                        "family": "Peristeras",
                        "given": "Vassilios"
                    },
                    {
                        "family": "Magnisalis",
                        "given": "Ioannis"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            5,
                            6
                        ]
                    ]
                },
                "abstract": "The public sector, private firms, business community, and civil society are generating data that are high in volume, veracity, and velocity and come from a diversity of sources. This type of data is today known as big data. Public administrations pursue big data as “new oil” and implement data-centric policies to collect, generate, process, share, exploit, and protect data for promoting good governance, transparency, innovative digital services, and citizens’ engagement in public policy. All of the above constitute the Government Big Data Ecosystem (GBDE). Despite the great interest in this ecosystem, there is a lack of clear definitions, the various important types of government data remain vague, the different actors and their roles are not well defined, while the impact in key public administration sectors is not yet deeply understood and assessed. Such research and literature gaps impose a crucial obstacle for a better understanding of the prospects and nascent issues in exploiting GBDE. With this study, we aim to start filling the above-mentioned gaps by organizing our findings from an extended Systematic Literature Review into a framework to organise and address the above-mentioned challenges. Our goal is to contribute in this fast-evolving area by bringing some clarity and establishing common understanding around key elements of the emerging GBDE.",
                "call-number": "10.1145/3425709",
                "collection-number": "8",
                "container-title": "J. Data and Information Quality",
                "DOI": "10.1145/3425709",
                "ISSN": "1936-1955",
                "issue": "2",
                "keyword": "Big data, big data actors and roles, data and information, data-driven government, government big data ecosystem",
                "number": "Article 8",
                "number-of-pages": "25",
                "page": "1–25",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "June 2021",
                "title": "Government Big Data Ecosystem: Definitions, Types of Data, Actors, and Roles and the Impact in Public Administrations",
                "URL": "https://doi.org/10.1145/3425709",
                "volume": "13"
            }
        },
        {
            "10.5555/3374138.3374194": {
                "id": "10.5555/3374138.3374194",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bawatna",
                        "given": "Mohammed"
                    },
                    {
                        "family": "Green",
                        "given": "Bertram"
                    },
                    {
                        "family": "Kovalev",
                        "given": "Sergey"
                    },
                    {
                        "family": "Deinert",
                        "given": "Jan-Christoph"
                    },
                    {
                        "family": "Knodel",
                        "given": "Oliver"
                    },
                    {
                        "family": "Spallek",
                        "given": "Rainer G."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            7,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            7,
                            22
                        ]
                    ]
                },
                "abstract": "In recent years, improvements in high-speed Analog-to-Digital Converters (ADC) and sensor technology has encouraged researchers to improve the performance of Data Acquisition (DAQ) systems for scientific experiments which require high speed and continuous data measurements --- in particular, measuring the electronic and magnetic properties of materials using pump-probe experiments at high repetition rates. Experiments at TELBE are capable of acquiring almost 100 Gigabytes of raw data every ten minutes. The DAQ system used at TELBE partitions the raw data into various subdirectories for further parallel processing utilizing the multicore structure of modern CPUs.Furthermore, several other types of processors that accelerate data processing like the GPU and FPGA have emerged to solve the challenges of processing the massive amount of raw data. However, the memory and network bottlenecks become a significant challenge in big data processing, and new scalable programming techniques are needed to solve these challenges. In this contribution, we will outline the design and implementation of our practical software approach for efficient parallel processing of our large data sets at the TELBE user facility.",
                "call-number": "10.5555/3374138.3374194",
                "collection-number": "56",
                "collection-title": "SummerSim '19",
                "container-title": "Proceedings of the 2019 Summer Simulation Conference",
                "event-place": "Berlin, Germany",
                "keyword": "signal processing, data analytics, data processing pipeline, big data, data acquisition systems",
                "number": "Article 56",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Society for Computer Simulation International",
                "publisher-place": "San Diego, CA, USA",
                "title": "Research and implementation of efficient parallel processing of big data at TELBE user facility"
            }
        },
        {
            "10.14778/2556549.2556557": {
                "id": "10.14778/2556549.2556557",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Chandramouli",
                        "given": "Badrish"
                    },
                    {
                        "family": "Goldstein",
                        "given": "Jonathan"
                    },
                    {
                        "family": "Quamar",
                        "given": "Abdul"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            9,
                            1
                        ]
                    ]
                },
                "abstract": "Analytics over the increasing quantity of data stored in the Cloud has become very expensive, particularly due to the pay-as-you-go Cloud computation model. Data scientists typically manually extract samples of increasing data size (progressive samples) using domain-specific sampling strategies for exploratory querying. This provides them with user-control, repeatable semantics, and result provenance. However, such solutions result in tedious workflows that preclude the reuse of work across samples. On the other hand, existing approximate query processing systems report early results, but do not offer the above benefits for complex ad-hoc queries. We propose a new progressive analytics system based on a progress model called Prism that (1) allows users to communicate progressive samples to the system; (2) allows efficient and deterministic query processing over samples; and (3) provides repeatable semantics and provenance to data scientists. We show that one can realize this model for atemporal relational queries using an unmodified temporal streaming engine, by re-interpreting temporal event fields to denote progress. Based on Prism, we build Now!, a progressive data-parallel computation framework for Windows Azure, where progress is understood as a first-class citizen in the framework. Now! works with \"progress-aware reducers\"- in particular, it works with streaming engines to support progressive SQL over big data. Extensive experiments on Windows Azure with real and synthetic workloads validate the scalability and benefits of Now! and its optimizations, over current solutions for progressive analytics.",
                "call-number": "10.14778/2556549.2556557",
                "container-title": "Proc. VLDB Endow.",
                "DOI": "10.14778/2556549.2556557",
                "ISSN": "2150-8097",
                "issue": "14",
                "number-of-pages": "12",
                "page": "1726–1737",
                "publisher": "VLDB Endowment",
                "source": "September 2013",
                "title": "Scalable progressive analytics on big data in the cloud",
                "URL": "https://doi.org/10.14778/2556549.2556557",
                "volume": "6"
            }
        },
        {
            "10.1145/3443467.3443468": {
                "id": "10.1145/3443467.3443468",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Xiong"
                    },
                    {
                        "family": "Wang",
                        "given": "ShiYun"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            11,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            11,
                            6
                        ]
                    ]
                },
                "abstract": "In the case of large-scale transmission of Novel Coronavirus pneumonia through air and contact and a long incubation period, it is particularly important to control the further spread of potential infections. By designing a big data analysis platform for individual positioning information, this paper confirms suspected cases, isolated cases and confirmed cases, which is conducive to the prevention and control of the epidemic and improves the work efficiency.",
                "call-number": "10.1145/3443467.3443468",
                "collection-title": "EITCE 2020",
                "container-title": "Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering",
                "DOI": "10.1145/3443467.3443468",
                "event-place": "Xiamen, China",
                "ISBN": "9781450387811",
                "keyword": "Differential GPS, Big data, Epidemic detection",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Design of Infectious Disease Prevention and Control Platform Based on Big Data Analysis of Location Information",
                "URL": "https://doi.org/10.1145/3443467.3443468"
            }
        },
        {
            "10.1145/3554726": {
                "id": "10.1145/3554726",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Battle",
                        "given": "Leilani"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            8,
                            30
                        ]
                    ]
                },
                "call-number": "10.1145/3554726",
                "container-title": "interactions",
                "DOI": "10.1145/3554726",
                "ISSN": "1072-5520",
                "issue": "5",
                "number-of-pages": "2",
                "page": "9–10",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "September - October 2022",
                "title": "Behavior-driven testing of big data exploration tools",
                "URL": "https://doi.org/10.1145/3554726",
                "volume": "29"
            }
        },
        {
            "10.1145/3289600.3291372": {
                "id": "10.1145/3289600.3291372",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhou",
                        "given": "Xiangmin"
                    },
                    {
                        "family": "Zhang",
                        "given": "Ji"
                    },
                    {
                        "family": "Zhang",
                        "given": "Yanchun"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            1,
                            30
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            1,
                            30
                        ]
                    ]
                },
                "abstract": "With the explosive growth of online service platforms, increasing number of people and enterprises are doing everything online. In order for organizations, governments, and individuals to understand their users, and promote their products or services, it is necessary for them to analyse big data and recommend the media or online services in real time. Effective recommendation of items of interest to consumers has become critical for enterprises in domains such as retail, e-commerce, and online media. Driven by the business successes, academic research in this field has also been active for many years. Through many scientific breakthroughs have been achieved, there are still tremendous challenges in developing effective and scalable recommendation systems for real-world industrial applications. Existing solutions focus on recommending items based on pre-set contexts, such as time, location, weather etc. The big data sizes and complex contextual information add further challenges to the deployment of advanced recommender systems. This workshop aims to bring together researchers with wide-ranging backgrounds to identify important research questions, to exchange ideas from different research disciplines, and, more generally, to facilitate discussion and innovation in the area of context-aware recommender systems and big data analytics.",
                "call-number": "10.1145/3289600.3291372",
                "collection-title": "WSDM '19",
                "container-title": "Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining",
                "DOI": "10.1145/3289600.3291372",
                "event-place": "Melbourne VIC, Australia",
                "ISBN": "9781450359405",
                "keyword": "context-aware recommendation, big data analysis",
                "number-of-pages": "2",
                "page": "842–843",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The 1st International Workshop on Context-Aware Recommendation Systems with Big Data Analytics (CARS-BDA)",
                "URL": "https://doi.org/10.1145/3289600.3291372"
            }
        },
        {
            "10.1145/3297663.3309676": {
                "id": "10.1145/3297663.3309676",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Vemulapati",
                        "given": "Jayanti"
                    },
                    {
                        "family": "Khastgir",
                        "given": "Anuruddha S."
                    },
                    {
                        "family": "Savalgi",
                        "given": "Chethana"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            4,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            4,
                            4
                        ]
                    ]
                },
                "abstract": "Big data analytics platforms on cloud are becoming mainstream technology enabling cost-effective rapid deployment of customer's Big Data applications delivering quicker insights from their data. It is, therefore, even more imperative that we have high performant platform infrastructure and application at a reasonable cost. This is only possible if we make a transition from traditional approach to execute and measure performance by adopting new AI techniques such as Machine Learning (ML) & predictive approach to performance benchmarking for every application domain.This paper proposes a high-level conceptual model for automated performance benchmarking which includes execution engine that has been designed to support a self-service model covering automated benchmarking in every application domain. The automated engine is supported by performance scaling recommendations via prescriptive analytics from real performance data set.We furthermore extended the recommendation capabilities of our self-service automated engine by introducing predictive analytics for making it more flexible in addressing 'what-if' scenarios to predict 'Right Scale' with measurement of \"Performance Cost Ratio\" (PCR). Finally, we also present some real-world industry examples which have seen the performance benefits in their applications with the recommendations given by our proposed model.",
                "call-number": "10.1145/3297663.3309676",
                "collection-title": "ICPE '19",
                "container-title": "Proceedings of the 2019 ACM/SPEC International Conference on Performance Engineering",
                "DOI": "10.1145/3297663.3309676",
                "event-place": "Mumbai, India",
                "ISBN": "9781450362399",
                "keyword": "right scale, performance metrics, ml, automation, big data, ai, scale factor, performance tuning, performance cost ratio, benchmarking, predictive analytics, complex deployments, auto scale",
                "number-of-pages": "7",
                "page": "103–109",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "AI Based Performance Benchmarking & Analysis of Big Data and Cloud Powered Applications: An in Depth View",
                "URL": "https://doi.org/10.1145/3297663.3309676"
            }
        },
        {
            "10.1145/2668897": {
                "id": "10.1145/2668897",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Barocas",
                        "given": "Solon"
                    },
                    {
                        "family": "Nissenbaum",
                        "given": "Helen"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            10,
                            27
                        ]
                    ]
                },
                "abstract": "Recognizing the inherent limitations of consent and anonymity.",
                "call-number": "10.1145/2668897",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/2668897",
                "ISSN": "0001-0782",
                "issue": "11",
                "number-of-pages": "3",
                "page": "31–33",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "November 2014",
                "title": "Big data's end run around procedural privacy protections",
                "URL": "https://doi.org/10.1145/2668897",
                "volume": "57"
            }
        },
        {
            "10.5555/2888619.2888709": {
                "id": "10.5555/2888619.2888709",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Gaku",
                        "given": "Rie"
                    },
                    {
                        "family": "Takakuwa",
                        "given": "Soemon"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            12,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            12,
                            6
                        ]
                    ]
                },
                "abstract": "Using simulation technology, a procedure is proposed for a big data-driven service-level analysis for a real retail store. First, a data generator is designed to randomly select a sample of an expected number of customers or sampling data on a certain day from a large-scale dataset of sales predefined. Second, the clerk schedules are inputted into a data table created using Excel. Finally, simulation modeling mimics the service process of the retail store to examine and analyze the customer service level based on the selected data and the inputted clerk schedules. The proposed procedure for big data-driven service-level analysis shows the relations between the influencing service-level elements between the number of customers coming into stores, the frequency of customers, and the average customer service time. The procedure is generic and can easily be used to examine the service level in the remote past or to analyze and forecast the future.",
                "call-number": "10.5555/2888619.2888709",
                "collection-title": "WSC '15",
                "container-title": "Proceedings of the 2015 Winter Simulation Conference",
                "event-place": "Huntington Beach, California",
                "ISBN": "9781467397414",
                "number-of-pages": "9",
                "page": "791–799",
                "publisher": "IEEE Press",
                "title": "Big data-driven service level analysis for a retail store"
            }
        },
        {
            "10.1145/3190578": {
                "id": "10.1145/3190578",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Bors",
                        "given": "Christian"
                    },
                    {
                        "family": "Gschwandtner",
                        "given": "Theresia"
                    },
                    {
                        "family": "Kriglstein",
                        "given": "Simone"
                    },
                    {
                        "family": "Miksch",
                        "given": "Silvia"
                    },
                    {
                        "family": "Pohl",
                        "given": "Margit"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            29
                        ]
                    ]
                },
                "abstract": "During data preprocessing, analysts spend a significant part of their time and effort profiling the quality of the data along with cleansing and transforming the data for further analysis. While quality metrics—ranging from general to domain-specific measures—support assessment of the quality of a dataset, there are hardly any approaches to visually support the analyst in customizing and applying such metrics. Yet, visual approaches could facilitate users’ involvement in data quality assessment. We present MetricDoc, an interactive environment for assessing data quality that provides customizable, reusable quality metrics in combination with immediate visual feedback. Moreover, we provide an overview visualization of these quality metrics along with error visualizations that facilitate interactive navigation of the data to determine the causes of quality issues present in the data. In this article, we describe the architecture, design, and evaluation of MetricDoc, which underwent several design cycles, including heuristic evaluation and expert reviews as well as a focus group with data quality, human-computer interaction, and visual analytics experts.",
                "call-number": "10.1145/3190578",
                "collection-number": "3",
                "container-title": "J. Data and Information Quality",
                "DOI": "10.1145/3190578",
                "ISSN": "1936-1955",
                "issue": "1",
                "keyword": "data quality metrics, visual exploration, Data profiling",
                "number": "Article 3",
                "number-of-pages": "26",
                "page": "1–26",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "March 2018",
                "title": "Visual Interactive Creation, Customization, and Analysis of Data Quality Metrics",
                "URL": "https://doi.org/10.1145/3190578",
                "volume": "10"
            }
        },
        {
            "10.1145/2588555.2610498": {
                "id": "10.1145/2588555.2610498",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zoumpatianos",
                        "given": "Kostas"
                    },
                    {
                        "family": "Idreos",
                        "given": "Stratos"
                    },
                    {
                        "family": "Palpanas",
                        "given": "Themis"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            18
                        ]
                    ]
                },
                "abstract": "Numerous applications continuously produce big amounts of data series, and in several time critical scenarios analysts need to be able to query these data as soon as they become available, which is not currently possible with the state-of-the-art indexing methods and for very large data series collections. In this paper, we present the first adaptive indexing mechanism, specifically tailored to solve the problem of indexing and querying very large data series collections. The main idea is that instead of building the complete index over the complete data set up-front and querying only later, we interactively and adaptively build parts of the index, only for the parts of the data on which the users pose queries. The net effect is that instead of waiting for extended periods of time for the index creation, users can immediately start exploring the data series. We present a detailed design and evaluation of adaptive data series indexing over both synthetic data and real-world workloads. The results show that our approach can gracefully handle large data series collections, while drastically reducing the data to query delay: by the time state-of-the-art indexing techniques finish indexing 1 billion data series (and before answering even a single query), adaptive data series indexing has already answered $3*10^5$ queries.",
                "call-number": "10.1145/2588555.2610498",
                "collection-title": "SIGMOD '14",
                "container-title": "Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data",
                "DOI": "10.1145/2588555.2610498",
                "event-place": "Snowbird, Utah, USA",
                "ISBN": "9781450323765",
                "keyword": "adaptive data-series index, adaptive indexing, nearest neighbor, data-series, similarity search",
                "number-of-pages": "12",
                "page": "1555–1566",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Indexing for interactive exploration of big data series",
                "URL": "https://doi.org/10.1145/2588555.2610498"
            }
        },
        {
            "10.1145/3007818.3007838": {
                "id": "10.1145/3007818.3007838",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Eom",
                        "given": "Chris Soo-Hyun"
                    },
                    {
                        "family": "Lee",
                        "given": "Wookey"
                    },
                    {
                        "family": "Lee",
                        "given": "James Jung-Hun"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            10,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            10,
                            17
                        ]
                    ]
                },
                "abstract": "In recent years, prodigious explosion of social network services may trigger new business models. However, it has negative aspects such as personal information spill or spamming, as well. Amongst conventional spam detection approaches, the studies which are based on vertex degrees or Local Clustering Coefficient have been caused false positive results so that normal vertices can be specified as spammers. In this paper, we propose a novel approach by employing the circuit structure in the social networks, which demonstrates the advantages of our work through the experiment.",
                "call-number": "10.1145/3007818.3007838",
                "collection-title": "EDB '16",
                "container-title": "Proceedings of the Sixth International Conference on Emerging Databases: Technologies, Applications, and Theory",
                "DOI": "10.1145/3007818.3007838",
                "event-place": "Jeju, Republic of Korea",
                "ISBN": "9781450347549",
                "keyword": "graph, local clustering coefficient, shortest path, spammer, circuit",
                "number-of-pages": "10",
                "page": "51–60",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Spammer detection for real-time big data graphs",
                "URL": "https://doi.org/10.1145/3007818.3007838"
            }
        },
        {
            "10.1145/3464385.3468146": {
                "id": "10.1145/3464385.3468146",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bertola",
                        "given": "Paola"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            7,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            7,
                            11
                        ]
                    ]
                },
                "abstract": "The availability of big data is creating a paradigm shift in understanding and driving public opinions, informing individual behaviors and expectations. Therefore, future decision-making processes within companies and institutions will be driven by envisioning capacities based on data analytics that can provide meaningful representations of social behaviors. The paper addresses the current and potential impacts that digital transformation and data analytics are producing in the fashion industry. In particular, it shows two dynamics. On the one hand, the advent of the Internet, particularly social media, has transformed the interaction between brands and their customers’ communities, pushing the fashion industry to embrace more sustainable models better reflecting their contemporary values, expectations, and behaviors. On the other hand, it explores how a new systemic approach to data analytics can empower the design process within the fashion industry to promote a radical sustainable transformation.",
                "call-number": "10.1145/3464385.3468146",
                "collection-number": "2",
                "collection-title": "CHItaly '21",
                "container-title": "CHItaly 2021: 14th Biannual Conference of the Italian SIGCHI Chapter",
                "DOI": "10.1145/3464385.3468146",
                "event-place": "Bolzano, Italy",
                "ISBN": "9781450389778",
                "keyword": "design driven innovation, fashion data analytics, sustainable development",
                "number": "Article 2",
                "number-of-pages": "8",
                "page": "1–8",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Fashion Within the Big Data Society: How can data enable fashion transition towards a more meaningful and sustainable paradigm?",
                "URL": "https://doi.org/10.1145/3464385.3468146"
            }
        },
        {
            "10.1145/3444370.3444614": {
                "id": "10.1145/3444370.3444614",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhang",
                        "given": "Yong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            12,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            12,
                            4
                        ]
                    ]
                },
                "abstract": "The essence of human resource management informatization is data. Firstly, human information is transformed into data, and then the data can be used. This requires that the comprehensive, complete, timely and effective human resource data is entered into the system, and then the data is analyzed by using the human resource management system to provide decision support for the management. Due to the complexity of the internal law of objective things and the limitation of people's cognition, it is impossible to analyze the internal causality of the actual object and establish a mathematical model in accordance with the mechanism law. Therefore, when some mathematical models cannot be established by mechanism analysis, we usually adopt the method of collecting a large amount of data, and establish the model based on the statistical analysis of the data. Among them, the most widely used random model is statistical regression model.",
                "call-number": "10.1145/3444370.3444614",
                "collection-title": "CIAT 2020",
                "container-title": "Proceedings of the 2020 International Conference on Cyberspace Innovation of Advanced Technologies",
                "DOI": "10.1145/3444370.3444614",
                "event-place": "Guangzhou, China",
                "ISBN": "9781450387828",
                "keyword": "Multiple regression analysis, data quality, human resources",
                "number-of-pages": "6",
                "page": "465–470",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Human resource data quality management based on multiple regression analysis",
                "URL": "https://doi.org/10.1145/3444370.3444614"
            }
        },
        {
            "10.1145/2631775.2631812": {
                "id": "10.1145/2631775.2631812",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Hidalgo",
                        "given": "Cesar"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            1
                        ]
                    ]
                },
                "abstract": "Big data can be used for more than improving the targeting of marketing campaigns. In this talk I will present five big data visualization engines we have created at the MIT Media Lab's Macro Connections group and will show how we can use big data and visualizations to improve our understanding of the development of economies, cultures and cities. The data visualization engines I will demo include (i) the Observatory of Economic Complexity (atlas.media.mit.edu), which is the most comprehensive tool for exploring international trade data created to date; (ii) DataViva (dataviva.info), which is a tool we created to open up data for the entire formal sector economy of Brazil, including data on all of the working force, municipalities, industries, and occupations of Brazil; (iii) Pantheon (pantheon.media.mit.edu), a dataset and visualization engine we created to explore global patterns of cultural production; (iv) Immersion (immersion.media.mit.edu), which is a tool that inverts the email interface, by focusing it on people rather than messages; and (v) Place Pulse and StreetScore (pulse.media.mit.edu & streetscore.media.mit.edu), which are crowd-sourcing and machine learning tools we have developed to help understand the aesthetic aspects of cities and their evolution.",
                "call-number": "10.1145/2631775.2631812",
                "collection-title": "HT '14",
                "container-title": "Proceedings of the 25th ACM conference on Hypertext and social media",
                "DOI": "10.1145/2631775.2631812",
                "event-place": "Santiago, Chile",
                "ISBN": "9781450329545",
                "keyword": "economic complexity, big data, urban computing, data visualization, cultural production, information visualization",
                "number-of-pages": "1",
                "page": "3",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data visualization engines for understanding the development of countries, social networks, culture and cities",
                "URL": "https://doi.org/10.1145/2631775.2631812"
            }
        },
        {
            "10.1145/3405962.3405970": {
                "id": "10.1145/3405962.3405970",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yamamoto",
                        "given": "Yukio"
                    },
                    {
                        "family": "Ishikawa",
                        "given": "Hiroshi"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            6,
                            30
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            6,
                            30
                        ]
                    ]
                },
                "abstract": "The data obtained by planetary explorations has various aspects such as decision making during an ongoing mission, anomaly detection for spacecraft safety, data archives for scientific analysis, and attractive snapshots for outreach. Each aspect requires each data formats and processing techniques. In this paper, we discuss changes in the environment surrounding planetary explorations and the handling of big data on computers. As a result, for the long-term preservation of scientific data, there must be standards and a community to endorse the standards. After standards, each community prepares the analysis tools. Furthermore, scientists need to make efforts not only in standardization but also in ensuring the quality of science. For highly informative data in recent years, the processing of data archives requires information science experts. Also, data providers or distributors should define data policies to clarify data usages to users. Finally, scientific analysis of cloud-based architecture due to big data and computer resources.",
                "call-number": "10.1145/3405962.3405970",
                "collection-title": "WIMS 2020",
                "container-title": "Proceedings of the 10th International Conference on Web Intelligence, Mining and Semantics",
                "DOI": "10.1145/3405962.3405970",
                "event-place": "Biarritz, France",
                "ISBN": "9781450375429",
                "keyword": "planetary exploration, Planetary Data System, SPICE",
                "number-of-pages": "3",
                "page": "88–90",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Data Management in Japanese Planetary Explorations for Big Data Era",
                "URL": "https://doi.org/10.1145/3405962.3405970"
            }
        },
        {
            "10.1145/2076450.2076453": {
                "id": "10.1145/2076450.2076453",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Stonebraker",
                        "given": "Michael"
                    },
                    {
                        "family": "Hong",
                        "given": "Jason"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            2,
                            1
                        ]
                    ]
                },
                "abstract": "The Communications Web site, http://cacm.acm.org, features more than a dozen bloggers in the BLOG@CACM community. In each issue of Communications, we'll publish selected posts or excerpts.twitterFollow us on Twitter at http://twitter.com/blogCACMhttp://cacm.acm.org/blogs/blog-cacmMichael Stonebraker issues a call to arms about research groups' data-management problems. Jason Hong discusses the nature of functionality with respect to design.",
                "call-number": "10.1145/2076450.2076453",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/2076450.2076453",
                "ISSN": "0001-0782",
                "issue": "2",
                "number-of-pages": "2",
                "page": "10–11",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "February 2012",
                "title": "Researchers' big data crisis; understanding design and functionality",
                "URL": "https://doi.org/10.1145/2076450.2076453",
                "volume": "55"
            }
        },
        {
            "10.1145/2808492.2808532": {
                "id": "10.1145/2808492.2808532",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chen",
                        "given": "Boyang"
                    },
                    {
                        "family": "Ge",
                        "given": "Shiming"
                    },
                    {
                        "family": "Xie",
                        "given": "Kaixuan"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            8,
                            19
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            8,
                            19
                        ]
                    ]
                },
                "abstract": "Conventional centroid location algorithms are all in two dimensions. In order to solve the problem that the conventional centroid location algorithms are useless when the point spread function is smaller than the size of the detector, the research is about the centroid location algorithm in three dimensions based on big data. By using the time parameter to link the big data of energy received by the detector at different time, not only the single image but the time sequence images are used in the algorithm, based on the geometric theorem, the exact position at the special time is calculated out. It is sure that, the algorithm is very steady when the sample number is enough, that means the phase of the sample point is nothing, and the error of the position got by the algorithm is less than 0.06 pixel when the non-uniformity of the detectors is smaller than 5%, that is usually the upper limit of the non-uniformity of the detector.",
                "call-number": "10.1145/2808492.2808532",
                "collection-number": "40",
                "collection-title": "ICIMCS '15",
                "container-title": "Proceedings of the 7th International Conference on Internet Multimedia Computing and Service",
                "DOI": "10.1145/2808492.2808532",
                "event-place": "Zhangjiajie, Hunan, China",
                "ISBN": "9781450335287",
                "keyword": "three dimensions, point target, centroid location",
                "number": "Article 40",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Centroid location algorithm in three dimensions based on big data",
                "URL": "https://doi.org/10.1145/2808492.2808532"
            }
        },
        {
            "10.5555/3069658.3069683": {
                "id": "10.5555/3069658.3069683",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "DePratti",
                        "given": "Roland"
                    },
                    {
                        "family": "Dancik",
                        "given": "Garrett M."
                    },
                    {
                        "family": "Lucci",
                        "given": "Fred"
                    },
                    {
                        "family": "Sampson",
                        "given": "Russell D."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            6,
                            1
                        ]
                    ]
                },
                "abstract": "Computer scientists have been developing techniques to glean useful information from datasets for decades. The nascent disciplines of Big Data and Data Science have evolved over the last 10 years due to the rapid explosion in the amount of data collected by scientists, businesses, and other organizations. It is imperative that the next generation of workers is educated with the necessary knowledge to confront Big Data problems. It is the role of higher education institutions to train future data scientists and Big Data practitioners to fill those positions that the marketplace needs. This paper describes the choices and decisions made by one higher education institution to develop a course in Big Data Programming and Concepts that will be part of a future concentration in Data Science.",
                "call-number": "10.5555/3069658.3069683",
                "container-title": "J. Comput. Sci. Coll.",
                "ISSN": "1937-4771",
                "issue": "6",
                "number-of-pages": "8",
                "page": "175–182",
                "publisher": "Consortium for Computing Sciences in Colleges",
                "publisher-place": "Evansville, IN, USA",
                "source": "June 2017",
                "title": "Development of an introductory big data programming and concepts course",
                "volume": "32"
            }
        },
        {
            "10.1145/3289402.3289536": {
                "id": "10.1145/3289402.3289536",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Amazal",
                        "given": "Houda"
                    },
                    {
                        "family": "Ramdani",
                        "given": "Mohammed"
                    },
                    {
                        "family": "Kissi",
                        "given": "Mohamed"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            24
                        ]
                    ]
                },
                "abstract": "Text classification is a domain that has been inspiring researchers since many years. Indeed, several approaches have been developed in order to find methods that improve the performance of text classification. But in last decades, because of the technological evolution, textual data becomes more and more abundant on the web. So that classical classification methods are unable to process this huge amount of data and consequently cannot produce satisfied results. Thus, new ways have been explored; to overcome the big dimensions of data, it was necessary to reduce the size of the features of documents and use parallel processing. For this, in our work, we developed a Term Frequency- Inverse Document Frequency (TF-IDF) parallel model to save only the most relevant words in documents. Then, we feed the dataset to a parallel Naive Bayes classifier. Both, the TF-IDF parallel model and parallel Naïve Bayes classifier were implemented on Hadoop system using the MapReduce architecture. The experimental results demonstrate the efficiency of the proposed method to improve the classification accuracy.",
                "call-number": "10.1145/3289402.3289536",
                "collection-number": "36",
                "collection-title": "SITA'18",
                "container-title": "Proceedings of the 12th International Conference on Intelligent Systems: Theories and Applications",
                "DOI": "10.1145/3289402.3289536",
                "event-place": "Rabat, Morocco",
                "ISBN": "9781450364621",
                "keyword": "Text classification, TF-IDF, Naïve Bayes, MapReduce, Machine Learning, Big Data",
                "number": "Article 36",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A Text Classification Approach using Parallel Naive Bayes in Big Data Context",
                "URL": "https://doi.org/10.1145/3289402.3289536"
            }
        },
        {
            "10.1145/3297067.3297093": {
                "id": "10.1145/3297067.3297093",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Meng",
                        "given": "Hailang"
                    },
                    {
                        "family": "Wang",
                        "given": "Xinhong"
                    },
                    {
                        "family": "Wang",
                        "given": "Xuesong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            11,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            11,
                            28
                        ]
                    ]
                },
                "abstract": "With the development of society, the number of vehicles increases rapidly. The vehicle plays an important role in people's life, however the problem of traffic safety caused by vehicles has also become increasingly prominent. In China, the high crash rate and casualty rate on expressways have always troubled traffic management department. So crash prediction on expressway becomes vital. Conventionally, crash prediction is based on traffic flow data. These data do not contain all the necessary factors. In this paper, we propose a method of prediction using real-world data, including historical accident data, road geometry data, vehicle speed data, and weather data. We treat the crash prediction problem as a binary classification problem. For classification, sample imbalanced is a great challenge in practice. Modifying sample weights is applied to handle this challenge. Three machine learning classification techniques, namely Random Forest (RF), Gradient Boosting Decision Tree (GBDT) and Xgboost, are considered to carry out the crash prediction task respectively. The best recall and precision rate of these models are respectively 0.764253 and 0.01062. The proposed method can be integrated into urban traffic control systems toward police dispatch and crash prevention.",
                "call-number": "10.1145/3297067.3297093",
                "collection-title": "SPML '18",
                "container-title": "Proceedings of the 2018 International Conference on Signal Processing and Machine Learning",
                "DOI": "10.1145/3297067.3297093",
                "event-place": "Shanghai, China",
                "ISBN": "9781450366052",
                "keyword": "feature extraction and selection, machine learning, Crash prediction, sample imbalance",
                "number-of-pages": "6",
                "page": "11–16",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Expressway Crash Prediction based on Traffic Big Data",
                "URL": "https://doi.org/10.1145/3297067.3297093"
            }
        },
        {
            "10.1145/2500489": {
                "id": "10.1145/2500489",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Rakthanmanon",
                        "given": "Thanawin"
                    },
                    {
                        "family": "Campana",
                        "given": "Bilson"
                    },
                    {
                        "family": "Mueen",
                        "given": "Abdullah"
                    },
                    {
                        "family": "Batista",
                        "given": "Gustavo"
                    },
                    {
                        "family": "Westover",
                        "given": "Brandon"
                    },
                    {
                        "family": "Zhu",
                        "given": "Qiang"
                    },
                    {
                        "family": "Zakaria",
                        "given": "Jesin"
                    },
                    {
                        "family": "Keogh",
                        "given": "Eamonn"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            9,
                            1
                        ]
                    ]
                },
                "abstract": "Most time series data mining algorithms use similarity search as a core subroutine, and thus the time taken for similarity search is the bottleneck for virtually all time series data mining algorithms, including classification, clustering, motif discovery, anomaly detection, and so on. The difficulty of scaling a search to large datasets explains to a great extent why most academic work on time series data mining has plateaued at considering a few millions of time series objects, while much of industry and science sits on billions of time series objects waiting to be explored. In this work we show that by using a combination of four novel ideas we can search and mine massive time series for the first time. We demonstrate the following unintuitive fact: in large datasets we can exactly search under Dynamic Time Warping (DTW) much more quickly than the current state-of-the-art Euclidean distance search algorithms. We demonstrate our work on the largest set of time series experiments ever attempted. In particular, the largest dataset we consider is larger than the combined size of all of the time series datasets considered in all data mining papers ever published. We explain how our ideas allow us to solve higher-level time series data mining problems such as motif discovery and clustering at scales that would otherwise be untenable. Moreover, we show how our ideas allow us to efficiently support the uniform scaling distance measure, a measure whose utility seems to be underappreciated, but which we demonstrate here. In addition to mining massive datasets with up to one trillion datapoints, we will show that our ideas also have implications for real-time monitoring of data streams, allowing us to handle much faster arrival rates and/or use cheaper and lower powered devices than are currently possible.",
                "call-number": "10.1145/2500489",
                "collection-number": "10",
                "container-title": "ACM Trans. Knowl. Discov. Data",
                "DOI": "10.1145/2500489",
                "ISSN": "1556-4681",
                "issue": "3",
                "keyword": "lower bounds, Time series, similarity search",
                "number": "Article 10",
                "number-of-pages": "31",
                "page": "1–31",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "September 2013",
                "title": "Addressing Big Data Time Series: Mining Trillions of Time Series Subsequences Under Dynamic Time Warping",
                "URL": "https://doi.org/10.1145/2500489",
                "volume": "7"
            }
        },
        {
            "10.1145/2640087.2644169": {
                "id": "10.1145/2640087.2644169",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Shi",
                        "given": "Justin Y."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            4
                        ]
                    ]
                },
                "abstract": "Data intensive parallel applications are harder to protect against transient software and hardware failures compared to traditional parallel applications. Due to the need for distributed data replication, the CAP Conjecture and Theorem define the ultimate limits for data intensive application's reliability, availability and overall scalability. This paper examines the two assumptions in the proof of CAP Theorem and proposes a statistic multiplexing paradigm for eliminating the reliability, availability and scalability limits of data intensive parallel applications.",
                "call-number": "10.1145/2640087.2644169",
                "collection-number": "19",
                "collection-title": "BigDataScience '14",
                "container-title": "Proceedings of the 2014 International Conference on Big Data Science and Computing",
                "DOI": "10.1145/2640087.2644169",
                "event-place": "Beijing, China",
                "ISBN": "9781450328913",
                "keyword": "CAP Theorem, Statistic Multiplexed Computing, CAP Conjectur, Unlimited Scalability of Extreme Scale Data Intensive Application",
                "number": "Article 19",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Symposium: CAP-Plus for Big Data",
                "URL": "https://doi.org/10.1145/2640087.2644169"
            }
        },
        {
            "10.1145/2808797.2808883": {
                "id": "10.1145/2808797.2808883",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Lee",
                        "given": "Chung-Hong"
                    },
                    {
                        "family": "Yang",
                        "given": "Hsin-Chang"
                    },
                    {
                        "family": "Lin",
                        "given": "Shih-Jan"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            8,
                            25
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            8,
                            25
                        ]
                    ]
                },
                "abstract": "In this work, an \"analytical data model of mosquito vector\" was developed to perform analytical computation to the character of the dengue vectors. Our goal is to investigate a way to understand how the temporal trend of collected dataset correlates with the incidence dengue as identified by national health authorities. Based upon the mosquito-vector big data collections, we investigate how changes in some specific variables such as rainfall, temperature, and humidity can dramatically affect the population of mosquito vectors, in order to provide early warnings of dengue outbreaks. Thus, our system will collectively collect online sensing data of the variables and store them in a database, in order to combine the historical big data as training datasets for analytical computation. Also, the developed model is able to merge the experimental datasets with current hot-topic information which is relevant to mosquito vectors obtained from data of social sensors (i.e. social messages). The experimental data show that our system is of great potentials in providing early warnings of dengue outbreaks.",
                "call-number": "10.1145/2808797.2808883",
                "collection-title": "ASONAM '15",
                "container-title": "Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015",
                "DOI": "10.1145/2808797.2808883",
                "event-place": "Paris, France",
                "ISBN": "9781450338547",
                "keyword": "Big Data, Data Mining, Dengue Outbreaks, Social Sensors, Machine Learning",
                "number-of-pages": "6",
                "page": "1428–1433",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Incorporating Big Data and Social Sensors in a Novel Early Warning System of Dengue Outbreaks",
                "URL": "https://doi.org/10.1145/2808797.2808883"
            }
        },
        {
            "10.5555/2753024.2753046": {
                "id": "10.5555/2753024.2753046",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "DePratti",
                        "given": "Roland A."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            1
                        ]
                    ]
                },
                "abstract": "We live in a world where massive amounts of data are being generated, leading to advances in disciplines including physics, astronomy, biology, sociology, and business. This so-called Big Data cannot be stored and analyzed using traditional data storage and processing applications, yet its successful storage, mining, and analyses are critical for advances in the fields mentioned above and others. Since April 2014, four Computer Science professors from Eastern Connecticut State University have been participating in Big Data training exercises and developing an Introductory Course in Big Data Programming. However, the broad scope of Big Data and its relative newness pose key challenges to course development.",
                "call-number": "10.5555/2753024.2753046",
                "container-title": "J. Comput. Sci. Coll.",
                "ISSN": "1937-4771",
                "issue": "6",
                "number-of-pages": "2",
                "page": "104–105",
                "publisher": "Consortium for Computing Sciences in Colleges",
                "publisher-place": "Evansville, IN, USA",
                "source": "June 2015",
                "title": "Challenges in designing an introductory course in big data programming: lightning talk",
                "volume": "30"
            }
        },
        {
            "10.1145/2818869.2818935": {
                "id": "10.1145/2818869.2818935",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Lee",
                        "given": "Chung-Hong"
                    },
                    {
                        "family": "Wu",
                        "given": "Chih-Hung"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            7
                        ]
                    ]
                },
                "abstract": "This paper presents an expansible machine learning approach applying the EV big data as the human sensor to extract driving behaviors and driving modes. A pattern recognition approach is proposed to model the driving pattern according to the energy consumption of an EV. The growing hierarchical self-organizing maps (GHSOM) is applied to learn driver's behaviors gradually in the offline process, and the clustered neurons are used as the training sets for implementing online classifiers based on support vector machine (SVM). This proposed framework would facilitate the understanding of driver's behaviors and help drivers overcome range anxiety.",
                "call-number": "10.1145/2818869.2818935",
                "collection-number": "10",
                "collection-title": "ASE BD&amp;SI '15",
                "container-title": "Proceedings of the ASE BigData & SocialInformatics 2015",
                "DOI": "10.1145/2818869.2818935",
                "event-place": "Kaohsiung, Taiwan",
                "ISBN": "9781450337359",
                "keyword": "EV big data, Electric vehicle, Driving behavior, Machine learning, Driving pattern recognition, Range anxiety",
                "number": "Article 10",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "An incremental learning technique for detecting driving behaviors using collected EV big data",
                "URL": "https://doi.org/10.1145/2818869.2818935"
            }
        },
        {
            "10.1145/2513549": {
                "id": "10.1145/2513549",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2013
                        ]
                    ]
                },
                "abstract": "It is our great pleasure to welcome you to the 2013 ACM International Workshop on Mining Unstructured Big Data using Natural Language Processing, which will be held at ACM International Conference on Information and Knowledge Management, CIKM 2013.Unstructured text data is heterogeneous and available in different formats, such as text document, scientific publication, web page, and customer comment. The availability of many big unstructured text datasets enables, while also challenges researchers to discover and explore valuable information/knowledge via different techniques.Mining semantics by using Natural Language Processing (NLP) methodologies is an important approach to uncover the \"latent knowledge/semantic\" of the unstructured text data. In the past decade, while a number of NLP based features already successfully used to enhance the performance of the text mining or information retrieval systems, we are also facing some challenges. For instance, most NLP algorithms' computational cost is high, and we can hardly employ them directly to large-scale text data for online systems.In this workshop, we aggregate different but highly related research communities, i.e., \"NLP\", \"Text Mining\" and \"IR\" researchers, to investigate the possible opportunities and challenges in semantic mining problem. Nine very interesting papers, covering semantic analysis, social media mining, real-time information extraction, and etc., will be presented in this workshop. For this workshop, an opportunity is offered to both NLP and text mining research communities to better clarify the opportunities and challenges in NLP based semantic mining for big unstructured text data with their research experience.We also encourage attendees to attend the keynote presentation - \"HathiTrust Data, Opportunities and Challenges for Text Mining and NLP\" by Dr. Beth A. Plale, Director of Data to Insight Center, and Professor at School of Informatics and Computing, Indiana University. HathiTrust is a partnership of academic & research institutions, offering a collection of millions of digitized from libraries around the world plus effective API access.We hope that you will find this program interesting and thought-provoking and that the workshop will provide you with a valuable opportunity to share ideas with other researchers and practitioners from institutions around the world.",
                "call-number": "10.1145/2513549",
                "container-title-short": "UnstructureNLP '13",
                "event-place": "San Francisco, California, USA",
                "genre": "proceeding",
                "ISBN": "9781450324151",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2013 international workshop on Mining unstructured big data using natural language processing"
            }
        },
        {
            "10.1145/3098593": {
                "id": "10.1145/3098593",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2017
                        ]
                    ]
                },
                "call-number": "10.1145/3098593",
                "container-title-short": "Big-DAMA '17",
                "event-place": "Los Angeles, CA, USA",
                "genre": "proceeding",
                "ISBN": "9781450350549",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the Workshop on Big Data Analytics and Machine Learning for Data Communication Networks"
            }
        },
        {
            "10.1145/3482632.3487482": {
                "id": "10.1145/3482632.3487482",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Luan",
                        "given": "Shaohong"
                    },
                    {
                        "family": "Wu",
                        "given": "Yunze"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            24
                        ]
                    ]
                },
                "abstract": "As big data technology penetrates all aspects of our lives; more and more industries are beginning to apply big data technology. Its robust data analysis, resource acquisition, and predictive capabilities have brought tremendous business activities as a brand-new data management technology. This article analyzes the big data technology application in business activities and introduces the principles of two essential algorithms in big data technology, clustering algorithm, and principal component analysis. Moreover, it introduces applying the mean shift clustering and principal component analysis in clustering algorithm to analyze the commercial data. Finally, a comprehensive analysis of the advantages and disadvantages of big data technology is made.",
                "call-number": "10.1145/3482632.3487482",
                "collection-title": "ICISCAE 2021",
                "container-title": "2021 4th International Conference on Information Systems and Computer Aided Education",
                "DOI": "10.1145/3482632.3487482",
                "event-place": "Dalian, China",
                "ISBN": "9781450390255",
                "number-of-pages": "5",
                "page": "2614–2618",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Application of big data technology and clustering algorithm in business activities",
                "URL": "https://doi.org/10.1145/3482632.3487482"
            }
        }
    ]
}