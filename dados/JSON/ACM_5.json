{
    "exportedDoiLength": 101,
    "fileName": "acm",
    "style": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<style xmlns=\"http://purl.org/net/xbiblio/csl\" class=\"in-text\" version=\"1.0\" demote-non-dropping-particle=\"sort-only\" default-locale=\"en-US\">\n    <!-- This style was edited with the Visual CSL Editor (http://editor.citationstyles.org/visualEditor/) -->\n    <info>\n        <title>BibTeX ACM citation style</title>\n        <id>http://www.zotero.org/styles/bibtex-acm-citation-style</id>\n        <link href=\"http://www.zotero.org/styles/bibtex-acm-citation-style\" rel=\"self\"/>\n        <link href=\"http://www.bibtex.org/\" rel=\"documentation\"/>\n        <author>\n            <name>Markus Schaffner</name>\n        </author>\n        <contributor>\n            <name>Richard Karnesky</name>\n            <email>karnesky+zotero@gmail.com</email>\n            <uri>http://arc.nucapt.northwestern.edu/Richard_Karnesky</uri>\n        </contributor>\n        <category citation-format=\"author-date\"/>\n        <category field=\"generic-base\"/>\n        <updated>2018-06-11T10:52:49+00:00</updated>\n        <rights license=\"http://creativecommons.org/licenses/by-sa/3.0/\">This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 License</rights>\n    </info>\n    <macro name=\"zotero2bibtexType\">\n        <choose>\n            <if type=\"BILL BOOK GRAPHIC LEGAL_CASE LEGISLATION MOTION_PICTURE SONG\" match=\"any\">\n                <choose>\n                    <if genre=\"rfc\"  match=\"any\">\n                       <text value=\"rfc\"/>\n                    </if>\n                     <else-if  genre=\"bibliography\" match=\"any\">\n                        <text value=\"bibliography\"/>\n                    </else-if>\n                    <else-if  genre=\"play_drama\" match=\"any\">\n                        <text value=\"playdrama\"/>\n                    </else-if>\n                    <else-if  genre=\"proceeding\" match=\"any\">\n                        <text value=\"proceedings\"/>\n                    </else-if>\n                    <else-if  genre=\"tech_brief\" match=\"any\">\n                        <text value=\"tech-brief\"/>\n                    </else-if>\n                    <else>\n                       <text value=\"book\"/>\n                    </else>\n                </choose>\n            </if>\n            <else-if type=\"CHAPTER\" match=\"any\">\n                <text value=\"inbook\"/>\n            </else-if>\n            <else-if type=\"ARTICLE ARTICLE_JOURNAL ARTICLE_MAGAZINE ARTICLE_NEWSPAPER\" match=\"any\">\n                <text value=\"article\"/>\n            </else-if>\n            <else-if type=\"THESIS\" match=\"any\">\n                <choose>\n                    <if variable=\"genre\">\n                        <text variable=\"genre\" text-case=\"lowercase\" strip-periods=\"true\"/>\n                    </if>\n                </choose>\n                <text value=\"thesis\"/>\n            </else-if>\n            <else-if type=\"PAPER_CONFERENCE\" match=\"any\">\n                <text value=\"inproceedings\"/>\n            </else-if>\n            <else-if type=\"REPORT\" match=\"any\">\n                <text value=\"techreport\"/>\n            </else-if>\n            <else-if type=\"DATASET\" match=\"any\">\n                <choose>\n                    <if genre=\"software\"  match=\"any\">\n                       <text value=\"software\"/>\n                    </if>\n                    <else>\n                       <text value=\"dataset\"/>\n                    </else>\n                </choose>\n            </else-if>\n            <else>\n                <text value=\"misc\"/>\n            </else>\n        </choose>\n    </macro>\n    <macro name=\"citeKey\">\n           <text variable=\"call-number\"/>\n    </macro>\n    <macro name=\"editor-short\">\n        <names variable=\"editor\">\n            <name form=\"short\" delimiter=\":\" delimiter-precedes-last=\"always\"/>\n        </names>\n    </macro>\n    <macro name=\"author-short\">\n        <names variable=\"author\">\n            <name form=\"short\" delimiter=\":\" delimiter-precedes-last=\"always\"/>\n        </names>\n    </macro>\n    <macro name=\"issued-year\">\n        <date variable=\"issued\">\n            <date-part name=\"year\"/>\n        </date>\n    </macro>\n    <macro name=\"issued-month\">\n        <choose>\n            <if type=\"ARTICLE\" match=\"any\">\n                <date variable=\"issued\">\n                    <date-part name=\"month\" form=\"short\" strip-periods=\"true\" text-case=\"lowercase\"/>\n                </date>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"issue-date\">\n        <choose>\n            <if type=\"ARTICLE ARTICLE_JOURNAL\" match=\"any\">\n                <choose>\n                    <if variable=\"note\" match=\"none\">\n                        <choose>\n                            <if variable=\"source\">\n                                 <text variable=\"source\"/>\n                            </if>\n                               <else>\n                                 <date date-parts=\"year-month\" form=\"text\" variable=\"issued\"/>\n                               </else>\n                        </choose>\n                    </if>\n                </choose>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"author\">\n        <names variable=\"author\">\n            <name sort-separator=\", \" delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n            <label form=\"long\" text-case=\"capitalize-first\"/>\n        </names>\n    </macro>\n    <macro name=\"editor-translator\">\n        <names variable=\"editor translator\" delimiter=\", \">\n            <name sort-separator=\", \" delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n            <label form=\"long\" text-case=\"capitalize-first\"/>\n        </names>\n    </macro>\n    <macro name=\"title\">\n        <choose>\n            <if genre=\"proceeding\" match=\"any\">\n                <text variable=\"container-title-short\" suffix=\": \"/>\n                <text variable=\"title\" text-case=\"title\"/>\n            </if>\n            <else-if type=\"ARTICLE_JOURNAL\" match=\"none\">\n                <text variable=\"title\" text-case=\"title\"/>\n            </else-if>\n        </choose>\n    </macro>\n    <macro name=\"volume\">\n        <choose>\n            <if type=\"ARTICLE BOOK ARTICLE_JOURNAL\" match=\"any\">\n                <text variable=\"volume\" prefix=\"volume = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"DOI\">\n        <choose>\n            <if type=\"ARTICLE PAPER_CONFERENCE\" match=\"any\">\n                <text variable=\"DOI\" prefix=\"doi = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"abstract\">\n        <if match=\"any\" variable=\"abstract\">\n            <text variable=\"abstract\"/>\n        </if>\n    </macro>\n    <macro name=\"URL\">\n        <text variable=\"URL\" prefix=\"url = {\" suffix=\"}\"/>\n    </macro>\n    <macro name=\"container-title\">\n        <choose>\n            <if type=\"CHAPTER PAPER_CONFERENCE\" match=\"any\">\n                <text variable=\"container-title\" prefix=\"booktitle = {\" suffix=\"}\" text-case=\"title\"/>\n            </if>\n            <else-if type=\"ARTICLE ARTICLE_JOURNAL\" match=\"any\">\n                <text variable=\"container-title\" prefix=\"journal = {\" suffix=\"}\" text-case=\"title\"/>\n            </else-if>\n        </choose>\n    </macro>\n    <macro name=\"pages\">\n        <group delimiter=\",&#10;\">\n            <choose>\n                <if match=\"any\" variable=\"collection-number\">\n                    <text variable=\"collection-number\" prefix=\"articleno = {\" suffix=\"}\"/>\n                </if>\n                <else>\n                    <text variable=\"page\" prefix=\"pages = {\" suffix=\"}\"/>\n                </else>\n            </choose>\n            <text variable=\"number-of-pages\" prefix=\"numpages = {\" suffix=\"}\"/>\n        </group>\n    </macro>\n    <macro name=\"edition\">\n        <text variable=\"edition\"/>\n    </macro>\n    <macro name=\"editor\">\n        <choose>\n            <if match=\"any\" type=\"THESIS\">\n                <names variable=\"editor\" delimiter=\", \" prefix=\"advisor = {\" suffix=\"}\">\n                    <name delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n                </names>\n            </if>\n            <else>\n               <names variable=\"editor\" delimiter=\", \" prefix=\"editor = {\" suffix=\"}\">\n                   <name delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n               </names>\n            </else>\n        </choose>\n    </macro>\n    <macro name=\"keyword\">\n        <choose>\n            <if type=\"ARTICLE PAPER_CONFERENCE DATASET\" match=\"any\">\n                <text variable=\"keyword\" prefix=\"keywords = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <citation et-al-min=\"11\" et-al-use-first=\"10\" disambiguate-add-year-suffix=\"true\" disambiguate-add-names=\"false\" disambiguate-add-givenname=\"false\" collapse=\"year\">\n        <layout delimiter=\"_\">\n            <text macro=\"citeKey\"/>\n        </layout>\n    </citation>\n    <bibliography hanging-indent=\"false\">\n        <layout>\n            <group display=\"right-inline\">\n                <text macro=\"zotero2bibtexType\" prefix=\"@\"/>\n                <group prefix=\"{\" suffix=\"&#10;}\" delimiter=\",&#10;\">\n                    <text macro=\"citeKey\"/>\n                    <text macro=\"author\" prefix=\"author = {\" suffix=\"}\"/>\n                    <text macro=\"editor\"/>\n                    <text macro=\"title\" prefix=\"title = {\" suffix=\"}\"/>\n                    <text macro=\"issued-year\" prefix=\"year = {\" suffix=\"}\"/>\n                    <text macro=\"issue-date\" prefix=\"issue_date = {\" suffix=\"}\"/>\n                    <text variable=\"ISBN\" prefix=\"isbn = {\" suffix=\"}\"/>\n                    <text variable=\"publisher\" prefix=\"publisher = {\" suffix=\"}\"/>\n                    <text variable=\"publisher-place\" prefix=\"address = {\" suffix=\"}\"/>\n                    <text variable=\"chapter-number\" prefix=\"chapter = {\" suffix=\"}\"/>\n                    <text macro=\"edition\" prefix=\"edition = {\" suffix=\"}\"/>\n                    <text macro=\"volume\"/>\n                    <text variable=\"issue\" prefix=\"number = {\" suffix=\"}\"/>\n                    <text variable=\"ISSN\" prefix=\"issn = {\" suffix=\"}\"/>\n                    <text variable=\"archive_location\" prefix=\"archiveLocation = {\" suffix=\"}\"/>\n                    <text macro=\"URL\"/>\n                    <text macro=\"DOI\"/>\n                    <text macro=\"abstract\" prefix=\"abstract = {\" suffix=\"}\"/>\n                    <text variable=\"note\" prefix=\"note = {\" suffix=\"}\"/>\n                    <text macro=\"container-title\"/>\n                    <text macro=\"issued-month\" prefix=\"month = {\" suffix=\"}\"/>\n                    <text macro=\"pages\"/>\n                    <text macro=\"keyword\"/>\n                    <text variable=\"event-place\" prefix=\"location = {\" suffix=\"}\"/>\n                    <choose>\n                        <if type=\"PAPER_CONFERENCE\" match=\"any\">\n                            <text variable=\"collection-title\" prefix=\"series = {\" suffix=\"}\"/>\n                        </if>\n                        <else>\n                            <text variable=\"collection-title\" prefix=\"collection = {\" suffix=\"}\"/>\n                        </else>\n                    </choose>\n                </group>\n            </group>\n        </layout>\n    </bibliography>\n</style>\n",
    "suffix": "bib",
    "locale": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<locale xmlns=\"http://purl.org/net/xbiblio/csl\" version=\"1.0\" xml:lang=\"en-US\">\n  <info>\n    <rights license=\"http://creativecommons.org/licenses/by-sa/3.0/\">This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 License</rights>\n    <updated>2012-07-04T23:31:02+00:00</updated>\n  </info>\n  <style-options punctuation-in-quote=\"true\"\n                 leading-noise-words=\"a,an,the\"\n                 name-as-sort-order=\"ja zh kr my hu vi\"\n                 name-never-short=\"ja zh kr my hu vi\"/>\n  <date form=\"text\">\n    <date-part name=\"month\" suffix=\" \"/>\n    <date-part name=\"day\" suffix=\", \"/>\n    <date-part name=\"year\"/>\n  </date>\n  <date form=\"numeric\">\n    <date-part name=\"month\" form=\"numeric-leading-zeros\" suffix=\"/\"/>\n    <date-part name=\"day\" form=\"numeric-leading-zeros\" suffix=\"/\"/>\n    <date-part name=\"year\"/>\n  </date>\n  <terms>\n    <term name=\"radio-broadcast\">radio broadcast</term>\n    <term name=\"television-broadcast\">television broadcast</term>\n    <term name=\"podcast\">podcast</term>\n    <term name=\"instant-message\">instant message</term>\n    <term name=\"email\">email</term>\n    <term name=\"number-of-volumes\">\n      <single>volume</single>\n      <multiple>volumes</multiple>\n    </term>\n    <term name=\"accessed\">accessed</term>\n    <term name=\"and\">and</term>\n    <term name=\"and\" form=\"symbol\">&amp;</term>\n    <term name=\"and others\">and others</term>\n    <term name=\"anonymous\">anonymous</term>\n    <term name=\"anonymous\" form=\"short\">anon.</term>\n    <term name=\"at\">at</term>\n    <term name=\"available at\">available at</term>\n    <term name=\"by\">by</term>\n    <term name=\"circa\">circa</term>\n    <term name=\"circa\" form=\"short\">c.</term>\n    <term name=\"cited\">cited</term>\n    <term name=\"edition\">\n      <single>edition</single>\n      <multiple>editions</multiple>\n    </term>\n    <term name=\"edition\" form=\"short\">ed.</term>\n    <term name=\"et-al\">et al.</term>\n    <term name=\"forthcoming\">forthcoming</term>\n    <term name=\"from\">from</term>\n    <term name=\"ibid\">ibid.</term>\n    <term name=\"in\">in</term>\n    <term name=\"in press\">in press</term>\n    <term name=\"internet\">internet</term>\n    <term name=\"interview\">interview</term>\n    <term name=\"letter\">letter</term>\n    <term name=\"no date\">no date</term>\n    <term name=\"no date\" form=\"short\">n.d.</term>\n    <term name=\"online\">online</term>\n    <term name=\"presented at\">presented at the</term>\n    <term name=\"reference\">\n      <single>reference</single>\n      <multiple>references</multiple>\n    </term>\n    <term name=\"reference\" form=\"short\">\n      <single>ref.</single>\n      <multiple>refs.</multiple>\n    </term>\n    <term name=\"retrieved\">retrieved</term>\n    <term name=\"scale\">scale</term>\n    <term name=\"version\">version</term>\n\n    <!-- ANNO DOMINI; BEFORE CHRIST -->\n    <term name=\"ad\">AD</term>\n    <term name=\"bc\">BC</term>\n\n    <!-- PUNCTUATION -->\n    <term name=\"open-quote\">“</term>\n    <term name=\"close-quote\">”</term>\n    <term name=\"open-inner-quote\">‘</term>\n    <term name=\"close-inner-quote\">’</term>\n    <term name=\"page-range-delimiter\">–</term>\n\n    <!-- ORDINALS -->\n    <term name=\"ordinal\">th</term>\n    <term name=\"ordinal-01\">st</term>\n    <term name=\"ordinal-02\">nd</term>\n    <term name=\"ordinal-03\">rd</term>\n    <term name=\"ordinal-11\">th</term>\n    <term name=\"ordinal-12\">th</term>\n    <term name=\"ordinal-13\">th</term>\n\n    <!-- LONG ORDINALS -->\n    <term name=\"long-ordinal-01\">first</term>\n    <term name=\"long-ordinal-02\">second</term>\n    <term name=\"long-ordinal-03\">third</term>\n    <term name=\"long-ordinal-04\">fourth</term>\n    <term name=\"long-ordinal-05\">fifth</term>\n    <term name=\"long-ordinal-06\">sixth</term>\n    <term name=\"long-ordinal-07\">seventh</term>\n    <term name=\"long-ordinal-08\">eighth</term>\n    <term name=\"long-ordinal-09\">ninth</term>\n    <term name=\"long-ordinal-10\">tenth</term>\n\n    <!-- LONG LOCATOR FORMS -->\n    <term name=\"book\">\n      <single>book</single>\n      <multiple>books</multiple>\n    </term>\n    <term name=\"chapter\">\n      <single>chapter</single>\n      <multiple>chapters</multiple>\n    </term>\n    <term name=\"column\">\n      <single>column</single>\n      <multiple>columns</multiple>\n    </term>\n    <term name=\"figure\">\n      <single>figure</single>\n      <multiple>figures</multiple>\n    </term>\n    <term name=\"folio\">\n      <single>folio</single>\n      <multiple>folios</multiple>\n    </term>\n    <term name=\"issue\">\n      <single>number</single>\n      <multiple>numbers</multiple>\n    </term>\n    <term name=\"line\">\n      <single>line</single>\n      <multiple>lines</multiple>\n    </term>\n    <term name=\"note\">\n      <single>note</single>\n      <multiple>notes</multiple>\n    </term>\n    <term name=\"opus\">\n      <single>opus</single>\n      <multiple>opera</multiple>\n    </term>\n    <term name=\"page\">\n      <single>page</single>\n      <multiple>pages</multiple>\n    </term>\n    <term name=\"paragraph\">\n      <single>paragraph</single>\n      <multiple>paragraph</multiple>\n    </term>\n    <term name=\"part\">\n      <single>part</single>\n      <multiple>parts</multiple>\n    </term>\n    <term name=\"section\">\n      <single>section</single>\n      <multiple>sections</multiple>\n    </term>\n    <term name=\"sub verbo\">\n      <single>sub verbo</single>\n      <multiple>sub verbis</multiple>\n    </term>\n    <term name=\"verse\">\n      <single>verse</single>\n      <multiple>verses</multiple>\n    </term>\n    <term name=\"volume\">\n      <single>volume</single>\n      <multiple>volumes</multiple>\n    </term>\n\n    <!-- SHORT LOCATOR FORMS -->\n    <term name=\"book\" form=\"short\">bk.</term>\n    <term name=\"chapter\" form=\"short\">chap.</term>\n    <term name=\"column\" form=\"short\">col.</term>\n    <term name=\"figure\" form=\"short\">fig.</term>\n    <term name=\"folio\" form=\"short\">f.</term>\n    <term name=\"issue\" form=\"short\">no.</term>\n    <term name=\"line\" form=\"short\">l.</term>\n    <term name=\"note\" form=\"short\">n.</term>\n    <term name=\"opus\" form=\"short\">op.</term>\n    <term name=\"page\" form=\"short\">\n      <single>p.</single>\n      <multiple>pp.</multiple>\n    </term>\n    <term name=\"paragraph\" form=\"short\">para.</term>\n    <term name=\"part\" form=\"short\">pt.</term>\n    <term name=\"section\" form=\"short\">sec.</term>\n    <term name=\"sub verbo\" form=\"short\">\n      <single>s.v.</single>\n      <multiple>s.vv.</multiple>\n    </term>\n    <term name=\"verse\" form=\"short\">\n      <single>v.</single>\n      <multiple>vv.</multiple>\n    </term>\n    <term name=\"volume\" form=\"short\">\n      <single>vol.</single>\n      <multiple>vols.</multiple>\n    </term>\n\n    <!-- SYMBOL LOCATOR FORMS -->\n    <term name=\"paragraph\" form=\"symbol\">\n      <single>¶</single>\n      <multiple>¶¶</multiple>\n    </term>\n    <term name=\"section\" form=\"symbol\">\n      <single>§</single>\n      <multiple>§§</multiple>\n    </term>\n\n    <!-- LONG ROLE FORMS -->\n    <term name=\"director\">\n      <single>director</single>\n      <multiple>directors</multiple>\n    </term>\n    <term name=\"editor\">\n      <single>editor</single>\n      <multiple>editors</multiple>\n    </term>\n    <term name=\"editorial-director\">\n      <single>editor</single>\n      <multiple>editors</multiple>\n    </term>\n    <term name=\"illustrator\">\n      <single>illustrator</single>\n      <multiple>illustrators</multiple>\n    </term>\n    <term name=\"translator\">\n      <single>translator</single>\n      <multiple>translators</multiple>\n    </term>\n    <term name=\"editortranslator\">\n      <single>editor &amp; translator</single>\n      <multiple>editors &amp; translators</multiple>\n    </term>\n\n    <!-- SHORT ROLE FORMS -->\n    <term name=\"director\" form=\"short\">\n      <single>dir.</single>\n      <multiple>dirs.</multiple>\n    </term>\n    <term name=\"editor\" form=\"short\">\n      <single>ed.</single>\n      <multiple>eds.</multiple>\n    </term>\n    <term name=\"editorial-director\" form=\"short\">\n      <single>ed.</single>\n      <multiple>eds.</multiple>\n    </term>\n    <term name=\"illustrator\" form=\"short\">\n      <single>ill.</single>\n      <multiple>ills.</multiple>\n    </term>\n    <term name=\"translator\" form=\"short\">\n      <single>tran.</single>\n      <multiple>trans.</multiple>\n    </term>\n    <term name=\"editortranslator\" form=\"short\">\n      <single>ed. &amp; tran.</single>\n      <multiple>eds. &amp; trans.</multiple>\n    </term>\n\n    <!-- VERB ROLE FORMS -->\n    <term name=\"director\" form=\"verb\">directed by</term>\n    <term name=\"editor\" form=\"verb\">edited by</term>\n    <term name=\"editorial-director\" form=\"verb\">edited by</term>\n    <term name=\"illustrator\" form=\"verb\">illustrated by</term>\n    <term name=\"interviewer\" form=\"verb\">interview by</term>\n    <term name=\"recipient\" form=\"verb\">to</term>\n    <term name=\"reviewed-author\" form=\"verb\">by</term>\n    <term name=\"translator\" form=\"verb\">translated by</term>\n    <term name=\"editortranslator\" form=\"verb\">edited &amp; translated by</term>\n\n    <!-- SHORT VERB ROLE FORMS -->\n    <term name=\"container-author\" form=\"verb-short\">by</term>\n    <term name=\"director\" form=\"verb-short\">dir.</term>\n    <term name=\"editor\" form=\"verb-short\">ed.</term>\n    <term name=\"editorial-director\" form=\"verb-short\">ed.</term>\n    <term name=\"illustrator\" form=\"verb-short\">illus.</term>\n    <term name=\"translator\" form=\"verb-short\">trans.</term>\n    <term name=\"editortranslator\" form=\"verb-short\">ed. &amp; trans.</term>\n\n    <!-- LONG MONTH FORMS -->\n    <term name=\"month-01\">January</term>\n    <term name=\"month-02\">February</term>\n    <term name=\"month-03\">March</term>\n    <term name=\"month-04\">April</term>\n    <term name=\"month-05\">May</term>\n    <term name=\"month-06\">June</term>\n    <term name=\"month-07\">July</term>\n    <term name=\"month-08\">August</term>\n    <term name=\"month-09\">September</term>\n    <term name=\"month-10\">October</term>\n    <term name=\"month-11\">November</term>\n    <term name=\"month-12\">December</term>\n\n    <!-- SHORT MONTH FORMS -->\n    <term name=\"month-01\" form=\"short\">Jan.</term>\n    <term name=\"month-02\" form=\"short\">Feb.</term>\n    <term name=\"month-03\" form=\"short\">Mar.</term>\n    <term name=\"month-04\" form=\"short\">Apr.</term>\n    <term name=\"month-05\" form=\"short\">May</term>\n    <term name=\"month-06\" form=\"short\">Jun.</term>\n    <term name=\"month-07\" form=\"short\">Jul.</term>\n    <term name=\"month-08\" form=\"short\">Aug.</term>\n    <term name=\"month-09\" form=\"short\">Sep.</term>\n    <term name=\"month-10\" form=\"short\">Oct.</term>\n    <term name=\"month-11\" form=\"short\">Nov.</term>\n    <term name=\"month-12\" form=\"short\">Dec.</term>\n\n    <!-- SEASONS -->\n    <term name=\"season-01\">Spring</term>\n    <term name=\"season-02\">Summer</term>\n    <term name=\"season-03\">Autumn</term>\n    <term name=\"season-04\">Winter</term>\n  </terms>\n</locale>\n",
    "contentType": "Application/x-bibtex",
    "items": [
        {
            "10.1145/3450287": {
                "id": "10.1145/3450287",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Zhao",
                        "given": "Liang"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            5,
                            23
                        ]
                    ]
                },
                "abstract": "Events are occurrences in specific locations, time, and semantics that nontrivially impact either our society or the nature, such as earthquakes, civil unrest, system failures, pandemics, and crimes. It is highly desirable to be able to anticipate the occurrence of such events in advance to reduce the potential social upheaval and damage caused. Event prediction, which has traditionally been prohibitively challenging, is now becoming a viable option in the big data era and is thus experiencing rapid growth, also thanks to advances in high performance computers and new Artificial Intelligence techniques. There is a large amount of existing work that focuses on addressing the challenges involved, including heterogeneous multi-faceted outputs, complex (e.g., spatial, temporal, and semantic) dependencies, and streaming data feeds. Due to the strong interdisciplinary nature of event prediction problems, most existing event prediction methods were initially designed to deal with specific application domains, though the techniques and evaluation procedures utilized are usually generalizable across different domains. However, it is imperative yet difficult to cross-reference the techniques across different domains, given the absence of a comprehensive literature survey for event prediction. This article aims to provide a systematic and comprehensive survey of the technologies, applications, and evaluations of event prediction in the big data era. First, systematic categorization and summary of existing techniques are presented, which facilitate domain experts’ searches for suitable techniques and help model developers consolidate their research at the frontiers. Then, comprehensive categorization and summary of major application domains are provided to introduce wider applications to model developers to help them expand the impacts of their research. Evaluation metrics and procedures are summarized and standardized to unify the understanding of model performance among stakeholders, model developers, and domain experts in various application domains. Finally, open problems and future directions are discussed. Additional resources related to event prediction are included in the paper website: http://cs.emory.edu/∼lzhao41/projects/event_prediction_site.html.",
                "call-number": "10.1145/3450287",
                "collection-number": "94",
                "container-title": "ACM Comput. Surv.",
                "DOI": "10.1145/3450287",
                "ISSN": "0360-0300",
                "issue": "5",
                "keyword": "big data, artificial intelligence, Event prediction",
                "number": "Article 94",
                "number-of-pages": "37",
                "page": "1–37",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "June 2022",
                "title": "Event Prediction in the Big Data Era: A Systematic Survey",
                "URL": "https://doi.org/10.1145/3450287",
                "volume": "54"
            }
        },
        {
            "10.1145/3264560.3264564": {
                "id": "10.1145/3264560.3264564",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chai",
                        "given": "Yuanyuan"
                    },
                    {
                        "family": "Zhu",
                        "given": "Mengyao"
                    },
                    {
                        "family": "Zhu",
                        "given": "Yilong"
                    },
                    {
                        "family": "Zhang",
                        "given": "Zizhou"
                    },
                    {
                        "family": "Zhang",
                        "given": "Zundong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            8,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            8,
                            3
                        ]
                    ]
                },
                "abstract": "Hierarchy is a fundamental characteristic of many complex systems. The methods of structural information have been taken as a prospective way for quantifying dynamical network complexity. This paper is based on the study of the high-dimensional natural structural information entropy in networks. And then we propose a new similarity District Structural Information (DSI) index, which takes the characteristics of network districts into consideration, to analyze the complexity of dynamical network districts. Based on the method, this paper applies the district structural information to explain the equilibrium problem in real-world networks. And taking Beijing traffic network and its districts to complete experiments demonstrates that the DSI index can reflect the equilibrium of the network and the districts effectively.",
                "call-number": "10.1145/3264560.3264564",
                "collection-title": "ICCBDC'18",
                "container-title": "Proceedings of the 2018 2nd International Conference on Cloud and Big Data Computing",
                "DOI": "10.1145/3264560.3264564",
                "event-place": "Barcelona, Spain",
                "ISBN": "9781450364744",
                "keyword": "Structural Information, Dynamical Complexity of Networks, Traffic Big Data, Network Districts",
                "number-of-pages": "5",
                "page": "28–32",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "On Two-Dimensional Structural Information of Beijing Transportation Networks Based on Traffic Big Data",
                "URL": "https://doi.org/10.1145/3264560.3264564"
            }
        },
        {
            "10.1145/3379247.3379298": {
                "id": "10.1145/3379247.3379298",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhai",
                        "given": "Chenggong"
                    },
                    {
                        "family": "Liu",
                        "given": "Nan"
                    },
                    {
                        "family": "Li",
                        "given": "Jianxiang"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            1,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            1,
                            4
                        ]
                    ]
                },
                "abstract": "In recent years, our army attaches great importance to the application of big data technology in the field of military logistics. With the concern of the head of the CMC, relevant departments actively deploy the application of big data technology. At present, big data technology is only applied in some units of the military feeding Industry, which is in the initial stage and has a huge development space. This paper mainly introduces the application status of big data technology, the application ideas and related supporting measures in the feeding Industry.",
                "call-number": "10.1145/3379247.3379298",
                "collection-title": "ICCDE 2020",
                "container-title": "Proceedings of 2020 the 6th International Conference on Computing and Data Engineering",
                "DOI": "10.1145/3379247.3379298",
                "event-place": "Sanya, China",
                "ISBN": "9781450376730",
                "keyword": "big data, Business Process Reengineering, Feeding Industry",
                "number-of-pages": "5",
                "page": "142–146",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Application Analysis of Big Data Technology in Feeding Industry",
                "URL": "https://doi.org/10.1145/3379247.3379298"
            }
        },
        {
            "10.1145/3545801": {
                "id": "10.1145/3545801",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2022
                        ]
                    ]
                },
                "call-number": "10.1145/3545801",
                "container-title-short": "ICBDC '22",
                "event-place": "Shenzhen, China",
                "genre": "proceeding",
                "ISBN": "9781450396097",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 7th International Conference on Big Data and Computing"
            }
        },
        {
            "10.1145/956750.956844": {
                "id": "10.1145/956750.956844",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Dasu",
                        "given": "Tamraparni"
                    },
                    {
                        "family": "Vesonder",
                        "given": "Gregg T."
                    },
                    {
                        "family": "Wright",
                        "given": "Jon R."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2003,
                            8,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2003,
                            8,
                            24
                        ]
                    ]
                },
                "abstract": "Traditionally, data quality programs have acted as a preprocessing stage to make data suitable for a data mining or analysis operation. Recently, data quality concepts have been applied to databases that support business operations such as provisioning and billing. Incorporating business rules that drive operations and their associated data processes is critically important to the success of such projects. However, there are many practical complications. For example, documentation on business rules is often meager. Rules change frequently. Domain knowledge is often fragmented across experts, and those experts do not always agree. Typically, rules have to be gathered from subject matter experts iteratively, and are discovered out of logical or procedural sequence, like a jigsaw puzzle. Our approach is to impement business rules as constraints on data in a classical expert system formalism sometimes called production rules. Our system works by allowing good data to pass through a system of constraints unchecked. Bad data violate constraints and are flagged, and then fed back after correction. Constraints are added incrementally as better understanding of the business rules is gained. We include a real-life case study.",
                "call-number": "10.1145/956750.956844",
                "collection-title": "KDD '03",
                "container-title": "Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining",
                "DOI": "10.1145/956750.956844",
                "event-place": "Washington, D.C.",
                "ISBN": "1581137370",
                "keyword": "static and dynamic constraints, business operations databases, data quality",
                "number-of-pages": "6",
                "page": "705–710",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Data quality through knowledge engineering",
                "URL": "https://doi.org/10.1145/956750.956844"
            }
        },
        {
            "10.1145/3195106.3195172": {
                "id": "10.1145/3195106.3195172",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Anshari",
                        "given": "Muhammad"
                    },
                    {
                        "family": "Almunawar",
                        "given": "Mohammad Nabil"
                    },
                    {
                        "family": "Lim",
                        "given": "Syamimi Ariff"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            2,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            2,
                            26
                        ]
                    ]
                },
                "abstract": "Big data is a relatively new approach in managing and analyzing a huge amount of dynamic data to discover useful information and knowledge. Even though big data is still in its infancy, it has been benefiting private and public organizations in large scale. Since public sector organizations have to maintain large amount of data from several domains, to utilize big data it is crucial that any challenges and issues faced in adapting big data to be addressed. This paper discusses the benefits and risks for accommodating big data and open government data for public services.",
                "call-number": "10.1145/3195106.3195172",
                "collection-title": "ICMLC 2018",
                "container-title": "Proceedings of the 2018 10th International Conference on Machine Learning and Computing",
                "DOI": "10.1145/3195106.3195172",
                "event-place": "Macau, China",
                "ISBN": "9781450363532",
                "keyword": "Open Government Data, Public Organization, Big data, Open Data",
                "number-of-pages": "5",
                "page": "140–144",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data and Open Government Data in Public Services",
                "URL": "https://doi.org/10.1145/3195106.3195172"
            }
        },
        {
            "10.1145/3006299.3006310": {
                "id": "10.1145/3006299.3006310",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Glauner",
                        "given": "Patrick"
                    },
                    {
                        "family": "Meira",
                        "given": "Jorge Augusto"
                    },
                    {
                        "family": "Dolberg",
                        "given": "Lautaro"
                    },
                    {
                        "family": "State",
                        "given": "Radu"
                    },
                    {
                        "family": "Bettinger",
                        "given": "Franck"
                    },
                    {
                        "family": "Rangoni",
                        "given": "Yves"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            12,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            12,
                            6
                        ]
                    ]
                },
                "abstract": "Electricity theft occurs around the world in both developed and developing countries and may range up to 40% of the total electricity distributed. More generally, electricity theft belongs to non-technical losses (NTL), which occur during the distribution of electricity in power grids. In this paper, we build features from the neighborhood of customers. We first split the area in which the customers are located into grids of different sizes. For each grid cell we then compute the proportion of inspected customers and the proportion of NTL found among the inspected customers. We then analyze the distributions of features generated and show why they are useful to predict NTL. In addition, we compute features from the consumption time series of customers. We also use master data features of customers, such as their customer class and voltage of their connection. We compute these features for a Big Data base of 31M meter readings, 700K customers and 400K inspection results. We then use these features to train four machine learning algorithms that are particularly suitable for Big Data sets because of their parallelizable structure: logistic regression, k-nearest neighbors, linear support vector machine and random forest. Using the neighborhood features instead of only analyzing the time series has resulted in appreciable results for Big Data sets for varying NTL proportions of 1%-90%. This work can therefore be deployed to a wide range of different regions.",
                "call-number": "10.1145/3006299.3006310",
                "collection-title": "BDCAT '16",
                "container-title": "Proceedings of the 3rd IEEE/ACM International Conference on Big Data Computing, Applications and Technologies",
                "DOI": "10.1145/3006299.3006310",
                "event-place": "Shanghai, China",
                "ISBN": "9781450346177",
                "keyword": "feature selection, non-technical losses, feature engineering, data mining, machine learning, time series classification, electricity theft detection",
                "number-of-pages": "9",
                "page": "253–261",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Neighborhood features help detecting non-technical losses in big data sets",
                "URL": "https://doi.org/10.1145/3006299.3006310"
            }
        },
        {
            "10.1145/3312714.3312728": {
                "id": "10.1145/3312714.3312728",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Hajiheydari",
                        "given": "Nastaran"
                    },
                    {
                        "family": "Talafidaryani",
                        "given": "Mojtaba"
                    },
                    {
                        "family": "Khabiri",
                        "given": "SeyedHossein"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            1,
                            10
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            1,
                            10
                        ]
                    ]
                },
                "abstract": "Huge sources of business value are emerging due to big data generated by the Internet of Things (IoT) technologies paired with Machine Learning (ML) and Data Mining (DM) techniques' ability to harness and extract hidden knowledge from data and consequently learning and improving spontaneously. This paper reviews different examples of analyzing big data generated through IoT in previous studies and in various domains; then claims their business Value Proposition Map deploying Value Proposition Canvas as a novel conceptual tool. As a result, the proposed unprecedented framework of this paper entitled \"IoT Big Data Value Map\" shows a roadmap from raw data to real-world business value creation, blossomed out of a kind of three-pillar structure: IoT, Data Mining, and Value Proposition Map. The result of this study paves the way for prototyping business models in this field based on value invention from huge data analysis generated by IoT devices in different industries. Furthermore, researchers may complete this map by associating proposed framework with potential customers' profile and their expectations.",
                "call-number": "10.1145/3312714.3312728",
                "collection-title": "ICSLT '19",
                "container-title": "Proceedings of the 5th International Conference on e-Society, e-Learning and e-Technologies",
                "DOI": "10.1145/3312714.3312728",
                "event-place": "Vienna, Austria",
                "ISBN": "9781450362351",
                "keyword": "IoT Big Data Value Map, Value Proposition Canvas, Value Proposition Map, Internet of Things (IoT), Data Mining",
                "number-of-pages": "6",
                "page": "98–103",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "IoT Big Data Value Map: How to Generate Value from IoT Data",
                "URL": "https://doi.org/10.1145/3312714.3312728"
            }
        },
        {
            "10.1145/3209415.3209479": {
                "id": "10.1145/3209415.3209479",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kudo",
                        "given": "Hiroko"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            4,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            4,
                            4
                        ]
                    ]
                },
                "abstract": "This paper investigates into a question through a failure case. The research question is; why we often fail to use the existing information and knowledge, including big data to design and/or implement public policies? The case is; the ticketing data, which was collected during the London Olympic Games and its so far under usage to design public policy related to health, well-being, and physical activities of the citizens. The research adopts qualitative analysis, including analysis of primary documents and semi-directive interviews. There is a limitation of single case study: however the case well represents the research question to provide preliminary investigation and to generate hypotheses for further studies.",
                "call-number": "10.1145/3209415.3209479",
                "collection-title": "ICEGOV '18",
                "container-title": "Proceedings of the 11th International Conference on Theory and Practice of Electronic Governance",
                "DOI": "10.1145/3209415.3209479",
                "event-place": "Galway, Ireland",
                "ISBN": "9781450354219",
                "keyword": "government failure, policy design, evidence-based policy making, government policy, Big Data",
                "number-of-pages": "7",
                "page": "609–615",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Bridging Big Data and Policy Making: A case study of failure",
                "URL": "https://doi.org/10.1145/3209415.3209479"
            }
        },
        {
            "10.1145/3546632.3546889": {
                "id": "10.1145/3546632.3546889",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Gu",
                        "given": "Wenjie"
                    },
                    {
                        "family": "Jia",
                        "given": "Shuangying"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            6,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            6,
                            18
                        ]
                    ]
                },
                "abstract": "As a virtualized resource realization mode, Hadoop cloud platform has become an open-source cloud computing architecture and big data analysis platform. The platform plays a pivotal role in the information field, but the security mechanism of the Hadoop cloud computing platform is relatively fragile. Users are concerned about privacy leakage using which severely restricts the application rate of Hadoop cloud computing platform. This paper conducts research and analysis on big data security and privacy protection technology under cloud computing, and proposes a strategy based on optimizing Hadoop security mechanism, from Hadoop platform identity authentication, Hadoop platform access authorization, Hadoop platform big data encryption security integrated mechanism to architecture, and implement the Hadoop platform, A big data security strategy of Hadoop provides technical support for enterprise applications with security requirements on the Hadoop platform.",
                "call-number": "10.1145/3546632.3546889",
                "collection-title": "CIUP '22",
                "container-title": "Proceedings of the 2022 International Conference on Computational Infrastructure and Urban Planning",
                "DOI": "10.1145/3546632.3546889",
                "event-place": "Nanchang, China",
                "ISBN": "9781450396363",
                "keyword": "Hadoop platform, Big data, security mechanism, cloud computing",
                "number-of-pages": "4",
                "page": "115–118",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on Security Mechanism of Hadoop Big Data Platform",
                "URL": "https://doi.org/10.1145/3546632.3546889"
            }
        },
        {
            "10.1145/3436829.3436838": {
                "id": "10.1145/3436829.3436838",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Maata",
                        "given": "Rolou Lyn R."
                    },
                    {
                        "family": "Cordova",
                        "given": "Ronald S."
                    },
                    {
                        "family": "Halibas",
                        "given": "Alrence"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            11,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            11,
                            11
                        ]
                    ]
                },
                "abstract": "Information security in big data plays a vital role in today's modern era of computing. It has become significant issue due to the popularity of Internet, free access of internet and data, online businesses, and communication technologies that have been emerged tremendously, making them a potential computer security threats. In order to overcome these threats, modern data communication uses cryptography as a technique to secure big data transmission efficiently and effectively. This paper aims to demonstrate the process of encryption and decryption of different big datasets and compare its results in terms of message size and time. There are seven (7) different big data files that have been loaded in a Java Netbeans twosifh algorithm program that includes app store, interactions train, border crossing, PP users, PP recipes, raw recipes and raw interactions for simulation purposes. The main purpose of simulation is to record the accuracy and efficiency of big data files used. The results of the simulation were recorded, compared, and analyzed to create valuable contribution to information security.",
                "call-number": "10.1145/3436829.3436838",
                "collection-title": "ICSIE 2020",
                "container-title": "Proceedings of the 2020 9th International Conference on Software and Information Engineering (ICSIE)",
                "DOI": "10.1145/3436829.3436838",
                "event-place": "Cairo, Egypt",
                "ISBN": "9781450377218",
                "keyword": "Big data, twofish algorithm, computer security",
                "number-of-pages": "5",
                "page": "56–60",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Performance Analysis of Twofish Cryptography Algorithm in Big Data",
                "URL": "https://doi.org/10.1145/3436829.3436838"
            }
        },
        {
            "10.1145/3524383.3524401": {
                "id": "10.1145/3524383.3524401",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhang",
                        "given": "Xiaoling"
                    },
                    {
                        "family": "Ren",
                        "given": "Weixin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            2,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            2,
                            26
                        ]
                    ]
                },
                "abstract": "Heart-to-heart talk education evolved from the dialogue teaching method of Confucius and heuristic teaching method (“midwifery”) of Socrates. With the increase of academic and psychological pressure of college students, heart-to-heart talk education has become an important way for colleges and universities to carry out ideological education and emotional counseling. And with the in-depth development of big data, the effectiveness and scientific nature of heart-to-heart talk education have been significantly improved. On the other hand, conducting heart-to-heart talk education with the help of big data technology also faces more technical and ethical challenges. Investigation and analysis shows that there are still problems such as lag, singleness, and randomness in heart-to-heart talks in the context of big data. To solve this problem, this paper proposes countermeasures from four aspects: platform construction, team building, application process, and data supervision to build a long-term mechanism for college students' heart-to-heart talks, which is of great significance for promoting the in-depth application of big data in the field of education and the innovative development of heart-to-heart talk education method.",
                "call-number": "10.1145/3524383.3524401",
                "collection-title": "ICBDE '22",
                "container-title": "Proceedings of the 5th International Conference on Big Data and Education",
                "DOI": "10.1145/3524383.3524401",
                "event-place": "Shanghai, China",
                "ISBN": "9781450395793",
                "keyword": "Long-term mechanism, Big data, College students;Heart-to-heart talk education",
                "number-of-pages": "5",
                "page": "189–193",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on the Long-term Mechanism Construction of College Students' “Heart-to-heart Talk Education” in the Era of Big Data",
                "URL": "https://doi.org/10.1145/3524383.3524401"
            }
        },
        {
            "10.1145/2642937.2643006": {
                "id": "10.1145/2642937.2643006",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "James Stephen",
                        "given": "Julian"
                    },
                    {
                        "family": "Savvides",
                        "given": "Savvas"
                    },
                    {
                        "family": "Seidel",
                        "given": "Russell"
                    },
                    {
                        "family": "Eugster",
                        "given": "Patrick"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            15
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            15
                        ]
                    ]
                },
                "abstract": "The ubiquitous nature of computers is driving a massive increase in the amount of data generated by humans and machines. Two natural consequences of this are the increased efforts to (a) derive meaningful information from accumulated data and (b) ensure that data is not used for unintended purposes. In the direction of analyzing massive amounts of data (a.), tools like MapReduce, Spark, Dryad and higher level scripting languages like Pig Latin and DryadLINQ have significantly improved corresponding tasks for software developers. The second, but equally important aspect of ensuring confidentiality (b.), has seen little support emerge for programmers: while advances in cryptographic techniques allow us to process directly on encrypted data, programmer-friendly and efficient ways of programming such data analysis jobs are still missing. This paper presents novel data flow analyses and program transformations for Pig Latin, that automatically enable the execution of corresponding scripts on encrypted data. We avoid fully homomorphic encryption because of its prohibitively high cost; instead, in some cases, we rely on a minimal set of operations performed by the client. We present the algorithms used for this translation, and empirically demonstrate the practical performance of our approach as well as improvements for programmers in terms of the effort required to preserve data confidentiality.",
                "call-number": "10.1145/2642937.2643006",
                "collection-title": "ASE '14",
                "container-title": "Proceedings of the 29th ACM/IEEE international conference on Automated software engineering",
                "DOI": "10.1145/2642937.2643006",
                "event-place": "Vasteras, Sweden",
                "ISBN": "9781450330138",
                "keyword": "cloud computing, privacy, big data",
                "number-of-pages": "12",
                "page": "277–288",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Program analysis for secure big data processing",
                "URL": "https://doi.org/10.1145/2642937.2643006"
            }
        },
        {
            "10.1145/3524383.3524393": {
                "id": "10.1145/3524383.3524393",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Liang",
                        "given": "Mingming"
                    },
                    {
                        "family": "Zhang",
                        "given": "Yuqing"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            2,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            2,
                            26
                        ]
                    ]
                },
                "abstract": "The COVID-19 pandemic imposes a tremendous burden upon society. Several studies have documented stressors and fears of COVID-19 for adult populations, but few studies pay attention to the COVID-19 stressors on children and adolescents. Assessing the stressors of COVID-19 on children and adolescents can provide the basis for interventions to bring children and adolescents' mental health \"out of the shadows.\" Entering the Era of \"Big Data,\" the psychological state can be assessed through integrative analysis of data. This study adopted a whole-group sampling method. After a new round of the COVID-19 epidemic caused by imported cases in Jiangsu and Fujian provinces of China, self-report questionnaires were sent to children and adolescents aged 10–18 years. 1815 valid questionnaires were collected. Data analysis was performed using SPSS and AMOS software (version 26). To revise and test the reliability and validity of the COVID-19 stressors scale for children and adolescents, as well as to investigate the differences in stressors between rural and urban based on Big-Data Mining. The results of this study indicate that the revised COVID-19 stressors scale, which includes a four-factor model of disease stressors, information stressors, measure stressors, and environmental stressors, has good reliability and validity for children and adolescents aged 10–18 years in a Chinese context. Big data-based demographic analysis showed that children and adolescents living in urban areas were generally less stressed about the COVID-19 epidemic than in rural areas.",
                "call-number": "10.1145/3524383.3524393",
                "collection-title": "ICBDE '22",
                "container-title": "Proceedings of the 5th International Conference on Big Data and Education",
                "DOI": "10.1145/3524383.3524393",
                "event-place": "Shanghai, China",
                "ISBN": "9781450395793",
                "keyword": "big data, adolescents, children, COVID-19 stressors",
                "number-of-pages": "6",
                "page": "387–392",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Revision of the child and adolescent COVID-19 stressors scale and Big Data-Based Analysis of Disparities in Urban and Rural Areas",
                "URL": "https://doi.org/10.1145/3524383.3524393"
            }
        },
        {
            "10.1145/2660168.2660187": {
                "id": "10.1145/2660168.2660187",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Weyde",
                        "given": "Tillman"
                    },
                    {
                        "family": "Cottrell",
                        "given": "Stephen"
                    },
                    {
                        "family": "Dykes",
                        "given": "Jason"
                    },
                    {
                        "family": "Benetos",
                        "given": "Emmanouil"
                    },
                    {
                        "family": "Wolff",
                        "given": "Daniel"
                    },
                    {
                        "family": "Tidhar",
                        "given": "Dan"
                    },
                    {
                        "family": "Kachkaev",
                        "given": "Alexander"
                    },
                    {
                        "family": "Plumbley",
                        "given": "Mark"
                    },
                    {
                        "family": "Dixon",
                        "given": "Simon"
                    },
                    {
                        "family": "Barthet",
                        "given": "Mathieu"
                    },
                    {
                        "family": "Gold",
                        "given": "Nicolas"
                    },
                    {
                        "family": "Abdallah",
                        "given": "Samer"
                    },
                    {
                        "family": "Alancar-Brayner",
                        "given": "Aquiles"
                    },
                    {
                        "family": "Mahey",
                        "given": "Mahendra"
                    },
                    {
                        "family": "Tovell",
                        "given": "Adam"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            12
                        ]
                    ]
                },
                "abstract": "Digital music libraries and collections are growing quickly and are increasingly made available for research. We argue that the use of large data collections will enable a better understanding of music performance and music in general, which will benefit areas such as music search and recommendation, music archiving and indexing, music production and education. However, to achieve these goals it is necessary to develop new musicological research methods, to create and adapt the necessary technological infrastructure, and to find ways of working with legal limitations. Most of the necessary basic technologies exist, but they need to be brought together and applied to musicology. We aim to address these challenges in the Digital Music Lab project, and we feel that with suitable methods and technology Big Music Data can provide new opportunities to musicology.",
                "call-number": "10.1145/2660168.2660187",
                "collection-title": "DLfM '14",
                "container-title": "Proceedings of the 1st International Workshop on Digital Libraries for Musicology",
                "DOI": "10.1145/2660168.2660187",
                "event-place": "London, United Kingdom",
                "ISBN": "9781450330022",
                "number-of-pages": "3",
                "page": "1–3",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data for Musicology",
                "URL": "https://doi.org/10.1145/2660168.2660187"
            }
        },
        {
            "10.1145/3337065": {
                "id": "10.1145/3337065",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Dai",
                        "given": "Hong-Ning"
                    },
                    {
                        "family": "Wong",
                        "given": "Raymond Chi-Wing"
                    },
                    {
                        "family": "Wang",
                        "given": "Hao"
                    },
                    {
                        "family": "Zheng",
                        "given": "Zibin"
                    },
                    {
                        "family": "Vasilakos",
                        "given": "Athanasios V."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            9,
                            13
                        ]
                    ]
                },
                "abstract": "The wide proliferation of various wireless communication systems and wireless devices has led to the arrival of big data era in large-scale wireless networks. Big data of large-scale wireless networks has the key features of wide variety, high volume, real-time velocity, and huge value leading to the unique research challenges that are different from existing computing systems. In this article, we present a survey of the state-of-art big data analytics (BDA) approaches for large-scale wireless networks. In particular, we categorize the life cycle of BDA into four consecutive stages: Data Acquisition, Data Preprocessing, Data Storage, and Data Analytics. We then present a detailed survey of the technical solutions to the challenges in BDA for large-scale wireless networks according to each stage in the life cycle of BDA. Moreover, we discuss the open research issues and outline the future directions in this promising area.",
                "call-number": "10.1145/3337065",
                "collection-number": "99",
                "container-title": "ACM Comput. Surv.",
                "DOI": "10.1145/3337065",
                "ISSN": "0360-0300",
                "issue": "5",
                "keyword": "wireless networks, machine learning, Big data",
                "number": "Article 99",
                "number-of-pages": "36",
                "page": "1–36",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "September 2020",
                "title": "Big Data Analytics for Large-scale Wireless Networks: Challenges and Opportunities",
                "URL": "https://doi.org/10.1145/3337065",
                "volume": "52"
            }
        },
        {
            "10.1145/3502300": {
                "id": "10.1145/3502300",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2021
                        ]
                    ]
                },
                "call-number": "10.1145/3502300",
                "container-title-short": "BDSIC 2021",
                "event-place": "Xiamen, China",
                "genre": "proceeding",
                "ISBN": "9781450390552",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "2021 3rd International Conference on Big-data Service and Intelligent Computation"
            }
        },
        {
            "10.1145/2592267": {
                "id": "10.1145/2592267",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Bean",
                        "given": "Jonathan"
                    },
                    {
                        "family": "Rosner",
                        "given": "Daniela"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            5,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/2592267",
                "container-title": "interactions",
                "DOI": "10.1145/2592267",
                "ISSN": "1072-5520",
                "issue": "3",
                "number-of-pages": "2",
                "page": "18–19",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "May-June 2014",
                "title": "Big data, diminished design?",
                "URL": "https://doi.org/10.1145/2592267",
                "volume": "21"
            }
        },
        {
            "10.1145/3440054": {
                "id": "10.1145/3440054",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2020
                        ]
                    ]
                },
                "call-number": "10.1145/3440054",
                "container-title-short": "BDSIC 2020",
                "event-place": "Xiamen, China",
                "genre": "proceeding",
                "ISBN": "9781450388399",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "2020 2nd International Conference on Big-data Service and Intelligent Computation"
            }
        },
        {
            "10.1145/2623330.2623615": {
                "id": "10.1145/2623330.2623615",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Anagnostopoulos",
                        "given": "Christos"
                    },
                    {
                        "family": "Triantafillou",
                        "given": "Peter"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            24
                        ]
                    ]
                },
                "abstract": "Solving the missing-value (MV) problem with small estimation errors in big data environments is a notoriously resource-demanding task. As datasets and their user community continuously grow, the problem can only be exacerbated. Assume that it is possible to have a single machine (`Godzilla'), which can store the massive dataset and support an ever-growing community submitting MV imputation requests. Is it possible to replace Godzilla by employing a large number of cohort machines so that imputations can be performed much faster, engaging cohorts in parallel, each of which accesses much smaller partitions of the original dataset? If so, it would be preferable for obvious performance reasons to access only a subset of all cohorts per imputation. In this case, can we decide swiftly which is the desired subset of cohorts to engage per imputation? But efficiency and scalability is just one key concern! Is it possible to do the above while ensuring comparable or even better than Godzilla's imputation estimation errors? In this paper we derive answers to these fundamentals questions and develop principled methods and a framework which offer large performance speed-ups and better, or comparable, errors to that of Godzilla, independently of which missing-value imputation algorithm is used. Our contributions involve Pythia, a framework and algorithms for providing the answers to the above questions and for engaging the appropriate subset of cohorts per MV imputation request. Pythia functionality rests on two pillars: (i) dataset (partition) signatures, one per cohort, and (ii) similarity notions and algorithms, which can identify the appropriate subset of cohorts to engage. Comprehensive experimentation with real and synthetic datasets showcase our efficiency, scalability, and accuracy claims.",
                "call-number": "10.1145/2623330.2623615",
                "collection-title": "KDD '14",
                "container-title": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining",
                "DOI": "10.1145/2623330.2623615",
                "event-place": "New York, New York, USA",
                "ISBN": "9781450329569",
                "keyword": "clustering, big data, missing value",
                "number-of-pages": "10",
                "page": "651–660",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Scaling out big data missing value imputations: pythia vs. godzilla",
                "URL": "https://doi.org/10.1145/2623330.2623615"
            }
        },
        {
            "10.1145/3205651.3205701": {
                "id": "10.1145/3205651.3205701",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Dagdia",
                        "given": "Zaineb Chelly"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            7,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            7,
                            6
                        ]
                    ]
                },
                "abstract": "In this work, we focus on the Dendritic Cell Algorithm (DCA), a bio-inspired classifier, and its limitation when coping with very large datasets. To overcome this limitation, we propose a novel distributed DCA version for data classification based on the MapReduce framework to distribute the functioning of this algorithm through a cluster of computing elements. Our experimental results show that our proposed distributed solution is suitable to enhance the performance of the DCA enabling the algorithm to be applied over big data classification problems.",
                "call-number": "10.1145/3205651.3205701",
                "collection-title": "GECCO '18",
                "container-title": "Proceedings of the Genetic and Evolutionary Computation Conference Companion",
                "DOI": "10.1145/3205651.3205701",
                "event-place": "Kyoto, Japan",
                "ISBN": "9781450357647",
                "keyword": "classification, distributed processing, big data, dendritic cell algorithm, scalability",
                "number-of-pages": "2",
                "page": "103–104",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A distributed dendritic cell algorithm for big data",
                "URL": "https://doi.org/10.1145/3205651.3205701"
            }
        },
        {
            "10.1145/3185768.3186300": {
                "id": "10.1145/3185768.3186300",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Ivanov",
                        "given": "Todor"
                    },
                    {
                        "family": "Singhal",
                        "given": "Rekha"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            4,
                            2
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            4,
                            2
                        ]
                    ]
                },
                "abstract": "Distributed big data processing and analytics applications demand a comprehensive end-to-end architecture stack consisting of big data technologies. However, there are many possible architecture patterns (e.g. Lambda, Kappa or Pipeline architectures) to choose from when implementing the application requirements. A big data technology in isolation may be best performing for a particular application, but its performance in connection with other technologies depends on the connectors and the environment. Similarly, existing big data benchmarks evaluate the performance of different technologies in isolation, but no work has been done on benchmarking big data architecture stacks as a whole. For example, BigBench (TPCx-BB) may be used to evaluate the performance of Spark, but is it applicable to PySpark or to Spark with Kafka stack as well? What is the impact of having different programming environments and/or any other technology like Spark? This vision paper proposes a new category of benchmark, called ABench, to fill this gap and discusses key aspects necessary for the performance evaluation of different big data architecture stacks.",
                "call-number": "10.1145/3185768.3186300",
                "collection-title": "ICPE '18",
                "container-title": "Companion of the 2018 ACM/SPEC International Conference on Performance Engineering",
                "DOI": "10.1145/3185768.3186300",
                "event-place": "Berlin, Germany",
                "ISBN": "9781450356299",
                "keyword": "bigbench, ABench, big data benchmarking, big data",
                "number-of-pages": "4",
                "page": "13–16",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "ABench: Big Data Architecture Stack Benchmark",
                "URL": "https://doi.org/10.1145/3185768.3186300"
            }
        },
        {
            "10.1145/3340531.3412173": {
                "id": "10.1145/3340531.3412173",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Song",
                        "given": "Shaoxu"
                    },
                    {
                        "family": "Zhang",
                        "given": "Aoqian"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            10,
                            19
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            10,
                            19
                        ]
                    ]
                },
                "abstract": "Data quality issues have been widely recognized in IoT data, and prevent the downstream applications. In this tutorial, we review the state-of-the-art techniques for IoT data quality management. In particular, we discuss how the dedicated approaches improve various data quality dimensions, including validity, completeness and consistency. Among others, we further highlight the recent advances by deep learning techniques for IoT data quality. Finally, we indicate the open problems in IoT data quality management, such as benchmark or interpretation of data quality issues.",
                "call-number": "10.1145/3340531.3412173",
                "collection-title": "CIKM '20",
                "container-title": "Proceedings of the 29th ACM International Conference on Information & Knowledge Management",
                "DOI": "10.1145/3340531.3412173",
                "event-place": "Virtual Event, Ireland",
                "ISBN": "9781450368599",
                "keyword": "internet of things, data curation",
                "number-of-pages": "2",
                "page": "3517–3518",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "IoT Data Quality",
                "URL": "https://doi.org/10.1145/3340531.3412173"
            }
        },
        {
            "10.1145/3178315.3178323": {
                "id": "10.1145/3178315.3178323",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Arruda",
                        "given": "Darlan"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            3,
                            28
                        ]
                    ]
                },
                "abstract": "Requirements Engineering (RE) plays an essential role in the software engineering process, being considered as one of the most critical phases of the software development life-cycle. As we might expect, then, the Requirements Engineering would play a similar role in the context of Big Data applications. However, practicing Requirements Engineering is a challenging and complex task. It involves (i) stakeholders with diverse backgrounds and levels of knowledge, (ii) different application domains, (iii) it is expensive and error-prone, (iii) it is important to be aligned with business goals, to name a few. Because it involves such complex activities, a lot has to be understood in order to properly address Requirements Engineering. Especially, when the technology domain (e.g., Big Data) is not yet well explored. In this context, this paper describes a research plan on Requirements Engineering involving the development of Big Data applications. The high-level goal is to investigate: (i) On the technical front, the Requirements Engineering activities with respect to the analysis and specification of Big Data requirements and, (ii) on the management side, the relationship between RE and Business Goals in the development of Big Data Software applications.",
                "call-number": "10.1145/3178315.3178323",
                "container-title": "SIGSOFT Softw. Eng. Notes",
                "DOI": "10.1145/3178315.3178323",
                "ISSN": "0163-5948",
                "issue": "1",
                "keyword": "business goals, empirical software engineering., big data applications, empirical studies, big data requirements engineering",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "January 2018",
                "title": "Requirements Engineering in the Context of Big Data Applications",
                "URL": "https://doi.org/10.1145/3178315.3178323",
                "volume": "43"
            }
        },
        {
            "10.1145/3305275": {
                "id": "10.1145/3305275",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2018
                        ]
                    ]
                },
                "call-number": "10.1145/3305275",
                "container-title-short": "ISBDAI '18",
                "event-place": "Hong Kong, Hong Kong",
                "genre": "proceeding",
                "ISBN": "9781450365703",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the International Symposium on Big Data and Artificial Intelligence"
            }
        },
        {
            "10.1145/3264560": {
                "id": "10.1145/3264560",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2018
                        ]
                    ]
                },
                "abstract": "ICCBDC 2018 and ICIIP 2018 provide a scientific platform for both local and international scientists, engineers and technologists who work in all aspects of cloud and big data computing, and intelligent information processing. In addition to the contributed papers, Prof. Hong Zhu from Oxford Brookes University, UK, Assoc. Prof. Huseyin Seker form the University of Northumbria at Newcastle, UK and Prof. Alfredo Cuzzocrea form University of Trieste, Italy were invited to deliver keynote speeches at ICCBDC 2018 2018 and ICIIP 2018.",
                "call-number": "10.1145/3264560",
                "container-title-short": "ICCBDC'18",
                "event-place": "Barcelona, Spain",
                "genre": "proceeding",
                "ISBN": "9781450364744",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2018 2nd International Conference on Cloud and Big Data Computing"
            }
        },
        {
            "10.1145/3507485.3507487": {
                "id": "10.1145/3507485.3507487",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Eltweri",
                        "given": "Ahmed"
                    },
                    {
                        "family": "Faccia",
                        "given": "Alessio"
                    },
                    {
                        "family": "Sawan",
                        "given": "Nedal"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            12,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            12,
                            3
                        ]
                    ]
                },
                "abstract": "Many achievements using big data are recorded in the vast majority of industrial sectors, accounting is no different, so big data is ubiquitous. The presence of big data within the practice of auditing is still at an early stage. A reliance upon technological tools, however, has resulted in the implementation of computer-assisted auditing techniques. This study, then, based on qualitative analyses, highlights how big data visualisations may assist the evaluation of auditors’ evidence so that data can be retrieved in ways that help produce professional judgments.",
                "call-number": "10.1145/3507485.3507487",
                "collection-title": "ICSEB 2021",
                "container-title": "2021 5th International Conference on Software and e-Business (ICSEB)",
                "DOI": "10.1145/3507485.3507487",
                "event-place": "Osaka, Japan",
                "ISBN": "9781450385831",
                "keyword": "IT, Auditor Judgment, Data Visualizations, Auditing Profession, Big Data",
                "number-of-pages": "6",
                "page": "7–12",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The Importance of Big Data Visualisations for Auditors’ Decisions",
                "URL": "https://doi.org/10.1145/3507485.3507487"
            }
        },
        {
            "10.1145/2756406.2756924": {
                "id": "10.1145/2756406.2756924",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Xie",
                        "given": "Zhiwu"
                    },
                    {
                        "family": "Chen",
                        "given": "Yinlin"
                    },
                    {
                        "family": "Speer",
                        "given": "Julie"
                    },
                    {
                        "family": "Walters",
                        "given": "Tyler"
                    },
                    {
                        "family": "Tarazaga",
                        "given": "Pablo A."
                    },
                    {
                        "family": "Kasarda",
                        "given": "Mary"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            21
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            21
                        ]
                    ]
                },
                "abstract": "We propose a use and reuse driven big data management approach that fuses the data repository and data processing capabilities in a co-located, public cloud. It answers to the urgent data management needs from the growing number of researchers who don't fit in the big science/small science dichotomy. This approach will allow researchers to more easily use, manage, and collaborate around big data sets, as well as give librarians the opportunity to work alongside the researchers to preserve and curate data while it is still fresh and being actively used. This also provides the technological foundation to foster a sharing culture more aligned with the open source software development paradigm than the lone-wolf, gift-exchanging small science sharing or the top-down, highly structured big science sharing. To materialize this vision, we provide a system architecture consisting of a scalable digital repository system coupled with the co-located cloud storage and cloud computing, as well as a job scheduler and a deployment management system. Motivated by Virginia Tech's Goodwin Hall instrumentation project, we implemented and evaluated a prototype. The results show not only sufficient capacities for this particular case, but also near perfect linear storage and data processing scalabilities under moderately high workload.",
                "call-number": "10.1145/2756406.2756924",
                "collection-title": "JCDL '15",
                "container-title": "Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries",
                "DOI": "10.1145/2756406.2756924",
                "event-place": "Knoxville, Tennessee, USA",
                "ISBN": "9781450335942",
                "keyword": "digital repository, big data, digital library, smart infrastructure, sensor data, cloud computing",
                "number-of-pages": "10",
                "page": "65–74",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Towards Use And Reuse Driven Big Data Management",
                "URL": "https://doi.org/10.1145/2756406.2756924"
            }
        },
        {
            "10.1145/2611567": {
                "id": "10.1145/2611567",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Jagadish",
                        "given": "H. V."
                    },
                    {
                        "family": "Gehrke",
                        "given": "Johannes"
                    },
                    {
                        "family": "Labrinidis",
                        "given": "Alexandros"
                    },
                    {
                        "family": "Papakonstantinou",
                        "given": "Yannis"
                    },
                    {
                        "family": "Patel",
                        "given": "Jignesh M."
                    },
                    {
                        "family": "Ramakrishnan",
                        "given": "Raghu"
                    },
                    {
                        "family": "Shahabi",
                        "given": "Cyrus"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            7,
                            1
                        ]
                    ]
                },
                "abstract": "Exploring the inherent technical challenges in realizing the potential of Big Data.",
                "call-number": "10.1145/2611567",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/2611567",
                "ISSN": "0001-0782",
                "issue": "7",
                "number-of-pages": "9",
                "page": "86–94",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "July 2014",
                "title": "Big data and its technical challenges",
                "URL": "https://doi.org/10.1145/2611567",
                "volume": "57"
            }
        },
        {
            "10.1145/3158341": {
                "id": "10.1145/3158341",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Penkler",
                        "given": "Dave"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            1,
                            30
                        ]
                    ]
                },
                "abstract": "The early digital economy during the dot-com days of internet commerce successfully faced its first big data challenges of click-stream analysis with map-reduce technology. Since then the digital economy has been becoming much more pervasive. As the digital economy evolves, looking to benefit from its burgeoning big data assets, an important technical-business challenge is emerging: How to acquire, store, access, and exploit the data at a cost that is lower than the incremental revenue or GDP that its exploitation generates. Especially now that efficiency increases, which lasted for 50 years thanks to improvements in semiconductor manufacturing, is slowing and coming to an end.",
                "call-number": "10.1145/3158341",
                "collection-number": "3",
                "container-title": "Ubiquity",
                "DOI": "10.1145/3158341",
                "issue": "January",
                "number": "Article 3",
                "number-of-pages": "9",
                "page": "1–9",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "January 2018",
                "title": "Technology and Business Challenges of Big Data in the Digital Economy: Big Data (Ubiquity symposium)",
                "URL": "https://doi.org/10.1145/3158341",
                "volume": "2018"
            }
        },
        {
            "10.1145/3291801.3291816": {
                "id": "10.1145/3291801.3291816",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sidibé",
                        "given": "Abdoulaye"
                    },
                    {
                        "family": "Shu",
                        "given": "Gao"
                    },
                    {
                        "family": "Ma",
                        "given": "Yunzhao"
                    },
                    {
                        "family": "Wanqi",
                        "given": "Wei"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            27
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            27
                        ]
                    ]
                },
                "abstract": "In the maintaining of inland navigational safety and security, the automatic detection of anomalous vessels trajectory behavior from a large amount of vessels traffic datasets produced by automatic identification systems (AIS) is an interesting task, and in another hand constitutes a challenge because of the size of the AIS data. In this paper we propose a new big data framework based on the Adaptive Kernel Density Estimation (AKDE) method, for abnormal vessel trajectory detection using Apache Spark. In the proposed framework, first, the water area is divided into space partitions. Second, on the Apache Spark distributed computing platform, the AKDE method is used to build in a parallel manner local models of normal vessels trajectory data for space partitions, as probability density functions (PDFs). Finally, the detection of abnormal trajectory data point is performed based on the corresponding built local models, by sequentially checking the real incoming trajectory data point. And a trajectory with a user-defined number of abnormal data points is considered to be an abnormal trajectory. In addition, we discuss the main features and some limitations of the proposed framework.",
                "call-number": "10.1145/3291801.3291816",
                "collection-title": "ICBDR 2018",
                "container-title": "Proceedings of the 2nd International Conference on Big Data Research",
                "DOI": "10.1145/3291801.3291816",
                "event-place": "Weihai, China",
                "ISBN": "9781450364768",
                "keyword": "AIS, Kernel Density Estimation, Apache Spark, Anomaly detection, Vessel Trajectory",
                "number-of-pages": "4",
                "page": "43–46",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data Framework for Abnormal Vessel Trajectories Detection using Adaptive Kernel Density Estimation",
                "URL": "https://doi.org/10.1145/3291801.3291816"
            }
        },
        {
            "10.1145/3481646": {
                "id": "10.1145/3481646",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2021
                        ]
                    ]
                },
                "call-number": "10.1145/3481646",
                "container-title-short": "ICCBDC 2021",
                "event-place": "Liverpool, United Kingdom",
                "genre": "proceeding",
                "ISBN": "9781450390408",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "2021 5th International Conference on Cloud and Big Data Computing (ICCBDC)"
            }
        },
        {
            "10.1145/2756406.2756943": {
                "id": "10.1145/2756406.2756943",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kanan",
                        "given": "Tarek"
                    },
                    {
                        "family": "Zhang",
                        "given": "Xuan"
                    },
                    {
                        "family": "Magdy",
                        "given": "Mohamed"
                    },
                    {
                        "family": "Fox",
                        "given": "Edward"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            21
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            21
                        ]
                    ]
                },
                "abstract": "Problem/project Based Learning (PBL) is a highly effective student-centered teaching method, where student teams learn by solving problems. This paper describes an instance of PBL applied to digital library education. We show the design, implementation, results, and partial evaluation of a Computational Linguistics course that provides students an opportunity to engage in active learning about adding value to digital libraries with large collections of text, i.e., one aspect of \"big data.\" Students are engaging in PBL with the semester long challenge of generating good English summaries of an event, given a large collection from our webpage archives. Six teams, each working with a different type of event, and applying three different summarization methods, learned how to generate good summaries; these have fair precision relative to the Wikipedia page that describes their event.",
                "call-number": "10.1145/2756406.2756943",
                "collection-title": "JCDL '15",
                "container-title": "Proceedings of the 15th ACM/IEEE-CS Joint Conference on Digital Libraries",
                "DOI": "10.1145/2756406.2756943",
                "event-place": "Knoxville, Tennessee, USA",
                "ISBN": "9781450335942",
                "keyword": "big data, problem based learning, text summarization, digital libraries, computational linguistics",
                "number-of-pages": "4",
                "page": "87–90",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data Text Summarization for Events: A Problem Based Learning Course",
                "URL": "https://doi.org/10.1145/2756406.2756943"
            }
        },
        {
            "10.1145/3524383": {
                "id": "10.1145/3524383",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2022
                        ]
                    ]
                },
                "call-number": "10.1145/3524383",
                "container-title-short": "ICBDE '22",
                "event-place": "Shanghai, China",
                "genre": "proceeding",
                "ISBN": "9781450395793",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 5th International Conference on Big Data and Education"
            }
        },
        {
            "10.1145/3152723.3152728": {
                "id": "10.1145/3152723.3152728",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Xiao",
                        "given": "Yan"
                    },
                    {
                        "family": "Fan",
                        "given": "Xixuan"
                    },
                    {
                        "family": "Dong",
                        "given": "Li"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            10,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            10,
                            22
                        ]
                    ]
                },
                "abstract": "Street as traffic carrier and public space of a city are playing increasingly important role in daily city life. The paper quantitatively explores vibrancy of Commercial Street, while referring to urban space syntax analysis method, taking Dalian as an example. The paper also explores the factors influencing the dynamic commercial block space based on poi, function density and function diversity, so as to provide theoretical guidance for the planning and design of the commercial block.",
                "call-number": "10.1145/3152723.3152728",
                "collection-title": "ICBDR 2017",
                "container-title": "Proceedings of the 2017 International Conference on Big Data Research",
                "DOI": "10.1145/3152723.3152728",
                "event-place": "Osaka, Japan",
                "ISBN": "9781450353564",
                "keyword": "Commercial Street, Point of Interest, Function Density, Data Augmented Design, Function Diversity",
                "number-of-pages": "5",
                "page": "7–11",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Quantitative Study on Commercial Street Vibrancy Based on Big Data: A Case of Dalian",
                "URL": "https://doi.org/10.1145/3152723.3152728"
            }
        },
        {
            "10.1145/2627770.2627773": {
                "id": "10.1145/2627770.2627773",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chatziantoniou",
                        "given": "Damianos"
                    },
                    {
                        "family": "Tselai",
                        "given": "Florents"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            22
                        ]
                    ]
                },
                "abstract": "Until recently, when relational systems was the main data management option and SQL the de facto language for querying/analyzing data, ODBC was an excellent API for applications to interact with the data provider. Standardization of data retrieval has helped innovation and productivity, allowing application developers to focus on the core of their ideas. However, the big data era added variety to all aspects of data facilitation: variety in data management options, variety in data formats, variety in querying/analyzing tasks. In this chaotic situation, standardizing data connectivity is more important than ever. What should be the replacement of ODBC? In this paper, we propose ODMC (Open Data Management Connectivity), a client-server protocol between data management entities (DMEs). A DME is anything that manages/manipulates data. In that respect, spreadsheets, java programs, Hadoop, RDBMs, stream engines, NoSQL, etc., all act as DMEs. In addition, there is no distinction between applications and data management servers, as in ODBC. A DME can be a data consumer in an ODMC instance and a data producer in another. This composability principle allows for the definition of analysis workflows. We present a preliminary implementation of ODMC for python-based DMEs. We argue that ODMC is simple, intuitive, scalable and suitable for both persistent and stream data.",
                "call-number": "10.1145/2627770.2627773",
                "collection-title": "DanaC'14",
                "container-title": "Proceedings of Workshop on Data analytics in the Cloud",
                "DOI": "10.1145/2627770.2627773",
                "event-place": "Snowbird, UT, USA",
                "ISBN": "9781450329972",
                "keyword": "open data management connectivity, big data interoperability, big data integration, big data web, data connectivity, ODMC",
                "number-of-pages": "4",
                "page": "1–4",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Introducing Data Connectivity in a Big Data Web",
                "URL": "https://doi.org/10.1145/2627770.2627773"
            }
        },
        {
            "10.1145/3154943.3154946": {
                "id": "10.1145/3154943.3154946",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Singh",
                        "given": "Ruchi"
                    },
                    {
                        "family": "Ananth",
                        "given": "Yashaswi"
                    },
                    {
                        "family": "Woo",
                        "given": "Dr. Jongwook"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            17
                        ]
                    ]
                },
                "abstract": "In this paper, we have analyzed the local business data and reviews to get insights on the popularity of a business and factors responsible for it. We have also analyzed the sentiments of the customer reviews for better understanding of business popularity. The total size of the dataset is 180 MB and we have adopted cloud computing service like Big Data Hadoop using HiveQL and Pig for query. Our preferred choice of framework for this project was Big Data Hadoop primarily because it is an open source software and its scalability and flexibility best suited our requirements.This project has helped us in understanding various aspects of the Local Businesses; factors driving their popularity, customer review patterns and regions that favor certain businesses the most, are a few of the many aspects to name. Analyzing the customer sentiments based on their reviews has helped us in realizing the importance of customer satisfaction, also it is possible to derive action plans to improve business performance to keep up with the competition.",
                "call-number": "10.1145/3154943.3154946",
                "collection-number": "3",
                "collection-title": "ICEC '17",
                "container-title": "Proceedings of the International Conference on Electronic Commerce",
                "DOI": "10.1145/3154943.3154946",
                "event-place": "Pangyo, Seongnam, Republic of Korea",
                "ISBN": "9781450353120",
                "keyword": "big data, reviews, azure, local business, hive, IBM bluemix, visualization, data analysis, hadoop",
                "number": "Article 3",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data analysis of local business and reviews",
                "URL": "https://doi.org/10.1145/3154943.3154946"
            }
        },
        {
            "10.1145/3447568.3448553": {
                "id": "10.1145/3447568.3448553",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Djebouri",
                        "given": "Djamila"
                    },
                    {
                        "family": "Keskes",
                        "given": "Nabil"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            6,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            6,
                            4
                        ]
                    ]
                },
                "abstract": "The emergence of web technologies is generating a data deluge called Big Data. All this data is in fact a gold mine to be exploited. However, we are confronted with huge volumes of heterogeneous data (various formats) and varied data (various sources) and in continuous expansion. To deal with this, some research works have introduced ontologies: this is the purpose of this paper. We present the Big Data concept on the one hand and the ontology concept on the other. We first recalled the definitions of Big Data, its main dimensions known by the 3 V (volume, velocity, variety), the fields of application as well as the various problems related to it. We reviewed the different solutions proposed as well as the existing tools by using the NoSQL and the Map-Reduce paradigm implemented in Hadoop and Spark.We then looked at the concept of ontology, starting by recalling the definition of ontology, so an ontology is a conceptual model to represent reality and on which it is possible to develop systems that can be shared and reused. Ontologies are used to represent a domain and reason about its entities.Finally, we presented and discussed some research works that combined ontologies and Big Data. We have found that there is a very abundant literature that deals with big data and ontologies separately, but few studies combine the two concepts together. We will therefore focus on the latter in order to enrich the scientific literature in the domain.",
                "call-number": "10.1145/3447568.3448553",
                "collection-number": "45",
                "collection-title": "ICIST '20",
                "container-title": "Proceedings of the 10th International Conference on Information Systems and Technologies",
                "DOI": "10.1145/3447568.3448553",
                "event-place": "Lecce, Italy",
                "ISBN": "9781450376556",
                "keyword": "Spark, ontology, HADOOP, Map-Reduce, Semantic Web, Knowledge Base, Big Data",
                "number": "Article 45",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Exploitation of ontological approaches in Big Data: A State of the Art",
                "URL": "https://doi.org/10.1145/3447568.3448553"
            }
        },
        {
            "10.1145/3097983.3098179": {
                "id": "10.1145/3097983.3098179",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yan",
                        "given": "Yizhou"
                    },
                    {
                        "family": "Cao",
                        "given": "Lei"
                    },
                    {
                        "family": "Kulhman",
                        "given": "Caitlin"
                    },
                    {
                        "family": "Rundensteiner",
                        "given": "Elke"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            13
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            13
                        ]
                    ]
                },
                "abstract": "In this work, we present the first distributed solution for the Local Outlier Factor (LOF) method -- a popular outlier detection technique shown to be very effective for datasets with skewed distributions. As datasets increase radically in size, highly scalable LOF algorithms leveraging modern distributed infrastructures are required. This poses significant challenges due to the complexity of the LOF definition, and a lack of access to the entire dataset at any individual compute machine. Our solution features a distributed LOF pipeline framework, called DLOF. Each stage of the LOF computation is conducted in a fully distributed fashion by leveraging our invariant observation for intermediate value management. Furthermore, we propose a data assignment strategy which ensures that each machine is self-sufficient in all stages of the LOF pipeline, while minimizing the number of data replicas. Based on the convergence property derived from analyzing this strategy in the context of real world datasets, we introduce a number of data-driven optimization strategies. These strategies not only minimize the computation costs within each stage, but also eliminate unnecessary communication costs by aggressively pushing the LOF computation into the early stages of the DLOF pipeline. Our comprehensive experimental study using both real and synthetic datasets confirms the efficiency and scalability of our approach to terabyte level data.",
                "call-number": "10.1145/3097983.3098179",
                "collection-title": "KDD '17",
                "container-title": "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
                "DOI": "10.1145/3097983.3098179",
                "event-place": "Halifax, NS, Canada",
                "ISBN": "9781450348874",
                "keyword": "big data, distributed processing, local outlier",
                "number-of-pages": "10",
                "page": "1225–1234",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Distributed Local Outlier Detection in Big Data",
                "URL": "https://doi.org/10.1145/3097983.3098179"
            }
        },
        {
            "10.1109/BDC.2014.18": {
                "id": "10.1109/BDC.2014.18",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Wozniak",
                        "given": "Justin M."
                    },
                    {
                        "family": "Sharma",
                        "given": "Hemant"
                    },
                    {
                        "family": "Armstrong",
                        "given": "Timothy G."
                    },
                    {
                        "family": "Wilde",
                        "given": "Michael"
                    },
                    {
                        "family": "Almer",
                        "given": "Jonathan D."
                    },
                    {
                        "family": "Foster",
                        "given": "Ian"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            12,
                            8
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            12,
                            8
                        ]
                    ]
                },
                "abstract": "New techniques in X-ray scattering science experiments produce large data sets that can require millions of high-performance processing hours per week of computation for analysis. In such applications, data is typically moved from X-ray detectors to a large parallel file system shared by all nodes of a peta scale supercomputer and then is read repeatedly as different science application tasks proceed. However, this straightforward implementation causes significant contention in the file system. We propose an alternative approach in which data is instead staged into and cached in compute node memory for extended periods, during which time various processing tasks may efficiently access it. We describe here such a big data staging framework, based on MPI-IO and the Swift parallel scripting language. We discuss a range of large-scale data management issues involved in X-ray scattering science and measure the performance benefits of the new staging framework for high-energy diffraction microscopy, an important emerging application in data-intensive X-ray scattering. We show that our framework accelerates scientific processing turnaround from three months to under 10 minutes, and that our I/O technique reduces input overheads by a factor of 5 on 8K Blue Gene/Q nodes.",
                "call-number": "10.1109/BDC.2014.18",
                "collection-title": "BDC '14",
                "container-title": "Proceedings of the 2014 IEEE/ACM International Symposium on Big Data Computing",
                "DOI": "10.1109/BDC.2014.18",
                "ISBN": "9781479918973",
                "keyword": "X-ray, Broadcast, scattering, Blue Gene, MPI, Swift, MPI-IO",
                "number-of-pages": "9",
                "page": "26–34",
                "publisher": "IEEE Computer Society",
                "publisher-place": "USA",
                "title": "Big Data Staging with MPI-IO for Interactive X-ray Science",
                "URL": "https://doi.org/10.1109/BDC.2014.18"
            }
        },
        {
            "10.1145/2486227.2486231": {
                "id": "10.1145/2486227.2486231",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Grinter",
                        "given": "Beki"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            7,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/2486227.2486231",
                "container-title": "interactions",
                "DOI": "10.1145/2486227.2486231",
                "ISSN": "1072-5520",
                "issue": "4",
                "number-of-pages": "2",
                "page": "10–11",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "July + August 2013",
                "title": "A big data confession",
                "URL": "https://doi.org/10.1145/2486227.2486231",
                "volume": "20"
            }
        },
        {
            "10.1145/3289430": {
                "id": "10.1145/3289430",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2018
                        ]
                    ]
                },
                "abstract": "With the sustainable development on information technology, and the widespread use of emerging technology, such as: cloud computing, internet of things and social network, the variety of Big Data is increasing day by day, and the scale of big date have expanded dramatically in recent years, which means the era of big data is coming silently. In order to keep up with the development of network technology, BDIOT2018 provide a platform to all scholars on relevant research area gather together on North China University of Technology, Beijing, China to share and discuss their experimental fruits or learn the most advanced innovative technologies from the outstanding experts on big data and internet of things. This conference is technically sponsored by North China University of Technology, China; University of Macau, Macau SAR; Dongguk University, The Republic of South Korea.",
                "call-number": "10.1145/3289430",
                "container-title-short": "BDIOT 2018",
                "event-place": "Beijing, China",
                "genre": "proceeding",
                "ISBN": "9781450365192",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2018 2nd International Conference on Big Data and Internet of Things"
            }
        },
        {
            "10.1145/505248.506010": {
                "id": "10.1145/505248.506010",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Pipino",
                        "given": "Leo L."
                    },
                    {
                        "family": "Lee",
                        "given": "Yang W."
                    },
                    {
                        "family": "Wang",
                        "given": "Richard Y."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2002,
                            4,
                            1
                        ]
                    ]
                },
                "abstract": "How good is a company's data quality? Answering this question requires usable data quality metrics. Currently, most data quality measures are developed on an ad hoc basis to solve specific problems [6, 8], and fundamental principles necessary for developing usable metrics in practice are lacking. In this article, we describe principles that can help organizations develop usable data quality metrics.",
                "call-number": "10.1145/505248.506010",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/505248.506010",
                "ISSN": "0001-0782",
                "issue": "4",
                "number-of-pages": "8",
                "page": "211–218",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "April 2002",
                "title": "Data quality assessment",
                "URL": "https://doi.org/10.1145/505248.506010",
                "volume": "45"
            }
        },
        {
            "10.1145/2788453": {
                "id": "10.1145/2788453",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Kitner",
                        "given": "Kathi R."
                    },
                    {
                        "family": "de Wet",
                        "given": "Thea"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            25
                        ]
                    ]
                },
                "abstract": "This forum addresses conceptual, methodological, and professional issues that arise in the UX field's continuing effort to contribute robust information about users to product planning and design. --- David Siegel and Susan Dray, Editors",
                "call-number": "10.1145/2788453",
                "container-title": "interactions",
                "DOI": "10.1145/2788453",
                "ISSN": "1072-5520",
                "issue": "4",
                "number-of-pages": "4",
                "page": "70–73",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "July - August 2015",
                "title": "Big city, big data",
                "URL": "https://doi.org/10.1145/2788453",
                "volume": "22"
            }
        },
        {
            "10.1145/3208352": {
                "id": "10.1145/3208352",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2018
                        ]
                    ]
                },
                "call-number": "10.1145/3208352",
                "container-title-short": "SBD'18",
                "event-place": "Houston, TX, USA",
                "genre": "proceeding",
                "ISBN": "9781450357791",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the International Workshop on Semantic Big Data"
            }
        },
        {
            "10.1145/2911451.2911550": {
                "id": "10.1145/2911451.2911550",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kumar",
                        "given": "Vipin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            7,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            7,
                            7
                        ]
                    ]
                },
                "abstract": "This talk will present an overview of research being done in a large interdisciplinary project on the development of novel data mining and machine learning approaches for analyzing massive amount of climate and ecosystem data now available from satellite and ground-based sensors, and physics-based climate model simulations. These information-rich data sets offer huge potential for monitoring, understanding, and predicting the behavior of the Earth's ecosystem and for advancing the science of global change. This talk will discuss challenges in analyzing such data sets and some of our research results in mapping the dynamics of surface water globally as well as detecting deforestation and fires in tropical forests using data from Earth observing satellites.",
                "call-number": "10.1145/2911451.2911550",
                "collection-title": "SIGIR '16",
                "container-title": "Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval",
                "DOI": "10.1145/2911451.2911550",
                "event-place": "Pisa, Italy",
                "ISBN": "9781450340694",
                "keyword": "spatio-temporal data, big data, rare class detection, monitoring global water dynamics, and heterogeneous data, incomplete, predictive models for imperfect, identifying tropical forest fires.",
                "number-of-pages": "1",
                "page": "3",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data in Climate: Opportunities and Challenges for Machine Learning",
                "URL": "https://doi.org/10.1145/2911451.2911550"
            }
        },
        {
            "10.1145/2680821.2680824": {
                "id": "10.1145/2680821.2680824",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yu",
                        "given": "Se-young"
                    },
                    {
                        "family": "Brownlee",
                        "given": "Nevil"
                    },
                    {
                        "family": "Mahanti",
                        "given": "Aniket"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            12,
                            2
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            12,
                            2
                        ]
                    ]
                },
                "abstract": "We present performance and fairness analysis of two TCP- based (GridFTP and FDT) and one UDP-based (UDT) big data transfer protocols. We perform long-haul performance experiments using a 10 Gb/s national network, and conduct fairness tests in our 10 Gb/s local network. Our results show that GridFTP with jumbo frames provides fast data transfers. GridFTP is also fair in sharing bandwidth with competing background TCP flows.",
                "call-number": "10.1145/2680821.2680824",
                "collection-title": "CoNEXT Student Workshop '14",
                "container-title": "Proceedings of the 2014 CoNEXT on Student Workshop",
                "DOI": "10.1145/2680821.2680824",
                "event-place": "Sydney, Australia",
                "ISBN": "9781450332828",
                "keyword": "big data transfer protocols, performance, fairness",
                "number-of-pages": "3",
                "page": "9–11",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Performance and Fairness Issues in Big Data Transfers",
                "URL": "https://doi.org/10.1145/2680821.2680824"
            }
        },
        {
            "10.1145/3493700.3493772": {
                "id": "10.1145/3493700.3493772",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Barua",
                        "given": "Hrishav Bakul"
                    },
                    {
                        "family": "Mondal",
                        "given": "Kartick Chandra"
                    },
                    {
                        "family": "Khatua",
                        "given": "Sunirmal"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            1,
                            8
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            1,
                            8
                        ]
                    ]
                },
                "abstract": "The current decade has beheld a tremendous spike in data volume, velocity, variety and many other such aspects which we call as Big Data and which gave birth to a new kind of science commonly known as ”Data Science”. With the ”Data Apocalypse” in progress, it is evident that the conventional methods to handle these data would not suffice. We need distributed and parallel architectures like Cloud services (IaaS, PaaS, SaaS, STaaS, etc.). But is that enough to satisfy our needs? Here, we propose a tutorial in a very different direction when we are talking about Data Science, that is, bringing greenness in Big Data and Machine Learning (ML). We divide the tutorial into two parts primarily assuming that we are using cloud backbone for analytic and prediction tasks. The first part speaks about the techniques and tools to bring energy efficiency/greenness in the algorithmic and code level for Big Data and ML using Approximate Computing. The second part talks about the green techniques and power models at the infrastructural level for the cloud.",
                "call-number": "10.1145/3493700.3493772",
                "collection-title": "CODS-COMAD 2022",
                "container-title": "5th Joint International Conference on Data Science & Management of Data (9th ACM IKDD CODS and 27th COMAD)",
                "DOI": "10.1145/3493700.3493772",
                "event-place": "Bangalore, India",
                "ISBN": "9781450385824",
                "keyword": "Green Computing, Approximate Computing, Power Modelling, Big Data, Resource Scheduling, Heuristics, Machine Learning, Data Science, Cloud Computing",
                "number-of-pages": "4",
                "page": "348–351",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Green Computing for Big Data and Machine Learning",
                "URL": "https://doi.org/10.1145/3493700.3493772"
            }
        },
        {
            "10.1145/3006386.3006387": {
                "id": "10.1145/3006386.3006387",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Raghothama",
                        "given": "Jayanth"
                    },
                    {
                        "family": "Shreenath",
                        "given": "Vinutha Magal"
                    },
                    {
                        "family": "Meijer",
                        "given": "Sebastiaan"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            10,
                            31
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            10,
                            31
                        ]
                    ]
                },
                "abstract": "The increasing pervasiveness of location-aware technologies is leading to the rise of large, spatio-temporal datasets and to the opportunity of discovering usable knowledge about the behaviors of people and objects. Applied extensively in transportation, spatial big data and its analytics can deliver useful insights on a number of different issues such as congestion, delays, public transport reliability and so on. Predominantly studied for its use in operational management, spatial big data can be used to provide insight in strategic applications as well, from planning and design to evaluation and management. Such large scale, streaming spatial big data can be used in the improvement of public transport, for example the design of public transport networks and reliability. In this paper, we analyze GTFS data from the cities of Stockholm and Rome to gain insight on the sources and factors influencing public transport delays in the cities. The analysis is performed on a combination of GTFS data with data from other sources. The paper points to key issues in the analysis of real time data, driven by the contextual setting in the two cities.",
                "call-number": "10.1145/3006386.3006387",
                "collection-title": "BigSpatial '16",
                "container-title": "Proceedings of the 5th ACM SIGSPATIAL International Workshop on Analytics for Big Geospatial Data",
                "DOI": "10.1145/3006386.3006387",
                "event-place": "Burlingame, California",
                "ISBN": "9781450345811",
                "keyword": "big data, decision making, public transport",
                "number-of-pages": "6",
                "page": "28–33",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Analytics on public transport delays with spatial big data",
                "URL": "https://doi.org/10.1145/3006386.3006387"
            }
        },
        {
            "10.1145/3323503.3345030": {
                "id": "10.1145/3323503.3345030",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Goularte",
                        "given": "Rudinei"
                    },
                    {
                        "family": "Trojahn",
                        "given": "Tiago H."
                    },
                    {
                        "family": "Kishi",
                        "given": "Rodrigo M."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            29
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            29
                        ]
                    ]
                },
                "abstract": "The popularization of systems, applications and devices to produce, view and share multimedia, saw the need to treat a large volume of data arise. In related areas (such as Multimedia Big Data, Data Science and Multimedia Information Retrieval) a key step is commonly referred as Multimedia Indexing or Multimedia Big Data Analysis, where the aim is to represent multimedia content into smaller, more manageable units, allowing the extraction of data features and information essential to the proper performance of the associated services. This mini-course discusses current tools and techniques for indexing, extracting and processing of multimodal multimedia content. The techniques are exemplified in Python OpenCV over different content (like images, audio, text and video), leading to the interest of services like Netflix, Google and YouTube on this subject, attracting the interest of researchers and developers.",
                "call-number": "10.1145/3323503.3345030",
                "collection-title": "WebMedia '19",
                "container-title": "Proceedings of the 25th Brazillian Symposium on Multimedia and the Web",
                "DOI": "10.1145/3323503.3345030",
                "event-place": "Rio de Janeiro, Brazil",
                "ISBN": "9781450367639",
                "keyword": "big data, multimedia information retrieval, multimedia",
                "number-of-pages": "3",
                "page": "25–27",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Multimedia information retrieval in big data using OpenCV python",
                "URL": "https://doi.org/10.1145/3323503.3345030"
            }
        },
        {
            "10.1145/2594538.2594551": {
                "id": "10.1145/2594538.2594551",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Fan",
                        "given": "Wenfei"
                    },
                    {
                        "family": "Geerts",
                        "given": "Floris"
                    },
                    {
                        "family": "Libkin",
                        "given": "Leonid"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            18
                        ]
                    ]
                },
                "abstract": "To make query answering feasible in big datasets, practitioners have been looking into the notion of scale independence of queries. Intuitively, such queries require only a relatively small subset of the data, whose size is determined by the query and access methods rather than the size of the dataset itself. This paper aims to formalize this notion and study its properties. We start by defining what it means to be scale-independent, and provide matching upper and lower bounds for checking scale independence, for queries in various languages, and for combined and data complexity. Since the complexity turns out to be rather high, and since scale-independent queries cannot be captured syntactically, we develop sufficient conditions for scale independence. We formulate them based on access schemas, which combine indexing and constraints together with bounds on the sizes of retrieved data sets. We then study two variations of scale-independent query answering, inspired by existing practical systems. One concerns incremental query answering: we check when query answers can be maintained in response to updates scale-independently. The other explores scale-independent query rewriting using views.",
                "call-number": "10.1145/2594538.2594551",
                "collection-title": "PODS '14",
                "container-title": "Proceedings of the 33rd ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems",
                "DOI": "10.1145/2594538.2594551",
                "event-place": "Snowbird, Utah, USA",
                "ISBN": "9781450323758",
                "keyword": "query answering, scale independence, big data",
                "number-of-pages": "12",
                "page": "51–62",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "On scale independence for querying big data",
                "URL": "https://doi.org/10.1145/2594538.2594551"
            }
        },
        {
            "10.1145/3358505": {
                "id": "10.1145/3358505",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2019
                        ]
                    ]
                },
                "abstract": "It is our greatest pleasure to welcome you to the 2019 3rd International Conference on Cloud and Big Data Computing (ICCBDC 2019) held at St Anne's College in University of Oxford, Oxford, United Kingdom. In this conference, you can expect to meet fellow researchers from both academia and industry, and to hear and discuss the latest technological advances in the field. In our previous runs of this conference series in London (2017) and Barcelona (2018), we have seen novel ideas and developments being shared and collaborations being established.",
                "call-number": "10.1145/3358505",
                "container-title-short": "ICCBDC 2019",
                "event-place": "Oxford, United Kingdom",
                "genre": "proceeding",
                "ISBN": "9781450371650",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2019 3rd International Conference on Cloud and Big Data Computing"
            }
        },
        {
            "10.1145/2464157.2466485": {
                "id": "10.1145/2464157.2466485",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bu",
                        "given": "Yingyi"
                    },
                    {
                        "family": "Borkar",
                        "given": "Vinayak"
                    },
                    {
                        "family": "Xu",
                        "given": "Guoqing"
                    },
                    {
                        "family": "Carey",
                        "given": "Michael J."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            20
                        ]
                    ]
                },
                "abstract": "Over the past decade, the increasing demands on data-driven business intelligence have led to the proliferation of large-scale, data-intensive applications that often have huge amounts of data (often at terabyte or petabyte scale) to process. An object-oriented programming language such as Java is often the developer's choice for implementing such applications, primarily due to its quick development cycle and rich community resource. While the use of such languages makes programming easier, significant performance problems can often be seen --- the combination of the inefficiencies inherent in a managed run-time system and the impact of the huge amount of data to be processed in the limited memory space often leads to memory bloat and performance degradation at a surprisingly early stage.This paper proposes a bloat-aware design paradigm towards the development of efficient and scalable Big Data applications in object-oriented GC enabled languages. To motivate this work, we first perform a study on the impact of several typical memory bloat patterns. These patterns are summarized from the user complaints on the mailing lists of two widely-used open-source Big Data applications. Next, we discuss our design paradigm to eliminate bloat. Using examples and real-world experience, we demonstrate that programming under this paradigm does not incur significant programming burden. We have implemented a few common data processing tasks both using this design and using the conventional object-oriented design. Our experimental results show that this new design paradigm is extremely effective in improving performance --- even for the moderate-size data sets processed, we have observed 2.5x+ performance gains, and the improvement grows substantially with the size of the data set.",
                "call-number": "10.1145/2464157.2466485",
                "collection-title": "ISMM '13",
                "container-title": "Proceedings of the 2013 international symposium on memory management",
                "DOI": "10.1145/2464157.2466485",
                "event-place": "Seattle, Washington, USA",
                "ISBN": "9781450321006",
                "keyword": "memory bloat, design, big data applications",
                "number-of-pages": "12",
                "page": "119–130",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A bloat-aware design for big data applications",
                "URL": "https://doi.org/10.1145/2464157.2466485"
            }
        },
        {
            "10.1145/2820783.2820854": {
                "id": "10.1145/2820783.2820854",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Baumann",
                        "given": "Peter"
                    },
                    {
                        "family": "Dumitru",
                        "given": "Alex Mircea"
                    },
                    {
                        "family": "Merticariu",
                        "given": "Vlad"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            11,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            11,
                            3
                        ]
                    ]
                },
                "abstract": "Flexible, scalable services on massive geo data receive much attention today. In particular, the OGC Web Coverage Service (WCS) standards suite has established a best practice for versatile access and retrieval on spatio-temporal \"Big Data\". Fewer efforts have been devoted, though, to an easy-to-use, standardized way of maintaining a service's offering. Our experience from supporting a series of heterogeneous, large-scale services reveals that this can become tedious indeed, due to heterogeneity and incompleteness of incoming data, operator-less transformation and ingest of large amounts of files, as well as the need for narrowly focused manual corrections and updates sometimes.In this contribution, we present the WCS-T (for \"Transaction\") specification which enables users and machines to perform atomic insertion, updating, and deletions through simple Web requests. WCS-T has been implemented and is actively being used in projects; recently, it has entered the adoption process in OGC to become part of the WCS suite.",
                "call-number": "10.1145/2820783.2820854",
                "collection-number": "64",
                "collection-title": "SIGSPATIAL '15",
                "container-title": "Proceedings of the 23rd SIGSPATIAL International Conference on Advances in Geographic Information Systems",
                "DOI": "10.1145/2820783.2820854",
                "event-place": "Seattle, Washington",
                "ISBN": "9781450339674",
                "keyword": "OGC, datacube, web coverage service, coverage, standards, geo services",
                "number": "Article 64",
                "number-of-pages": "4",
                "page": "1–4",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Grooming big data from afar",
                "URL": "https://doi.org/10.1145/2820783.2820854"
            }
        },
        {
            "10.1007/s00778-018-0515-8": {
                "id": "10.1007/s00778-018-0515-8",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Liu",
                        "given": "Yuchen"
                    },
                    {
                        "family": "Liu",
                        "given": "Hai"
                    },
                    {
                        "family": "Xiao",
                        "given": "Dongqing"
                    },
                    {
                        "family": "Eltabakh",
                        "given": "Mohamed Y."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            12,
                            1
                        ]
                    ]
                },
                "abstract": "Correlations among the data attributes are abundant and inherent in most application domains. These correlations, if managed in systematic and efficient ways, would enable various optimization opportunities. Unfortunately, the state-of-art techniques are all heavily tailored toward optimizing factors intrinsic to relational databases, e.g., predicate selectivity, random I/O accesses, and secondary indexes, which are mostly not applicable to the modern big data infrastructures, e.g., Hadoop and Spark. In this paper, we propose the EXORD$$^+$$+ system for exploiting the data's correlations in big data query optimization. EXORD$$^+$$+ supports two types of correlations; hard (which does not allow for exceptions) and soft (which allows for exceptions). We introduce a three-phase approach for managing soft correlations including: (1) validating and judging the worthiness of soft correlations, (2) selecting and preparing the soft correlations for deployment, and (3) exploiting the correlations in query optimization. EXORD$$^+$$+ introduces a novel cost-benefit model for adaptively selecting the most beneficial soft correlations given a query workload. We show the complexity of this problem (NP-Hard) and propose a heuristic to efficiently solve it in a polynomial time. Moreover, we present incremental maintenance algorithms for efficiently updating the system's state under data appends and workload changes. EXORD$$^+$$+ prototype is implemented as an extension to the Hive engine on top of Hadoop. The experimental evaluation shows the potential of EXORD$$^+$$+ in achieving more than 10x speedup while introducing minimal storage overheads.",
                "call-number": "10.1007/s00778-018-0515-8",
                "container-title": "The VLDB Journal",
                "DOI": "10.1007/s00778-018-0515-8",
                "ISSN": "1066-8888",
                "issue": "6",
                "keyword": "Soft and hard correlations, Query optimization, Big data, Incremental maintenance, Data correlations",
                "number-of-pages": "26",
                "page": "873–898",
                "publisher": "Springer-Verlag",
                "publisher-place": "Berlin, Heidelberg",
                "source": "December  2018",
                "title": "Adaptive correlation exploitation in big data query optimization",
                "URL": "https://doi.org/10.1007/s00778-018-0515-8",
                "volume": "27"
            }
        },
        {
            "10.1145/3378936.3378957": {
                "id": "10.1145/3378936.3378957",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Hujran",
                        "given": "Omar"
                    },
                    {
                        "family": "Alikaj",
                        "given": "Ahmad"
                    },
                    {
                        "family": "Durrani",
                        "given": "Usman Khan"
                    },
                    {
                        "family": "Al-Dmour",
                        "given": "Nidal"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            1,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            1,
                            12
                        ]
                    ]
                },
                "abstract": "This research discusses the effect of big data and Internet technologies on the music industry. Specifically, this paper addresses two research questions; (1) how do modern businesses in the music industry implement the use of Internet technologies and big data to ensure their success in the market, and (2) what are the advantages and drawbacks of implementing digital business models in the music industry? To answer the research questions, two real-life cases (i.e. Shazam and Spotify) were analyzed to show how modern businesses in the music industry implement big data and Internet technologies to ensure their success in the market. Furthermore, previous literature and secondary resources were used to explain the development of traditional business models into digital business models in the music industry. In addition to discussing the benefits and drawbacks of implementing the modern digital business model.",
                "call-number": "10.1145/3378936.3378957",
                "collection-title": "ICSIM '20",
                "container-title": "Proceedings of the 3rd International Conference on Software Engineering and Information Management",
                "DOI": "10.1145/3378936.3378957",
                "event-place": "Sydney, NSW, Australia",
                "ISBN": "9781450376907",
                "keyword": "Music, Business Analytics, Shazam, Spotify, Big Data",
                "number-of-pages": "5",
                "page": "5–9",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data and its Effect on the Music Industry",
                "URL": "https://doi.org/10.1145/3378936.3378957"
            }
        },
        {
            "10.1145/3341620.3341636": {
                "id": "10.1145/3341620.3341636",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Tan",
                        "given": "Haowen"
                    },
                    {
                        "family": "Chung",
                        "given": "Ilyong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            6,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            6,
                            11
                        ]
                    ]
                },
                "abstract": "Nowadays, the construction of efficient intelligent transportation system (ITS) has become a new trend for metropolitan cities with increasingly large populations. As one of the most significant component of ITS, the vehicular ad hoc networks (VANETs) are capable of building temporary vehicular sensor networks for efficient and dynamic information exchange between vehicles and road side units (RSUs). As a matter of fact, the traditional VANETs have limited computing and storing capabilities, which restrict the rapid development VANETs services provided to the drivers. Hence, with the rapid development of big data facilities, the cloud-assisted VANETs structure is proposed in order to enhance the capabilities of VANETs. In addition, due to the inherent wireless communication characteristics, data transmissions of VANETs suffer from charted and uncharted security risks and attacks. Thus proper security strategies should be adopted to guarantee secure communication and driver privacy. Emphasizing on the above issues, we develop an efficient cloud-assisted certificateless grouping authentication scheme for VANETs. In our design, vehicle anonymity is provided during the entire communication process. Note that most of the current authenticating schemes assume the secure channel between the RSU and vehicles in order for initial key message transmission, which is not necessary in our scheme.",
                "call-number": "10.1145/3341620.3341636",
                "collection-title": "BDE 2019",
                "container-title": "Proceedings of the 2019 International Conference on Big Data Engineering",
                "DOI": "10.1145/3341620.3341636",
                "event-place": "Hong Kong, Hong Kong",
                "ISBN": "9781450360913",
                "keyword": "group authentication, VANETs, conditional privacy, anonymous identity, certificateless",
                "number-of-pages": "7",
                "page": "107–113",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A Secure Cloud-Assisted Certificateless Group Authentication Scheme for VANETs in Big Data Environment",
                "URL": "https://doi.org/10.1145/3341620.3341636"
            }
        },
        {
            "10.1145/3022227.3022232": {
                "id": "10.1145/3022227.3022232",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Saad",
                        "given": "Amna"
                    },
                    {
                        "family": "Amran",
                        "given": "Ahmad Roshidi"
                    },
                    {
                        "family": "Phillips",
                        "given": "Iain William"
                    },
                    {
                        "family": "Salagean",
                        "given": "Ana M."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            1,
                            5
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            1,
                            5
                        ]
                    ]
                },
                "abstract": "VoIP users increase each day. However, the documentation on the behavior of VoIP applications is still lacking. The needs to understand and generalize the behavior of applications like Skype, GoogleTalk and SIP based applications grow each day. There are many factors that influenced the performance of a VoIP application such as bandwidth, packet loss rate, delay, jitter, codec type and CPU power of the end devices. The user experience of the service is important since, VoIP is a real time application running over the best effort internet. Since VoIP data co-exist with other data on the internet, extracting, transforming, loading and analyzing the selected VoIP application is a challenge. We design an instrument to do data collections, data massaging, data analysis and data interpretation of large amounts of network packet. The result shows that GoogleTalk, Skype and Express Talk are more sensitive to the impairments due to packet loss rate and jitter rather than to the impairment due to delay. Bandwidth and other resources like a de-jitter buffer and a gateway's CPU and memory are important in order to produce a good quality VoIP service. The lack of these resources would result in several packets lost before they reach a destination or the packets arrive too late to join the other packets in the de-jitter buffer at the destination gateway. The gateway would drop these packets if the de-jitter buffer is full or not enough memory or CPU powers to process the packets. A gateway closer to the receiver end decapsulates IPSec or TLS packets. The gateway also decodes the voice packets before the packets entering the receiving machine. High throughputs do not imply high Perceptual Evaluation of Speech Quality for Wideband (PESQ-WB) scores. The throughput size is determined by the codec type and the security features that are implemented on the infrastructure.",
                "call-number": "10.1145/3022227.3022232",
                "collection-number": "5",
                "collection-title": "IMCOM '17",
                "container-title": "Proceedings of the 11th International Conference on Ubiquitous Information Management and Communication",
                "DOI": "10.1145/3022227.3022232",
                "event-place": "Beppu, Japan",
                "ISBN": "9781450348881",
                "keyword": "impairments, VoIP protocol, CVSS, big data, resources, PESQ",
                "number": "Article 5",
                "number-of-pages": "8",
                "page": "1–8",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data analysis on secure VoIP services",
                "URL": "https://doi.org/10.1145/3022227.3022232"
            }
        },
        {
            "10.1145/2513190.2517828": {
                "id": "10.1145/2513190.2517828",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Cuzzocrea",
                        "given": "Alfredo"
                    },
                    {
                        "family": "Bellatreche",
                        "given": "Ladjel"
                    },
                    {
                        "family": "Song",
                        "given": "Il-Yeol"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            10,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            10,
                            28
                        ]
                    ]
                },
                "abstract": "In this paper, we highlight open problems and actual research trends in the field of Data Warehousing and OLAP over Big Data, an emerging term in Data Warehousing and OLAP research. We also derive several novel research directions arising in this field, and put emphasis on possible contributions to be achieved by future research efforts.",
                "call-number": "10.1145/2513190.2517828",
                "collection-title": "DOLAP '13",
                "container-title": "Proceedings of the sixteenth international workshop on Data warehousing and OLAP",
                "DOI": "10.1145/2513190.2517828",
                "event-place": "San Francisco, California, USA",
                "ISBN": "9781450324120",
                "keyword": "big multidimensional data, big data, olap, data warehousing",
                "number-of-pages": "4",
                "page": "67–70",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Data warehousing and OLAP over big data: current challenges and future research directions",
                "URL": "https://doi.org/10.1145/2513190.2517828"
            }
        },
        {
            "10.1145/2990473": {
                "id": "10.1145/2990473",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Wang",
                        "given": "Kun"
                    },
                    {
                        "family": "Mi",
                        "given": "Jun"
                    },
                    {
                        "family": "Xu",
                        "given": "Chenhan"
                    },
                    {
                        "family": "Zhu",
                        "given": "Qingquan"
                    },
                    {
                        "family": "Shu",
                        "given": "Lei"
                    },
                    {
                        "family": "Deng",
                        "given": "Der-Jiunn"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            10,
                            12
                        ]
                    ]
                },
                "abstract": "In the age of multimedia big data, the popularity of mobile devices has been in an unprecedented growth, the speed of data increasing is faster than ever before, and Internet traffic is rapidly increasing, not only in volume but also in heterogeneity. Therefore, data processing and network overload have become two urgent problems. To address these problems, extensive papers have been published on image analysis using deep learning, but only a few works have exploited this approach for video analysis. In this article, a hybrid-stream model is proposed to solve these problems for video analysis. Functionality of this model covers Data Preprocessing, Data Classification, and Data-Load-Reduction Processing. Specifically, an improved Convolutional Neural Networks (CNN) classification algorithm is designed to evaluate the importance of each video frame and video clip to enhance classification precision. Then, a reliable keyframe extraction mechanism will recognize the importance of each frame or clip, and decide whether to abandon it automatically by a series of correlation operations. The model will reduce data load to a dynamic threshold changed by σ, control the input size of the video in mobile Internet, and thus reduce network overload. Through experimental simulations, we find that the size of processed video has been effectively reduced and the quality of experience (QoE) has not been lowered due to a suitably selected parameter η. The simulation also shows that the model has a steady performance and is powerful enough for continuously growing multimedia big data.",
                "call-number": "10.1145/2990473",
                "collection-number": "76",
                "container-title": "ACM Trans. Multimedia Comput. Commun. Appl.",
                "DOI": "10.1145/2990473",
                "ISSN": "1551-6857",
                "issue": "5s",
                "keyword": "big data, load reduction, real-time, mobile Internet, Multimedia, networking",
                "number": "Article 76",
                "number-of-pages": "20",
                "page": "1–20",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "December 2016",
                "title": "Real-Time Load Reduction in Multimedia Big Data for Mobile Internet",
                "URL": "https://doi.org/10.1145/2990473",
                "volume": "12"
            }
        },
        {
            "10.1145/3372938.3373003": {
                "id": "10.1145/3372938.3373003",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Alcabnani",
                        "given": "Sara"
                    },
                    {
                        "family": "Oubezza",
                        "given": "Mohamed"
                    },
                    {
                        "family": "Elkafi",
                        "given": "Jamal"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            23
                        ]
                    ]
                },
                "abstract": "Managing and extracting useful knowledge from social media sources is a challenge. It has attracted a lot of attention from universities and industry. To meet this challenge, semantic analysis of textual data is the subject matter.Today, with the connection present everywhere and at any time, considerable data is born. These data or data become a key player for understanding, analyzing, anticipating and solving major economic, political, social and scientific problems. Data also changes our working procedures, our cultural environment, even restructuring our way of thinking. And just as the scientific, managerial and financial world is interested in Big Data, a new discipline is growing: Fast Data. In addition to the salient volume of data; another variant becomes decisive, the ability to efficiently process data in all their diversity, transforming it into knowledge by providing the right information to the right person at the right time, or even using it to predict the future.The exploitation of Big Data requires the proposition of new adapted mathematical and IT approaches but also a reengineering of managerial approaches for the control of the informational environment of a public or private organization. While basing itself on a strategic information management approach such as Economic Intelligence (EI). The latter combines and encompasses Business Intelligence techniques for internal data management and business intelligence techniques for monitoring and controlling external information flows. However, Big Data, as a boundless source of information for EI, has upset the traditional EI process, which requires a reengineering of the EI approach. My research works perfectly in this context characterized by an uncertain and unpredictable environment.We ask to propose an ontology-based, service-oriented, agile and scalable Social Business Intelligence approach to extract the semantics of textual data and define the domain of massive data. In other words, we semantically analyze social data at two levels, namely the level of the entity and the level of the domain.",
                "call-number": "10.1145/3372938.3373003",
                "collection-number": "65",
                "collection-title": "BDIoT'19",
                "container-title": "Proceedings of the 4th International Conference on Big Data and Internet of Things",
                "DOI": "10.1145/3372938.3373003",
                "event-place": "Rabat, Morocco",
                "ISBN": "9781450372404",
                "keyword": "Ontology, Cloud, Distributed Processing, Big Data, Social BI, Fast Data",
                "number": "Article 65",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "An approach for the implementation of semantic Big Data Analytics in the Social Business Intelligence process on distributed environments (Cloud computing)",
                "URL": "https://doi.org/10.1145/3372938.3373003"
            }
        },
        {
            "10.1145/3183440.3190334": {
                "id": "10.1145/3183440.3190334",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Gulzar",
                        "given": "Muhammad Ali"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            27
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            27
                        ]
                    ]
                },
                "abstract": "An abundance of data in many disciplines of science, engineering, national security, health care, and business has led to the emerging field of Big Data Analytics that run in a cloud computing environment. To process massive quantities of data in the cloud, developers leverage Data-Intensive Scalable Computing (DISC) systems such as Google's MapReduce, Hadoop, and Spark.Currently, developers do not have easy means to debug DISC applications. The use of cloud computing makes application development feel more like batch jobs and the nature of debugging is therefore post-mortem. Developers of big data applications write code that implements a data processing pipeline and test it on their local workstation with a small sample data, downloaded from a TB-scale data warehouse. They cross fingers and hope that the program works in the expensive production cloud. When a job fails or they get a suspicious result, data scientists spend hours guessing at the source of the error, digging through post-mortem logs. In such cases, the data scientists may want to pinpoint the root cause of errors by investigating a subset of corresponding input records.The vision of my work is to provide interactive, real-time and automated debugging services for big data processing programs in modern DISC systems with minimum performance impact. My work investigates the following research questions in the context of big data analytics: (1) What are the necessary debugging primitives for interactive big data processing? (2) What scalable fault localization algorithms are needed to help the user to localize and characterize the root causes of errors? (3) How can we improve testing efficiency during iterative development of DISC applications by reasoning the semantics of dataflow operators and user-defined functions used inside dataflow operators in tandem?To answer these questions, we synthesize and innovate ideas from software engineering, big data systems, and program analysis, and coordinate innovations across the software stack from the user-facing API all the way down to the systems infrastructure.",
                "call-number": "10.1145/3183440.3190334",
                "collection-title": "ICSE '18",
                "container-title": "Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings",
                "DOI": "10.1145/3183440.3190334",
                "event-place": "Gothenburg, Sweden",
                "ISBN": "9781450356633",
                "keyword": "big data, and data cleaning, test minimization, debugging and testing, data provenance, fault localization, automated debugging, data-intensive scalable computing (DISC)",
                "number-of-pages": "3",
                "page": "509–511",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Interactive and automated debugging for big data analytics",
                "URL": "https://doi.org/10.1145/3183440.3190334"
            }
        },
        {
            "10.1145/3387168.3387220": {
                "id": "10.1145/3387168.3387220",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yu",
                        "given": "Song"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            26
                        ]
                    ]
                },
                "abstract": "This paper presented an integrated retrieval system based on medical big data, aiming at the characteristics of medical data, such as diversity, large quantity and complex structure. The data center is built with data extraction module and data storage module in the system. The index module is built based on Solr and the data is presented in a webpage. The system keeps proper loose coupling among modules with high availability and extension. In a hospital application environment, this system realizes the function of real-time retrieval, and provides effective support for clinical decision.",
                "call-number": "10.1145/3387168.3387220",
                "collection-number": "59",
                "collection-title": "ICVISP 2019",
                "container-title": "Proceedings of the 3rd International Conference on Vision, Image and Signal Processing",
                "DOI": "10.1145/3387168.3387220",
                "event-place": "Vancouver, BC, Canada",
                "ISBN": "9781450376259",
                "keyword": "Solr, Medical Big Data, Data storage",
                "number": "Article 59",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Integrated Retrieval System Based on Medical Big Data",
                "URL": "https://doi.org/10.1145/3387168.3387220"
            }
        },
        {
            "10.1145/3396956.3398253": {
                "id": "10.1145/3396956.3398253",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Potiguara Carvalho",
                        "given": "Artur"
                    },
                    {
                        "family": "Potiguara Carvalho",
                        "given": "Fernanda"
                    },
                    {
                        "family": "Dias Canedo",
                        "given": "Edna"
                    },
                    {
                        "family": "Potiguara Carvalho",
                        "given": "Pedro Henrique"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            6,
                            15
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            6,
                            15
                        ]
                    ]
                },
                "abstract": "In a massive processing data era, an emerging impasse has taking scenario: privacy. In this context, personal data receive particular attention, witch its laws and guidelines that ensure better and legal use of data. The General Data Protection Regulation (GDPR) - in the European Union - and the Brazilian General Data Protection Law (LGPD) - in Brazil - lead to anonymisation (and its processes and techniques) as a way to reach secure use of personal data. However, expectations placed on this tool must be reconsidered according to risks and limits of its use, mainly when this technique is applied to Big Data. We discussed whether anonymisation used in conjunction with good data governance practices could provide greater protection for privacy. We conclude that good governance practices can strengthen privacy in anonymous data belonging to a Big Data, and we present a suggestive governance framework aimed at privacy.",
                "call-number": "10.1145/3396956.3398253",
                "collection-title": "dg.o '20",
                "container-title": "The 21st Annual International Conference on Digital Government Research",
                "DOI": "10.1145/3396956.3398253",
                "event-place": "Seoul, Republic of Korea",
                "ISBN": "9781450387910",
                "keyword": "Personal Data Protection, Big Data, Privacy, Governance, Anonymisation",
                "number-of-pages": "11",
                "page": "185–195",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data, Anonymisation and Governance to Personal Data Protection",
                "URL": "https://doi.org/10.1145/3396956.3398253"
            }
        },
        {
            "10.1145/2837060.2837091": {
                "id": "10.1145/2837060.2837091",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kim",
                        "given": "Ji-Dae"
                    },
                    {
                        "family": "Chi",
                        "given": "Su-Young"
                    },
                    {
                        "family": "Song",
                        "given": "Young-Wook"
                    },
                    {
                        "family": "Cho",
                        "given": "Wan-Sup"
                    },
                    {
                        "family": "Yoo",
                        "given": "Kwan-Hee"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            20
                        ]
                    ]
                },
                "abstract": "The adoption of manufacturing big data system (MBDS) is anticipated to enhance the competitiveness of small and medium-sized manufacturing firms (SMMFs), as massive amount of big data proliferate in the field of manufacturing industries. Several professionals argue that it is necessary to take an attentive approach in designing appropriate MBDS for SMMFs. This study examines appropriate design options, based on the information design theory, product-service system theory, and contingency theory, which would elevate the adoption probability of MBDS of Korean SMMFs. An empirical analysis of 191 Korean SMMFs reveals the following results. First, SMMFs put similar degree of importance on the entire design attributes of MBDS from big data gathering to information visualization. Second, SMMFs prefer payment per use of low-cost MBDS that provides more simplified information (e.g., on-spot monitoring and 2 dimension visualization) and utilizes open cloud as well as open telecommunication network. However, the firms want to have an independent and sophisticated MBDS that includes professional big data analysis and visualization software tool.",
                "call-number": "10.1145/2837060.2837091",
                "collection-title": "BigDAS '15",
                "container-title": "Proceedings of the 2015 International Conference on Big Data Applications and Services",
                "DOI": "10.1145/2837060.2837091",
                "event-place": "Jeju Island, Republic of Korea",
                "ISBN": "9781450338462",
                "keyword": "Manufacturing Big Data System, Design, Small and Medium-Sized Manufacturing Firms, Utility, Manufacturing Type",
                "number-of-pages": "5",
                "page": "184–188",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Design Strategy for Enhancing Adoption of Manufacturing Big Data System (MBDS) in Korean Small and Medium-Sized Manufacturing Firms (SMMFs)",
                "URL": "https://doi.org/10.1145/2837060.2837091"
            }
        },
        {
            "10.1145/2524224.2524227": {
                "id": "10.1145/2524224.2524227",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Theera-Ampornpunt",
                        "given": "Nawanol"
                    },
                    {
                        "family": "Bagchi",
                        "given": "Saurabh"
                    },
                    {
                        "family": "Joshi",
                        "given": "Kaustubh R."
                    },
                    {
                        "family": "Panta",
                        "given": "Rajesh K."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            11,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            11,
                            3
                        ]
                    ]
                },
                "abstract": "There are many large infrastructures that instrument everything from network performance metrics to user activities. However, the collected data are generally used for long-term planning instead of improving reliability and user experience in real time. In this paper, we present our vision of how such collections of data can be used in real time to enhance the dependability of cellular network services. We first discuss mitigation mechanisms that can be used to improve reliability, but incur a high cost which prohibit them to be used except in certain conditions. We present two case studies where analyses of real cellular network traffic data show that we can identify these conditions.",
                "call-number": "10.1145/2524224.2524227",
                "collection-number": "2",
                "collection-title": "HotDep '13",
                "container-title": "Proceedings of the 9th Workshop on Hot Topics in Dependable Systems",
                "DOI": "10.1145/2524224.2524227",
                "event-place": "Farmington, Pennsylvania",
                "ISBN": "9781450324571",
                "keyword": "data mining, wireless, big data, cellular",
                "number": "Article 2",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Using big data for more dependability: a cellular network tale",
                "URL": "https://doi.org/10.1145/2524224.2524227"
            }
        },
        {
            "10.5555/2819289.2819295": {
                "id": "10.5555/2819289.2819295",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Mirakhorli",
                        "given": "Mehdi"
                    },
                    {
                        "family": "Chen",
                        "given": "Hong-Mei"
                    },
                    {
                        "family": "Kazman",
                        "given": "Rick"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            5,
                            16
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            5,
                            16
                        ]
                    ]
                },
                "abstract": "An architecture recommender system can help programmers make better design choices to address their architectural quality attribute concerns while doing their daily programming tasks. We mine big data to detect and extract a large set of architectural design concepts, such as design patterns, design tactics, architecture styles, etc., to be used in our architecture recommender system called ARS. However, mining big data poses many practical challenges for system implementation. The volume, velocity and variety of our data set, like all other big data systems, requires careful planning. This first challenge is to select appropriate technologies from the large number of available products for our system implementation. Building on these technologies our greatest challenge is to custom-fit our algorithms to the parallel processing platform we have selected for ARS, to meet our performance goals.",
                "call-number": "10.5555/2819289.2819295",
                "collection-title": "BIGDSE '15",
                "container-title": "Proceedings of the First International Workshop on BIG Data Software Engineering",
                "event-place": "Florence, Italy",
                "keyword": "tactics, open architecture, design knowledge, patterns, mining internet scale software repositories",
                "number-of-pages": "4",
                "page": "15–18",
                "publisher": "IEEE Press",
                "title": "Mining big data for detecting, extracting and recommending architectural design concepts"
            }
        },
        {
            "10.1145/2491894.2466485": {
                "id": "10.1145/2491894.2466485",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bu",
                        "given": "Yingyi"
                    },
                    {
                        "family": "Borkar",
                        "given": "Vinayak"
                    },
                    {
                        "family": "Xu",
                        "given": "Guoqing"
                    },
                    {
                        "family": "Carey",
                        "given": "Michael J."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            20
                        ]
                    ]
                },
                "abstract": "Over the past decade, the increasing demands on data-driven business intelligence have led to the proliferation of large-scale, data-intensive applications that often have huge amounts of data (often at terabyte or petabyte scale) to process. An object-oriented programming language such as Java is often the developer's choice for implementing such applications, primarily due to its quick development cycle and rich community resource. While the use of such languages makes programming easier, significant performance problems can often be seen --- the combination of the inefficiencies inherent in a managed run-time system and the impact of the huge amount of data to be processed in the limited memory space often leads to memory bloat and performance degradation at a surprisingly early stage.This paper proposes a bloat-aware design paradigm towards the development of efficient and scalable Big Data applications in object-oriented GC enabled languages. To motivate this work, we first perform a study on the impact of several typical memory bloat patterns. These patterns are summarized from the user complaints on the mailing lists of two widely-used open-source Big Data applications. Next, we discuss our design paradigm to eliminate bloat. Using examples and real-world experience, we demonstrate that programming under this paradigm does not incur significant programming burden. We have implemented a few common data processing tasks both using this design and using the conventional object-oriented design. Our experimental results show that this new design paradigm is extremely effective in improving performance --- even for the moderate-size data sets processed, we have observed 2.5x+ performance gains, and the improvement grows substantially with the size of the data set.",
                "call-number": "10.1145/2491894.2466485",
                "collection-title": "ISMM '13",
                "container-title": "Proceedings of the 2013 international symposium on memory management",
                "DOI": "10.1145/2491894.2466485",
                "event-place": "Seattle, Washington, USA",
                "ISBN": "9781450321006",
                "keyword": "big data applications, design, memory bloat",
                "number-of-pages": "12",
                "page": "119–130",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A bloat-aware design for big data applications",
                "URL": "https://doi.org/10.1145/2491894.2466485"
            }
        },
        {
            "10.1145/2555670.2466485": {
                "id": "10.1145/2555670.2466485",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Bu",
                        "given": "Yingyi"
                    },
                    {
                        "family": "Borkar",
                        "given": "Vinayak"
                    },
                    {
                        "family": "Xu",
                        "given": "Guoqing"
                    },
                    {
                        "family": "Carey",
                        "given": "Michael J."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            20
                        ]
                    ]
                },
                "abstract": "Over the past decade, the increasing demands on data-driven business intelligence have led to the proliferation of large-scale, data-intensive applications that often have huge amounts of data (often at terabyte or petabyte scale) to process. An object-oriented programming language such as Java is often the developer's choice for implementing such applications, primarily due to its quick development cycle and rich community resource. While the use of such languages makes programming easier, significant performance problems can often be seen --- the combination of the inefficiencies inherent in a managed run-time system and the impact of the huge amount of data to be processed in the limited memory space often leads to memory bloat and performance degradation at a surprisingly early stage.This paper proposes a bloat-aware design paradigm towards the development of efficient and scalable Big Data applications in object-oriented GC enabled languages. To motivate this work, we first perform a study on the impact of several typical memory bloat patterns. These patterns are summarized from the user complaints on the mailing lists of two widely-used open-source Big Data applications. Next, we discuss our design paradigm to eliminate bloat. Using examples and real-world experience, we demonstrate that programming under this paradigm does not incur significant programming burden. We have implemented a few common data processing tasks both using this design and using the conventional object-oriented design. Our experimental results show that this new design paradigm is extremely effective in improving performance --- even for the moderate-size data sets processed, we have observed 2.5x+ performance gains, and the improvement grows substantially with the size of the data set.",
                "call-number": "10.1145/2555670.2466485",
                "container-title": "SIGPLAN Not.",
                "DOI": "10.1145/2555670.2466485",
                "ISSN": "0362-1340",
                "issue": "11",
                "keyword": "big data applications, memory bloat, design",
                "number-of-pages": "12",
                "page": "119–130",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "November 2013",
                "title": "A bloat-aware design for big data applications",
                "URL": "https://doi.org/10.1145/2555670.2466485",
                "volume": "48"
            }
        },
        {
            "10.1145/3147213.3155013": {
                "id": "10.1145/3147213.3155013",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chang",
                        "given": "Wo"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            12,
                            5
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            12,
                            5
                        ]
                    ]
                },
                "abstract": "Big Data is the term used to describe the deluge of data in our networked, digitized, sensor-laden, information driven world. There is a broad agreement among commercial, academic, and government leaders about the remarkable potential of \"Big Data\" to spark innovation, fuel commerce, and drive progress. The availability of vast data resources carries the potential to answer questions previously out of reach. However, there is also broad agreement on the ability of Big Data to overwhelm traditional approaches. Big Data architectures come in many shapes and forms ranging from academic research settings to product-oriented workflows. With massive-scale dynamic data being generate from social media, Internet of Things, Smart Cities, and others, it is critical to analyze these data in real-time and provide proactive decision. With the advancement of computer architecture in multi-cores and GPUs, and fast communication between CPUs and GPUs, parallel processing utilizes these platforms could optimize resources at a reduced time. This presentation will provide the past, current, and future activities of the NIST Big Data Public Working Group (NBD-PWG) and how the NIST Reference Architecture may address the rate at which data volumes, speeds, and complexity are growing requires new forms of computing infrastructure to enable Big Data analytics interoperability such that analytics tools can be re-usable, deployable, and operational. The focus of NBD-PWG is to form a community of interest from industry, academia, and government, with the goal of developing consensus definitions, taxonomies, secure reference architectures, and standards roadmap which would create vendor-neutral, technology and infrastructure agnostic framework. The aim is to enable Big Data stakeholders to pick-and-choose best analytics tools for their processing under the most suitable computing platforms and clusters while allowing value-additions from Big Data service providers and flow of data between the stakeholders in a cohesive and secure manner.",
                "call-number": "10.1145/3147213.3155013",
                "collection-title": "UCC '17",
                "container-title": "Proceedings of the10th International Conference on Utility and Cloud Computing",
                "DOI": "10.1145/3147213.3155013",
                "event-place": "Austin, Texas, USA",
                "ISBN": "9781450351492",
                "keyword": "big data reference architecture, high-performance computing, many cpus/cores/gpus, big data analytics",
                "number-of-pages": "1",
                "page": "3",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "NIST Big Data Reference Architecture for Analytics and Beyond",
                "URL": "https://doi.org/10.1145/3147213.3155013"
            }
        },
        {
            "10.14778/2367502.2367572": {
                "id": "10.14778/2367502.2367572",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Labrinidis",
                        "given": "Alexandros"
                    },
                    {
                        "family": "Jagadish",
                        "given": "H. V."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            8,
                            1
                        ]
                    ]
                },
                "abstract": "The promise of data-driven decision-making is now being recognized broadly, and there is growing enthusiasm for the notion of \"Big Data,\" including the recent announcement from the White House about new funding initiatives across different agencies, that target research for Big Data. While the promise of Big Data is real -- for example, it is estimated that Google alone contributed 54 billion dollars to the US economy in 2009 -- there is no clear consensus on what is Big Data. In fact, there have been many controversial statements about Big Data, such as \"Size is the only thing that matters.\" In this panel we will try to explore the controversies and debunk the myths surrounding Big Data.",
                "call-number": "10.14778/2367502.2367572",
                "container-title": "Proc. VLDB Endow.",
                "DOI": "10.14778/2367502.2367572",
                "ISSN": "2150-8097",
                "issue": "12",
                "number-of-pages": "2",
                "page": "2032–2033",
                "publisher": "VLDB Endowment",
                "source": "August 2012",
                "title": "Challenges and opportunities with big data",
                "URL": "https://doi.org/10.14778/2367502.2367572",
                "volume": "5"
            }
        },
        {
            "10.1145/3386723.3387886": {
                "id": "10.1145/3386723.3387886",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Tantaoui",
                        "given": "Mouad"
                    },
                    {
                        "family": "Laanaoui",
                        "given": "My Driss"
                    },
                    {
                        "family": "Kabil",
                        "given": "Mustapha"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            3,
                            31
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            3,
                            31
                        ]
                    ]
                },
                "abstract": "In this paper, we propose a new prediction system in real time using Big Data to improve the VANET network. Firstly, The Traffic density and average speed are calculated in each section of road, and then the risk of vehicle accident is predicted in instantaneous manner with parallel data processing, which makes execution faster.",
                "call-number": "10.1145/3386723.3387886",
                "collection-number": "67",
                "collection-title": "NISS2020",
                "container-title": "Proceedings of the 3rd International Conference on Networking, Information Systems & Security",
                "DOI": "10.1145/3386723.3387886",
                "event-place": "Marrakech, Morocco",
                "ISBN": "9781450376341",
                "keyword": "Big Data, VANET, Lambda architecture, Traffic density",
                "number": "Article 67",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Real-time Prediction of Accident using Big Data System",
                "URL": "https://doi.org/10.1145/3386723.3387886"
            }
        },
        {
            "10.1145/3426020.3426052": {
                "id": "10.1145/3426020.3426052",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Park",
                        "given": "Byeonghwa"
                    },
                    {
                        "family": "Noh",
                        "given": "Mijin"
                    },
                    {
                        "family": "Lee",
                        "given": "Choong Kwon"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            9,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            9,
                            17
                        ]
                    ]
                },
                "abstract": "This study aims to investigate the effect of big data analytics capability on big data values and business performance from the organizations performing big data analytics, which is one of the leading technologies in the fourth industrial revolution. For this study, the values of big data include transactional, strategic, transformational, and informational values. We conducted a survey and analyzed data from 200 professionals in organizations who had the experience of performing big data analytics. Structural equation modeling is used to test the research hypotheses. The results suggest that big data analytics capability has positive relationships with values of big data analytics and business performance. Of the values of big data analytics, however, the informational value of big data does not affect business performance. The results of this research are expected to provide researchers and practitioners who are interested in big data with useful information.",
                "call-number": "10.1145/3426020.3426052",
                "collection-title": "SMA 2020",
                "container-title": "The 9th International Conference on Smart Media and Applications",
                "DOI": "10.1145/3426020.3426052",
                "event-place": "Jeju, Republic of Korea",
                "ISBN": "9781450389259",
                "keyword": "Big data analytics, big data value, business performance",
                "number-of-pages": "3",
                "page": "132–134",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The Relationships between Capabilities and Values of Big Data Analytics",
                "URL": "https://doi.org/10.1145/3426020.3426052"
            }
        },
        {
            "10.1145/2792838.2799670": {
                "id": "10.1145/2792838.2799670",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sar Shalom",
                        "given": "Oren"
                    },
                    {
                        "family": "Berkovsky",
                        "given": "Shlomo"
                    },
                    {
                        "family": "Ronen",
                        "given": "Royi"
                    },
                    {
                        "family": "Ziklik",
                        "given": "Elad"
                    },
                    {
                        "family": "Amihood",
                        "given": "Amir"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            9,
                            16
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            9,
                            16
                        ]
                    ]
                },
                "abstract": "Although data quality has been recognized as an important factor in the broad information systems research, it has received little attention in recommender systems. Data quality matters are typically addressed in recommenders by ad-hoc cleansing methods, which prune noisy or unreliable records from the data. However, the setting of the cleansing parameters is often done arbitrarily, without thorough consideration of the data characteristics. In this work, we turn to two central data quality problems in recommender systems: sparsity and redundancy. We devise models for setting data-dependent thresholds and sampling levels, and evaluate these using a collection of public and proprietary datasets. We observe that the models accurately predict data cleansing parameters, while having minor effect on the accuracy of the generated recommendations.",
                "call-number": "10.1145/2792838.2799670",
                "collection-title": "RecSys '15",
                "container-title": "Proceedings of the 9th ACM Conference on Recommender Systems",
                "DOI": "10.1145/2792838.2799670",
                "event-place": "Vienna, Austria",
                "ISBN": "9781450336925",
                "keyword": "redundancy, sparsity, data quality, recommender systems",
                "number-of-pages": "4",
                "page": "257–260",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Data Quality Matters in Recommender Systems",
                "URL": "https://doi.org/10.1145/2792838.2799670"
            }
        },
        {
            "10.1145/3417990.3422004": {
                "id": "10.1145/3417990.3422004",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Khalajzadeh",
                        "given": "Hourieh"
                    },
                    {
                        "family": "Verma",
                        "given": "Tarun"
                    },
                    {
                        "family": "Simmons",
                        "given": "Andrew J."
                    },
                    {
                        "family": "Grundy",
                        "given": "John"
                    },
                    {
                        "family": "Abdelrazek",
                        "given": "Mohamed"
                    },
                    {
                        "family": "Hosking",
                        "given": "John"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            10,
                            16
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            10,
                            16
                        ]
                    ]
                },
                "abstract": "We outline the key requirements for a Big Data modelling recommender tool. Our web-based tool is suitable for capturing system requirements in big data analytics applications involving diverse stakeholders. It promotes awareness of the datasets and algorithm implementations that are available to leverage in the design of the solution. We implement these ideas in BiDaML-web, a proof of concept recommender system for Big Data applications, and evaluate the tool using an empirical study with a group of 16 target end-users. Participants found the integrated recommender and technique suggestion tools helpful and highly rated the overall BiDaML web-based modelling experience. BiDaML-web is available at https://bidaml.web.app/ and the source code can be accessed at https://github.com/tarunverma23/bidaml.",
                "call-number": "10.1145/3417990.3422004",
                "collection-number": "7",
                "collection-title": "MODELS '20",
                "container-title": "Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings",
                "DOI": "10.1145/3417990.3422004",
                "event-place": "Virtual Event, Canada",
                "ISBN": "9781450381352",
                "keyword": "BiDaML, big data applications, recommender",
                "number": "Article 7",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "User-centred tooling for modelling of big data applications",
                "URL": "https://doi.org/10.1145/3417990.3422004"
            }
        },
        {
            "10.1145/2351316.2351327": {
                "id": "10.1145/2351316.2351327",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Magnusson",
                        "given": "Jonathan"
                    },
                    {
                        "family": "Kvernvik",
                        "given": "Tor"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            8,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            8,
                            12
                        ]
                    ]
                },
                "abstract": "This paper describes a scalable solution for identifying influential subscribers in for example telecom networks. The solution estimates one weighted value of influence out of several Social Network Analysis(SNA) metrics. The novel method for aggregation of several metrics utilizes machine learning to train models. A prototype solution has been implemented on a Hadoop platform to support scalability and to reduce hard ware cost by enabling the usage of commodity computers. The SNA algorithms have been adapted to efficiently execute on the MapReduce distributed platform. The prototype solution has been tested on a Hadoop cluster. The tests have verified that the solution can scale to support networks with millions of subscribers. Both real data from a telecom network operator with 2.4 million subscribers and synthetic data for networks up to 100 million subscribers have been used to verify the scalability and accuracy of the solution. The correlation between metrics have been analyzed to identify the information gain from each metric.",
                "call-number": "10.1145/2351316.2351327",
                "collection-title": "BigMine '12",
                "container-title": "Proceedings of the 1st International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications",
                "DOI": "10.1145/2351316.2351327",
                "event-place": "Beijing, China",
                "ISBN": "9781450315470",
                "keyword": "scalability, big data, social network analysis, machine learning, telecommunication",
                "number-of-pages": "8",
                "page": "77–84",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Subscriber classification within telecom networks utilizing big data technologies and machine learning",
                "URL": "https://doi.org/10.1145/2351316.2351327"
            }
        },
        {
            "10.1145/2976744": {
                "id": "10.1145/2976744",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Yu",
                        "given": "Kui"
                    },
                    {
                        "family": "Wu",
                        "given": "Xindong"
                    },
                    {
                        "family": "Ding",
                        "given": "Wei"
                    },
                    {
                        "family": "Pei",
                        "given": "Jian"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            12,
                            3
                        ]
                    ]
                },
                "abstract": "Feature selection is important in many big data applications. Two critical challenges closely associate with big data. First, in many big data applications, the dimensionality is extremely high, in millions, and keeps growing. Second, big data applications call for highly scalable feature selection algorithms in an online manner such that each feature can be processed in a sequential scan. We present SAOLA, a <underline>S</underline>calable and <underline>A</underline>ccurate <underline>O</underline>n<underline>L</underline>ine <underline>A</underline>pproach for feature selection in this paper. With a theoretical analysis on bounds of the pairwise correlations between features, SAOLA employs novel pairwise comparison techniques and maintains a parsimonious model over time in an online manner. Furthermore, to deal with upcoming features that arrive by groups, we extend the SAOLA algorithm, and then propose a new group-SAOLA algorithm for online group feature selection. The group-SAOLA algorithm can online maintain a set of feature groups that is sparse at the levels of both groups and individual features simultaneously. An empirical study using a series of benchmark real datasets shows that our two algorithms, SAOLA and group-SAOLA, are scalable on datasets of extremely high dimensionality and have superior performance over the state-of-the-art feature selection methods.",
                "call-number": "10.1145/2976744",
                "collection-number": "16",
                "container-title": "ACM Trans. Knowl. Discov. Data",
                "DOI": "10.1145/2976744",
                "ISSN": "1556-4681",
                "issue": "2",
                "keyword": "group features, Online feature selection, big data, extremely high dimensionality",
                "number": "Article 16",
                "number-of-pages": "39",
                "page": "1–39",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "May 2017",
                "title": "Scalable and Accurate Online Feature Selection for Big Data",
                "URL": "https://doi.org/10.1145/2976744",
                "volume": "11"
            }
        },
        {
            "10.1145/1651415.1651417": {
                "id": "10.1145/1651415.1651417",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Farinha",
                        "given": "José"
                    },
                    {
                        "family": "Trigueiros",
                        "given": "Maria José"
                    },
                    {
                        "family": "Belo",
                        "given": "Orlando"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2009,
                            11,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2009,
                            11,
                            6
                        ]
                    ]
                },
                "abstract": "Currently available data quality tools provide development environments that significantly decrease the effort in dealing with common data problems, such as those related with attribute domain validation, syntax checking, or value matching against a reference master data repository. On the contrary, more complex and specific data quality functionalities, whose requirements usually derive from application domain business rules, have to be developed from scratch, usually leading to high costs of development and maintenance. This paper introduces the concept of inheritance in a metadata-driven approach to simplified data quality rule management. The approach is based on the belief that even complex data quality rules very often adhere to recurring patterns that can be encoded and encapsulated as reusable, abstract templates. The approach is supported by a metamodel developed on top of OMG's Common Warehouse Metamodel, herein extended with the ability to derive new rule patterns from existing ones, through inheritance. The inheritance metamodel is presented in UML and its application is illustrated with a running example.",
                "call-number": "10.1145/1651415.1651417",
                "collection-title": "MoSE+DQS '09",
                "container-title": "Proceedings of the first international workshop on Model driven service engineering and data quality and security",
                "DOI": "10.1145/1651415.1651417",
                "event-place": "Hong Kong, China",
                "ISBN": "9781605588162",
                "keyword": "data quality, conceptual modeling, metadata, patterns, cwm, inheritance",
                "number-of-pages": "8",
                "page": "1–8",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Using inheritance in a metadata based approach to data quality assessment",
                "URL": "https://doi.org/10.1145/1651415.1651417"
            }
        },
        {
            "10.1145/2640087.2644149": {
                "id": "10.1145/2640087.2644149",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Mohammadian",
                        "given": "Esmaeil"
                    },
                    {
                        "family": "Noferesti",
                        "given": "Morteza"
                    },
                    {
                        "family": "Jalili",
                        "given": "Rasool"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            4
                        ]
                    ]
                },
                "abstract": "This paper proposes an anonymization algorithm (FAST) to speed up anonymization of big data streams. The proposed parallel algorithm provides an efficient big data anonymization by a multithread technique. A proactive time-expiration heuristic is applied to publish data before they are being expired. Our simulation results indicate significant improvement in big data stream anonymization in terms of information loss and cost metric.",
                "call-number": "10.1145/2640087.2644149",
                "collection-number": "23",
                "collection-title": "BigDataScience '14",
                "container-title": "Proceedings of the 2014 International Conference on Big Data Science and Computing",
                "DOI": "10.1145/2640087.2644149",
                "event-place": "Beijing, China",
                "ISBN": "9781450328913",
                "keyword": "Privacy, Anonymization, Stream, Big data",
                "number": "Article 23",
                "number-of-pages": "8",
                "page": "1–8",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "FAST: Fast Anonymization of Big Data Streams",
                "URL": "https://doi.org/10.1145/2640087.2644149"
            }
        },
        {
            "10.1145/2508859.2512502": {
                "id": "10.1145/2508859.2512502",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Reznik",
                        "given": "Leon"
                    },
                    {
                        "family": "Bertino",
                        "given": "Elisa"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            11,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            11,
                            4
                        ]
                    ]
                },
                "abstract": "Data quality (DQ) is essential to achieve data trustworthiness, as it assures that data is free of errors, complete, and consistent. This paper proposes an approach to evaluate DQ in multichannel sensor networks and systems with heterogeneous data sources. The approach integrates various DQ indicators ranging from traditional data accuracy metrics to network security and business performance measures. It demonstrates the advantage of including security metrics into the DQ evaluation for the design optimization of data fusion procedures and even the whole data collection and communication systems. The DQ metrics composition and calculus are discussed. However, the major attention is paid to the analysis of the relationship between conventional data accuracy metrics and network security indicators.",
                "call-number": "10.1145/2508859.2512502",
                "collection-title": "CCS '13",
                "container-title": "Proceedings of the 2013 ACM SIGSAC conference on Computer & communications security",
                "DOI": "10.1145/2508859.2512502",
                "event-place": "Berlin, Germany",
                "ISBN": "9781450324779",
                "keyword": "computer security evaluation, data fusion., data accuracy, data quality",
                "number-of-pages": "4",
                "page": "1367–1370",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "POSTER: Data quality evaluation: integrating security and accuracy",
                "URL": "https://doi.org/10.1145/2508859.2512502"
            }
        },
        {
            "10.1145/3447548.3470817": {
                "id": "10.1145/3447548.3470817",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Gupta",
                        "given": "Nitin"
                    },
                    {
                        "family": "Mujumdar",
                        "given": "Shashank"
                    },
                    {
                        "family": "Patel",
                        "given": "Hima"
                    },
                    {
                        "family": "Masuda",
                        "given": "Satoshi"
                    },
                    {
                        "family": "Panwar",
                        "given": "Naveen"
                    },
                    {
                        "family": "Bandyopadhyay",
                        "given": "Sambaran"
                    },
                    {
                        "family": "Mehta",
                        "given": "Sameep"
                    },
                    {
                        "family": "Guttula",
                        "given": "Shanmukha"
                    },
                    {
                        "family": "Afzal",
                        "given": "Shazia"
                    },
                    {
                        "family": "Sharma Mittal",
                        "given": "Ruhi"
                    },
                    {
                        "family": "Munigala",
                        "given": "Vitobha"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            8,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            8,
                            14
                        ]
                    ]
                },
                "abstract": "The quality of training data has a huge impact on the efficiency, accuracy and complexity of machine learning tasks. Data remains susceptible to errors or irregularities that may be introduced during collection, aggregation or annotation stage. This necessitates profiling and assessment of data to understand its suitability for machine learning tasks and failure to do so can result in inaccurate analytics and unreliable decisions. While researchers and practitioners have focused on improving the quality of models, there are limited efforts towards improving the data quality.Assessing the quality of the data across intelligently designed metrics and developing corresponding transformation operations to address the quality gaps helps to reduce the effort of a data scientist for iterative debugging of the ML pipeline to improve model performance. This tutorial highlights the importance of analysing data quality in terms of its value for ML applications. Finding the data quality issues in data helps different personas like data stewards, data scientists, subject matter experts, or machine learning scientists to get relevant data insights and take remedial actions to rectify any issue. This tutorial surveys all the important data quality related approaches for structured, unstructured and spatio-temporal domains discussed in literature, focusing on the intuition behind them, highlighting their strengths and similarities, and illustrates their applicability to real-world problems. Finally we will discuss the interesting work IBM Research is doing in this space.",
                "call-number": "10.1145/3447548.3470817",
                "collection-title": "KDD '21",
                "container-title": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining",
                "DOI": "10.1145/3447548.3470817",
                "event-place": "Virtual Event, Singapore",
                "ISBN": "9781450383325",
                "keyword": "quality metrics, data quality, machine learning",
                "number-of-pages": "2",
                "page": "4040–4041",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Data Quality for Machine Learning Tasks",
                "URL": "https://doi.org/10.1145/3447548.3470817"
            }
        },
        {
            "10.1145/3053600.3053630": {
                "id": "10.1145/3053600.3053630",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Ciavotta",
                        "given": "Michele"
                    },
                    {
                        "family": "Gianniti",
                        "given": "Eugenio"
                    },
                    {
                        "family": "Ardagna",
                        "given": "Danilo"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            4,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            4,
                            18
                        ]
                    ]
                },
                "abstract": "The aim of this work is to present the problem of Capacity Allocation for multiple classes of Big Data applications running in the Cloud. The objective is the minimization of the renting out costs subject to the fulfillment of QoS requirements expressed in terms of application deadlines. We propose a preliminary version of a tool embedding a local-search-based algorithm exploiting also an integer nonlinear mathematical formulation and a queueing network simulation to solve the problem.",
                "call-number": "10.1145/3053600.3053630",
                "collection-title": "ICPE '17 Companion",
                "container-title": "Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion",
                "DOI": "10.1145/3053600.3053630",
                "event-place": "L&apos;Aquila, Italy",
                "ISBN": "9781450348997",
                "keyword": "cloud, qos, capacity allocation., big data",
                "number-of-pages": "2",
                "page": "175–176",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Capacity Allocation for Big Data Applications in the Cloud",
                "URL": "https://doi.org/10.1145/3053600.3053630"
            }
        },
        {
            "10.1145/2627534.2627556": {
                "id": "10.1145/2627534.2627556",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Madan",
                        "given": "Bharat B."
                    },
                    {
                        "family": "Banik",
                        "given": "Manoj"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            4,
                            17
                        ]
                    ]
                },
                "abstract": "Data driven decisions derived from big data have become critical in many application domains, fueling the demand for collection, transportation, storage and processing of massive volumes of data. Such applications have made data a valuable resource that needs to be provided appropriate security. High value associated with big data sets has rendered big data storage systems attractive targets for cyber attackers, whose goal is to compromise the Confidentiality, Integrity and Availability of data and information. Common defense strategy for protecting cyber assets has been to first take preventive measures, and if these fail, detecting intrusions and finally recovery. Unfortunately, attackers have developed tremendous technical sophistication to defeat most defensive mechanisms. Alternative strategy is to design architectures which are intrinsically attack tolerant. This paper describes a technique that involves eliminating single point of security failures through fragmentation, coding, dispersion and reassembly. It is shown that this technique can be successfully applied to routing, networked storage systems, and big data file systems to make them attack tolerant.",
                "call-number": "10.1145/2627534.2627556",
                "container-title": "SIGMETRICS Perform. Eval. Rev.",
                "DOI": "10.1145/2627534.2627556",
                "ISSN": "0163-5999",
                "issue": "4",
                "keyword": "data availability, attack tolerance, big-data security, data integrity, secure storage, data confidentiality",
                "number-of-pages": "5",
                "page": "65–69",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "March 2014",
                "title": "Attack tolerant architecture for big data file systems",
                "URL": "https://doi.org/10.1145/2627534.2627556",
                "volume": "41"
            }
        },
        {
            "10.1145/2378356": {
                "id": "10.1145/2378356",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2012
                        ]
                    ]
                },
                "abstract": "Data is growing at an exponential rate and several systems have emerged to store and analyze such large amounts of data. These systems, termed “Big data systems” are fast evolving Examples include the NoSQL storage systems, Hadoop Map-Reduce, data analytics platforms, search and indexing platforms, and messaging infrastructures. These systems address needs for structured and unstructured data across a wide spectrum of domains such as web, social networks, enterprise, cloud, mobile, sensor networks, multimedia/streaming, cyberphysical and high performance systems, and for multiple application verticals such as biosciences, healthcare, transportation, public sector, energy utilities, oil & gas, and scientific computing.With increasing scale and complexity, managing these big data systems to cope with failures and performance problems is becoming non-trivial. New resource management and scheduling mechanisms are also needed for such systems, and so are mechanisms for tuning and support from platform layers. Several open source and proprietary solutions have been proposed to address these requirements, with extensive contributions from industry and academia. However, there remain substantial challenges, including those that pertain to such systems' autonomic and self-management capabilities.The objective of the MBDS workshop is to bring together researchers, practitioners, system administrators, system programmers, and others interested in sharing and presenting their perspectives on the effective management of big data systems. The focus of the workshop is on novel and practical, systems-oriented work. MBDS offers an opportunity for researchers and practitioners from industry, academia, and national labs to showcase the latest advances in this area and to also discuss and identify future directions and challenges in all aspects on autonomic management of big data systems.Papers are solicited on all aspects of big data management. Specific topics of interest include, but are not limited, to the following: Autonomic and self-managing techniques Application-level resource management and scheduling mechanisms System tuning/auto-tuning and configuration management Performance management, fault management, and power management Scalability challenges Complexity challenges, as for composite, cross-tier systems with multiple control loops Unified management of 'data in motion' and 'data at rest' Dealing with both structured and unstructured data Monitoring, diagnosis, and automated behaviour detection System-level principles and support for resource management Holistic management across hardware and software Implications of emerging hardware technologies such as non-volatile memory Domain specific challenges in web, cloud, social networks, mobile, sensor networks, streaming analytics, cyber-physical systems System building and experience papers for specific industry verticals",
                "call-number": "10.1145/2378356",
                "container-title-short": "MBDS '12",
                "event-place": "San Jose, California, USA",
                "genre": "proceeding",
                "ISBN": "9781450317528",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2012 workshop on Management of big data systems"
            }
        },
        {
            "10.1109/WI-IAT.2014.15": {
                "id": "10.1109/WI-IAT.2014.15",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Hansmann",
                        "given": "Thomas"
                    },
                    {
                        "family": "Niemeyer",
                        "given": "Peter"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            11
                        ]
                    ]
                },
                "abstract": "Big Data is one of the latest emerging topics in the field of business information systems, and is marketed as being the key for companies' future success. Many analytic solutions are offered by IT companies to help other businesses with the flood of data that is generated within and outside of a company. Despite the extensive use of the notion Big Data for marketing purposes, there is no common understanding of how to characterize the elements of the Big Data concept. The authors contribute to the clarification of this concept with a methodologically enriched literature review by deriving characteristic dimensions from existing definitions of Big Data. These dimensions are validated and enriched with a two-step approach by applying topic models on 248 publications relevant to Big Data. The authors propose that the concept of Big Data can be described by the dimensions of data, IT infrastructure, applied methods, and an applications perspective. The assignment of the results to a generic data analysis process reveals that recent publications focus on data analysis and processing, and less attention is given to the initial data selection or the visualization and utilization of the analysis results.",
                "call-number": "10.1109/WI-IAT.2014.15",
                "collection-title": "WI-IAT '14",
                "container-title": "Proceedings of the 2014 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT) - Volume 01",
                "DOI": "10.1109/WI-IAT.2014.15",
                "ISBN": "9781479941438",
                "keyword": "literature review, topic models, Big Data",
                "number-of-pages": "9",
                "page": "43–51",
                "publisher": "IEEE Computer Society",
                "publisher-place": "USA",
                "title": "Big Data - Characterizing an Emerging Research Field Using Topic Models",
                "URL": "https://doi.org/10.1109/WI-IAT.2014.15"
            }
        },
        {
            "10.1145/2628071.2671429": {
                "id": "10.1145/2628071.2671429",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Harshvardhan"
                    },
                    {
                        "family": "Amato",
                        "given": "Nancy M."
                    },
                    {
                        "family": "Rauchweger",
                        "given": "Lawrence"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            24
                        ]
                    ]
                },
                "abstract": "With the advent of big-data, processing large graphs quickly has become increasingly important. Most existing approaches either utilize in-memory processing techniques, which can only process graphs that fit completely in RAM, or disk-based techniques that sacrifice performance.In this work, we propose a novel RAM-Disk hybrid approach to graph processing that can scale well from a single shared-memory node to large distributed-memory systems. It works by partitioning the graph into subgraphs that fit in RAM and uses a paging-like technique to load subgraphs. We show that without modifying the algorithms, this approach can scale from small memory-constrained systems (such as tablets) to large-scale distributed machines with 16,000+ cores.",
                "call-number": "10.1145/2628071.2671429",
                "collection-title": "PACT '14",
                "container-title": "Proceedings of the 23rd international conference on Parallel architectures and compilation",
                "DOI": "10.1145/2628071.2671429",
                "event-place": "Edmonton, AB, Canada",
                "ISBN": "9781450328098",
                "keyword": "out-of-core graph algorithms, graph analytics, distributed computing, parallel graph processing, big data",
                "number-of-pages": "2",
                "page": "517–518",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Processing Big Data Graphs on Memory-Restricted Systems",
                "URL": "https://doi.org/10.1145/2628071.2671429"
            }
        },
        {
            "10.1145/3416921": {
                "id": "10.1145/3416921",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2020
                        ]
                    ]
                },
                "abstract": "The main goal and feature of the conference are to bring together scientists, engineers and industry researchers together to exchange and share their experiences, research results and discuss emerging practical problems and solutions. ICCBDC 2020 received 39 submissions of research papers. After a strict reviewing process, 23 of them have been accepted for presentation at the conference and publication in the proceedings. The conference program included invited talks, six research paper presentation sessions and one industry session. It covered recent trends and advances made in the fields of cloud and big data computing. All accepted papers were presented online in 15 minutes followed by discussions. This conference proceedings consists of the research papers presented at ICCBDC 2020.",
                "call-number": "10.1145/3416921",
                "container-title-short": "ICCBDC '20",
                "event-place": "Virtual, United Kingdom",
                "genre": "proceeding",
                "ISBN": "9781450375382",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2020 4th International Conference on Cloud and Big Data Computing"
            }
        },
        {
            "10.1145/3402569.3409038": {
                "id": "10.1145/3402569.3409038",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Changxin",
                        "given": "Song"
                    },
                    {
                        "family": "Ke",
                        "given": "Ma"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            5,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            5,
                            22
                        ]
                    ]
                },
                "abstract": "With the updating and upgrading of hospital network information diagnosis and treatment, in the medical disease diagnosis, data processing and scientific research, we usually use a variety of big data and cloud computing technology, combined with clinical biology, medicine and other diseases diagnosis and treatment plan, and carry out biological information data collection, mining, analysis, processing and storage. In order to meet the needs of data variables for different medical treatment activities, this article focuses on the analysis of the causes of hypertension diseases in different regions around the essential hypertension (EH) by using the improved ant colony optimization algorithm (IACO), including the external environment, racial differences, genetic heterogeneity, and the single nucleotide polymorphism (SNP) polymorphism data and SNP-SNP combination in each gene coding region. Information mining and parallel computing analysis are carried out to obtain more objective and accurate results of complex disease assessment.",
                "call-number": "10.1145/3402569.3409038",
                "collection-title": "ICDEL 2020",
                "container-title": "Proceedings of the 5th International Conference on Distance Education and Learning",
                "DOI": "10.1145/3402569.3409038",
                "event-place": "Beijing, China",
                "ISBN": "9781450377546",
                "keyword": "big data mining, research, Bioinformatics, methods",
                "number-of-pages": "4",
                "page": "166–169",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on Big Data Mining Method of Bioinformatics",
                "URL": "https://doi.org/10.1145/3402569.3409038"
            }
        },
        {
            "10.1145/3257818": {
                "id": "10.1145/3257818",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kelly",
                        "given": "Terence"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            4
                        ]
                    ]
                },
                "call-number": "10.1145/3257818",
                "collection-title": "SOSP '15",
                "container-title": "Proceedings of the 25th Symposium on Operating Systems Principles",
                "DOI": "10.1145/3257818",
                "event-place": "Monterey, California",
                "ISBN": "9781450338349",
                "page": "",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Session details: Big data",
                "URL": "https://doi.org/10.1145/3257818"
            }
        },
        {
            "10.1145/2640087.2644187": {
                "id": "10.1145/2640087.2644187",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Mohammadian",
                        "given": "Esmaeil"
                    },
                    {
                        "family": "Noferesti",
                        "given": "Morteza"
                    },
                    {
                        "family": "Jalili",
                        "given": "Rasool"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            4
                        ]
                    ]
                },
                "abstract": "This paper proposes an anonymization algorithm (FAST) to speed up anonymization of big data streams. The proposed parallel algorithm provides an efficient big data anonymization by a multithread technique. A proactive time-expiration heuristic is applied to publish data before they are being expired. Our simulation results indicate significant improvement in big data stream anonymization in terms of information loss and cost metric.",
                "call-number": "10.1145/2640087.2644187",
                "collection-number": "31",
                "collection-title": "BigDataScience '14",
                "container-title": "Proceedings of the 2014 International Conference on Big Data Science and Computing",
                "DOI": "10.1145/2640087.2644187",
                "event-place": "Beijing, China",
                "ISBN": "9781450328913",
                "keyword": "Anonymization, Stream, Big data, Privacy",
                "number": "Article 31",
                "number-of-pages": "2",
                "page": "1–2",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "FAST: Fast Anonymization of Big Data Streams",
                "URL": "https://doi.org/10.1145/2640087.2644187"
            }
        },
        {
            "10.1145/2911975": {
                "id": "10.1145/2911975",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Kugler",
                        "given": "Logan"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            5,
                            23
                        ]
                    ]
                },
                "abstract": "Big data is touted as a cure-all for challenges in business, government, and healthcare, but as disease outbreak predictions show, big data often fails.",
                "call-number": "10.1145/2911975",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/2911975",
                "ISSN": "0001-0782",
                "issue": "6",
                "number-of-pages": "2",
                "page": "15–16",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "June 2016",
                "title": "What happens when big data blunders?",
                "URL": "https://doi.org/10.1145/2911975",
                "volume": "59"
            }
        },
        {
            "10.1145/3415958.3433082": {
                "id": "10.1145/3415958.3433082",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Dessalk",
                        "given": "Yared Dejene"
                    },
                    {
                        "family": "Nikolov",
                        "given": "Nikolay"
                    },
                    {
                        "family": "Matskin",
                        "given": "Mihhail"
                    },
                    {
                        "family": "Soylu",
                        "given": "Ahmet"
                    },
                    {
                        "family": "Roman",
                        "given": "Dumitru"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            11,
                            2
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            11,
                            2
                        ]
                    ]
                },
                "abstract": "Big Data processing involves handling large and complex data sets, incorporating different tools and frameworks as well as other processes that help organisations make sense of their data collected from various sources. This set of operations, referred to as Big Data workflows, require taking advantage of the elasticity of cloud infrastructures for scalability. In this paper, we present the design and prototype implementation of a Big Data workflow approach based on the use of software container technologies and message-oriented middleware (MOM) to enable highly scalable workflow execution. The approach is demonstrated in a use case together with a set of experiments that demonstrate the practical applicability of the proposed approach for the scalable execution of Big Data workflows. Furthermore, we present a scalability comparison of our proposed approach with that of Argo Workflows - one of the most prominent tools in the area of Big Data workflows.",
                "call-number": "10.1145/3415958.3433082",
                "collection-title": "MEDES '20",
                "container-title": "Proceedings of the 12th International Conference on Management of Digital EcoSystems",
                "DOI": "10.1145/3415958.3433082",
                "event-place": "Virtual Event, United Arab Emirates",
                "ISBN": "9781450381154",
                "keyword": "Domain-specific languages, Big Data workflows, Software containers",
                "number-of-pages": "8",
                "page": "76–83",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Scalable Execution of Big Data Workflows using Software Containers",
                "URL": "https://doi.org/10.1145/3415958.3433082"
            }
        },
        {
            "10.1145/2808719.2816984": {
                "id": "10.1145/2808719.2816984",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Deng",
                        "given": "Xin"
                    },
                    {
                        "family": "Wu",
                        "given": "Donghui"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            9,
                            9
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            9,
                            9
                        ]
                    ]
                },
                "abstract": "This panel discussion will first review a few current big data and predictive modeling topics in healthcare in both providers and payers marketspace, including the problems, current status and challenges, and opportunities for big data and future trends. Follow the opening remarks, the panelists will provide their own insights and point of views on some of the topics, and interactive discussion among themselves and audience. Among many of the topics, a few examples are: Improve quality outcomes through analytics and predictive modeling; Reduce and prevent hospital re-admission through risk predictions and case management; Discover Abuse, Waste and Fraud in Healthcare Providers; Improve population health through personalized interventions; Understand the population signed through Health Insurance Exchange Marketplace (HIX); Population Risk Adjustment; Improve CMS STARS rating; Provider Quality Measurement and Regulator Reporting; Provider Risk and Revenue management; Unified Patient Record, Big Data Challenges for Providers and Payers, etc.",
                "call-number": "10.1145/2808719.2816984",
                "collection-title": "BCB '15",
                "container-title": "Proceedings of the 6th ACM Conference on Bioinformatics, Computational Biology and Health Informatics",
                "DOI": "10.1145/2808719.2816984",
                "event-place": "Atlanta, Georgia",
                "ISBN": "9781450338530",
                "keyword": "population health management, health informatics, data integration, big data platform, predictive analytics",
                "number-of-pages": "1",
                "page": "677",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data and predictive modeling topics in healthcare",
                "URL": "https://doi.org/10.1145/2808719.2816984"
            }
        },
        {
            "10.1145/3158344": {
                "id": "10.1145/3158344",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Kowolenko",
                        "given": "Michael"
                    },
                    {
                        "family": "Vouk",
                        "given": "Mladen A."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            3,
                            19
                        ]
                    ]
                },
                "abstract": "The ability to leverage diverse data types requires a robust and dynamic approach to systems design. The needs of a data scientist are as varied as the questions being explored. Compute systems have focused on the management and analysis of structured data as the driving force of analytics in business. As open source platforms have evolved, the ability to apply compute to unstructured information has exposed an array of platforms and tools available to the business and technical community. We have developed a platform that meets the needs of the analytics user requirements of both structured and unstructured data. This analytics workbench is based on acquisition, transformation, and analysis using open source tools such as Nutch, Tika, Elastic, Python, PostgreSQL, and Django to implement a cognitive compute environment that can handle widely diverse data, and can leverage the ever-expanding capabilities of infrastructure in order to provide intelligence augmentation.",
                "call-number": "10.1145/3158344",
                "collection-number": "2",
                "container-title": "Ubiquity",
                "DOI": "10.1145/3158344",
                "issue": "March",
                "number": "Article 2",
                "number-of-pages": "15",
                "page": "1–15",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "March 2018",
                "title": "Developing an Open Source 'Big Data' Cognitive Computing Platform: Big Data (Ubiquity symposium)",
                "URL": "https://doi.org/10.1145/3158344",
                "volume": "2018"
            }
        },
        {
            "10.1145/3027385.3029445": {
                "id": "10.1145/3027385.3029445",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Oi",
                        "given": "Misato"
                    },
                    {
                        "family": "Yamada",
                        "given": "Masanori"
                    },
                    {
                        "family": "Okubo",
                        "given": "Fumiya"
                    },
                    {
                        "family": "Shimada",
                        "given": "Atsushi"
                    },
                    {
                        "family": "Ogata",
                        "given": "Hiroaki"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            3,
                            13
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            3,
                            13
                        ]
                    ]
                },
                "abstract": "In this paper, we examined whether previous findings on educational big data consisting of e-book logs from a given academic course can be reproduced with different data from other academic courses. The previous findings showed that (1) students who attained consistently good achievement more frequently browsed different e-books and their pages than low achievers and that (2) this difference was found only for logs of preparation for course sessions (preview), not for reviewing material (review). Preliminarily, we analyzed e-book logs from four courses. The results were reproduced in only one course and only partially, that is, (1) high achievers more frequently changed e-books than low achievers (2) for preview. This finding suggests that to allow effective usage of learning and teaching analyses, we need to carefully construct an educational environment to ensure reproducibility.",
                "call-number": "10.1145/3027385.3029445",
                "collection-title": "LAK '17",
                "container-title": "Proceedings of the Seventh International Learning Analytics & Knowledge Conference",
                "DOI": "10.1145/3027385.3029445",
                "event-place": "Vancouver, British Columbia, Canada",
                "ISBN": "9781450348706",
                "keyword": "reproducibility, educational big data, e-book",
                "number-of-pages": "2",
                "page": "536–537",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Reproducibility of findings from educational big data: a preliminary study",
                "URL": "https://doi.org/10.1145/3027385.3029445"
            }
        },
        {
            "10.1145/2487575.2506179": {
                "id": "10.1145/2487575.2506179",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Getoor",
                        "given": "Lise"
                    },
                    {
                        "family": "Machanavajjhala",
                        "given": "Ashwin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            8,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            8,
                            11
                        ]
                    ]
                },
                "abstract": "Entity resolution (ER), the problem of extracting, matching and resolving entity mentions in structured and unstructured data, is a long-standing challenge in database management, information retrieval, machine learning, natural language processing and statistics. Accurate and fast entity resolution has huge practical implications in a wide variety of commercial, scientific and security domains. Despite the long history of work on entity resolution, there is still a surprising diversity of approaches, and lack of guiding theory. Meanwhile, in the age of big data, the need for high quality entity resolution is growing, as we are inundated with more and more data, all of which needs to be integrated, aligned and matched, before further utility can be extracted. In this tutorial, we bring together perspectives on entity resolution from a variety of fields, including databases, information retrieval, natural language processing and machine learning, to provide, in one setting, a survey of a large body of work. We discuss both the practical aspects and theoretical underpinnings of ER. We describe existing solutions, current challenges and open research problems. In addition to giving attendees a thorough understanding of existing ER models, algorithms and evaluation methods, the tutorial will cover important research topics such as scalable ER, active and lightly supervised ER, and query-driven ER.",
                "call-number": "10.1145/2487575.2506179",
                "collection-title": "KDD '13",
                "container-title": "Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining",
                "DOI": "10.1145/2487575.2506179",
                "event-place": "Chicago, Illinois, USA",
                "ISBN": "9781450321747",
                "number-of-pages": "1",
                "page": "1527",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Entity resolution for big data",
                "URL": "https://doi.org/10.1145/2487575.2506179"
            }
        },
        {
            "10.1145/3090354": {
                "id": "10.1145/3090354",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2017
                        ]
                    ]
                },
                "call-number": "10.1145/3090354",
                "container-title-short": "BDCA'17",
                "event-place": "Tetouan, Morocco",
                "genre": "proceeding",
                "ISBN": "9781450348522",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2nd international Conference on Big Data, Cloud and Applications"
            }
        },
        {
            "10.1145/3524383.3524399": {
                "id": "10.1145/3524383.3524399",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yang",
                        "given": "Xuxin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            2,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            2,
                            26
                        ]
                    ]
                },
                "abstract": "Under the Big Data, Intelligentization, Mobile Internet and Cloud Computing, the accounting and the accounting profession face new opportunities and difficulties, and the new standards for accounting expertise are established. Because of the imbalance between supply and demand, there is currently an excess and oversupply of accounting skills in China. In order to deal with this challenge, this paper proposes the path of training applied accounting talents based on the DES model. On this basis, it examines the current situation of insufficient accounting talent cultivated by accounting higher education in China from a perspective of supply, and analyzes the society's demand for accounting talent under Big Data, Intelligentization, Mobile Internet and Cloud Computing from a perspective of demand. Then, it is found that the supply cannot match the demand effectively. Thus, in the Big Data, Intelligentization, Mobile Internet and Cloud Computing environment, this paper proposes the paths of reconstructing accounting talent cultivation goals, systematically adding information-based curriculum, optimizing teaching evaluation mechanism, focusing on faculty construction, establishing teaching modes of student participation, and stressing cross-border capability cultivation.",
                "call-number": "10.1145/3524383.3524399",
                "collection-title": "ICBDE '22",
                "container-title": "Proceedings of the 5th International Conference on Big Data and Education",
                "DOI": "10.1145/3524383.3524399",
                "event-place": "Shanghai, China",
                "ISBN": "9781450395793",
                "keyword": "Cultivation Path, Accounting Ability, DES Model, Applied Accounting Talents, Big Data, Intelligentization, Mobile Internet and Cloud Computing",
                "number-of-pages": "6",
                "page": "183–188",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The Path of Cultivating Applied Accounting Talents Based on DES Model under Big Data, Intelligentization, Mobile Internet and Cloud Computing",
                "URL": "https://doi.org/10.1145/3524383.3524399"
            }
        },
        {
            "10.1145/3085228.3085275": {
                "id": "10.1145/3085228.3085275",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Gong",
                        "given": "Yiwei"
                    },
                    {
                        "family": "Janssen",
                        "given": "Marijn"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            6,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            6,
                            7
                        ]
                    ]
                },
                "abstract": "Governments from all over the world are struggling to take advantage of big data developments. Enterprise Architecture (EA) can be used as an instrument to integrate big data (BD) in the existing business processes and ICT-landscape. In this policy paper, we explore the role of EA in the adoption of BD. For this, we adopted a qualitative case study approach and investigated a large administrative organization that was in the process of adopting BD. We found in our case study that the first attempts were focused on integrating big data in the current landscape, but this encountered too many challenges that halt progress. To overcome the challenges, a separate BD department and accompanying infrastructure was created. The strategy was first to reap the benefits of BD and to understand what should be done, and thereafter integrating the working systems in the existing landscape. The findings suggest that current infrastructures might not be suitable for integrating BD and substantial changes are needed first. In the case the role of BD needed to be first clarified before EA could play a role in adopting BD. EA should deal with the uncertainties and complexities by ensuring a configurable landscape, by providing an incremental approach for adapting the infrastructure step-by-step, before the benefits of big data can be gained. Developing an incremental migration plan was found to be a key aspect for the adoption of BD.",
                "call-number": "10.1145/3085228.3085275",
                "collection-title": "dg.o '17",
                "container-title": "Proceedings of the 18th Annual International Conference on Digital Government Research",
                "DOI": "10.1145/3085228.3085275",
                "event-place": "Staten Island, NY, USA",
                "ISBN": "9781450353175",
                "keyword": "enterprise architecture, ICT-architecture, open data, BOLD, e-government, infrastructure, big data",
                "number-of-pages": "6",
                "page": "505–510",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Enterprise Architectures for Supporting the Adoption of Big Data",
                "URL": "https://doi.org/10.1145/3085228.3085275"
            }
        },
        {
            "10.1145/3156818": {
                "id": "10.1145/3156818",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Bruno",
                        "given": "Rodrigo"
                    },
                    {
                        "family": "Ferreira",
                        "given": "Paulo"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            1,
                            10
                        ]
                    ]
                },
                "abstract": "The need to process and store massive amounts of data—Big Data—is a reality. In areas such as scientific experiments, social networks management, credit card fraud detection, targeted advertisement, and financial analysis, massive amounts of information are generated and processed daily to extract valuable, summarized information. Due to its fast development cycle (i.e., less expensive to develop), mainly because of automatic memory management, and rich community resources, managed object-oriented programming languages (e.g., Java) are the first choice to develop Big Data platforms (e.g., Cassandra, Spark) on which such Big Data applications are executed.However, automatic memory management comes at a cost. This cost is introduced by the garbage collector, which is responsible for collecting objects that are no longer being used. Although current (classic) garbage collection algorithms may be applicable to small-scale applications, these algorithms are not appropriate for large-scale Big Data environments, as they do not scale in terms of throughput and pause times.In this work, current Big Data platforms and their memory profiles are studied to understand why classic algorithms (which are still the most commonly used) are not appropriate, and also to analyze recently proposed and relevant memory management algorithms, targeted to Big Data environments. The scalability of recent memory management algorithms is characterized in terms of throughput (improves the throughput of the application) and pause time (reduces the latency of the application) when compared to classic algorithms. The study is concluded by presenting a taxonomy of the described works and some open problems, with regard to Big Data memory management, that could be addressed in future works.",
                "call-number": "10.1145/3156818",
                "collection-number": "20",
                "container-title": "ACM Comput. Surv.",
                "DOI": "10.1145/3156818",
                "ISSN": "0360-0300",
                "issue": "1",
                "keyword": "Big Data, storage platform, scalability, memory managed runtime, Java, processing platforms, Garbage collection, Big Data environment",
                "number": "Article 20",
                "number-of-pages": "35",
                "page": "1–35",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "January 2019",
                "title": "A Study on Garbage Collection Algorithms for Big Data Environments",
                "URL": "https://doi.org/10.1145/3156818",
                "volume": "51"
            }
        },
        {
            "10.1145/3105971.3105979": {
                "id": "10.1145/3105971.3105979",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Keck",
                        "given": "Mandy"
                    },
                    {
                        "family": "Kammer",
                        "given": "Dietrich"
                    },
                    {
                        "family": "Gründer",
                        "given": "Thomas"
                    },
                    {
                        "family": "Thom",
                        "given": "Thomas"
                    },
                    {
                        "family": "Kleinsteuber",
                        "given": "Martin"
                    },
                    {
                        "family": "Maasch",
                        "given": "Alexander"
                    },
                    {
                        "family": "Groh",
                        "given": "Rainer"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            14
                        ]
                    ]
                },
                "abstract": "Data Analysts have to deal with an ever-growing amount of data resources. One way to make sense of this data is to extract features and use clustering algorithms to group items according to a similarity measure. Algorithm developers are challenged when evaluating the performance of the algorithm since it is hard to identify features that influence the clustering. Moreover, many algorithms can be trained using a semi-supervised approach, where human users provide ground truth samples by manually grouping single items. Hence, visualization techniques are needed that help data analysts achieve their goal in evaluating Big data clustering algorithms. In this context, Multidimensional Scaling (MDS) has become a prominent visualization tool. In this paper, we propose a combination with glyphs that can provide a detailed view of specific features involved in MDS. In consequence, human users can understand, adjust, and ultimately improve clustering algorithms. We present a thorough glyph design, which is founded in a comprehensive survey of related work and report the results of a controlled experiments, where participants solved data analysis tasks with both glyphs and a traditional textual display of data values.",
                "call-number": "10.1145/3105971.3105979",
                "collection-title": "VINCI '17",
                "container-title": "Proceedings of the 10th International Symposium on Visual Information Communication and Interaction",
                "DOI": "10.1145/3105971.3105979",
                "event-place": "Bangkok, Thailand",
                "ISBN": "9781450352925",
                "keyword": "big data, multidimensional scaling, visual cluster analysis, Glyph-based visualization techniques",
                "number-of-pages": "8",
                "page": "129–136",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Towards Glyph-based visualizations for big data clustering",
                "URL": "https://doi.org/10.1145/3105971.3105979"
            }
        }
    ]
}