{
    "exportedDoiLength": 102,
    "fileName": "acm",
    "style": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<style xmlns=\"http://purl.org/net/xbiblio/csl\" class=\"in-text\" version=\"1.0\" demote-non-dropping-particle=\"sort-only\" default-locale=\"en-US\">\n    <!-- This style was edited with the Visual CSL Editor (http://editor.citationstyles.org/visualEditor/) -->\n    <info>\n        <title>BibTeX ACM citation style</title>\n        <id>http://www.zotero.org/styles/bibtex-acm-citation-style</id>\n        <link href=\"http://www.zotero.org/styles/bibtex-acm-citation-style\" rel=\"self\"/>\n        <link href=\"http://www.bibtex.org/\" rel=\"documentation\"/>\n        <author>\n            <name>Markus Schaffner</name>\n        </author>\n        <contributor>\n            <name>Richard Karnesky</name>\n            <email>karnesky+zotero@gmail.com</email>\n            <uri>http://arc.nucapt.northwestern.edu/Richard_Karnesky</uri>\n        </contributor>\n        <category citation-format=\"author-date\"/>\n        <category field=\"generic-base\"/>\n        <updated>2018-06-11T10:52:49+00:00</updated>\n        <rights license=\"http://creativecommons.org/licenses/by-sa/3.0/\">This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 License</rights>\n    </info>\n    <macro name=\"zotero2bibtexType\">\n        <choose>\n            <if type=\"BILL BOOK GRAPHIC LEGAL_CASE LEGISLATION MOTION_PICTURE SONG\" match=\"any\">\n                <choose>\n                    <if genre=\"rfc\"  match=\"any\">\n                       <text value=\"rfc\"/>\n                    </if>\n                     <else-if  genre=\"bibliography\" match=\"any\">\n                        <text value=\"bibliography\"/>\n                    </else-if>\n                    <else-if  genre=\"play_drama\" match=\"any\">\n                        <text value=\"playdrama\"/>\n                    </else-if>\n                    <else-if  genre=\"proceeding\" match=\"any\">\n                        <text value=\"proceedings\"/>\n                    </else-if>\n                    <else-if  genre=\"tech_brief\" match=\"any\">\n                        <text value=\"tech-brief\"/>\n                    </else-if>\n                    <else>\n                       <text value=\"book\"/>\n                    </else>\n                </choose>\n            </if>\n            <else-if type=\"CHAPTER\" match=\"any\">\n                <text value=\"inbook\"/>\n            </else-if>\n            <else-if type=\"ARTICLE ARTICLE_JOURNAL ARTICLE_MAGAZINE ARTICLE_NEWSPAPER\" match=\"any\">\n                <text value=\"article\"/>\n            </else-if>\n            <else-if type=\"THESIS\" match=\"any\">\n                <choose>\n                    <if variable=\"genre\">\n                        <text variable=\"genre\" text-case=\"lowercase\" strip-periods=\"true\"/>\n                    </if>\n                </choose>\n                <text value=\"thesis\"/>\n            </else-if>\n            <else-if type=\"PAPER_CONFERENCE\" match=\"any\">\n                <text value=\"inproceedings\"/>\n            </else-if>\n            <else-if type=\"REPORT\" match=\"any\">\n                <text value=\"techreport\"/>\n            </else-if>\n            <else-if type=\"DATASET\" match=\"any\">\n                <choose>\n                    <if genre=\"software\"  match=\"any\">\n                       <text value=\"software\"/>\n                    </if>\n                    <else>\n                       <text value=\"dataset\"/>\n                    </else>\n                </choose>\n            </else-if>\n            <else>\n                <text value=\"misc\"/>\n            </else>\n        </choose>\n    </macro>\n    <macro name=\"citeKey\">\n           <text variable=\"call-number\"/>\n    </macro>\n    <macro name=\"editor-short\">\n        <names variable=\"editor\">\n            <name form=\"short\" delimiter=\":\" delimiter-precedes-last=\"always\"/>\n        </names>\n    </macro>\n    <macro name=\"author-short\">\n        <names variable=\"author\">\n            <name form=\"short\" delimiter=\":\" delimiter-precedes-last=\"always\"/>\n        </names>\n    </macro>\n    <macro name=\"issued-year\">\n        <date variable=\"issued\">\n            <date-part name=\"year\"/>\n        </date>\n    </macro>\n    <macro name=\"issued-month\">\n        <choose>\n            <if type=\"ARTICLE\" match=\"any\">\n                <date variable=\"issued\">\n                    <date-part name=\"month\" form=\"short\" strip-periods=\"true\" text-case=\"lowercase\"/>\n                </date>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"issue-date\">\n        <choose>\n            <if type=\"ARTICLE ARTICLE_JOURNAL\" match=\"any\">\n                <choose>\n                    <if variable=\"note\" match=\"none\">\n                        <choose>\n                            <if variable=\"source\">\n                                 <text variable=\"source\"/>\n                            </if>\n                               <else>\n                                 <date date-parts=\"year-month\" form=\"text\" variable=\"issued\"/>\n                               </else>\n                        </choose>\n                    </if>\n                </choose>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"author\">\n        <names variable=\"author\">\n            <name sort-separator=\", \" delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n            <label form=\"long\" text-case=\"capitalize-first\"/>\n        </names>\n    </macro>\n    <macro name=\"editor-translator\">\n        <names variable=\"editor translator\" delimiter=\", \">\n            <name sort-separator=\", \" delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n            <label form=\"long\" text-case=\"capitalize-first\"/>\n        </names>\n    </macro>\n    <macro name=\"title\">\n        <choose>\n            <if genre=\"proceeding\" match=\"any\">\n                <text variable=\"container-title-short\" suffix=\": \"/>\n                <text variable=\"title\" text-case=\"title\"/>\n            </if>\n            <else-if type=\"ARTICLE_JOURNAL\" match=\"none\">\n                <text variable=\"title\" text-case=\"title\"/>\n            </else-if>\n        </choose>\n    </macro>\n    <macro name=\"volume\">\n        <choose>\n            <if type=\"ARTICLE BOOK ARTICLE_JOURNAL\" match=\"any\">\n                <text variable=\"volume\" prefix=\"volume = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"DOI\">\n        <choose>\n            <if type=\"ARTICLE PAPER_CONFERENCE\" match=\"any\">\n                <text variable=\"DOI\" prefix=\"doi = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"abstract\">\n        <if match=\"any\" variable=\"abstract\">\n            <text variable=\"abstract\"/>\n        </if>\n    </macro>\n    <macro name=\"URL\">\n        <text variable=\"URL\" prefix=\"url = {\" suffix=\"}\"/>\n    </macro>\n    <macro name=\"container-title\">\n        <choose>\n            <if type=\"CHAPTER PAPER_CONFERENCE\" match=\"any\">\n                <text variable=\"container-title\" prefix=\"booktitle = {\" suffix=\"}\" text-case=\"title\"/>\n            </if>\n            <else-if type=\"ARTICLE ARTICLE_JOURNAL\" match=\"any\">\n                <text variable=\"container-title\" prefix=\"journal = {\" suffix=\"}\" text-case=\"title\"/>\n            </else-if>\n        </choose>\n    </macro>\n    <macro name=\"pages\">\n        <group delimiter=\",&#10;\">\n            <choose>\n                <if match=\"any\" variable=\"collection-number\">\n                    <text variable=\"collection-number\" prefix=\"articleno = {\" suffix=\"}\"/>\n                </if>\n                <else>\n                    <text variable=\"page\" prefix=\"pages = {\" suffix=\"}\"/>\n                </else>\n            </choose>\n            <text variable=\"number-of-pages\" prefix=\"numpages = {\" suffix=\"}\"/>\n        </group>\n    </macro>\n    <macro name=\"edition\">\n        <text variable=\"edition\"/>\n    </macro>\n    <macro name=\"editor\">\n        <choose>\n            <if match=\"any\" type=\"THESIS\">\n                <names variable=\"editor\" delimiter=\", \" prefix=\"advisor = {\" suffix=\"}\">\n                    <name delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n                </names>\n            </if>\n            <else>\n               <names variable=\"editor\" delimiter=\", \" prefix=\"editor = {\" suffix=\"}\">\n                   <name delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n               </names>\n            </else>\n        </choose>\n    </macro>\n    <macro name=\"keyword\">\n        <choose>\n            <if type=\"ARTICLE PAPER_CONFERENCE DATASET\" match=\"any\">\n                <text variable=\"keyword\" prefix=\"keywords = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <citation et-al-min=\"11\" et-al-use-first=\"10\" disambiguate-add-year-suffix=\"true\" disambiguate-add-names=\"false\" disambiguate-add-givenname=\"false\" collapse=\"year\">\n        <layout delimiter=\"_\">\n            <text macro=\"citeKey\"/>\n        </layout>\n    </citation>\n    <bibliography hanging-indent=\"false\">\n        <layout>\n            <group display=\"right-inline\">\n                <text macro=\"zotero2bibtexType\" prefix=\"@\"/>\n                <group prefix=\"{\" suffix=\"&#10;}\" delimiter=\",&#10;\">\n                    <text macro=\"citeKey\"/>\n                    <text macro=\"author\" prefix=\"author = {\" suffix=\"}\"/>\n                    <text macro=\"editor\"/>\n                    <text macro=\"title\" prefix=\"title = {\" suffix=\"}\"/>\n                    <text macro=\"issued-year\" prefix=\"year = {\" suffix=\"}\"/>\n                    <text macro=\"issue-date\" prefix=\"issue_date = {\" suffix=\"}\"/>\n                    <text variable=\"ISBN\" prefix=\"isbn = {\" suffix=\"}\"/>\n                    <text variable=\"publisher\" prefix=\"publisher = {\" suffix=\"}\"/>\n                    <text variable=\"publisher-place\" prefix=\"address = {\" suffix=\"}\"/>\n                    <text variable=\"chapter-number\" prefix=\"chapter = {\" suffix=\"}\"/>\n                    <text macro=\"edition\" prefix=\"edition = {\" suffix=\"}\"/>\n                    <text macro=\"volume\"/>\n                    <text variable=\"issue\" prefix=\"number = {\" suffix=\"}\"/>\n                    <text variable=\"ISSN\" prefix=\"issn = {\" suffix=\"}\"/>\n                    <text variable=\"archive_location\" prefix=\"archiveLocation = {\" suffix=\"}\"/>\n                    <text macro=\"URL\"/>\n                    <text macro=\"DOI\"/>\n                    <text macro=\"abstract\" prefix=\"abstract = {\" suffix=\"}\"/>\n                    <text variable=\"note\" prefix=\"note = {\" suffix=\"}\"/>\n                    <text macro=\"container-title\"/>\n                    <text macro=\"issued-month\" prefix=\"month = {\" suffix=\"}\"/>\n                    <text macro=\"pages\"/>\n                    <text macro=\"keyword\"/>\n                    <text variable=\"event-place\" prefix=\"location = {\" suffix=\"}\"/>\n                    <choose>\n                        <if type=\"PAPER_CONFERENCE\" match=\"any\">\n                            <text variable=\"collection-title\" prefix=\"series = {\" suffix=\"}\"/>\n                        </if>\n                        <else>\n                            <text variable=\"collection-title\" prefix=\"collection = {\" suffix=\"}\"/>\n                        </else>\n                    </choose>\n                </group>\n            </group>\n        </layout>\n    </bibliography>\n</style>\n",
    "suffix": "bib",
    "locale": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<locale xmlns=\"http://purl.org/net/xbiblio/csl\" version=\"1.0\" xml:lang=\"en-US\">\n  <info>\n    <rights license=\"http://creativecommons.org/licenses/by-sa/3.0/\">This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 License</rights>\n    <updated>2012-07-04T23:31:02+00:00</updated>\n  </info>\n  <style-options punctuation-in-quote=\"true\"\n                 leading-noise-words=\"a,an,the\"\n                 name-as-sort-order=\"ja zh kr my hu vi\"\n                 name-never-short=\"ja zh kr my hu vi\"/>\n  <date form=\"text\">\n    <date-part name=\"month\" suffix=\" \"/>\n    <date-part name=\"day\" suffix=\", \"/>\n    <date-part name=\"year\"/>\n  </date>\n  <date form=\"numeric\">\n    <date-part name=\"month\" form=\"numeric-leading-zeros\" suffix=\"/\"/>\n    <date-part name=\"day\" form=\"numeric-leading-zeros\" suffix=\"/\"/>\n    <date-part name=\"year\"/>\n  </date>\n  <terms>\n    <term name=\"radio-broadcast\">radio broadcast</term>\n    <term name=\"television-broadcast\">television broadcast</term>\n    <term name=\"podcast\">podcast</term>\n    <term name=\"instant-message\">instant message</term>\n    <term name=\"email\">email</term>\n    <term name=\"number-of-volumes\">\n      <single>volume</single>\n      <multiple>volumes</multiple>\n    </term>\n    <term name=\"accessed\">accessed</term>\n    <term name=\"and\">and</term>\n    <term name=\"and\" form=\"symbol\">&amp;</term>\n    <term name=\"and others\">and others</term>\n    <term name=\"anonymous\">anonymous</term>\n    <term name=\"anonymous\" form=\"short\">anon.</term>\n    <term name=\"at\">at</term>\n    <term name=\"available at\">available at</term>\n    <term name=\"by\">by</term>\n    <term name=\"circa\">circa</term>\n    <term name=\"circa\" form=\"short\">c.</term>\n    <term name=\"cited\">cited</term>\n    <term name=\"edition\">\n      <single>edition</single>\n      <multiple>editions</multiple>\n    </term>\n    <term name=\"edition\" form=\"short\">ed.</term>\n    <term name=\"et-al\">et al.</term>\n    <term name=\"forthcoming\">forthcoming</term>\n    <term name=\"from\">from</term>\n    <term name=\"ibid\">ibid.</term>\n    <term name=\"in\">in</term>\n    <term name=\"in press\">in press</term>\n    <term name=\"internet\">internet</term>\n    <term name=\"interview\">interview</term>\n    <term name=\"letter\">letter</term>\n    <term name=\"no date\">no date</term>\n    <term name=\"no date\" form=\"short\">n.d.</term>\n    <term name=\"online\">online</term>\n    <term name=\"presented at\">presented at the</term>\n    <term name=\"reference\">\n      <single>reference</single>\n      <multiple>references</multiple>\n    </term>\n    <term name=\"reference\" form=\"short\">\n      <single>ref.</single>\n      <multiple>refs.</multiple>\n    </term>\n    <term name=\"retrieved\">retrieved</term>\n    <term name=\"scale\">scale</term>\n    <term name=\"version\">version</term>\n\n    <!-- ANNO DOMINI; BEFORE CHRIST -->\n    <term name=\"ad\">AD</term>\n    <term name=\"bc\">BC</term>\n\n    <!-- PUNCTUATION -->\n    <term name=\"open-quote\">“</term>\n    <term name=\"close-quote\">”</term>\n    <term name=\"open-inner-quote\">‘</term>\n    <term name=\"close-inner-quote\">’</term>\n    <term name=\"page-range-delimiter\">–</term>\n\n    <!-- ORDINALS -->\n    <term name=\"ordinal\">th</term>\n    <term name=\"ordinal-01\">st</term>\n    <term name=\"ordinal-02\">nd</term>\n    <term name=\"ordinal-03\">rd</term>\n    <term name=\"ordinal-11\">th</term>\n    <term name=\"ordinal-12\">th</term>\n    <term name=\"ordinal-13\">th</term>\n\n    <!-- LONG ORDINALS -->\n    <term name=\"long-ordinal-01\">first</term>\n    <term name=\"long-ordinal-02\">second</term>\n    <term name=\"long-ordinal-03\">third</term>\n    <term name=\"long-ordinal-04\">fourth</term>\n    <term name=\"long-ordinal-05\">fifth</term>\n    <term name=\"long-ordinal-06\">sixth</term>\n    <term name=\"long-ordinal-07\">seventh</term>\n    <term name=\"long-ordinal-08\">eighth</term>\n    <term name=\"long-ordinal-09\">ninth</term>\n    <term name=\"long-ordinal-10\">tenth</term>\n\n    <!-- LONG LOCATOR FORMS -->\n    <term name=\"book\">\n      <single>book</single>\n      <multiple>books</multiple>\n    </term>\n    <term name=\"chapter\">\n      <single>chapter</single>\n      <multiple>chapters</multiple>\n    </term>\n    <term name=\"column\">\n      <single>column</single>\n      <multiple>columns</multiple>\n    </term>\n    <term name=\"figure\">\n      <single>figure</single>\n      <multiple>figures</multiple>\n    </term>\n    <term name=\"folio\">\n      <single>folio</single>\n      <multiple>folios</multiple>\n    </term>\n    <term name=\"issue\">\n      <single>number</single>\n      <multiple>numbers</multiple>\n    </term>\n    <term name=\"line\">\n      <single>line</single>\n      <multiple>lines</multiple>\n    </term>\n    <term name=\"note\">\n      <single>note</single>\n      <multiple>notes</multiple>\n    </term>\n    <term name=\"opus\">\n      <single>opus</single>\n      <multiple>opera</multiple>\n    </term>\n    <term name=\"page\">\n      <single>page</single>\n      <multiple>pages</multiple>\n    </term>\n    <term name=\"paragraph\">\n      <single>paragraph</single>\n      <multiple>paragraph</multiple>\n    </term>\n    <term name=\"part\">\n      <single>part</single>\n      <multiple>parts</multiple>\n    </term>\n    <term name=\"section\">\n      <single>section</single>\n      <multiple>sections</multiple>\n    </term>\n    <term name=\"sub verbo\">\n      <single>sub verbo</single>\n      <multiple>sub verbis</multiple>\n    </term>\n    <term name=\"verse\">\n      <single>verse</single>\n      <multiple>verses</multiple>\n    </term>\n    <term name=\"volume\">\n      <single>volume</single>\n      <multiple>volumes</multiple>\n    </term>\n\n    <!-- SHORT LOCATOR FORMS -->\n    <term name=\"book\" form=\"short\">bk.</term>\n    <term name=\"chapter\" form=\"short\">chap.</term>\n    <term name=\"column\" form=\"short\">col.</term>\n    <term name=\"figure\" form=\"short\">fig.</term>\n    <term name=\"folio\" form=\"short\">f.</term>\n    <term name=\"issue\" form=\"short\">no.</term>\n    <term name=\"line\" form=\"short\">l.</term>\n    <term name=\"note\" form=\"short\">n.</term>\n    <term name=\"opus\" form=\"short\">op.</term>\n    <term name=\"page\" form=\"short\">\n      <single>p.</single>\n      <multiple>pp.</multiple>\n    </term>\n    <term name=\"paragraph\" form=\"short\">para.</term>\n    <term name=\"part\" form=\"short\">pt.</term>\n    <term name=\"section\" form=\"short\">sec.</term>\n    <term name=\"sub verbo\" form=\"short\">\n      <single>s.v.</single>\n      <multiple>s.vv.</multiple>\n    </term>\n    <term name=\"verse\" form=\"short\">\n      <single>v.</single>\n      <multiple>vv.</multiple>\n    </term>\n    <term name=\"volume\" form=\"short\">\n      <single>vol.</single>\n      <multiple>vols.</multiple>\n    </term>\n\n    <!-- SYMBOL LOCATOR FORMS -->\n    <term name=\"paragraph\" form=\"symbol\">\n      <single>¶</single>\n      <multiple>¶¶</multiple>\n    </term>\n    <term name=\"section\" form=\"symbol\">\n      <single>§</single>\n      <multiple>§§</multiple>\n    </term>\n\n    <!-- LONG ROLE FORMS -->\n    <term name=\"director\">\n      <single>director</single>\n      <multiple>directors</multiple>\n    </term>\n    <term name=\"editor\">\n      <single>editor</single>\n      <multiple>editors</multiple>\n    </term>\n    <term name=\"editorial-director\">\n      <single>editor</single>\n      <multiple>editors</multiple>\n    </term>\n    <term name=\"illustrator\">\n      <single>illustrator</single>\n      <multiple>illustrators</multiple>\n    </term>\n    <term name=\"translator\">\n      <single>translator</single>\n      <multiple>translators</multiple>\n    </term>\n    <term name=\"editortranslator\">\n      <single>editor &amp; translator</single>\n      <multiple>editors &amp; translators</multiple>\n    </term>\n\n    <!-- SHORT ROLE FORMS -->\n    <term name=\"director\" form=\"short\">\n      <single>dir.</single>\n      <multiple>dirs.</multiple>\n    </term>\n    <term name=\"editor\" form=\"short\">\n      <single>ed.</single>\n      <multiple>eds.</multiple>\n    </term>\n    <term name=\"editorial-director\" form=\"short\">\n      <single>ed.</single>\n      <multiple>eds.</multiple>\n    </term>\n    <term name=\"illustrator\" form=\"short\">\n      <single>ill.</single>\n      <multiple>ills.</multiple>\n    </term>\n    <term name=\"translator\" form=\"short\">\n      <single>tran.</single>\n      <multiple>trans.</multiple>\n    </term>\n    <term name=\"editortranslator\" form=\"short\">\n      <single>ed. &amp; tran.</single>\n      <multiple>eds. &amp; trans.</multiple>\n    </term>\n\n    <!-- VERB ROLE FORMS -->\n    <term name=\"director\" form=\"verb\">directed by</term>\n    <term name=\"editor\" form=\"verb\">edited by</term>\n    <term name=\"editorial-director\" form=\"verb\">edited by</term>\n    <term name=\"illustrator\" form=\"verb\">illustrated by</term>\n    <term name=\"interviewer\" form=\"verb\">interview by</term>\n    <term name=\"recipient\" form=\"verb\">to</term>\n    <term name=\"reviewed-author\" form=\"verb\">by</term>\n    <term name=\"translator\" form=\"verb\">translated by</term>\n    <term name=\"editortranslator\" form=\"verb\">edited &amp; translated by</term>\n\n    <!-- SHORT VERB ROLE FORMS -->\n    <term name=\"container-author\" form=\"verb-short\">by</term>\n    <term name=\"director\" form=\"verb-short\">dir.</term>\n    <term name=\"editor\" form=\"verb-short\">ed.</term>\n    <term name=\"editorial-director\" form=\"verb-short\">ed.</term>\n    <term name=\"illustrator\" form=\"verb-short\">illus.</term>\n    <term name=\"translator\" form=\"verb-short\">trans.</term>\n    <term name=\"editortranslator\" form=\"verb-short\">ed. &amp; trans.</term>\n\n    <!-- LONG MONTH FORMS -->\n    <term name=\"month-01\">January</term>\n    <term name=\"month-02\">February</term>\n    <term name=\"month-03\">March</term>\n    <term name=\"month-04\">April</term>\n    <term name=\"month-05\">May</term>\n    <term name=\"month-06\">June</term>\n    <term name=\"month-07\">July</term>\n    <term name=\"month-08\">August</term>\n    <term name=\"month-09\">September</term>\n    <term name=\"month-10\">October</term>\n    <term name=\"month-11\">November</term>\n    <term name=\"month-12\">December</term>\n\n    <!-- SHORT MONTH FORMS -->\n    <term name=\"month-01\" form=\"short\">Jan.</term>\n    <term name=\"month-02\" form=\"short\">Feb.</term>\n    <term name=\"month-03\" form=\"short\">Mar.</term>\n    <term name=\"month-04\" form=\"short\">Apr.</term>\n    <term name=\"month-05\" form=\"short\">May</term>\n    <term name=\"month-06\" form=\"short\">Jun.</term>\n    <term name=\"month-07\" form=\"short\">Jul.</term>\n    <term name=\"month-08\" form=\"short\">Aug.</term>\n    <term name=\"month-09\" form=\"short\">Sep.</term>\n    <term name=\"month-10\" form=\"short\">Oct.</term>\n    <term name=\"month-11\" form=\"short\">Nov.</term>\n    <term name=\"month-12\" form=\"short\">Dec.</term>\n\n    <!-- SEASONS -->\n    <term name=\"season-01\">Spring</term>\n    <term name=\"season-02\">Summer</term>\n    <term name=\"season-03\">Autumn</term>\n    <term name=\"season-04\">Winter</term>\n  </terms>\n</locale>\n",
    "contentType": "Application/x-bibtex",
    "items": [
        {
            "10.1145/2799979.2799995": {
                "id": "10.1145/2799979.2799995",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Stepanova",
                        "given": "Taiana"
                    },
                    {
                        "family": "Pechenkin",
                        "given": "Alexander"
                    },
                    {
                        "family": "Lavrova",
                        "given": "Daria"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            9,
                            8
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            9,
                            8
                        ]
                    ]
                },
                "abstract": "Global corporations and government organizations are nowadays represented in cyberspace in the form of numerous large-scale heterogeneous information systems, which implement corresponding business, technological and other types of processes. This extends the set of security analysis tasks, stated for these infrastructures, and tangles already existing tasks. This paper addresses the challenge of increasing penetration testing automation level through the adoption of semi-automatic knowledge extraction from the huge amounts of heterogeneous regularly updated data. The proposed solution is based on the novel penetration testing ontology, which gives a holistic view on the results of security analysis. Designed ontology is evaluated within the penetration testing framework prototype and binds together the conceptual (process) abstraction level, addressed by security experts, and technical abstraction level, employed in modern security analysis tools and methods.",
                "call-number": "10.1145/2799979.2799995",
                "collection-title": "SIN '15",
                "container-title": "Proceedings of the 8th International Conference on Security of Information and Networks",
                "DOI": "10.1145/2799979.2799995",
                "event-place": "Sochi, Russia",
                "ISBN": "9781450334532",
                "keyword": "large-scale systems, big data, penetration testing, ontology",
                "number-of-pages": "8",
                "page": "142–149",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Ontology-based big data approach to automated penetration testing of large-scale heterogeneous systems",
                "URL": "https://doi.org/10.1145/2799979.2799995"
            }
        },
        {
            "10.1145/2859889.2883587": {
                "id": "10.1145/2859889.2883587",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Singhal",
                        "given": "Rekha"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            3,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            3,
                            12
                        ]
                    ]
                },
                "abstract": "Digitization of user services and cheap access to the internet has led to two critical problems- quick response to end-user queries and faster analysis of large accumulated data to serve users better. This has also led to the advent of various big data processing technologies, each of them has architecture specific parameters to tune for optimal execution of the application. There are also challenges in optimal scheduling of analytic queries for faster analysis, which lead to the problem of estimating analytic queries execution time for large data sizes on the production system. A production system may be an enterprise database system or a cluster of machines with Hadoop etc, where each machine may be of different hardware configuration (known as heterogeneous environment). In the first part of this tutorial, we shall present need and challenges for tuning big data applications on various platforms. This is followed by discussion on various existing solutions for application tuning. The second part of the tutorial presents the challenges and state of the art for estimating application execution time.",
                "call-number": "10.1145/2859889.2883587",
                "collection-title": "ICPE '16 Companion",
                "container-title": "Companion Publication for ACM/SPEC on International Conference on Performance Engineering",
                "DOI": "10.1145/2859889.2883587",
                "event-place": "Delft, The Netherlands",
                "ISBN": "9781450341479",
                "number-of-pages": "1",
                "page": "29",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Tutorial on Challenges for Big Data Application Performance Tuning and Prediction",
                "URL": "https://doi.org/10.1145/2859889.2883587"
            }
        },
        {
            "10.1145/288195.288292": {
                "id": "10.1145/288195.288292",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Disney",
                        "given": "Anne M."
                    },
                    {
                        "family": "Johnson",
                        "given": "Philip M."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            1998,
                            11,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            1998,
                            11,
                            1
                        ]
                    ]
                },
                "abstract": "The Personal Software Process (PSP) is used by software engineers to gather and analyze data about their work. Published studies typically use data collected using the PSP to draw quantitative conclusions about its impact upon programmer behavior and product quality. However, our experience using PSP in both industrial and academic settings revealed problems both in collection of data and its later analysis. We hypothesized that these two kinds of data quality problems could make a significant impact upon the value of PSP measures. To test this hypothesis, we built a tool to automate the PSP and then examined 89 projects completed by ten subjects using the PSP manually in an educational setting. We discovered 1539 primary errors and categorized them by type, subtype, severity, and age. To examine the collection problem we looked at the 90 errors that represented impossible combinations of data and at other less concrete anomalies in Time Recording Logs and Defect Recording Logs. To examine the analysis problem we developed a rule set, corrected the errors as far as possible, and compared the original and corrected data. This resulted in significant differences for measures such as yield and the cost-performance ratio, confirming our hypothesis. Our results raise questions about the accuracy of manually collected and analyzed PSP data, indicate that integrated tool support may be required for high quality PSP data analysis, and suggest that external measures should be used when attempting to evaluate the impact of the PSP upon programmer behavior and product quality.",
                "call-number": "10.1145/288195.288292",
                "collection-title": "SIGSOFT '98/FSE-6",
                "container-title": "Proceedings of the 6th ACM SIGSOFT international symposium on Foundations of software engineering",
                "DOI": "10.1145/288195.288292",
                "event-place": "Lake Buena Vista, Florida, USA",
                "ISBN": "1581131089",
                "keyword": "empirical software engineering, personal software process, measurement dysfunction, automated process support, defects",
                "number-of-pages": "10",
                "page": "143–152",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Investigating data quality problems in the PSP",
                "URL": "https://doi.org/10.1145/288195.288292"
            }
        },
        {
            "10.1145/291252.288292": {
                "id": "10.1145/291252.288292",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Disney",
                        "given": "Anne M."
                    },
                    {
                        "family": "Johnson",
                        "given": "Philip M."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            1998,
                            11,
                            1
                        ]
                    ]
                },
                "abstract": "The Personal Software Process (PSP) is used by software engineers to gather and analyze data about their work. Published studies typically use data collected using the PSP to draw quantitative conclusions about its impact upon programmer behavior and product quality. However, our experience using PSP in both industrial and academic settings revealed problems both in collection of data and its later analysis. We hypothesized that these two kinds of data quality problems could make a significant impact upon the value of PSP measures. To test this hypothesis, we built a tool to automate the PSP and then examined 89 projects completed by ten subjects using the PSP manually in an educational setting. We discovered 1539 primary errors and categorized them by type, subtype, severity, and age. To examine the collection problem we looked at the 90 errors that represented impossible combinations of data and at other less concrete anomalies in Time Recording Logs and Defect Recording Logs. To examine the analysis problem we developed a rule set, corrected the errors as far as possible, and compared the original and corrected data. This resulted in significant differences for measures such as yield and the cost-performance ratio, confirming our hypothesis. Our results raise questions about the accuracy of manually collected and analyzed PSP data, indicate that integrated tool support may be required for high quality PSP data analysis, and suggest that external measures should be used when attempting to evaluate the impact of the PSP upon programmer behavior and product quality.",
                "call-number": "10.1145/291252.288292",
                "container-title": "SIGSOFT Softw. Eng. Notes",
                "DOI": "10.1145/291252.288292",
                "ISSN": "0163-5948",
                "issue": "6",
                "keyword": "automated process support, personal software process, measurement dysfunction, empirical software engineering, defects",
                "number-of-pages": "10",
                "page": "143–152",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "Nov. 1998",
                "title": "Investigating data quality problems in the PSP",
                "URL": "https://doi.org/10.1145/291252.288292",
                "volume": "23"
            }
        },
        {
            "10.1145/3232116.3232143": {
                "id": "10.1145/3232116.3232143",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Xie",
                        "given": "Xiaolan"
                    },
                    {
                        "family": "Li",
                        "given": "Xinrong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            19
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            19
                        ]
                    ]
                },
                "abstract": "With the rapid development of information technology, big data plays an increasingly important role in the research and practice of education and teaching. Online education has also become a research hotspot. To solve the problem of lack of personalized exercises and accurate teaching feedback in online education, a content-based recommendation model in big data and a clustering model based on EM algorithm is proposed in this paper. First of all, the students' answer of questions is recorded. Then the characteristic information is extracted, so recommends of the exercises are provided by the model according to the personal characteristic information. Then, all the students' recommendation information is stored in the feature library, in which the information of students are clustered, and the teaching effect is fed back according to the characteristic parameters of each category. On the one hand, the status of students' learning is fed back; On the other hand, the level of teachers' teaching level is also fed back. Finally, the model works well through experiments, with the good performance that it can improve the efficiency of online learning.",
                "call-number": "10.1145/3232116.3232143",
                "collection-title": "ICIIP '18",
                "container-title": "Proceedings of the 3rd International Conference on Intelligent Information Processing",
                "DOI": "10.1145/3232116.3232143",
                "event-place": "Guilin, China",
                "ISBN": "9781450364966",
                "keyword": "personalized exercises, EM algorithm, recommendation algorithm, online learning, teaching feedback",
                "number-of-pages": "6",
                "page": "166–171",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on Personalized Exercises and Teaching Feedback Based on Big Data",
                "URL": "https://doi.org/10.1145/3232116.3232143"
            }
        },
        {
            "10.1145/3107514.3107518": {
                "id": "10.1145/3107514.3107518",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Wu",
                        "given": "Jinrong"
                    },
                    {
                        "family": "Sinnott",
                        "given": "Richard O."
                    },
                    {
                        "family": "Effendy",
                        "given": "Jemie"
                    },
                    {
                        "family": "Glöckner",
                        "given": "Stephan"
                    },
                    {
                        "family": "Hu",
                        "given": "William"
                    },
                    {
                        "family": "Li",
                        "given": "Jiajie"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            20
                        ]
                    ]
                },
                "abstract": "The Environmental Determinants of Islet Auto- immunity (ENDIA) project is Australia's largest study into the causes of Type-1 Diabetes (T1D). The ENDIA study is supported by a Cloud-based software platform including a clinical registry comprising extensive longitudinal information on families at risk of having a child that might go on to develop T1D. This registry includes both demographic and clinical information on families and children as well as the environmental factors that might influence the onset of T1D. A multitude of samples are obtained through the study and used to support a diverse portfolio of bioinformatics data analytics. The quality of the data in the registry is essential to the overall success of the project. This paper presents a Cloud-based log-analytics platform that supports the detailed analysis of patterns of usage of the registry by the clinical centres and collaborators involved. We explore the impact that the usage patterns have on the overall data quality. We also consider ways of improving data quality by mothers entering their own data through targeted mobile applications that have been developed for dietary data collection.",
                "call-number": "10.1145/3107514.3107518",
                "collection-title": "ICMHI '17",
                "container-title": "Proceedings of the 1st International Conference on Medical and Health Informatics 2017",
                "DOI": "10.1145/3107514.3107518",
                "event-place": "Taichung City, Taiwan",
                "ISBN": "9781450352246",
                "keyword": "Type-1 diabetes, Cloud, auditing, log analysis",
                "number-of-pages": "10",
                "page": "18–27",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Usage Patterns and Data Quality: A Case Study of a National Type-1 Diabetes Study",
                "URL": "https://doi.org/10.1145/3107514.3107518"
            }
        },
        {
            "10.1145/3482632.3482734": {
                "id": "10.1145/3482632.3482734",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Ren",
                        "given": "Xiaojie"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            24
                        ]
                    ]
                },
                "abstract": "Under the background of big data era, online banking has achieved rapid development and has undergone qualitative changes. Online banking is a new financial form. The application of big data has promoted the development of online banking to a great extent, provided strong technical support for it, and improved the business model of online banking. The application of AI (artificial intelligence) in insurance, credit reporting, asset allocation, big data risk control and other financial fields has brought new changes to the financial industry. As a brand-new technology model, the combination of big data and AI with economy has realized the deep excavation of various resources, which can ensure the quality and efficiency of economic development and reduce the comprehensive cost, thus effectively enhancing the overall competitiveness of China's economy and gaining more initiative in the fierce international competition. This paper investigates the current situation of big data application in online banking, analyzes its potential value and main challenges, and discusses the traditional financial big data application and innovation path based on AI algorithm.",
                "call-number": "10.1145/3482632.3482734",
                "collection-title": "ICISCAE 2021",
                "container-title": "2021 4th International Conference on Information Systems and Computer Aided Education",
                "DOI": "10.1145/3482632.3482734",
                "event-place": "Dalian, China",
                "ISBN": "9781450390255",
                "number-of-pages": "4",
                "page": "482–485",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Application and Innovation of Traditional Financial Big Data Based on AI Algorithm",
                "URL": "https://doi.org/10.1145/3482632.3482734"
            }
        },
        {
            "10.1145/2643132": {
                "id": "10.1145/2643132",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Daries",
                        "given": "Jon P."
                    },
                    {
                        "family": "Reich",
                        "given": "Justin"
                    },
                    {
                        "family": "Waldo",
                        "given": "Jim"
                    },
                    {
                        "family": "Young",
                        "given": "Elise M."
                    },
                    {
                        "family": "Whittinghill",
                        "given": "Jonathan"
                    },
                    {
                        "family": "Ho",
                        "given": "Andrew Dean"
                    },
                    {
                        "family": "Seaton",
                        "given": "Daniel Thomas"
                    },
                    {
                        "family": "Chuang",
                        "given": "Isaac"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            1
                        ]
                    ]
                },
                "abstract": "Quality social science research and the privacy of human subjects require trust.",
                "call-number": "10.1145/2643132",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/2643132",
                "ISSN": "0001-0782",
                "issue": "9",
                "number-of-pages": "8",
                "page": "56–63",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "September 2014",
                "title": "Privacy, anonymity, and big data in the social sciences",
                "URL": "https://doi.org/10.1145/2643132",
                "volume": "57"
            }
        },
        {
            "10.1145/2432596.2432601": {
                "id": "10.1145/2432596.2432601",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Topi",
                        "given": "Heikki"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            3,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/2432596.2432601",
                "container-title": "ACM Inroads",
                "DOI": "10.1145/2432596.2432601",
                "ISSN": "2153-2184",
                "issue": "1",
                "number-of-pages": "2",
                "page": "12–13",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "March 2013",
                "title": "Where is big data in your information systems curriculum?",
                "URL": "https://doi.org/10.1145/2432596.2432601",
                "volume": "4"
            }
        },
        {
            "10.1145/3017611.3017627": {
                "id": "10.1145/3017611.3017627",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Liu",
                        "given": "Kuien"
                    },
                    {
                        "family": "Wang",
                        "given": "Haozhou"
                    },
                    {
                        "family": "Yao",
                        "given": "Yandong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            10,
                            31
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            10,
                            31
                        ]
                    ]
                },
                "abstract": "Cloud storage is a kind of external storage which can provide by unlimited storage space with high availability and low cost on maintenance. On the other side, the size of geospatial data is too large and is increasing dramatically which makes such data is hard to be stored in the local data warehouse. Hence following the benefits of Cloud storage, such geospatial data is suitable to be stored in Cloud storage and managed by local data warehouse. However, there is a gap between Cloud storages and data warehouses built on traditional infrastructures, such as the mostly adopted massive parallel processing (MPP) based data warehouse. Therefore, in this paper, we propose a middleware-like architecture to connect MPP data warehouse and Cloud storage. It supports traditional geospatial data retrieving while integrating the Cloud storage lineage by a set of technical designs. Based on the prototype system and practical data, we demonstrate the appreciable performance and the flexibility for other third parties' development. Another major contribution of this paper is that we implement the prototype on open-source data warehouse and we make it open-sourced to public.",
                "call-number": "10.1145/3017611.3017627",
                "collection-number": "16",
                "collection-title": "EM-GIS '16",
                "container-title": "Proceedings of the Second ACM SIGSPATIALInternational Workshop on the Use of GIS in Emergency Management",
                "DOI": "10.1145/3017611.3017627",
                "event-place": "Burlingame, California",
                "ISBN": "9781450345804",
                "keyword": "data warehouse, cloud storage, geospatial",
                "number": "Article 16",
                "number-of-pages": "4",
                "page": "1–4",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "On storing and retrieving geospatial big-data in cloud",
                "URL": "https://doi.org/10.1145/3017611.3017627"
            }
        },
        {
            "10.5555/3042094.3042253": {
                "id": "10.5555/3042094.3042253",
                "type": "CHAPTER",
                "author": [
                    {
                        "family": "Bowman",
                        "given": "Casey N."
                    },
                    {
                        "family": "Miller",
                        "given": "John A."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            12,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            12,
                            11
                        ]
                    ]
                },
                "abstract": "Improving the efficiency, safety, and cost of road systems is an essential social problem that must be solved as the number of drivers, and the size of mass transit systems increase. Methodologies used for the construction of traffic simulations need to be examined in the context of real world big traffic data. This data can be used to create models for vehicle arrivals, turning behavior, and traffic flow. Our work focuses mainly on generating models for these concepts and using them to drive microscopic traffic simulations built upon real world data. Strengths and weaknesses of various simulation optimization techniques are also considered as a methodology issue, since the nature of traffic systems weakens the effectiveness of some optimization techniques.",
                "call-number": "10.5555/3042094.3042253",
                "container-title": "Proceedings of the 2016 Winter Simulation Conference",
                "ISBN": "9781509044849",
                "number-of-pages": "12",
                "page": "1206–1217",
                "publisher": "IEEE Press",
                "title": "Modeling traffic flow using simulation and big data analytics"
            }
        },
        {
            "10.1145/3442705.3442714": {
                "id": "10.1145/3442705.3442714",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Tang",
                        "given": "Jing"
                    },
                    {
                        "family": "Jia",
                        "given": "Tao"
                    },
                    {
                        "family": "Chen",
                        "given": "Haibo"
                    },
                    {
                        "family": "Wei",
                        "given": "Chuncheng"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            12,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            12,
                            4
                        ]
                    ]
                },
                "abstract": "With the popularity of digital cryptocurrency such as bitcoin, blockchain, as a new distributed framework with decentralization, non rewriting and traceability, has sprung up rapidly and has been applied in many industries such as finance, medical treatment, information security, etc. In order to ensure the security of transaction data, all key information in the business needs to enter the blockchain network. In the field of artificial intelligence, model data (i.e. effective feature point data set) will be the key information and will be used frequently. However, these feature point datasets may be megabytes, auspicious, or even terahertz. Then, the performance of big data transaction in blockchain network will be a problem worthy of study. Therefore, this paper proposes a blockchain big data storage method based on IPFs. This method mainly solves the transaction performance problem of large text data in the blockchain network. The data larger than 100 megabytes are stored in IPFs to obtain the hash certificate of text. The hash code is the only transaction voucher in the blockchain network. It greatly improves the transaction efficiency of blockchain network. In this paper, a comparative experiment is set up to further prove the efficiency of our method.",
                "call-number": "10.1145/3442705.3442714",
                "collection-title": "VSIP '20",
                "container-title": "2020 2nd International Conference on Video, Signal and Image Processing",
                "DOI": "10.1145/3442705.3442714",
                "event-place": "Jakarta, Indonesia",
                "ISBN": "9781450388931",
                "keyword": "BigData, blockchain, IPFS, Decentralization",
                "number-of-pages": "6",
                "page": "55–60",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on Big Data Storage Method based on IPFS and Blockchain",
                "URL": "https://doi.org/10.1145/3442705.3442714"
            }
        },
        {
            "10.1145/3544109.3544143": {
                "id": "10.1145/3544109.3544143",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yang",
                        "given": "Na"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            4,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            4,
                            14
                        ]
                    ]
                },
                "call-number": "10.1145/3544109.3544143",
                "collection-title": "IPEC '22",
                "container-title": "Proceedings of the 3rd Asia-Pacific Conference on Image Processing, Electronics and Computers",
                "DOI": "10.1145/3544109.3544143",
                "event-place": "Dalian, China",
                "ISBN": "9781450395786",
                "number-of-pages": "4",
                "page": "187–190",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Smart Tourism Management Model Based on Big Data Technology",
                "URL": "https://doi.org/10.1145/3544109.3544143"
            }
        },
        {
            "10.14778/3090163.3090168": {
                "id": "10.14778/3090163.3090168",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Anderson",
                        "given": "Michael"
                    },
                    {
                        "family": "Smith",
                        "given": "Shaden"
                    },
                    {
                        "family": "Sundaram",
                        "given": "Narayanan"
                    },
                    {
                        "family": "Capotă",
                        "given": "Mihai"
                    },
                    {
                        "family": "Zhao",
                        "given": "Zheguang"
                    },
                    {
                        "family": "Dulloor",
                        "given": "Subramanya"
                    },
                    {
                        "family": "Satish",
                        "given": "Nadathur"
                    },
                    {
                        "family": "Willke",
                        "given": "Theodore L."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            4,
                            1
                        ]
                    ]
                },
                "abstract": "Apache Spark is a popular framework for data analytics with attractive features such as fault tolerance and interoperability with the Hadoop ecosystem. Unfortunately, many analytics operations in Spark are an order of magnitude or more slower compared to native implementations written with high performance computing tools such as MPI. There is a need to bridge the performance gap while retaining the benefits of the Spark ecosystem such as availability, productivity, and fault tolerance. In this paper, we propose a system for integrating MPI with Spark and analyze the costs and benefits of doing so for four distributed graph and machine learning applications. We show that offloading computation to an MPI environment from within Spark provides 3.1−17.7× speedups on the four sparse applications, including all of the overheads. This opens up an avenue to reuse existing MPI libraries in Spark with little effort.",
                "call-number": "10.14778/3090163.3090168",
                "container-title": "Proc. VLDB Endow.",
                "DOI": "10.14778/3090163.3090168",
                "ISSN": "2150-8097",
                "issue": "8",
                "number-of-pages": "12",
                "page": "901–912",
                "publisher": "VLDB Endowment",
                "source": "April 2017",
                "title": "Bridging the gap between HPC and big data frameworks",
                "URL": "https://doi.org/10.14778/3090163.3090168",
                "volume": "10"
            }
        },
        {
            "10.1145/3078468.3078500": {
                "id": "10.1145/3078468.3078500",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Garion",
                        "given": "Shelly"
                    },
                    {
                        "family": "Kolodner",
                        "given": "Hillel"
                    },
                    {
                        "family": "Adir",
                        "given": "Allon"
                    },
                    {
                        "family": "Aharoni",
                        "given": "Ehud"
                    },
                    {
                        "family": "Greenberg",
                        "given": "Lev"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            22
                        ]
                    ]
                },
                "abstract": "We use Apache Spark analytics to investigate the logs of an operational cloud object store service to understand how it is being used. This investigation involves going over very large amounts of historical data (PBs of records in some cases) collected over long periods of time retroactively. Existing tools, such as Elasticsearch-Logstash-Kibana (ELK), are mainly used for presenting short-term metrics and can-not perform advanced analytics such as machine learning. A possible solution is to save for long periods only certain aggregations or calculations produced from the raw log data, such as averages or histograms, however these must be decided in advance, and cannot be changed retroactively since the raw data has already been discarded. Spark allows us to gain insights going over historical data collected over long periods of time and to apply the historical models on online data in a simple and efficient way.",
                "call-number": "10.1145/3078468.3078500",
                "collection-number": "30",
                "collection-title": "SYSTOR '17",
                "container-title": "Proceedings of the 10th ACM International Systems and Storage Conference",
                "DOI": "10.1145/3078468.3078500",
                "event-place": "Haifa, Israel",
                "ISBN": "9781450350358",
                "number": "Article 30",
                "number-of-pages": "1",
                "page": "1",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data analysis of cloud storage logs using spark",
                "URL": "https://doi.org/10.1145/3078468.3078500"
            }
        },
        {
            "10.1145/2345316.2345324": {
                "id": "10.1145/2345316.2345324",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Tossavainen",
                        "given": "Olli-Pekka"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            7,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            7,
                            1
                        ]
                    ]
                },
                "abstract": "Real time traffic monitoring systems perform spatial and time dependent analysis of measurement data of different types such as traditional inductive loop detector data, microwave radar data, and GPS data. The goal of these systems is to provide information such as average speeds, volumes and densities on a given segment of a roadway. One of the fastest growing data source for traffic monitoring systems is GPS data collected from mobile devices. To some extent, in the industry GPS data is already replacing the traditional traffic sensing technologies.There is a large demand in industry and transportation agencies to have access to high resolution state of traffic on highways and arterial roads globally. This means that traffic information providers have to provide traffic information on a resolution that goes beyond the widely used TMC code based representation of the roadway.In order to obtain the high resolution state of traffic, noisy observations need to be fused into a mathematical model that represents the evolution of the system either based on physics or statistics. Common frameworks for fusing the data into physical models include for example Kalman filtering and particle filtering.Prior to the data fusion stage in the real time system, offline geospatial modelling has already been done. For example, construction and calibration of an accurate physics based traffic model includes tasks such as building a directed graph of the road network, detection of road geometry at lane level and speed limit detection. In all these tasks, GPS data is vital.Real time systems that use GPS data include geospatial pre-processing components such as map matching and path inference. The rapidly growing volume of GPS data cannot be handled using traditional methods but instead parallel computing systems are needed to handle the future volumes. Also, the new high resolution algorithms are developed to leverage the parallel processing frameworks.In this talk I will discuss directions taken to respond to the demand of providing high resolution information about the state of the traffic both in the context of modeling and implementation of a large scale system.",
                "call-number": "10.1145/2345316.2345324",
                "collection-number": "6",
                "collection-title": "COM.Geo '12",
                "container-title": "Proceedings of the 3rd International Conference on Computing for Geospatial Research and Applications",
                "DOI": "10.1145/2345316.2345324",
                "event-place": "Washington, D.C., USA",
                "ISBN": "9781450311137",
                "number": "Article 6",
                "number-of-pages": "1",
                "page": "1",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data computing for traffic information by GPS sensing",
                "URL": "https://doi.org/10.1145/2345316.2345324"
            }
        },
        {
            "10.1145/3357223.3362720": {
                "id": "10.1145/3357223.3362720",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Rui"
                    },
                    {
                        "family": "Guo",
                        "given": "Peizhen"
                    },
                    {
                        "family": "Hu",
                        "given": "Bo"
                    },
                    {
                        "family": "Hu",
                        "given": "Wenjun"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            11,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            11,
                            20
                        ]
                    ]
                },
                "abstract": "Despite extensive investigation of job scheduling in data-intensive computation frameworks, less consideration has been given to optimizing job partitioning for resource utilization and efficient processing. Instead, partitioning and job sizing are a form of dark art, typically left to developer intuition and trial-and-error style experimentation.In this work, we propose that just as job scheduling and resource allocation are out-sourced to a trusted mechanism external to the workload, so too should be the responsibility for partitioning data as a determinant for task size. Job partitioning essentially involves determining the partition sizes to match the resource allocation at the finest granularity. This is a complex, multi-dimensional problem that is highly application specific: resource allocation, computational runtime, shuffle and reduce communication requirements, and task startup overheads all have strong influence on the most effective task size for efficient processing. Depending on the partition size, the job completion time can differ by as much as 10 times!Fortunately, we observe a general trend underlying the tradeoff between full resource utilization and system overhead across different settings. The optimal job partition size balances these two conflicting forces. Given this trend, we design Libra to automate job partitioning as a framework extension. We integrate Libra with Spark and evaluate its performance on EC2. Compared to state-of-the-art techniques, Libra can reduce the individual job execution time by 25% to 70%.",
                "call-number": "10.1145/3357223.3362720",
                "collection-title": "SoCC '19",
                "container-title": "Proceedings of the ACM Symposium on Cloud Computing",
                "DOI": "10.1145/3357223.3362720",
                "event-place": "Santa Cruz, CA, USA",
                "ISBN": "9781450369732",
                "keyword": "Automatic Task Sizing, Data-analytic Systems, Big Data Systems",
                "number-of-pages": "13",
                "page": "364–376",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Libra and the Art of Task Sizing in Big-Data Analytic Systems",
                "URL": "https://doi.org/10.1145/3357223.3362720"
            }
        },
        {
            "10.1145/3097983.3105813": {
                "id": "10.1145/3097983.3105813",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Berglund",
                        "given": "Andy"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            13
                        ]
                    ]
                },
                "abstract": "The recent advances in genome sequencing and analyses of the billions of base pairs in genomic data have been a boon for moving forward our understanding of human disease. In this talk I will describe how genome sequencing has dramatically improved our understanding of the most common adult form of muscular dystrophy, which is myotonic dystrophy. Two different genetic mutations cause thousands of changes in the cells and tissues of myotonic dystrophy patients. Genome sequencing has allowed us to precisely determine the degree of changes across patients, correlate these changes to disease symptoms and allow us to determine quickly in cell and animal models the effectiveness of therapeutic strategies for myotonic dystrophy.",
                "call-number": "10.1145/3097983.3105813",
                "collection-title": "KDD '17",
                "container-title": "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
                "DOI": "10.1145/3097983.3105813",
                "event-place": "Halifax, NS, Canada",
                "ISBN": "9781450348874",
                "keyword": "genomic data, genome sequencing, muscular dystrophy, myotonic dystrophy, data mining.",
                "number-of-pages": "1",
                "page": "11",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Mining Big Data in NeuroGenetics to Understand Muscular Dystrophy",
                "URL": "https://doi.org/10.1145/3097983.3105813"
            }
        },
        {
            "10.1145/2378016.2378019": {
                "id": "10.1145/2378016.2378019",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Curé",
                        "given": "Olivier"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            10,
                            1
                        ]
                    ]
                },
                "abstract": "Many health care systems and services exploit drug related information stored in databases. The poor data quality of these databases, e.g. inaccuracy of drug contraindications, can lead to catastrophic consequences for the health condition of patients. Hence it is important to ensure their quality in terms of data completeness and soundness.In the database domain, standard Functional Dependencies (FDs) and INclusion Dependencies (INDs), have been proposed to prevent the insertion of incorrect data. But they are generally not expressive enough to represent a domain-specific set of constraints. To this end, conditional dependencies, i.e. standard dependencies extended with tableau patterns containing constant values, have been introduced and several methods have been proposed for their discovery and representation. The quality of drug databases can be considerably improved by their usage.Moreover, pharmacology information is inherently hierarchical and many standards propose graph structures to represent them, e.g. the Anatomical Therapeutic Chemical classification (ATC) or OpenGalen’s terminology. In this article, we emphasize that the technologies of the Semantic Web are adapted to represent these hierarchical structures, i.e. in RDFS and OWL. We also present a solution for representing conditional dependencies using a query language defined for these graph oriented structures, namely SPARQL. The benefits of this approach are interoperability with applications and ontologies of the Semantic Web as well as a reasoning-based query execution solution to clean underlying databases.",
                "call-number": "10.1145/2378016.2378019",
                "collection-number": "3",
                "container-title": "J. Data and Information Quality",
                "DOI": "10.1145/2378016.2378019",
                "ISSN": "1936-1955",
                "issue": "1",
                "keyword": "Data quality, conditional dependencies, description logics",
                "number": "Article 3",
                "number-of-pages": "21",
                "page": "1–21",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "October 2012",
                "title": "Improving the Data Quality of Drug Databases using Conditional Dependencies and Ontologies",
                "URL": "https://doi.org/10.1145/2378016.2378019",
                "volume": "4"
            }
        },
        {
            "10.1145/2598902": {
                "id": "10.1145/2598902",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Goodman",
                        "given": "Elizabeth"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            5,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/2598902",
                "container-title": "interactions",
                "DOI": "10.1145/2598902",
                "ISSN": "1072-5520",
                "issue": "3",
                "number-of-pages": "3",
                "page": "22–24",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "May-June 2014",
                "title": "Design and ethics in the era of big data",
                "URL": "https://doi.org/10.1145/2598902",
                "volume": "21"
            }
        },
        {
            "10.1145/3538228": {
                "id": "10.1145/3538228",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Spychiger",
                        "given": "Florian"
                    },
                    {
                        "family": "Tessone",
                        "given": "Claudio J."
                    },
                    {
                        "family": "Zavolokina",
                        "given": "Liudmila"
                    },
                    {
                        "family": "Schwabe",
                        "given": "Gerhard"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            9,
                            10
                        ]
                    ]
                },
                "abstract": "Inspired by an industry initiative to address the celebrated market for lemons (poor-quality used cars), we investigate how incentives for a permissioned blockchain-based system in the automobile ecosystem can be designed to ensure high-quality data storage and use by different stakeholders. The peer-to-peer distributed ledger platform connects organizations and car owners with disparate interests and hidden intentions. While previous literature has chiefly examined incentives for permissionless platforms, we leverage studies about crowdsensing applications to stimulate research on incentives in permissioned blockchains. This article uses the action design research approach to create an incentive system featuring a rating mechanism influenced by data correction measures. Furthermore, we propose relying on certain institutions capable of assessing data generated within the system. This combined approach of a decentralized data correction and an institutionalized data assessment is distinct from similar incentive systems suggested by literature. By using an agent-based model with strategy evolution, we evaluate the proposed incentive system. Our findings indicate that a rating-based revenue distribution leads to markedly higher data quality in the system. Additionally, the incentive system reveals hidden information of the agents and alleviates agency problems, contributing to an understanding of incentive design in inter-organizational blockchain-based data platforms. Furthermore, we explore incentive design in permissioned blockchains and discuss its latest implications.",
                "call-number": "10.1145/3538228",
                "collection-number": "3",
                "container-title": "Distrib. Ledger Technol.",
                "DOI": "10.1145/3538228",
                "ISSN": "2769-6472",
                "issue": "1",
                "keyword": "Blockchain, peer-to-peer market, data quality, incentives, action design research",
                "number": "Article 3",
                "number-of-pages": "27",
                "page": "1–27",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "September 2022",
                "title": "Incentivizing Data Quality in Blockchain-Based Systems—The Case of the Digital Cardossier",
                "URL": "https://doi.org/10.1145/3538228",
                "volume": "1"
            }
        },
        {
            "10.1109/TNET.2019.2943884": {
                "id": "10.1109/TNET.2019.2943884",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Yun",
                        "given": "Daqing"
                    },
                    {
                        "family": "Wu",
                        "given": "Chase Q."
                    },
                    {
                        "family": "Rao",
                        "given": "Nageswara S. V."
                    },
                    {
                        "family": "Kettimuthu",
                        "given": "Rajkumar"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            12,
                            1
                        ]
                    ]
                },
                "abstract": "Big data transfer in next-generation scientific applications is now commonly carried out over dedicated channels in high-performance networks (HPNs), where transport protocols play a critical role in maximizing application-level throughput. Optimizing the performance of these protocols is challenging: i) transport protocols perform differently in various network environments, and the protocol choice is not straightforward; ii) even for a given protocol in a given environment, different parameter settings of the protocol may lead to significantly different performance and oftentimes the default setting does not yield the best performance. However, it is prohibitively time-consuming to conduct exhaustive transport profiling due to the large parameter space. In this paper, we propose a PRofiling Optimization Based DAta Transfer Advisor (ProbData) to help end users determine the most effective transport method with the most appropriate parameter settings to achieve satisfactory performance for big data transfer over dedicated connections in HPNs. ProbData employs a fast profiling scheme based on the Simultaneous Perturbation Stochastic Approximation algorithm, namely, FastProf, to accelerate the exploration of the optimal operational zones of various transport methods to improve profiling efficiency. We first present a theoretical background of the optimized profiling approach in ProbData and then detail its design and implementation. The advising procedure and performance benefits of FastProf and ProbData are illustrated and evaluated by both extensive emulations based on real-life performance measurements and experiments over various physical connections in existing production HPNs.",
                "call-number": "10.1109/TNET.2019.2943884",
                "container-title": "IEEE/ACM Trans. Netw.",
                "DOI": "10.1109/TNET.2019.2943884",
                "ISSN": "1063-6692",
                "issue": "6",
                "number-of-pages": "14",
                "page": "2280–2293",
                "publisher": "IEEE Press",
                "source": "Dec. 2019",
                "title": "Advising Big Data Transfer Over Dedicated Connections Based on Profiling Optimization",
                "URL": "https://doi.org/10.1109/TNET.2019.2943884",
                "volume": "27"
            }
        },
        {
            "10.1145/3498765.3498846": {
                "id": "10.1145/3498765.3498846",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Wang",
                        "given": "Chenyu"
                    },
                    {
                        "family": "Jiang",
                        "given": "Bai'an"
                    },
                    {
                        "family": "Zhong",
                        "given": "Shichang"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            22
                        ]
                    ]
                },
                "abstract": "The teaching effect of music courses in Colleges and universities is closely related to the teaching quality of teachers. Starting with the application of big data in the teaching quality evaluation system of colleges and universities, this paper objectively summarizes the application of big data in the teaching quality evaluation system of music courses in Colleges and universities. Finally, Put forward the countermeasures to strengthen the application of big data in the teaching quality evaluation system of music courses in Colleges and Universities: gradually optimize the teaching quality evaluation system and enrich the evaluation content; Optimize the display form of teaching quality evaluation and highlight the role of evaluation; At the same time, improve students' enthusiasm for participation, mobilize students' enthusiasm for participating in the evaluation, and improve the quality of the course.",
                "call-number": "10.1145/3498765.3498846",
                "collection-title": "ICETC 2021",
                "container-title": "2021 13th International Conference on Education Technology and Computers",
                "DOI": "10.1145/3498765.3498846",
                "event-place": "Wuhan, China",
                "ISBN": "9781450385114",
                "keyword": "Big data, Teaching, Evaluation, College",
                "number-of-pages": "6",
                "page": "252–257",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on the Application of Big Data in the Evaluation System of Music Teaching in Chinese Colleges and Universities",
                "URL": "https://doi.org/10.1145/3498765.3498846"
            }
        },
        {
            "10.1145/3207677.3277994": {
                "id": "10.1145/3207677.3277994",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhang",
                        "given": "Han"
                    },
                    {
                        "family": "Wang",
                        "given": "Kuisheng"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            22
                        ]
                    ]
                },
                "abstract": "With1 the rapid development of the Internet, Internet credit business has emerged and the process is now booming. As a result, there is a problem of predicting credit demand of users. Therefore, we propose a method of using big data analysis to forecast the credit demand of users in this paper, which is used to reduce the risk of credit business and improve the utilization of funds.",
                "call-number": "10.1145/3207677.3277994",
                "collection-number": "28",
                "collection-title": "CSAE '18",
                "container-title": "Proceedings of the 2nd International Conference on Computer Science and Application Engineering",
                "DOI": "10.1145/3207677.3277994",
                "event-place": "Hohhot, China",
                "ISBN": "9781450365123",
                "keyword": "credit demand, Data analysis, ReliefF feature extraction algorithm, GBDT (Gradient Boosting Decision Tree) model, K-means clustering algorithm",
                "number": "Article 28",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on Customer Credit Demand Forecasting Based on Big Data Analysis",
                "URL": "https://doi.org/10.1145/3207677.3277994"
            }
        },
        {
            "10.1145/3416028.3416029": {
                "id": "10.1145/3416028.3416029",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Shiau",
                        "given": "Yeajou"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            8,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            8,
                            7
                        ]
                    ]
                },
                "abstract": "This study explores the reasons for the suspension and dropout of full-time university students at a university in Taiwan and suggests better timing and strategies for student counseling. In this study, the narrative statistical analysis is used to analyze and discuss the sample objects, and then use data mining technology to find characteristic phenomena and classification conditions of the students who are suspended or dropout. Other studies related to dropouts rarely use leading indicators to predict the student dropout probability in real-time, most likely because of the timeliness and availability of student data. Therefore, this study proposes to use daily changes in absence indicators as predictive variables. Through the use of discriminant analysis to construct discriminant functions, the coefficient value of each student's withdrawal from university and early warning threshold for determining withdrawal from university can be presented in real-time in order to effectively provide the student with immediate counseling.",
                "call-number": "10.1145/3416028.3416029",
                "collection-title": "IMMS 2020",
                "container-title": "Proceedings of the 2020 3rd International Conference on Information Management and Management Science",
                "DOI": "10.1145/3416028.3416029",
                "event-place": "London, United Kingdom",
                "ISBN": "9781450375467",
                "keyword": "Decision tree model, Data mining, Counseling decision, Bayesian probability classification table",
                "number-of-pages": "7",
                "page": "1–7",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "University Dropout Prevention through the Application of Big Data",
                "URL": "https://doi.org/10.1145/3416028.3416029"
            }
        },
        {
            "10.1145/3263376": {
                "id": "10.1145/3263376",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Lall",
                        "given": "Ashwin"
                    },
                    {
                        "family": "Czajkowski",
                        "given": "Grzegorz"
                    },
                    {
                        "family": "Wang",
                        "given": "Haixun"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            4,
                            17
                        ]
                    ]
                },
                "call-number": "10.1145/3263376",
                "container-title": "SIGMETRICS Perform. Eval. Rev.",
                "DOI": "10.1145/3263376",
                "ISSN": "0163-5999",
                "issue": "4",
                "number-of-pages": "1",
                "page": "",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "March 2014",
                "title": "Session details: Special issue on big data analytics workshop",
                "URL": "https://doi.org/10.1145/3263376",
                "volume": "41"
            }
        },
        {
            "10.1145/3424978.3425137": {
                "id": "10.1145/3424978.3425137",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Shi",
                        "given": "Qiao"
                    },
                    {
                        "family": "Wang",
                        "given": "Honglv"
                    },
                    {
                        "family": "Lu",
                        "given": "Hailong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            10,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            10,
                            20
                        ]
                    ]
                },
                "abstract": "In order to improve the operation quality of the cross-enterprise batch management system in the tobacco industry, a comprehensive data quality index evaluation model is proposed in this paper. By analyzing the characteristics of batch management data, 7 indicators are selected to evaluate the system data, and the influence of human factors is eliminated by the combination weight determined by the analytic hierarchy process (AHP) and entropy weight method (EWM). The proposed evaluation model is applied to the quality assessment of the actual statistical data of Zhejiang Tobacco Industries Co. and six cooperative production enterprises in the cigarette industry. The results show that the model can scientifically evaluate the system data quality of each enterprise, intuitively rank the data quality of various enterprises, and truly reflect the change trend of data quality, indicating the feasibility and effectiveness of the model. This method can provide support for improving the data quality level of the cross-enterprise batch management system.",
                "call-number": "10.1145/3424978.3425137",
                "collection-number": "152",
                "collection-title": "CSAE 2020",
                "container-title": "Proceedings of the 4th International Conference on Computer Science and Application Engineering",
                "DOI": "10.1145/3424978.3425137",
                "event-place": "Sanya, China",
                "ISBN": "9781450377720",
                "keyword": "Batch management, Data quality, Tobacco industry, Analytic hierarchy process, Entropy weight method, Synthetic evaluation",
                "number": "Article 152",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research and Application of AHP-EWM-based Comprehensive Evaluation of Data Quality",
                "URL": "https://doi.org/10.1145/3424978.3425137"
            }
        },
        {
            "10.1145/3055167.3055180": {
                "id": "10.1145/3055167.3055180",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Qi",
                        "given": "Danrui"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            14
                        ]
                    ]
                },
                "call-number": "10.1145/3055167.3055180",
                "collection-title": "SIGMOD '17",
                "container-title": "Proceedings of the 2017 ACM International Conference on Management of Data",
                "DOI": "10.1145/3055167.3055180",
                "event-place": "Chicago, Illinois, USA",
                "ISBN": "9781450341998",
                "keyword": "explanation, data cleaning",
                "number-of-pages": "3",
                "page": "10–12",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "On Concise Explanations of Non-Answers over Big Data",
                "URL": "https://doi.org/10.1145/3055167.3055180"
            }
        },
        {
            "10.1145/304182.304568": {
                "id": "10.1145/304182.304568",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Jarke",
                        "given": "Matthias"
                    },
                    {
                        "family": "Quix",
                        "given": "Christoph"
                    },
                    {
                        "family": "Blees",
                        "given": "Guido"
                    },
                    {
                        "family": "Lehmann",
                        "given": "Dirk"
                    },
                    {
                        "family": "Michalk",
                        "given": "Gunter"
                    },
                    {
                        "family": "Stierl",
                        "given": "Stefan"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            1999,
                            6,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            1999,
                            6,
                            1
                        ]
                    ]
                },
                "abstract": "Research and products for the integration of heterogeneous legacy source databases in data warehousing have addressed numerous data quality problems in or between the sources. Such a solution is marketed by Team4 for the decision support of mobile sales representatives, using advanced view maintenance and replication management techniques in an environment based on relational data warehouse technology and Lotus Notes-based client systems. However, considering total information supply chain management, the capture of poor operational data, to be cleaned later in the data warehouse, appears sub-optimal. Based on the observation that decision support clients are often closely linked to operational data entry, we have addressed the problem of mapping the data warehouse data quality techniques back to data quality measures for improving OLTP data. The solution requires a warehouse-to-OLTP workflow which employs a combination of view maintenance and view update techniques.",
                "call-number": "10.1145/304182.304568",
                "collection-title": "SIGMOD '99",
                "container-title": "Proceedings of the 1999 ACM SIGMOD international conference on Management of data",
                "DOI": "10.1145/304182.304568",
                "event-place": "Philadelphia, Pennsylvania, USA",
                "ISBN": "1581130848",
                "number-of-pages": "2",
                "page": "536–537",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Improving OLTP data quality using data warehouse mechanisms",
                "URL": "https://doi.org/10.1145/304182.304568"
            }
        },
        {
            "10.1145/304181.304568": {
                "id": "10.1145/304181.304568",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Jarke",
                        "given": "Matthias"
                    },
                    {
                        "family": "Quix",
                        "given": "Christoph"
                    },
                    {
                        "family": "Blees",
                        "given": "Guido"
                    },
                    {
                        "family": "Lehmann",
                        "given": "Dirk"
                    },
                    {
                        "family": "Michalk",
                        "given": "Gunter"
                    },
                    {
                        "family": "Stierl",
                        "given": "Stefan"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            1999,
                            6,
                            1
                        ]
                    ]
                },
                "abstract": "Research and products for the integration of heterogeneous legacy source databases in data warehousing have addressed numerous data quality problems in or between the sources. Such a solution is marketed by Team4 for the decision support of mobile sales representatives, using advanced view maintenance and replication management techniques in an environment based on relational data warehouse technology and Lotus Notes-based client systems. However, considering total information supply chain management, the capture of poor operational data, to be cleaned later in the data warehouse, appears sub-optimal. Based on the observation that decision support clients are often closely linked to operational data entry, we have addressed the problem of mapping the data warehouse data quality techniques back to data quality measures for improving OLTP data. The solution requires a warehouse-to-OLTP workflow which employs a combination of view maintenance and view update techniques.",
                "call-number": "10.1145/304181.304568",
                "container-title": "SIGMOD Rec.",
                "DOI": "10.1145/304181.304568",
                "ISSN": "0163-5808",
                "issue": "2",
                "number-of-pages": "2",
                "page": "536–537",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "June 1999",
                "title": "Improving OLTP data quality using data warehouse mechanisms",
                "URL": "https://doi.org/10.1145/304181.304568",
                "volume": "28"
            }
        },
        {
            "10.1145/3381027": {
                "id": "10.1145/3381027",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Herodotou",
                        "given": "Herodotos"
                    },
                    {
                        "family": "Chen",
                        "given": "Yuxing"
                    },
                    {
                        "family": "Lu",
                        "given": "Jiaheng"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            4,
                            26
                        ]
                    ]
                },
                "abstract": "Big data processing systems (e.g., Hadoop, Spark, Storm) contain a vast number of configuration parameters controlling parallelism, I/O behavior, memory settings, and compression. Improper parameter settings can cause significant performance degradation and stability issues. However, regular users and even expert administrators grapple with understanding and tuning them to achieve good performance. We investigate existing approaches on parameter tuning for both batch and stream data processing systems and classify them into six categories: rule-based, cost modeling, simulation-based, experiment-driven, machine learning, and adaptive tuning. We summarize the pros and cons of each approach and raise some open research problems for automatic parameter tuning.",
                "call-number": "10.1145/3381027",
                "collection-number": "43",
                "container-title": "ACM Comput. Surv.",
                "DOI": "10.1145/3381027",
                "ISSN": "0360-0300",
                "issue": "2",
                "keyword": "Storm, MapReduce, self-tuning, Parameter tuning, stream, Spark",
                "number": "Article 43",
                "number-of-pages": "37",
                "page": "1–37",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "March 2021",
                "title": "A Survey on Automatic Parameter Tuning for Big Data Processing Systems",
                "URL": "https://doi.org/10.1145/3381027",
                "volume": "53"
            }
        },
        {
            "10.1109/CCGrid.2014.123": {
                "id": "10.1109/CCGrid.2014.123",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Gunarathne",
                        "given": "Thilina"
                    },
                    {
                        "family": "Qiu",
                        "given": "Judy"
                    },
                    {
                        "family": "Gannon",
                        "given": "Dennis"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            5,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            5,
                            26
                        ]
                    ]
                },
                "abstract": "We generalize MapReduce, Iterative MapReduce and data intensive MPI runtime as a layered Map-Collective architecture with Map-AllGather, Map-AllReduce, MapReduceMergeBroadcast and Map-ReduceScatter patterns as the initial focus. Map-collectives improve the performance and efficiency of the computations while at the same time facilitating ease of use for the users. These collective primitives can be applied to multiple runtimes and we propose building high performance robust implementations that cross cluster and cloud systems. Here we present results for two collectives shared between Hadoop (where we term our extension H-Collectives) on clusters and the Twister4Azure Iterative MapReduce for the Azure Cloud. Our prototype implementations of Map-AllGather and Map-AllReduce primitives achieved up to 33% performance improvement for K-means Clustering and up to 50% improvement for Multi-Dimensional Scaling, while also improving the user friendliness. In some cases, use of Map-collectives virtually eliminated almost all the overheads of the computations.",
                "call-number": "10.1109/CCGrid.2014.123",
                "collection-title": "CCGRID '14",
                "container-title": "Proceedings of the 14th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing",
                "DOI": "10.1109/CCGrid.2014.123",
                "event-place": "Chicago, Illinois",
                "ISBN": "9781479927838",
                "keyword": "collectives, MDS, cloud, K-means, twister, performance, MapReduce, HPC",
                "number-of-pages": "10",
                "page": "236–245",
                "publisher": "IEEE Press",
                "title": "Towards a collective layer in the big data stack",
                "URL": "https://doi.org/10.1109/CCGrid.2014.123"
            }
        },
        {
            "10.5555/3233397.3233483": {
                "id": "10.5555/3233397.3233483",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Albadarneh",
                        "given": "Jafar"
                    },
                    {
                        "family": "Talafha",
                        "given": "Bashar"
                    },
                    {
                        "family": "Al-Ayyoub",
                        "given": "Mahmoud"
                    },
                    {
                        "family": "Zaqaibeh",
                        "given": "Belal"
                    },
                    {
                        "family": "Al-Smadi",
                        "given": "Mohammad"
                    },
                    {
                        "family": "Jararweh",
                        "given": "Yaser"
                    },
                    {
                        "family": "Benkhelifa",
                        "given": "Elhadj"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            12,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            12,
                            7
                        ]
                    ]
                },
                "abstract": "Authorship authentication of a certain text is concerned with correctly attributing it to its author based on its contents. It is a very important problem with deep root in history as many classical texts have doubtful attributions. The information age and ubiquitous use of the Internet is further complicating this problem and adding more dimensions to it. We are interested in the modern version of this problem where the text whose authorship needs authentication is an online text found in online social networks. Specifically, we are interested in the authorship authentication of tweets. This is not the only challenging aspect we consider here. Another challenging aspect is the language of the tweets. Most current works and existing tools support English. We chose to focus on the very important, yet largely understudied, Arabic language. Finally, we add another challenging aspect to the problem at hand by addressing it at a very large scale. We present our effort to employ big data analytics to address the authorship authentication problem of Arabic tweets. We start by crawling a dataset of more than 53K tweets distributed across 20 authors. We then use preprocessing steps to clean the data and prepare it for analysis. The next step is to compute the feature vectors of each tweet. We use the Bag-Of-Words (BOW) approach and compute the weights using the Term Frequency-Inverse Document Frequency (TF-IDF). Then, we feed the dataset to a Naive Bayes classifier implemented on a parallel and distributed computing framework known as Hadoop. To the best of our knowledge, none of the previous works on authorship authentication of Arabic text addressed the unique challenges associated with (1) tweets and (2) large-scale datasets. This makes our work unique on many levels. The results show that the testing accuracy is not very high (61.6%), which is expected in the very challenging setting that we consider.",
                "call-number": "10.5555/3233397.3233483",
                "collection-title": "UCC '15",
                "container-title": "Proceedings of the 8th International Conference on Utility and Cloud Computing",
                "event-place": "Limassol, Cyprus",
                "ISBN": "9780769556970",
                "number-of-pages": "5",
                "page": "448–452",
                "publisher": "IEEE Press",
                "title": "Using big data analytics for authorship authentication of arabic tweets"
            }
        },
        {
            "10.1145/3318299.3318388": {
                "id": "10.1145/3318299.3318388",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhuo",
                        "given": "Zhiyi"
                    },
                    {
                        "family": "Zhang",
                        "given": "Shanhu"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            2,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            2,
                            22
                        ]
                    ]
                },
                "abstract": "This article reviews relevant theories and literature on big data management, management decision-making, execution, and other aspects, discusses the two significant factors of decision-making force and executive power that are the realization of corporate strategic goals, and puts forward the corporate data in the context of big data. The operating model (mainly for the enterprise's decision-making and implementation) faces new opportunities and challenges, that is, through in-depth analysis and exploration of big data management can effectively improve the company's decision-making ability and execution efficiency, and promote the realization of corporate strategic goals.",
                "call-number": "10.1145/3318299.3318388",
                "collection-title": "ICMLC '19",
                "container-title": "Proceedings of the 2019 11th International Conference on Machine Learning and Computing",
                "DOI": "10.1145/3318299.3318388",
                "event-place": "Zhuhai, China",
                "ISBN": "9781450366007",
                "keyword": "decision-making, literature review, execution, Big data management",
                "number-of-pages": "6",
                "page": "268–273",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on the Application of Big Data Management in Enterprise Management Decision-making and Execution Literature Review",
                "URL": "https://doi.org/10.1145/3318299.3318388"
            }
        },
        {
            "10.14778/3402707.3402709": {
                "id": "10.14778/3402707.3402709",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Campbell",
                        "given": "David"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2011,
                            8,
                            1
                        ]
                    ]
                },
                "abstract": "\"Big Data\" is a hot topic but, in many ways, we are still trying to define what the phrase \"Big Data\" means. For many, there are more questions than answers at this point. Is it about size alone? Complexity? Variability? Data shape? Price/performance? New workloads? New types of users? Are existing data models, data management systems, data languages, and BI/ETL tools relevant in this space? Is MapReduce really a \"major step backwards\"? I have spent time over the last several years trying to answer many of these questions to my own satisfaction. As part of the journey I have witnessed a number of natural patterns that emerge in big data processing. In this talk I will present a catalog of these patterns and illustrate them across a scale spectrum from megabytes to 100s of petabytes. Finally, I will offer some thoughts around a systems and research agenda for this new world.",
                "call-number": "10.14778/3402707.3402709",
                "container-title": "Proc. VLDB Endow.",
                "DOI": "10.14778/3402707.3402709",
                "ISSN": "2150-8097",
                "issue": "11",
                "number-of-pages": "1",
                "page": "694",
                "publisher": "VLDB Endowment",
                "source": "August 2011",
                "title": "Is it still \"Big Data\" if it fits in my pocket?",
                "URL": "https://doi.org/10.14778/3402707.3402709",
                "volume": "4"
            }
        },
        {
            "10.1145/3510361": {
                "id": "10.1145/3510361",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Xia",
                        "given": "Feng"
                    },
                    {
                        "family": "Guo",
                        "given": "Teng"
                    },
                    {
                        "family": "Bai",
                        "given": "Xiaomei"
                    },
                    {
                        "family": "Shatte",
                        "given": "Adrian"
                    },
                    {
                        "family": "Liu",
                        "given": "Zitao"
                    },
                    {
                        "family": "Tang",
                        "given": "Jiliang"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            3,
                            30
                        ]
                    ]
                },
                "abstract": "The failure of obtaining employment could lead to serious psychosocial outcomes such as depression and substance abuse, especially for college students who may be less cognitively and emotionally mature. In addition to academic performance, employers’ unconscious biases are a potential obstacle to graduating students in becoming employed. Thus, it is necessary to understand the nature of such unconscious biases to assist students at an early stage with personalized intervention. In this paper, we analyze the existing bias in college graduate employment through a large-scale education dataset and develop a framework called SUMMER (biaS-aware gradUate eMployMEnt pRediction) to predict students’ employment status and employment preference while considering biases. The framework consists of four major components. Firstly, we resolve the heterogeneity of student courses by embedding academic performance into a unified space. Next, we apply a Wasserstein generative adversarial network with gradient penalty (WGAN-GP) to overcome the label imbalance problem of employment data. Thirdly, we adopt a temporal convolutional network to comprehensively capture sequential information of academic performance across semesters. Finally, we design a bias-based regularization to smooth the job market biases. We conduct extensive experiments on a large-scale educational dataset and the results demonstrate the effectiveness of our prediction framework.",
                "call-number": "10.1145/3510361",
                "collection-number": "39",
                "container-title": "ACM/IMS Trans. Data Sci.",
                "DOI": "10.1145/3510361",
                "ISSN": "2691-1922",
                "issue": "4",
                "keyword": "educational big data, bias, prediction, data analysis, Graduate employment",
                "number": "Article 39",
                "number-of-pages": "24",
                "page": "1–24",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "November 2021",
                "title": "SUMMER: Bias-aware Prediction of Graduate Employment Based on Educational Big Data",
                "URL": "https://doi.org/10.1145/3510361",
                "volume": "2"
            }
        },
        {
            "10.1145/3358505.3358509": {
                "id": "10.1145/3358505.3358509",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Faccia",
                        "given": "Alessio"
                    },
                    {
                        "family": "Mosteanu",
                        "given": "Narcisa Roxana"
                    },
                    {
                        "family": "Fahed",
                        "given": "Mariam"
                    },
                    {
                        "family": "Capitanio",
                        "given": "Fabian"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            28
                        ]
                    ]
                },
                "abstract": "Accounting Information Systems (AISs) are fundamental for the recording of the accounting transactions of any company and for the preparation of financial statements, as required by the legislation on financial accounting. However, information systems are not only limited to accounting for the management of a company, but it is often necessary to implement additional information systems to manage other operational aspects such as inventory management, personnel, security, big data management for marketing and the provision of a broad corporate strategy. All these aspects, in general, in order to lead the company towards success, must be integrated with each other. Many software can manage all these aspects of management, but they do not allow integrated management and top management cannot control and reconcile all information. For this reason Enterprise resource plannings (ERPs), formed by different modules, are very common. ERPs allow the flow of information to be managed in an integrated manner using a single system, avoiding duplication, errors and loss and information. All the operations are reported systematically also and above all on the accounting module, which is the one that guides all the others. This research paper is focused on the comparison of currently most used AISs and ERPs in the UAE, also analyzing the market and the size of businesses in the area. The research highlighted the opportunities and limitations of the information systems currently available, as well as the characteristics of the companies that determined the dissemination of the programs in use.",
                "call-number": "10.1145/3358505.3358509",
                "collection-title": "ICCBDC 2019",
                "container-title": "Proceedings of the 2019 3rd International Conference on Cloud and Big Data Computing",
                "DOI": "10.1145/3358505.3358509",
                "event-place": "Oxford, United Kingdom",
                "ISBN": "9781450371650",
                "keyword": "UAE, Accounting Information Systems, market analysis, big data, ERP",
                "number-of-pages": "5",
                "page": "90–94",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Accounting Information Systems and ERP in the UAE: An Assessment of the Current and Future Challenges to Handle Big Data",
                "URL": "https://doi.org/10.1145/3358505.3358509"
            }
        },
        {
            "10.1145/3495018.3495446": {
                "id": "10.1145/3495018.3495446",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chen",
                        "given": "Fei"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            23
                        ]
                    ]
                },
                "abstract": "With the popularization of Internet technology, network big data has penetrated into every household. Various multimedia networks have enriched everyone's lives. At the same time, the scale of multimedia network data has become larger and larger, making the balanced scheduling of big data networks The problem is becoming more and more obvious. The problem of the unbalanced load of the multimedia network big data network has always been an object of attention. Therefore, for the problem of resource balance scheduling in multimedia network data, finding an effective network optimization algorithm plays an important role in improving the load balance of large-scale multimedia network resources. The main research content of this paper is based on the Fibonacci tree optimization algorithm. For the research on the balanced scheduling of media network big data, the Fibonacci tree optimization algorithm is a new intelligent optimization algorithm based on the Fibonacci method and the golden section method. The algorithm solves the optimal solution of the problem through alternate iterations of global exploration and local optimization. The final results of the study show that the throughput and delay of different algorithms are quite different when the number of tasks is the same. The Fibonacci tree optimization algorithm method in this paper has a throughput rate of 13.26mb/s and a delay of 16.28ms, which is similar. It has the highest throughput rate and lower latency than other algorithms, which shows that the Fibonacci tree optimization algorithm can adjust resources adaptively to the big data network environment, and the advantages of big data balanced scheduling are fully demonstrated.",
                "call-number": "10.1145/3495018.3495446",
                "collection-title": "AIAM2021",
                "container-title": "2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture",
                "DOI": "10.1145/3495018.3495446",
                "event-place": "Manchester, United Kingdom",
                "ISBN": "9781450385046",
                "number-of-pages": "5",
                "page": "1586–1590",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Multimedia Network Big Data Balanced Scheduling Based On Fibonacci Tree Optimization Algorithm",
                "URL": "https://doi.org/10.1145/3495018.3495446"
            }
        },
        {
            "10.1145/3288599.3295594": {
                "id": "10.1145/3288599.3295594",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Valluripally",
                        "given": "Samaikya"
                    },
                    {
                        "family": "Raju",
                        "given": "Murugesan"
                    },
                    {
                        "family": "Calyam",
                        "given": "Prasad"
                    },
                    {
                        "family": "Chisholm",
                        "given": "Matthew"
                    },
                    {
                        "family": "Sivarathri",
                        "given": "Sai Swathi"
                    },
                    {
                        "family": "Mosa",
                        "given": "Abu"
                    },
                    {
                        "family": "Joshi",
                        "given": "Trupti"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            1,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            1,
                            4
                        ]
                    ]
                },
                "abstract": "The adoption of big data analytics in healthcare applications is overwhelming not only because of the huge volume of data being analyzed, but also because of the heterogeneity and sensitivity of the data. Effective and efficient analysis and visualization of secure patient health records are needed to e.g., find new trends in disease management, determining risk factors for diseases, and personalized medicine. In this paper, we propose a novel community cloud architecture to help clinicians and researchers to have easy/increased accessibility to data sets from multiple sources, while also ensuring security compliance of data providers is not compromised. Our cloud-based system design configuration with cloudlet principles ensures application performance has high-speed processing, and data analytics is sufficiently scalable while adhering to security standards (e.g., HIPAA, NIST). Through a case study, we show how our community cloud architecture can be implemented along with best practices in an ophthalmology case study which includes health big data (i.e., Health Facts database, I2B2, Millennium) hosted in a campus cloud infrastructure featuring virtual desktop thin-clients and relevant Data Classification Levels in storage.",
                "call-number": "10.1145/3288599.3295594",
                "collection-title": "ICDCN '19",
                "container-title": "Proceedings of the 20th International Conference on Distributed Computing and Networking",
                "DOI": "10.1145/3288599.3295594",
                "event-place": "Bangalore, India",
                "ISBN": "9781450360944",
                "keyword": "electronic health records, big data application, smart healthcare, security standard compliance, cloud architecture",
                "number-of-pages": "4",
                "page": "377–380",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Community cloud architecture to improve use accessibility with security compliance in health big data applications",
                "URL": "https://doi.org/10.1145/3288599.3295594"
            }
        },
        {
            "10.1145/3230905.3230944": {
                "id": "10.1145/3230905.3230944",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Tajmouati",
                        "given": "Samya"
                    },
                    {
                        "family": "Abarda",
                        "given": "Abdallah"
                    },
                    {
                        "family": "El Moudden",
                        "given": "Mustapha"
                    },
                    {
                        "family": "Dakkon",
                        "given": "Mohamed"
                    },
                    {
                        "family": "Esghir",
                        "given": "Mustapha"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            2
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            2
                        ]
                    ]
                },
                "abstract": "The use of analysis and classification methods for big data is difficult. Several proposals consist in dividing randomly the population into b sub-samples and aggregating the parameters using an estimator based on the average parameters of these selected sub-samples. This paper aims to find a solution that minimizes calculations by selecting a small number b* sub-samples and keeping the same precision. We can apply this approach to the several method to measure its relevance.",
                "call-number": "10.1145/3230905.3230944",
                "collection-number": "16",
                "collection-title": "LOPAL '18",
                "container-title": "Proceedings of the International Conference on Learning and Optimization Algorithms: Theory and Applications",
                "DOI": "10.1145/3230905.3230944",
                "event-place": "Rabat, Morocco",
                "ISBN": "9781450353045",
                "keyword": "classification method, massive data, Latent class analysis",
                "number": "Article 16",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A study of the application of statistical methods for Big data",
                "URL": "https://doi.org/10.1145/3230905.3230944"
            }
        },
        {
            "10.1145/3481056.3481080": {
                "id": "10.1145/3481056.3481080",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yuxi",
                        "given": "Zhai"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            7,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            7,
                            23
                        ]
                    ]
                },
                "abstract": "Under the background of big data, the mental health education of college students is facing new challenges and opportunities. Psychological health education for college students is an educational course that integrates theoretical knowledge teaching, psychological experience and training, and is the main front for disseminating mental health knowledge. This research comprehensively expands the various data collection methods of the curriculum, and on the basis of in-depth analysis of the massive data of college students, comprehensively grasps the problems of college students' mental health. This can guide the development of targeted education and activities, and enhance the effectiveness of mental health education for college students. Taking the mental health education of college students as the research object, explore the ways of college students' mental health education under the background of big data, and build an \"online and offline\" mixed teaching model with the help of positive psychology. The purpose of this model is to stimulate the inner positive forces of students and improve the mental health education system for college students.CCS CONCEPTS • Applied computing • Education • Computer-assisted instruction",
                "call-number": "10.1145/3481056.3481080",
                "collection-title": "ICEMT 2021",
                "container-title": "2021 5th International Conference on Education and Multimedia Technology",
                "DOI": "10.1145/3481056.3481080",
                "event-place": "Kyoto, Japan",
                "ISBN": "9781450390224",
                "keyword": "Mental health education, College students, Positive psychology, Big data",
                "number-of-pages": "5",
                "page": "51–55",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Exploration in the Ways of Mental Health Education of College Students in the Context of Big Data",
                "URL": "https://doi.org/10.1145/3481056.3481080"
            }
        },
        {
            "10.14778/2367502.2367519": {
                "id": "10.14778/2367502.2367519",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Chen",
                        "given": "Yanpei"
                    },
                    {
                        "family": "Alspaugh",
                        "given": "Sara"
                    },
                    {
                        "family": "Katz",
                        "given": "Randy"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            8,
                            1
                        ]
                    ]
                },
                "abstract": "Within the past few years, organizations in diverse industries have adopted MapReduce-based systems for large-scale data processing. Along with these new users, important new workloads have emerged which feature many small, short, and increasingly interactive jobs in addition to the large, long-running batch jobs for which MapReduce was originally designed. As interactive, large-scale query processing is a strength of the RDBMS community, it is important that lessons from that field be carried over and applied where possible in this new domain. However, these new workloads have not yet been described in the literature. We fill this gap with an empirical analysis of MapReduce traces from six separate business-critical deployments inside Facebook and at Cloudera customers in e-commerce, telecommunications, media, and retail. Our key contribution is a characterization of new MapReduce workloads which are driven in part by interactive analysis, and which make heavy use of query-like programming frameworks on top of MapReduce. These workloads display diverse behaviors which invalidate prior assumptions about MapReduce such as uniform data access, regular diurnal patterns, and prevalence of large jobs. A secondary contribution is a first step towards creating a TPC-like data processing benchmark for MapReduce.",
                "call-number": "10.14778/2367502.2367519",
                "container-title": "Proc. VLDB Endow.",
                "DOI": "10.14778/2367502.2367519",
                "ISSN": "2150-8097",
                "issue": "12",
                "number-of-pages": "12",
                "page": "1802–1813",
                "publisher": "VLDB Endowment",
                "source": "August 2012",
                "title": "Interactive analytical processing in big data systems: a cross-industry study of MapReduce workloads",
                "URL": "https://doi.org/10.14778/2367502.2367519",
                "volume": "5"
            }
        },
        {
            "10.1145/3149572.3149598": {
                "id": "10.1145/3149572.3149598",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kim",
                        "given": "Tae-Hak"
                    },
                    {
                        "family": "Kim",
                        "given": "Seong-Jin"
                    },
                    {
                        "family": "Ok",
                        "given": "Hyun"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            10,
                            9
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            10,
                            9
                        ]
                    ]
                },
                "abstract": "Overloading is a major factor in the damage to road facilities such as bridges and traffic accidents, and the Ministry of Land, Transport and Maritime Affairs is in the process of fixing and moving the main points to overhaul. Moving control is more effective than stationary control, but it is possible to avoid interrupting the driver because the existing control pattern is well known along with the location of intruder by intuition. Therefore, in this study, we analyzed data such as investigation of oversight activities, existing enforcement information, and traffic volume information as an improvement measure to preemptively block intermittent vehicles. The analysis methods were analyzed to derive future delivery methods, along with analysis techniques such as logistic regression analysis and analysis methods, and methods for selecting the best possible location for selecting the routes.",
                "call-number": "10.1145/3149572.3149598",
                "collection-title": "ICIME 2017",
                "container-title": "Proceedings of the 9th International Conference on Information Management and Engineering",
                "DOI": "10.1145/3149572.3149598",
                "event-place": "Barcelona, Spain",
                "ISBN": "9781450353373",
                "keyword": "Big-Data, Cargo Vehicle Traffic, DTG, Fines imposition system, Traffic volume information system, MOLIT, Overload, Patterns",
                "number-of-pages": "5",
                "page": "55–59",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A Study on the Cargo Vehicle Traffic Patterns Analysis Using Big Data",
                "URL": "https://doi.org/10.1145/3149572.3149598"
            }
        },
        {
            "10.1145/3352740.3352748": {
                "id": "10.1145/3352740.3352748",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Min",
                        "given": "Chen"
                    },
                    {
                        "family": "Jinfen",
                        "given": "Ye"
                    },
                    {
                        "family": "Haoyu",
                        "given": "Zhu"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            6,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            6,
                            28
                        ]
                    ]
                },
                "abstract": "In modern enterprise management, more and more companies value employee performance. Performance is equivalent to the external behavior of the company for employees. Effective performance management can stimulate all aspects of employees' work and enhance corporate image. Therefore, performance management runs through the whole work of employees. It is the key to improve employees' behavior and quality.With the acceleration of China's reform, opening up and modernization drive, more and more students need to receive higher education, which is followed by the emergence of private colleges. The number of private colleges is growing and the scale is expanding, which has gradually become an important part of higher education in China. Therefore, the management of private college teachers is crucial and inevitable. In fact, the performance management of private college teachers has become a widely studied issue. How to conduct an objective, fair and effective performance appraisal of teachers in private colleges has been paid more and more attention. Based on the reflection on the performance management of private college teachers, this paper takes a typical private college A College as an example, through the form of investigation report, to analyze the status quo and problems of teachers' performance. On this basis, the current performance management of teachers in private colleges is analyzed and suggested about improvement are put forward. Finally, through the analysis of the performance management of teachers in A College, this paper summarizes the problems that should be focused on in sustainable development of China's private colleges.",
                "call-number": "10.1145/3352740.3352748",
                "collection-title": "EBDIT 2019",
                "container-title": "Proceedings of the 2019 3rd International Workshop on Education, Big Data and Information Technology",
                "DOI": "10.1145/3352740.3352748",
                "event-place": "Guilin, China",
                "ISBN": "9781450372053",
                "keyword": "teachers, performance, analysis, private colleges, current situation",
                "number-of-pages": "8",
                "page": "40–47",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "An Empirical Analysis of the Performance Management System of Private College Teachers under the Background of Big Data: Taking A College as an example",
                "URL": "https://doi.org/10.1145/3352740.3352748"
            }
        },
        {
            "10.1145/3269206.3274270": {
                "id": "10.1145/3269206.3274270",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bereta",
                        "given": "Konstantina"
                    },
                    {
                        "family": "Koubarakis",
                        "given": "Manolis"
                    },
                    {
                        "family": "Manegold",
                        "given": "Stefan"
                    },
                    {
                        "family": "Stamoulis",
                        "given": "George"
                    },
                    {
                        "family": "Demir",
                        "given": "Begüm"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            17
                        ]
                    ]
                },
                "abstract": "Some particularly important rich sources of open and free big geospatial data are the Earth observation (EO) programs of various countries such as the Landsat program of the US and the Copernicus programme of the European Union. EO data is a paradigmatic case of big data and the same is true for the big information and big knowledge extracted from it. EO data (satellite images and in-situ data), and the information and knowledge extracted from it, can be utilized in many applications with financial and environmental impact in areas such as emergency management, climate change, agriculture and security.",
                "call-number": "10.1145/3269206.3274270",
                "collection-title": "CIKM '18",
                "container-title": "Proceedings of the 27th ACM International Conference on Information and Knowledge Management",
                "DOI": "10.1145/3269206.3274270",
                "event-place": "Torino, Italy",
                "ISBN": "9781450360142",
                "keyword": "copernicus program, earth observation data, linked geospatial data, semantic web",
                "number-of-pages": "2",
                "page": "2293–2294",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "From Big Data to Big Information and Big Knowledge: the Case of Earth Observation Data",
                "URL": "https://doi.org/10.1145/3269206.3274270"
            }
        },
        {
            "10.1145/3020078.3021787": {
                "id": "10.1145/3020078.3021787",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Cong",
                        "given": "Jason"
                    },
                    {
                        "family": "Fang",
                        "given": "Zhenman"
                    },
                    {
                        "family": "Huang",
                        "given": "Muhuan"
                    },
                    {
                        "family": "Wang",
                        "given": "Libo"
                    },
                    {
                        "family": "Wu",
                        "given": "Di"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            2,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            2,
                            22
                        ]
                    ]
                },
                "abstract": "To efficiently process a tremendous amount of data, today's big data applications tend to distribute the datasets into multiple partitions, such that each partition can be fit into memory and be processed by a separate core/server in parallel. Meanwhile, due to the limited scaling of general-purpose CPUs, FPGAs have emerged as an attractive alternative to accelerate big data applications due to their low power, high performance and energy efficiency. In this paper we aim to answer one key question: How should the multicore CPU and FPGA coordinate together to optimize the performance of big data applications? To address the above question, we conduct a step-by-step case study to perform CPU and FPGA co-optimization for in-memory Samtool sorting in genomic data processing, which is one of the most important big data applications for personalized healthcare. First, to accelerate the time-consuming compression algorithm and its associated cyclic redundancy check (CRC) in Samtool sorting, we implement a portable and maintainable FPGA accelerator using high-level synthesis (HLS). Although FPGAs are traditionally well-known to be suitable for compression and CRC, we find that a straightforward integration of this FPGA accelerator into the multi-threaded Samtool sorting only achieves marginal system throughput improvement over the software baseline running on a 12-core CPU. To improve system performance, we propose a dataflow execution model to effectively orchestrate the computation between the multi-threaded CPU and FPGA. Experimental results show that our co-optimized CPU-FPGA system achieves a 2.6x speedup for in-memory Samtool sorting.",
                "call-number": "10.1145/3020078.3021787",
                "collection-title": "FPGA '17",
                "container-title": "Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays",
                "DOI": "10.1145/3020078.3021787",
                "event-place": "Monterey, California, USA",
                "ISBN": "9781450343541",
                "keyword": "compression and CRC, genome data sorting, dataflow execution",
                "number-of-pages": "1",
                "page": "291",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "CPU-FPGA Co-Optimization for Big Data Applications: A Case Study of In-Memory Samtool Sorting (Abstract Only)",
                "URL": "https://doi.org/10.1145/3020078.3021787"
            }
        },
        {
            "10.1145/2811411.2811481": {
                "id": "10.1145/2811411.2811481",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Han",
                        "given": "Youngsub"
                    },
                    {
                        "family": "Lee",
                        "given": "Hyeoncheol"
                    },
                    {
                        "family": "Kim",
                        "given": "Yanggon"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            9
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            9
                        ]
                    ]
                },
                "abstract": "A huge amount of data is being generated by social media in real time. Accordingly, demands for extracting meaningful information from the social data have been dramatically increased. However, most of the previous research encompasses potential problems with data processing, management and analysis in real time. In this paper, we propose a distributed system architecture for generating meaningful information from text-based social data. The system collects data from multi-source channels, such as Twitter, YouTube, and The New York Times. Also, the system extracts terms and sentiment from each document using data mining technologies. In addition, the system uses HDFS, Map-reduce, and message service to handle the huge data. By analyzing keywords in texts and user account information, the system generates a summary of results including terms, sentiments and data variations for further analysis, including reputation, social trends, and customer reactions. The experiment results show that our approach is able to effectively process the social data in real time.",
                "call-number": "10.1145/2811411.2811481",
                "collection-title": "RACS",
                "container-title": "Proceedings of the 2015 Conference on research in adaptive and convergent systems",
                "DOI": "10.1145/2811411.2811481",
                "event-place": "Prague, Czech Republic",
                "ISBN": "9781450337380",
                "keyword": "distributed computing, data mining, big data, sentiment analysis, crawling, message driven processing, Hadoop, natural language processing",
                "number-of-pages": "6",
                "page": "74–79",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A real-time knowledge extracting system from social big data using distributed architecture",
                "URL": "https://doi.org/10.1145/2811411.2811481"
            }
        },
        {
            "10.1145/3018896.3066908": {
                "id": "10.1145/3018896.3066908",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bounceur",
                        "given": "Ahcène"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            3,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            3,
                            22
                        ]
                    ]
                },
                "abstract": "Our world is digitized everyday and increasingly. In 2020, it is expected that over 70% of the population will live in or around cities. To guarantee a good quality of life, it is necessary to ensure fast and reliable services in all areas, in particular those which are mainly based on the use of connected objects. This is one of the cornerstones of a smart city project. It will make possible to provide close to real-time the remote monitoring of sick patients, the monitoring of the environment in order to know its evolution over time and to anticipate developments that can be harmful to health and the environment itself, and to accurately analyze the signals transmitted by the on-board sensors.To further develop domains such as eHealth or the monitoring of other networks in the context of Smart Cities, fast and reliable design tools are needed. Their objectives are to study the realizability of such networks, their behavior in terms of energy consumption, safety, cost and other reliability parameters.This keynote aims to present a new platform called CupCarbon that allows to design systems of connected objects mainly representing sensors and to prepare future deployments of large-scale IoT infrastructures for Smart cities in optimal conditions. This kind of platforms will be a part of systems in the world that will participate in the generation of Big Data.1",
                "call-number": "10.1145/3018896.3066908",
                "collection-number": "3",
                "collection-title": "ICC '17",
                "container-title": "Proceedings of the Second International Conference on Internet of things, Data and Cloud Computing",
                "DOI": "10.1145/3018896.3066908",
                "event-place": "Cambridge, United Kingdom",
                "ISBN": "9781450347747",
                "keyword": "visibility tree, interference, alpha-stable distribution, radio propagation channel, cupcarbon simulation",
                "number": "Article 3",
                "number-of-pages": "1",
                "page": "1",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "From smart-city and IoT simulation to big data generation",
                "URL": "https://doi.org/10.1145/3018896.3066908"
            }
        },
        {
            "10.1145/2791405.2791549": {
                "id": "10.1145/2791405.2791549",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sheshasaayee",
                        "given": "Ananthi"
                    },
                    {
                        "family": "Lakshmi",
                        "given": "J. V. N."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            8,
                            10
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            8,
                            10
                        ]
                    ]
                },
                "abstract": "Big Data processing is currently becoming increasingly important in modern era due to continuous growth of the amount of data generated in various fields. Architecture for Big Data usually ranges across multiple machines and clusters consisting of various sub systems. To potentially speed up the processing, a unified way of machine learning is applied on MapReduce frame work. A broadly applicable programming model MapReduce is applied on different learning algorithms belonging to machine learning family for all business decisions. This paper presents parallel implementation of various machine learning algorithms, includes K-Means, Logistic Regression implemented on top of MapReduce model.",
                "call-number": "10.1145/2791405.2791549",
                "collection-title": "WCI '15",
                "container-title": "Proceedings of the Third International Symposium on Women in Computing and Informatics",
                "DOI": "10.1145/2791405.2791549",
                "event-place": "Kochi, India",
                "ISBN": "9781450333610",
                "keyword": "Serial Implementation, MapReduce, Hadoop, Parallel Implementation, Logistic Regression",
                "number-of-pages": "5",
                "page": "635–639",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A Theoretical Model for Big Data Analytics using Machine Learning Algorithms",
                "URL": "https://doi.org/10.1145/2791405.2791549"
            }
        },
        {
            "10.1145/3507454.3507459": {
                "id": "10.1145/3507454.3507459",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Hope",
                        "given": "Lacy"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            8,
                            25
                        ]
                    ]
                },
                "abstract": "The evolution of digital tools and platforms has ushered in new possibilities for researchers, scholars, and practitioners of rhetoric and composition and adjacent fields like technical communication. These technologies change the ways we can gather, store, and use larger datasets, prompting new discussions on what big data methods look like in the field. The chapters housed in Amanda Licastro and Benjamin Miller's edited collection Composition and Big Data investigate the promises, concerns, and areas for further conversation regarding the applications of big data methods in composition-focused research.",
                "call-number": "10.1145/3507454.3507459",
                "container-title": "Commun. Des. Q. Rev",
                "DOI": "10.1145/3507454.3507459",
                "issue": "1",
                "number-of-pages": "3",
                "page": "51–53",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "March 2022",
                "title": "Review of \"Composition and Big Data edited by Amanda Licastro and Benjamin Miller,\" Licastro, A. & Miller, B. (Eds.). (2021). Composition and big data. University of Pittsburg Press.",
                "URL": "https://doi.org/10.1145/3507454.3507459",
                "volume": "10"
            }
        },
        {
            "10.1145/3498851.3498977": {
                "id": "10.1145/3498851.3498977",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Aihua"
                    },
                    {
                        "family": "Zhan",
                        "given": "Qiyuan"
                    },
                    {
                        "family": "Xu",
                        "given": "Weijia"
                    },
                    {
                        "family": "Zhang",
                        "given": "Yuejin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            12,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            12,
                            14
                        ]
                    ]
                },
                "abstract": "With the development of computer technology, large amounts of data are stored and analyzed, which provides a new perspective for analyzing social and economic problems and assisting scientific decision-making. Tourism is the main source of revenues for many cities in China, and research on the prosperity of the tourism industry is very important. Based on the electric power big data, this paper analyzed the internal connection between electricity, economy, and tourism prosperity index, and chose the electricity sales data of several industry sectors as the analysis indicators to build the new tourism prosperity index system. We made an empirical analysis using data from Chengde City, Hebei Province, and put forward relevant policy suggestions.",
                "call-number": "10.1145/3498851.3498977",
                "collection-title": "WI-IAT '21",
                "container-title": "IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology",
                "DOI": "10.1145/3498851.3498977",
                "event-place": "Melbourne, VIC, Australia",
                "ISBN": "9781450391870",
                "keyword": "Tourism Prosperity Index, Power Data, Tourist City, Composite Index",
                "number-of-pages": "6",
                "page": "347–352",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on Tourism Prosperity Index Based on the Power Big Data",
                "URL": "https://doi.org/10.1145/3498851.3498977"
            }
        },
        {
            "10.1145/2967878.2967919": {
                "id": "10.1145/2967878.2967919",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sunaina"
                    },
                    {
                        "family": "S.",
                        "given": "Sowmya Kamath"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            7,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            7,
                            6
                        ]
                    ]
                },
                "abstract": "Real time document summarization is a critical need nowadays, owing to the large volume of information available for our reading, and our inability to deal with this entirely due to limitations of time and resources. Oftentimes, information is available in multiple sources, offering multiple contexts and viewpoints on a single topic of interest. Automated multi-document summarization (MDS) techniques aim to address this problem. However, current techniques for automated MDS suffer from low precision and accuracy with reference to a given subject matter, when compared to those summaries prepared by humans and takes large time to create the summary when the input given is too huge. In this paper, we propose a hybrid MDS technique combining feature based algorithms and dynamic programming for generating a summary from multiple documents based on user provided query. Further, in real-world scenarios, Web search serves up a large number of URLs to users, and the work of making sense of these with reference to a particular query is left to the user. In this context, an efficient parallelized MDS technique based on Hadoop is also presented, for serving a concise summary of multiple Webpage contents for a given user query in reduced time duration.",
                "call-number": "10.1145/2967878.2967919",
                "collection-number": "37",
                "collection-title": "ICCCNT '16",
                "container-title": "Proceedings of the 7th International Conference on Computing Communication and Networking Technologies",
                "DOI": "10.1145/2967878.2967919",
                "event-place": "Dallas, TX, USA",
                "ISBN": "9781450341790",
                "keyword": "map-reduce, multi-document summarization, dynamic programming, natural language processing",
                "number": "Article 37",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Query-oriented Unsupervised Multi-document Summarization on Big Data",
                "URL": "https://doi.org/10.1145/2967878.2967919"
            }
        },
        {
            "10.1145/2994539.2994546": {
                "id": "10.1145/2994539.2994546",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sillaber",
                        "given": "Christian"
                    },
                    {
                        "family": "Sauerwein",
                        "given": "Clemens"
                    },
                    {
                        "family": "Mussmann",
                        "given": "Andrea"
                    },
                    {
                        "family": "Breu",
                        "given": "Ruth"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            10,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            10,
                            24
                        ]
                    ]
                },
                "abstract": "In the last couple of years, organizations have demonstrated an increased willingness to participate in threat intelligence sharing platforms. The open exchange of information and knowledge regarding threats, vulnerabilities, incidents and mitigation strategies results from the organizations' growing need to protect against today's sophisticated cyber attacks. To investigate data quality challenges that might arise in threat intelligence sharing, we conducted focus group discussions with ten expert stakeholders from security operations centers of various globally operating organizations. The study addresses several factors affecting shared threat intelligence data quality at multiple levels, including collecting, processing, sharing and storing data. As expected, the study finds that the main factors that affect shared threat intelligence data stem from the limitations and complexities associated with integrating and consolidating shared threat intelligence from different sources while ensuring the data's usefulness for an inhomogeneous group of participants.Data quality is extremely important for shared threat intelligence. As our study has shown, there are no fundamentally new data quality issues in threat intelligence sharing. However, as threat intelligence sharing is an emerging domain and a large number of threat intelligence sharing tools are currently being rushed to market, several data quality issues -- particularly related to scalability and data source integration -- deserve particular attention.",
                "call-number": "10.1145/2994539.2994546",
                "collection-title": "WISCS '16",
                "container-title": "Proceedings of the 2016 ACM on Workshop on Information Sharing and Collaborative Security",
                "DOI": "10.1145/2994539.2994546",
                "event-place": "Vienna, Austria",
                "ISBN": "9781450345651",
                "keyword": "data quality challenges, threat intelligence sharing data quality, cyber security operations center, threat intelligence data",
                "number-of-pages": "6",
                "page": "65–70",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Data Quality Challenges and Future Research Directions in Threat Intelligence Sharing Practice",
                "URL": "https://doi.org/10.1145/2994539.2994546"
            }
        },
        {
            "10.1145/2593728.2593733": {
                "id": "10.1145/2593728.2593733",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Iren",
                        "given": "Deniz"
                    },
                    {
                        "family": "Kul",
                        "given": "Gokhan"
                    },
                    {
                        "family": "Bilgen",
                        "given": "Semih"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            2
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            2
                        ]
                    ]
                },
                "abstract": "Cloud computing and crowdsourcing are growing trends in IT. Combining the strengths of both machine and human clouds within a hybrid design enables us to overcome certain problems and achieve efficiencies. In this paper we present a case in which we developed a hybrid, throw-away prototype software system to solve a big data cleaning problem in which we corrected and normalized a data set of 53,822 academic publication records. The first step in our solution consists of utilization of external DOI query web services to label the records with matching DOIs. Then we used customized string similarity calculation algorithms based on Levensthein Distance and Jaccard Index to grade the similarity between records. Finally we used crowdsourcing to identify duplicates among the residual record set consisting of similar yet not identical records. We consider this proof of concept to be successful and report that we achieved certain results that we could not have achieved by using either human or machine clouds alone.",
                "call-number": "10.1145/2593728.2593733",
                "collection-title": "CSI-SE 2014",
                "container-title": "Proceedings of the 1st International Workshop on CrowdSourcing in Software Engineering",
                "DOI": "10.1145/2593728.2593733",
                "event-place": "Hyderabad, India",
                "ISBN": "9781450328579",
                "keyword": "Crowdsourcing, Crowdservice, Cloud Computing",
                "number-of-pages": "4",
                "page": "15–18",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Utilization of synergetic human-machine clouds: a big data cleaning case",
                "URL": "https://doi.org/10.1145/2593728.2593733"
            }
        },
        {
            "10.1145/3344948.3344988": {
                "id": "10.1145/3344948.3344988",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Ali",
                        "given": "Shaukat"
                    },
                    {
                        "family": "Damiani",
                        "given": "Ferruccio"
                    },
                    {
                        "family": "Dustdar",
                        "given": "Schahram"
                    },
                    {
                        "family": "Sanseverino",
                        "given": "Marialuisa"
                    },
                    {
                        "family": "Viroli",
                        "given": "Mirko"
                    },
                    {
                        "family": "Weyns",
                        "given": "Danny"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            9,
                            9
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            9,
                            9
                        ]
                    ]
                },
                "abstract": "We advocate a novel concept of dependable intelligent edge systems (DIES) i.e., the edge systems ensuring a high degree of dependability (e.g., security, safety, and robustness) and autonomy because of their applications in critical domains. Building DIES entail a paradigm shift in architectures for acquiring, storing, and processing potentially large amounts of complex data: data management is placed at the edge between the data sources and local processing entities, with loose coupling to storage and processing services located in the cloud. As such, the literal definition of edge and intelligence is adopted, i.e., the ability to acquire and apply knowledge and skills is shifted towards the edge of the network, outside the cloud infrastructure. This paradigm shift offers flexibility, auto configuration, and auto diagnosis, but also introduces novel challenges.",
                "call-number": "10.1145/3344948.3344988",
                "collection-title": "ECSA '19",
                "container-title": "Proceedings of the 13th European Conference on Software Architecture - Volume 2",
                "DOI": "10.1145/3344948.3344988",
                "event-place": "Paris, France",
                "ISBN": "9781450371421",
                "keyword": "adaptation, formal methods, dependability",
                "number-of-pages": "4",
                "page": "177–180",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data from the cloud to the edge: the aggregate computing solution",
                "URL": "https://doi.org/10.1145/3344948.3344988"
            }
        },
        {
            "10.1145/3297662.3365807": {
                "id": "10.1145/3297662.3365807",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Shahoud",
                        "given": "Shadi"
                    },
                    {
                        "family": "Gunnarsdottir",
                        "given": "Sonja"
                    },
                    {
                        "family": "Khalloof",
                        "given": "Hatem"
                    },
                    {
                        "family": "Duepmeier",
                        "given": "Clemens"
                    },
                    {
                        "family": "Hagenmeyer",
                        "given": "Veit"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            11,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            11,
                            12
                        ]
                    ]
                },
                "abstract": "Driven by the great advance of machine learning in a wide range of application areas, the need for developing machine learning frameworks effectively as well as easily usable by novices increased dramatically. Furthermore, building machine learning models in the context of big data environments still represents a great challenge. In the present paper, we tackle these challenges by introducing a new generic framework for efficiently facilitating the training, testing, managing, storing, and retrieving of machine learning models in the context of big data. The framework makes use of a powerful big data software stack and a microservice architecture for a fully manageable and highly scalable solution. A highly configurable user interface is introduced giving the user the ability to easily train, test, and manage machine learning models. Moreover, it automatically indexes models and allows flexible exploration of them in the visual interface. The performance of the new framework is evaluated on state-of-the-arts machine learning algorithms: it is shown that storing and retrieving machine learning models as well as a respective acceptable low overhead demonstrate an efficient approach to facilitate machine learning in big data environments.",
                "call-number": "10.1145/3297662.3365807",
                "collection-title": "MEDES '19",
                "container-title": "Proceedings of the 11th International Conference on Management of Digital EcoSystems",
                "DOI": "10.1145/3297662.3365807",
                "event-place": "Limassol, Cyprus",
                "ISBN": "9781450362382",
                "keyword": "Machine Learning, Big Data, Web-based Applications, Microservice, Data Analytic",
                "number-of-pages": "8",
                "page": "80–87",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Facilitating and Managing Machine Learning and Data Analysis Tasks in Big Data Environments using Web and Microservice Technologies",
                "URL": "https://doi.org/10.1145/3297662.3365807"
            }
        },
        {
            "10.1145/3482632.3483079": {
                "id": "10.1145/3482632.3483079",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhang",
                        "given": "Xiaoyu"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            24
                        ]
                    ]
                },
                "abstract": "As a theoretical and practical subject, \"Big Data Prediction Methods and Technologies\" needs teaching reform. Based on the integrated talent training model of TOPCARES-CDIO, the teaching reform of the curriculum is probed from three aspects: teaching concept, teaching goal and teaching implementation. Finally, it will contribute to the cultivation of compound talents with excellent big data prediction methods and technical theories, strong practical ability and strong comprehensive quality.",
                "call-number": "10.1145/3482632.3483079",
                "collection-title": "ICISCAE 2021",
                "container-title": "2021 4th International Conference on Information Systems and Computer Aided Education",
                "DOI": "10.1145/3482632.3483079",
                "event-place": "Dalian, China",
                "ISBN": "9781450390255",
                "number-of-pages": "3",
                "page": "1043–1045",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data Forecasting Methods and Technology Curriculum Teaching Reform under TOPCARES-CDIO",
                "URL": "https://doi.org/10.1145/3482632.3483079"
            }
        },
        {
            "10.1145/2949550.2949556": {
                "id": "10.1145/2949550.2949556",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chiu",
                        "given": "Chui-hui"
                    },
                    {
                        "family": "Lewis",
                        "given": "Nathan"
                    },
                    {
                        "family": "Singh",
                        "given": "Dipak Kumar"
                    },
                    {
                        "family": "Das",
                        "given": "Arghya Kusum"
                    },
                    {
                        "family": "Jalazai",
                        "given": "Mohammad M."
                    },
                    {
                        "family": "Platania",
                        "given": "Richard"
                    },
                    {
                        "family": "Goswami",
                        "given": "Sayan"
                    },
                    {
                        "family": "Lee",
                        "given": "Kisung"
                    },
                    {
                        "family": "Park",
                        "given": "Seung-Jong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            7,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            7,
                            17
                        ]
                    ]
                },
                "abstract": "In recent years, big data analysis has been widely applied to many research fields including biology, physics, transportation, and material science. Even though the demands for big data migration and big data analysis are dramatically increasing in campus IT infrastructures, there are several technical challenges that need to be addressed. First of all, frequent big data transmission between storage systems in different research groups imposes heavy burdens on a regular campus network. Second, the current campus IT infrastructure is not designed to fully utilize the hardware capacity for big data migration and analysis. Last but not the least, running big data applications on top of large-scale high-performance computing facilities is not straightforward, especially for researchers and engineers in non-IT disciplines.We develop a campus IT cyberinfrastructure for big data migration and analysis, called BIC-LSU, which consists of a task-aware Clos OpenFlow network, high-performance cache storage servers, customized high-performance transfer applications, a light-weight control framework to manipulate existing big data storage systems and job scheduling systems, and a comprehensive social networking-enabled web portal. BIC-LSU achieves 40Gb/s disk-to-disk big data transmission, maintains short average transmission task completion time, enables the convergence of control on commonly deployed storage and job scheduling systems, and enhances easiness of big data analysis with a universal user-friendly interface. BIC-LSU software requires minimum dependencies and has high extensibility. Other research institutes can easily customize and deploy BIC-LSU as an augmented service on their existing IT infrastructures.",
                "call-number": "10.1145/2949550.2949556",
                "collection-number": "28",
                "collection-title": "XSEDE16",
                "container-title": "Proceedings of the XSEDE16 Conference on Diversity, Big Data, and Science at Scale",
                "DOI": "10.1145/2949550.2949556",
                "event-place": "Miami, USA",
                "ISBN": "9781450347556",
                "keyword": "solid-state drive storage server, software-defined networking, science gateway, task-aware network scheduling, Big data",
                "number": "Article 28",
                "number-of-pages": "8",
                "page": "1–8",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "BIC-LSU: Big Data Research Integration with Cyberinfrastructure for LSU",
                "URL": "https://doi.org/10.1145/2949550.2949556"
            }
        },
        {
            "10.1145/3495018.3495386": {
                "id": "10.1145/3495018.3495386",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhong",
                        "given": "Xiaoqing"
                    },
                    {
                        "family": "Fu",
                        "given": "Dandan"
                    },
                    {
                        "family": "Zhong",
                        "given": "Chongjie"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            23
                        ]
                    ]
                },
                "abstract": "In today's information technology era, computers are still a necessity of modern society. Computer data mining technology is a necessary means in the big data environment. Nowadays, in our daily life and work, Massive data and information need to be processed, especially for the financial industry, all kinds of data need to be processed by financial practitioners. How to process the data quickly and grasp the key information more quickly and accurately is the concern of many financial elites. The idea of applying computer data mining technology to financial big data has aroused the interest of many relevant people. On this basis, this paper selects a famous commercial bank as the research object to explore the influence of computer data mining technology on financial big data analysis. And from the experimental data, the data processing method optimized by computer data mining technology is more efficient, and the time spent on data processing is greatly reduced, even relatively less than 60%, up to 69%. In addition, 61% of the employees are satisfied with the optimization method, much more than half of them.",
                "call-number": "10.1145/3495018.3495386",
                "collection-title": "AIAM2021",
                "container-title": "2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture",
                "DOI": "10.1145/3495018.3495386",
                "event-place": "Manchester, United Kingdom",
                "ISBN": "9781450385046",
                "number-of-pages": "4",
                "page": "1300–1303",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Application of Financial Big Data Analysis Based on Computer Data Mining Technology",
                "URL": "https://doi.org/10.1145/3495018.3495386"
            }
        },
        {
            "10.1145/2909132.2927471": {
                "id": "10.1145/2909132.2927471",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bornschlegl",
                        "given": "Marco X."
                    },
                    {
                        "family": "Manieri",
                        "given": "Andrea"
                    },
                    {
                        "family": "Walsh",
                        "given": "Paul"
                    },
                    {
                        "family": "Catarci",
                        "given": "Tiziana"
                    },
                    {
                        "family": "Hemmje",
                        "given": "Matthias L."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            6,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            6,
                            7
                        ]
                    ]
                },
                "abstract": "Handling the complexity of relevant data requires new techniques about data access, visualization, perception, and interaction for innovative and successful strategies. In order to address human-computer interaction, cognitive eficiency, and interoperability problems, a generic information visualization, user empowerment, as well as service integration and mediation approach based on the existing state-of-the-art in the relevant areas of computer science has to be achieved.This workshop will address these issues with a special focus on supporting distributed Big Data analysis in Virtual Research Environments (VREs). In this way, the overall scope and goal of the workshop is to bring together researchers in these areas to achieve a road map, which can support the acceleration in research activities by means of transforming, enriching, and deploying advanced visual user interfaces for managing and using e-Science infrastructures. Advancements in this fields of research can i.e. support the, creation, configuration, management, and usage of distributed Big Data analysis in VREs.",
                "call-number": "10.1145/2909132.2927471",
                "collection-title": "AVI '16",
                "container-title": "Proceedings of the International Working Conference on Advanced Visual Interfaces",
                "DOI": "10.1145/2909132.2927471",
                "event-place": "Bari, Italy",
                "ISBN": "9781450341318",
                "keyword": "User Empowerment, Virtual Research Environments, Advanced Visual User Interfaces, Distributed Big Data Analysis, Information Visualization",
                "number-of-pages": "5",
                "page": "363–367",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Road Mapping Infrastructures for Advanced Visual Interfaces Supporting Big Data Applications in Virtual Research Environments",
                "URL": "https://doi.org/10.1145/2909132.2927471"
            }
        },
        {
            "10.1145/3349341.3349502": {
                "id": "10.1145/3349341.3349502",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Dai",
                        "given": "Jianhua"
                    },
                    {
                        "family": "Jin",
                        "given": "Libo"
                    },
                    {
                        "family": "Wang",
                        "given": "Xinyang"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            7,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            7,
                            12
                        ]
                    ]
                },
                "abstract": "With the popularity of the Main-melody films such as \"Wolf 2\" and \"Mekong River Action\" in 2017, \"Red Sea Action\" in 2018, a small wave of development climax of Chinese main-melody films has been set off. Film box office is an important index to measure the success of a film. The analysis and study of the factors affecting the box office of the film provides an indispensable theoretical basis for the development of the film industry. This survey selected 100 main-melody films which were the top box office films in 2013-2018 as the research data. Scores, number of commentaries, actor influence and director influence were taken as independent variables, while box office was taken as a dependent variable for correlation test and regression analysis.",
                "call-number": "10.1145/3349341.3349502",
                "collection-title": "AICS 2019",
                "container-title": "Proceedings of the 2019 International Conference on Artificial Intelligence and Computer Science",
                "DOI": "10.1145/3349341.3349502",
                "event-place": "Wuhan, Hubei, China",
                "ISBN": "9781450371506",
                "keyword": "big data, regression analysis, film box office, main-melody film",
                "number-of-pages": "4",
                "page": "741–744",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Factors Affecting the Box Office of Chinese Main-Melody Films Based on Big Data",
                "URL": "https://doi.org/10.1145/3349341.3349502"
            }
        },
        {
            "10.1145/2554688.2554694": {
                "id": "10.1145/2554688.2554694",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Wang",
                        "given": "Chao"
                    },
                    {
                        "family": "Li",
                        "given": "Xi"
                    },
                    {
                        "family": "Zhou",
                        "given": "Xuehai"
                    },
                    {
                        "family": "Chen",
                        "given": "Yunji"
                    },
                    {
                        "family": "Cheung",
                        "given": "Ray C.C."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            2,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            2,
                            26
                        ]
                    ]
                },
                "abstract": "Next-generation sequencing (NGS) problems have attracted many attentions of researchers in biological and medical computing domains. The current state-of-the-art NGS computing machines are dramatically lowering the cost and increasing the throughput of DNA sequencing. In this paper, we propose a practical study that uses Xilinx Zynq board to summarize acceleration engines using FPGA accelerators and ARM processors for the state-of-the-art short read mapping approaches. The heterogeneous processors and accelerators are coupled with each other using a general Hadoop distributed processing framework. First the reads are collected by the central server, and then distributed to multiple accelerators on the Zynq for hardware acceleration. Therefore, the combination of hardware acceleration and Map-Reduce execution flow could greatly accelerate the task of aligning short length reads to a known reference genome. Our approach is based on preprocessing the reference genomes and iterative jobs for aligning the continuous incoming reads. The hardware acceleration is based on the creditable read-mapping algorithm RMAP software approach. Furthermore, the speedup analysis on a Hadoop cluster, which concludes 8 development boards, is evaluated. Experimental results demonstrate that our proposed architecture and methods has the speedup of more than 112X, and is scalable with the number of accelerators. Finally, the Zynq based cluster has efficient potential to accelerate even general large scale big data applications.This work was supported by the NSFC grants No. 61379040, No. 61272131 and No. 61202053.",
                "call-number": "10.1145/2554688.2554694",
                "collection-title": "FPGA '14",
                "container-title": "Proceedings of the 2014 ACM/SIGDA international symposium on Field-programmable gate arrays",
                "DOI": "10.1145/2554688.2554694",
                "event-place": "Monterey, California, USA",
                "ISBN": "9781450326711",
                "keyword": "hardware acceleration., genome sequencing, fpga, rmap, bioinformatics",
                "number-of-pages": "1",
                "page": "247",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data genome sequencing on Zynq based clusters (abstract only)",
                "URL": "https://doi.org/10.1145/2554688.2554694"
            }
        },
        {
            "10.1145/2695664.2695753": {
                "id": "10.1145/2695664.2695753",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Nascimento",
                        "given": "Dimas C."
                    },
                    {
                        "family": "Pires",
                        "given": "Carlos Eduardo"
                    },
                    {
                        "family": "Mestre",
                        "given": "Demetrio Gomes"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            4,
                            13
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            4,
                            13
                        ]
                    ]
                },
                "abstract": "Cloud Computing as a service has become a topic of increasing interest. The outsourcing of duties and infrastructure to external parties became a crucial concept for many business models. In this paper we discuss the design and experimental evaluation of provisioning algorithms, in a Data Quality-aware Service (DQaS) context, that enables dynamic Data Quality Service Level Agreements (DQSLA) management and optimization of cloud resources. The DQaS has been designed to respond effectively to the DQSLA requirements of the service customers, by minimizing SLA penalties and provisioning the cloud infrastructure for the execution of data quality algorithms. An experimental evaluation of the proposed provisioning algorithms, carried out through simulation, has provided very encouraging results that confirm the adequacy of these algorithms in the DQaS context.",
                "call-number": "10.1145/2695664.2695753",
                "collection-title": "SAC '15",
                "container-title": "Proceedings of the 30th Annual ACM Symposium on Applied Computing",
                "DOI": "10.1145/2695664.2695753",
                "event-place": "Salamanca, Spain",
                "ISBN": "9781450331968",
                "keyword": "machine learning, data quality, cloud computing, provisioning, metaheuristic",
                "number-of-pages": "8",
                "page": "1696–1703",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A data quality-aware cloud service based on metaheuristic and machine learning provisioning algorithms",
                "URL": "https://doi.org/10.1145/2695664.2695753"
            }
        },
        {
            "10.1145/3561202": {
                "id": "10.1145/3561202",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Firmani",
                        "given": "Donatella"
                    },
                    {
                        "family": "Tanca",
                        "given": "Letizia"
                    },
                    {
                        "family": "Torlone",
                        "given": "Riccardo"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            8,
                            30
                        ]
                    ]
                },
                "abstract": "This editorial summarizes the content of the Special Issue on Data Quality and Ethics of the Journal of Data and Information Quality (JDIQ). The issue accepted submissions from June 1 to July 30, 2021.",
                "call-number": "10.1145/3561202",
                "container-title": "J. Data and Information Quality",
                "DOI": "10.1145/3561202",
                "ISSN": "1936-1955",
                "note": "Just Accepted",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Editorial: Special Issue on Data Quality and Ethics",
                "URL": "https://doi.org/10.1145/3561202"
            }
        },
        {
            "10.1145/3428502.3428515": {
                "id": "10.1145/3428502.3428515",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Lue"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            9,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            9,
                            23
                        ]
                    ]
                },
                "abstract": "Macao is a tourist city. When the COVID-19 epidemic occurred, Macao's risks and pressures were enormous. However, the response policies of the Government are timely and effective, making Macao one of the lightest epidemic regions in the world. This article reviewed the SAR government's anti-epidemic policies, and found four most important policies all based on the E-government technology and the implementation of big data: 1. Quickly screen, restrict and isolate tourists from the affected areas; 2. Supply masks; 3. Accurate collection, in-depth analysis and rapid release of information; 4. Electronic consumer card.",
                "call-number": "10.1145/3428502.3428515",
                "collection-title": "ICEGOV 2020",
                "container-title": "Proceedings of the 13th International Conference on Theory and Practice of Electronic Governance",
                "DOI": "10.1145/3428502.3428515",
                "event-place": "Athens, Greece",
                "ISBN": "9781450376747",
                "keyword": "Public Health Crisis, Big data, COVID-19 Epidemic, Special Webpage against Epidemics, E-government",
                "number-of-pages": "4",
                "page": "112–115",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Macao government fights the COVID-19 epidemics with the help of e-Government and big data",
                "URL": "https://doi.org/10.1145/3428502.3428515"
            }
        },
        {
            "10.1145/2378016.2378018": {
                "id": "10.1145/2378016.2378018",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Collins",
                        "given": "Claire"
                    },
                    {
                        "family": "Janssens",
                        "given": "Kelly"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            10,
                            1
                        ]
                    ]
                },
                "abstract": "In Ireland, while detailed information is available regarding hospital attendance, little is known regarding general (family) practice attendance. However, it is conservatively estimated that there are almost nine times as many general practice encounters than there are hospital encounters each year in Ireland. This represents a very significant gap in health information. Indeed, general practice has been shown in other countries to be an important and rich source of information about the health of the population, their behaviors and their utilization of health services. Funded by the Health Information and Quality Authority (HIQA), the Irish College of General Practitioners (ICGP) undertook a feasibility study of diagnostic coding of routinely entered patient data and the creation of a national general practice morbidity and epidemiological database (GPMED project). This article outlines the process of data quality issue management undertaken.The study’s findings suggest that the quality of data collection and reporting structures available in general practice throughout Ireland at the outset of this project were not adequate to permit the creation of a database of sufficient quality for service planning and policy or epidemiological research. Challenges include the dearth of a minimum standard of data recorded in consultations by GPs and the absence of the digital data recording and exporting infrastructure within Irish patient management software systems. In addition, there is at present a lack of recognition regarding the value of such data for patient management and service planning---including importantly, data collectors who do not fully accept the merit of maintaining data, which has a direct consequence for data quality. The work of this project has substantial implications for the data available to the health sector in Ireland and contributes to the knowledge base internationally regarding general practice morbidity data.",
                "call-number": "10.1145/2378016.2378018",
                "collection-number": "2",
                "container-title": "J. Data and Information Quality",
                "DOI": "10.1145/2378016.2378018",
                "ISSN": "1936-1955",
                "issue": "1",
                "keyword": "family practice, Data quality, epidemiology",
                "number": "Article 2",
                "number-of-pages": "9",
                "page": "1–9",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "October 2012",
                "title": "Creating a General (Family) Practice Epidemiological Database in Ireland - Data Quality Issue Management",
                "URL": "https://doi.org/10.1145/2378016.2378018",
                "volume": "4"
            }
        },
        {
            "10.1145/1966901.1966903": {
                "id": "10.1145/1966901.1966903",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Fürber",
                        "given": "Christian"
                    },
                    {
                        "family": "Hepp",
                        "given": "Martin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2011,
                            3,
                            25
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2011,
                            3,
                            25
                        ]
                    ]
                },
                "abstract": "Reliable decision-making and reliable information based on Semantic Web data requires methodologies and techniques for managing the quality of the published data. To make things more complicated, the judgment of what is \"good\" data will often depend on the task at hand or the subjective requirements of data owners or data consumers. Some data quality requirements can be modeled using data quality rules, i.e. executable definitions that allow the identification and measurement of data quality problems. In this paper, we provide a conceptual model that allows the representation of such rules and other quality-related knowledge using the Resource Description Framework (RDF) and the Web Ontology Language (OWL). Based on our model, it is possible to monitor and assess the quality of data sources and to automate data cleansing tasks. The use of a generic conceptual model based on Semantic Web formalisms supports the definition of reusable, broadly applicable SPARQL queries and portable applications for data quality management (DQM). Furthermore, the explicit representation of rules in RDF/OWL facilitates rule management tasks, e.g. for analyzing consistency among the rules, and allows to collaborate and create a shared understanding.",
                "call-number": "10.1145/1966901.1966903",
                "collection-title": "LWDM '11",
                "container-title": "Proceedings of the 1st International Workshop on Linked Web Data Management",
                "DOI": "10.1145/1966901.1966903",
                "event-place": "Uppsala, Sweden",
                "ISBN": "9781450306089",
                "keyword": "data quality management, SPARQL, semantic web, knowledge representation, information quality, ontology, trust, linked data management",
                "number-of-pages": "8",
                "page": "1–8",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Towards a vocabulary for data quality management in semantic web architectures",
                "URL": "https://doi.org/10.1145/1966901.1966903"
            }
        },
        {
            "10.1145/3472456.3472488": {
                "id": "10.1145/3472456.3472488",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Wu",
                        "given": "Yuewen"
                    },
                    {
                        "family": "Wu",
                        "given": "Heng"
                    },
                    {
                        "family": "Xu",
                        "given": "Yuanjia"
                    },
                    {
                        "family": "Hu",
                        "given": "Yi"
                    },
                    {
                        "family": "Zhang",
                        "given": "Wenbo"
                    },
                    {
                        "family": "Zhong",
                        "given": "Hua"
                    },
                    {
                        "family": "Huang",
                        "given": "Tao"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            8,
                            9
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            8,
                            9
                        ]
                    ]
                },
                "abstract": "Cloud providers are presented with a bewildering choice of VM types for a range of contemporary data processing frameworks today. However, existing performance modeling and machine learning efforts cannot pick optimal VM types for multiple frameworks simultaneously, since they are difficult to balance model accuracy and model training cost. We propose Vesta, a novel transfer learning approach, to address this challenge: (1) it abstracts knowledge of VM type selection through offline benchmarking on multiple frameworks; (2) it employs a two-layer bipartite graph to represent knowledge across frameworks; (3) it minimizes training overhead by reus-ing the knowledge to select the best VM type for given applications. Comparing with state-of-the-art efforts, our experiments on 30 applications of Hadoop, Hive and Spark show that  Vesta can improve application performance up to 51% while reducing 85% training overhead.",
                "call-number": "10.1145/3472456.3472488",
                "collection-number": "85",
                "collection-title": "ICPP 2021",
                "container-title": "50th International Conference on Parallel Processing",
                "DOI": "10.1145/3472456.3472488",
                "event-place": "Lemont, IL, USA",
                "ISBN": "9781450390682",
                "keyword": "big data application, virtual machine, transfer learning, multiple frameworks",
                "number": "Article 85",
                "number-of-pages": "11",
                "page": "1–11",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Best VM Selection for Big Data Applications across Multiple Frameworks by Transfer Learning",
                "URL": "https://doi.org/10.1145/3472456.3472488"
            }
        },
        {
            "10.5555/2755753.2757169": {
                "id": "10.5555/2755753.2757169",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kanoun",
                        "given": "Karim"
                    },
                    {
                        "family": "van der Schaar",
                        "given": "Mihaela"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            3,
                            9
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            3,
                            9
                        ]
                    ]
                },
                "abstract": "Several techniques have been proposed to adapt Big-Data streaming applications to resource constraints. These techniques are mostly implemented at the application layer and make simplistic assumptions about the system resources and they are often agnostic to the system capabilities. Moreover, they often assume that the data streams characteristics and their processing needs are stationary, which is not true in practice. In fact, data streams are highly dynamic and may also experience concept drift, thereby requiring continuous online adaptation of the throughput and quality to each processing task. Hence, existing solutions for Big-Data streaming applications are often too conservative or too aggressive. To address these limitations, we propose an online energy-efficient scheduler which maximizes the QoS (i.e., throughput and output quality) of Big-Data streaming applications under energy and resources constraints. Our scheduler uses online adaptive reinforcement learning techniques and requires no offline information. Moreover, our scheduler is able to detect concept drifts and to smoothly adapt the scheduling strategy. Our experiments realized on a chain of tasks modeling real-life streaming application demonstrate that our scheduler is able to learn the scheduling policy and to adapt it such that it maximizes the targeted QoS given energy constraint as the Big-Data characteristics are dynamically changing.",
                "call-number": "10.5555/2755753.2757169",
                "collection-title": "DATE '15",
                "container-title": "Proceedings of the 2015 Design, Automation & Test in Europe Conference & Exhibition",
                "event-place": "Grenoble, France",
                "ISBN": "9783981537048",
                "number-of-pages": "4",
                "page": "1547–1550",
                "publisher": "EDA Consortium",
                "publisher-place": "San Jose, CA, USA",
                "title": "Big-data streaming applications scheduling with online learning and concept drift detection"
            }
        },
        {
            "10.1145/3167132.3167376": {
                "id": "10.1145/3167132.3167376",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bellaaj",
                        "given": "Hatem"
                    },
                    {
                        "family": "Mdhaffar",
                        "given": "Afef"
                    },
                    {
                        "family": "Jmaiel",
                        "given": "Mohamed"
                    },
                    {
                        "family": "Mseddi",
                        "given": "Sondes Hdiji"
                    },
                    {
                        "family": "Freisleben",
                        "given": "Bernd"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            4,
                            9
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            4,
                            9
                        ]
                    ]
                },
                "abstract": "The purpose of disease registries is to collect and analyze data related to specific diseases in terms of incidence and prevalence. Since the data is typically entered by wearable sensors and/or human caregivers, errors in the data fields are often inevitable. In this paper, we propose a new approach to improve data quality in disease registries based on (a) a semi-random combination of parameters and (b) a learning algorithm for detecting and signaling the loss of quality of the entered data. To implement the approach, we have developed a novel adaptive neuro-fuzzy inference system. It is applied to specific sections of the Tunisian Fanconi Anemia Registry with the aims of reducing false alarms and automatically adjusting the parameters of coefficients of the disease. Our experimental results indicate that both aims can be achieved and effectively lead to improved data quality in disease registries.",
                "call-number": "10.1145/3167132.3167376",
                "collection-title": "SAC '18",
                "container-title": "Proceedings of the 33rd Annual ACM Symposium on Applied Computing",
                "DOI": "10.1145/3167132.3167376",
                "event-place": "Pau, France",
                "ISBN": "9781450351911",
                "keyword": "disease registry, data quality, fuzzy logic, ANFIS",
                "number-of-pages": "4",
                "page": "30–33",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "An adaptive neuro-fuzzy inference system for improving data quality in disease registries",
                "URL": "https://doi.org/10.1145/3167132.3167376"
            }
        },
        {
            "10.1145/2967938.2967944": {
                "id": "10.1145/2967938.2967944",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Song",
                        "given": "Mingcong"
                    },
                    {
                        "family": "Hu",
                        "given": "Yang"
                    },
                    {
                        "family": "Xu",
                        "given": "Yunlong"
                    },
                    {
                        "family": "Li",
                        "given": "Chao"
                    },
                    {
                        "family": "Chen",
                        "given": "Huixiang"
                    },
                    {
                        "family": "Yuan",
                        "given": "Jingling"
                    },
                    {
                        "family": "Li",
                        "given": "Tao"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            9,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            9,
                            11
                        ]
                    ]
                },
                "abstract": "Convolutional Neural Networks (CNNs) have substantially advanced the state-of-the-art accuracies of object recognition, which is the core function of a myriad of modern multimedia processing techniques such as image/video processing, speech recognition, and natural language processing. GPU-based accelerators gained increasing attention because a large amount of highly parallel neurons in CNN naturally matches the GPU computation pattern. In this work, we perform comprehensive experiments to investigate the performance bottlenecks and overheads of current GPU acceleration platform for scale-out CNN-based big data processing.In our characterization, we observe two significant semantic gaps: framework gap that lies between CNN-based data processing workflow and data processing manner in distributed framework; and the standalone gap that lies between the uneven computation loads at different CNN layers and fixed computing capacity provisioning of current GPU acceleration library. To bridge these gaps, we propose D3NN, a Distributed, Decoupled, and Dynamically tuned GPU acceleration framework for modern CNN architectures. In particular, D3NN features a novel analytical model that enables accurate time estimation of GPU accelerated CNN processing with only 5-10% error. Our evaluation results show the throughput of standalone processing node using D3NN gains up to 3.7X performance improvement over current standalone GPU acceleration platform. Our CNN-oriented GPU acceleration library with built-in dynamic batching scheme achieves up to 1.5X performance improvement over the non-batching scheme and outperforms the state-of-the-art deep learning library by up to 28% (performance mode) ~ 67% (memory-efficient mode).",
                "call-number": "10.1145/2967938.2967944",
                "collection-title": "PACT '16",
                "container-title": "Proceedings of the 2016 International Conference on Parallel Architectures and Compilation",
                "DOI": "10.1145/2967938.2967944",
                "event-place": "Haifa, Israel",
                "ISBN": "9781450341219",
                "keyword": "deep learning, gpu, big data, distributed system",
                "number-of-pages": "12",
                "page": "315–326",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Bridging the Semantic Gaps of GPU Acceleration for Scale-out CNN-based Big Data Processing: Think Big, See Small",
                "URL": "https://doi.org/10.1145/2967938.2967944"
            }
        },
        {
            "10.1145/3482632.3483176": {
                "id": "10.1145/3482632.3483176",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhou",
                        "given": "Ming"
                    },
                    {
                        "family": "Ye",
                        "given": "Liaokun"
                    },
                    {
                        "family": "He",
                        "given": "Chaohu"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            24
                        ]
                    ]
                },
                "abstract": "This paper aims to construct a competency model based on the sum of a series of competency characteristics required by PEICAU (physical education in collage and universities) under the background of big data, and use this model to predict the performance of the competency model of PEICAU. After one semester of training, the work performance of the experimental group and the control group was investigated. The results of statistical analysis showed that the average score of the experimental group was higher than that of the control group in terms of overall work performance, and there was a significant difference at the level of 0.01. In terms of learning performance, the mean score of the experimental group was higher than that of the control group, and the difference was significant at the level of 0.001. Experimental results show that, by setting the different training contents, physical education teachers through training, there are obvious differences in enhancing performance, based on PE teachers' competence characteristics model of training the effect is higher than that of traditional physical education teacher training effect of these measures, the PE teachers' work characteristic model of performance predictive power got a further test by experiment.",
                "call-number": "10.1145/3482632.3483176",
                "collection-title": "ICISCAE 2021",
                "container-title": "2021 4th International Conference on Information Systems and Computer Aided Education",
                "DOI": "10.1145/3482632.3483176",
                "event-place": "Dalian, China",
                "ISBN": "9781450390255",
                "number-of-pages": "4",
                "page": "1472–1475",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Competency Model of College PHYSICAL Education Teachers based on Big Data",
                "URL": "https://doi.org/10.1145/3482632.3483176"
            }
        },
        {
            "10.1145/3467707.3467730": {
                "id": "10.1145/3467707.3467730",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Yue"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            4,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            4,
                            23
                        ]
                    ]
                },
                "abstract": "HDFS has been widely used by many video service websites, but its load balancing tool does not consider the bandwidth consumption characteristics of video file online playback and the heterogeneous performance difference of NameNode in metadata allocation problem. The dynamic load imbalance of cluster makes the utilization of bandwidth resources low. In this paper, a HDFS NameNode dynamic load balancing tool (NDLBT) for city monitoring video in urban surveillance video big data storage in cloud storage environment is proposed. method. Firstly, it analyzes the relationship between the bandwidth consumption and the bit rate, data block size and access heat of the video file when the video file is played online, and a new load evaluation model is established. On this basis, it adds consideration to the bandwidth consumption factor in the load scheme generation and load scheduling, and through the dynamic adaptive backup of multi-replica heterogeneous nodes of metadata. The dynamic distribution of metadata is realized under the consideration of node performance and load, and the performance of metadata server cluster is guaranteed. Finally, combined with cache strategy and automatic recovery mechanism, the reading and writing of metadata is improved. The simulation results show that compared with the proposed method, we can effectively avoid the aggregation of high bandwidth consumption data blocks. In the experimental scenario where high bandwidth consumption video files are used as service access hotspots, the proposed method is superior to the original load balancing method in 90% scenarios, and can reduce the bandwidth peak value of bottleneck nodes in data node clusters by 20%.",
                "call-number": "10.1145/3467707.3467730",
                "collection-title": "ICCAI 2021",
                "container-title": "2021 7th International Conference on Computing and Artificial Intelligence",
                "DOI": "10.1145/3467707.3467730",
                "event-place": "Tianjin, China",
                "ISBN": "9781450389501",
                "keyword": "Cloud storage, urban surveillance video, big data storage, metadata management, HDFS, dynamic load balancing",
                "number-of-pages": "8",
                "page": "160–167",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Dynamic Load Balancing Method for Urban Surveillance Video Big Data Storage Based on HDFS",
                "URL": "https://doi.org/10.1145/3467707.3467730"
            }
        },
        {
            "10.1145/3482632.3483009": {
                "id": "10.1145/3482632.3483009",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yuan",
                        "given": "Meijuan"
                    },
                    {
                        "family": "Yan",
                        "given": "Fei"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            24
                        ]
                    ]
                },
                "abstract": "Informatization is an important step in the development of colleges and universities and an important part of the modernization of education management. In the process of promoting education management informatization, the regional differences in Chinese universities are obvious. Under the background of big data era, informatization has become the inevitable trend of teaching management development. Under this trend, in order to meet the learning needs of students, this paper uses big data technology as an advanced tool to build the information teaching management system, analyze the development situation of universities and abroad, review the literature, investigate 5 universities in a province, analyze the development situation, understand the problems, summarize the development, and conclude the transformation of education management is very necessary.",
                "call-number": "10.1145/3482632.3483009",
                "collection-title": "ICISCAE 2021",
                "container-title": "2021 4th International Conference on Information Systems and Computer Aided Education",
                "DOI": "10.1145/3482632.3483009",
                "event-place": "Dalian, China",
                "ISBN": "9781450390255",
                "number-of-pages": "5",
                "page": "749–753",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Information Transformation of Teaching Management System Based on Big Data Investigation Technology",
                "URL": "https://doi.org/10.1145/3482632.3483009"
            }
        },
        {
            "10.5555/2486788.2486842": {
                "id": "10.5555/2486788.2486842",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Shang",
                        "given": "Weiyi"
                    },
                    {
                        "family": "Jiang",
                        "given": "Zhen Ming"
                    },
                    {
                        "family": "Hemmati",
                        "given": "Hadi"
                    },
                    {
                        "family": "Adams",
                        "given": "Bram"
                    },
                    {
                        "family": "Hassan",
                        "given": "Ahmed E."
                    },
                    {
                        "family": "Martin",
                        "given": "Patrick"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            5,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            5,
                            18
                        ]
                    ]
                },
                "abstract": "Big data analytics is the process of examining large amounts of data (big data) in an effort to uncover hidden patterns or unknown correlations. Big Data Analytics Applications (BDA Apps) are a new type of software applications, which analyze big data using massive parallel processing frameworks (e.g., Hadoop). Developers of such applications typically develop them using a small sample of data in a pseudo-cloud environment. Afterwards, they deploy the applications in a large-scale cloud environment with considerably more processing power and larger input data (reminiscent of the mainframe days). Working with BDA App developers in industry over the past three years, we noticed that the runtime analysis and debugging of such applications in the deployment phase cannot be easily addressed by traditional monitoring and debugging approaches. In this paper, as a first step in assisting developers of BDA Apps for cloud deployments, we propose a lightweight approach for uncovering differences between pseudo and large-scale cloud deployments. Our approach makes use of the readily-available yet rarely used execution logs from these platforms. Our approach abstracts the execution logs, recovers the execution sequences, and compares the sequences between the pseudo and cloud deployments. Through a case study on three representative Hadoop-based BDA Apps, we show that our approach can rapidly direct the attention of BDA App developers to the major differences between the two deployments. Knowledge of such differences is essential in verifying BDA Apps when analyzing big data in the cloud. Using injected deployment faults, we show that our approach not only significantly reduces the deployment verification effort, but also provides very few false positives when identifying deployment failures.",
                "call-number": "10.5555/2486788.2486842",
                "collection-title": "ICSE '13",
                "container-title": "Proceedings of the 2013 International Conference on Software Engineering",
                "event-place": "San Francisco, CA, USA",
                "ISBN": "9781467330763",
                "number-of-pages": "10",
                "page": "402–411",
                "publisher": "IEEE Press",
                "title": "Assisting developers of big data analytics applications when deploying on hadoop clouds"
            }
        },
        {
            "10.1145/3495018.3501140": {
                "id": "10.1145/3495018.3501140",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Bin"
                    },
                    {
                        "family": "Zhou",
                        "given": "Zhisheng"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            23
                        ]
                    ]
                },
                "abstract": "In the development of e-commerce, Haiquan data gradually exerts its commercial value. Whether this value can be fully mined depends on the way of data mining and data utilization. Aiming at the background of massive big data demand, a personalized recommendation engine model based on collaborative filtering and content-based combined recommendation algorithms is proposed, and hot recommendation based on text similarity is tentatively incorporated. This model is proposed for the problems faced by big data recommendation. It includes two main modules: offline data calculation and online recommendation. Finally, a simulation experiment was carried out through the real data set of a certain domestic e-commerce and the Movie Lens data set to demonstrate the rationality of the improvement.",
                "call-number": "10.1145/3495018.3501140",
                "collection-title": "AIAM2021",
                "container-title": "2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture",
                "DOI": "10.1145/3495018.3501140",
                "event-place": "Manchester, United Kingdom",
                "ISBN": "9781450385046",
                "number-of-pages": "4",
                "page": "2564–2567",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Application of Recommendation Algorithm in Electronic Commerce through Computer Big Data Technology",
                "URL": "https://doi.org/10.1145/3495018.3501140"
            }
        },
        {
            "10.1145/3486611.3491139": {
                "id": "10.1145/3486611.3491139",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Dong",
                        "given": "Bing"
                    },
                    {
                        "family": "Markovic",
                        "given": "Romana"
                    },
                    {
                        "family": "Carlucci",
                        "given": "Salvatore"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            11,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            11,
                            17
                        ]
                    ]
                },
                "abstract": "The proliferation of urban sensing, IoT, and big data in buildings, cities, and urban areas provides unprecedented opportunities for a deeper understanding of occupant behavior, transportation, and energy and water usage patterns. However, utilizing the existing data sources and modeling methods in building science to model urban scale occupant behaviors can be pretty challenging. Therefore, technological progress is needed to unlock its full potential. In order to fulfill the latter task, this workshop focuses on the methodologies for big urban and building data collection, analytics, modeling, and real-world technology deployment. The workshop aims to open discussion on the current challenges of big data in smart buildings and cities.",
                "call-number": "10.1145/3486611.3491139",
                "collection-title": "BuildSys '21",
                "container-title": "Proceedings of the 8th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation",
                "DOI": "10.1145/3486611.3491139",
                "event-place": "Coimbra, Portugal",
                "ISBN": "9781450391146",
                "keyword": "digital cities, smart buildings, machine learning, big data analysis, modeling and prediction, occupant behavior",
                "number-of-pages": "3",
                "page": "338–340",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The 1st ACM international workshop on big data and machine learning for smart buildings and cities",
                "URL": "https://doi.org/10.1145/3486611.3491139"
            }
        },
        {
            "10.1145/3348445.3348479": {
                "id": "10.1145/3348445.3348479",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Puarungroj",
                        "given": "Wichai"
                    },
                    {
                        "family": "Phromkhot",
                        "given": "Suchada"
                    },
                    {
                        "family": "Boonsirisumpun",
                        "given": "Narong"
                    },
                    {
                        "family": "Pongpatrakant",
                        "given": "Pathapong"
                    },
                    {
                        "family": "Sangpradid",
                        "given": "Satith"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            7,
                            27
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            7,
                            27
                        ]
                    ]
                },
                "abstract": "The government agencies require decision support information before commencing their community development projects in rural areas. However, such information is not always available or does not meet their requirements. This research presents the design and development of the WebGIS, which is intended to store and provide spatially related household information for government agencies. This research has been conducted as a part of a provincial big data project. In this research, the spatial database system and the data visualization of the database were designed and developed by focusing on the details of each house in the targeted villages. The data were collected by the researchers from the study areas, which comprised 5 villages in Loei and Khonkaen Provinces in Thailand. The important household and location data were collected and combined with the community data from the Community Development Office. The GIS was developed using QGIS where the geolocation of each house in the villages was applied on the map derived from Google map. The data were analyzed and visualized in different formats such as color, table, and graph in order to establish the data classification and summarization. The system and data were finally evaluated by the Community Development Office and community leaders in terms of system performance and data accuracy.",
                "call-number": "10.1145/3348445.3348479",
                "collection-title": "ICCCM 2019",
                "container-title": "Proceedings of the 2019 7th International Conference on Computer and Communications Management",
                "DOI": "10.1145/3348445.3348479",
                "event-place": "Bangkok, Thailand",
                "ISBN": "9781450371957",
                "keyword": "Spatial database, Village improvement, WebGIS, Geographic information systems, Community development",
                "number-of-pages": "4",
                "page": "115–118",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "WebGIS for Managing Household Data within a Provincial Big Data Project",
                "URL": "https://doi.org/10.1145/3348445.3348479"
            }
        },
        {
            "10.1145/3318464.3380584": {
                "id": "10.1145/3318464.3380584",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Siddiqui",
                        "given": "Tarique"
                    },
                    {
                        "family": "Jindal",
                        "given": "Alekh"
                    },
                    {
                        "family": "Qiao",
                        "given": "Shi"
                    },
                    {
                        "family": "Patel",
                        "given": "Hiren"
                    },
                    {
                        "family": "Le",
                        "given": "Wangchao"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            6,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            6,
                            11
                        ]
                    ]
                },
                "abstract": "Query processing over big data is ubiquitous in modern clouds, where the system takes care of picking both the physical query execution plans and the resources needed to run those plans, using a cost-based query optimizer. A good cost model, therefore, is akin to better resource efficiency and lower operational costs. Unfortunately, the production workloads at Microsoft show that costs are very complex to model for big data systems. In this work, we investigate two key questions: (i) can we learn accurate cost models for big data systems, and (ii) can we integrate the learned models within the query optimizer. To answer these, we make three core contributions. First, we exploit workload patterns to learn a large number of individual cost models and combine them to achieve high accuracy and coverage over a long period. Second, we propose extensions to Cascades framework to pick optimal resources, i.e, number of containers, during query planning. And third, we integrate the learned cost models within the Cascade-style query optimizer of SCOPE at Microsoft. We evaluate the resulting system, Cleo, in a production environment using both production and TPC-H workloads. Our results show that the learned cost models are 2 to 3 orders of magnitude more accurate, and 20X more correlated with the actual runtimes, with a large majority (70%) of the plan changes leading to substantial improvements in latency as well as resource usage.",
                "call-number": "10.1145/3318464.3380584",
                "collection-title": "SIGMOD '20",
                "container-title": "Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data",
                "DOI": "10.1145/3318464.3380584",
                "event-place": "Portland, OR, USA",
                "ISBN": "9781450367356",
                "keyword": "resource optimization, query optimization, machine learning, cost models",
                "number-of-pages": "15",
                "page": "99–113",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Cost Models for Big Data Query Processing: Learning, Retrofitting, and Our Findings",
                "URL": "https://doi.org/10.1145/3318464.3380584"
            }
        },
        {
            "10.1145/291469.291471": {
                "id": "10.1145/291469.291471",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Ballou",
                        "given": "Donald P."
                    },
                    {
                        "family": "Tayi",
                        "given": "Giri Kumar"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            1999,
                            1,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/291469.291471",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/291469.291471",
                "ISSN": "0001-0782",
                "issue": "1",
                "number-of-pages": "6",
                "page": "73–78",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "Jan. 1999",
                "title": "Enhancing data quality in data warehouse environments",
                "URL": "https://doi.org/10.1145/291469.291471",
                "volume": "42"
            }
        },
        {
            "10.1145/269012.269024": {
                "id": "10.1145/269012.269024",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Kaplan",
                        "given": "David"
                    },
                    {
                        "family": "Krishnan",
                        "given": "Ramayya"
                    },
                    {
                        "family": "Padman",
                        "given": "Rema"
                    },
                    {
                        "family": "Peters",
                        "given": "James"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            1998,
                            2,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/269012.269024",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/269012.269024",
                "ISSN": "0001-0782",
                "issue": "2",
                "number-of-pages": "7",
                "page": "72–78",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "Feb. 1998",
                "title": "Assessing data quality in accounting information systems",
                "URL": "https://doi.org/10.1145/269012.269024",
                "volume": "41"
            }
        },
        {
            "10.1145/3363542.3363548": {
                "id": "10.1145/3363542.3363548",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Ng",
                        "given": "T. S. Eugene"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            19
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            19
                        ]
                    ]
                },
                "call-number": "10.1145/3363542.3363548",
                "collection-number": "6",
                "collection-title": "OptSys '19",
                "container-title": "Proceedings of the ACM SIGCOMM 2019 Workshop on Optical Systems Design",
                "DOI": "10.1145/3363542.3363548",
                "event-place": "Beijing, China",
                "ISBN": "9781450368780",
                "number": "Article 6",
                "number-of-pages": "1",
                "page": "1",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data and optical lightpaths driven data center network",
                "URL": "https://doi.org/10.1145/3363542.3363548"
            }
        },
        {
            "10.1145/3254549": {
                "id": "10.1145/3254549",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kalyanaraman",
                        "given": "Ananth"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            20
                        ]
                    ]
                },
                "call-number": "10.1145/3254549",
                "collection-title": "ACM-BCB '17",
                "container-title": "Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology,and Health Informatics",
                "DOI": "10.1145/3254549",
                "event-place": "Boston, Massachusetts, USA",
                "ISBN": "9781450347228",
                "page": "",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Session details: Session 6: Big Data in Bioinformatics I",
                "URL": "https://doi.org/10.1145/3254549"
            }
        },
        {
            "10.1145/240455.240479": {
                "id": "10.1145/240455.240479",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Wand",
                        "given": "Yair"
                    },
                    {
                        "family": "Wang",
                        "given": "Richard Y."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            1996,
                            11,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/240455.240479",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/240455.240479",
                "ISSN": "0001-0782",
                "issue": "11",
                "number-of-pages": "10",
                "page": "86–95",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "Nov. 1996",
                "title": "Anchoring data quality dimensions in ontological foundations",
                "URL": "https://doi.org/10.1145/240455.240479",
                "volume": "39"
            }
        },
        {
            "10.1145/3494583.3494608": {
                "id": "10.1145/3494583.3494608",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Deniswara",
                        "given": "Kevin"
                    },
                    {
                        "family": "Kartono Rahim",
                        "given": "Rano"
                    },
                    {
                        "family": "Hamsal",
                        "given": "Mohammad"
                    },
                    {
                        "family": "Furinto",
                        "given": "Asnan"
                    },
                    {
                        "family": "Anthony",
                        "given": "Alexander"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            27
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            27
                        ]
                    ]
                },
                "abstract": "The purpose of this study is to determine the perception of the existence of big data on auditors supported by the use of the UTAUT Model. Empirical evidence will be tested on performance expectations, effort expectations, social influences, facilitating conditions, and trust that are predicted to influence behavioral intentions. This research was conducted using quantitative methods on 70 samples of auditor respondents who work in Public Accounting Firms in Indonesia. The analytical method used in this study is PLS-SEM with behavioral intention as the dependent variable. This study found that the variables of independent performance expectations, business expectations, social influences, and facilitation conditions had no significant effect on behavioral intentions. While the trust variable has a significant positive effect. The abstract needs to summarize the content of the paper.",
                "call-number": "10.1145/3494583.3494608",
                "collection-title": "ICIBE 2021",
                "container-title": "The 2021 7th International Conference on Industrial and Business Engineering",
                "DOI": "10.1145/3494583.3494608",
                "event-place": "Macau, China",
                "ISBN": "9781450390644",
                "keyword": "Public Accounting Firm, UTAUT Model, Big Data, Behavioral Intention, Auditor",
                "number-of-pages": "8",
                "page": "43–50",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Analysis of the Auditor's Perspective on the Use of Big Data in Financial Statements: UTAUT Model Approach",
                "URL": "https://doi.org/10.1145/3494583.3494608"
            }
        },
        {
            "10.1145/3446999.3447629": {
                "id": "10.1145/3446999.3447629",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "LIU",
                        "given": "YANCHAO"
                    },
                    {
                        "family": "Liu",
                        "given": "HongLiang"
                    },
                    {
                        "family": "NIAN",
                        "given": "GUANHUA"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            12,
                            25
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            12,
                            25
                        ]
                    ]
                },
                "abstract": "The pipeline steel for the third-line engineering of West-East was successful produced in Benxi Steel, based on their hot strip mills equipment advantage. However, the impact toughness was unstable during the production. In this research, optical microscope, scanning electron microscopy (SEM) and energy dispersive analysis (EDS) test were used to study on the relationships between different alloy content and microstructure in pipeline steel. What's more, the effect of alloy content on strength and impact toughness in pipeline steel was explored based on the statistics of alloy composition and the mechanical properties in production. The results show that, the alloying elements in pipeline steel can be divided into three categories in this condition. First, Ni, Cu and Mo alloy elements promote the MA constituents transformation, and leading the impact toughness decreases. So, it should be appropriate to reduce the content of these alloy elements, or improvement the cooling process. Second, Cr and Mn alloy, which have no significant effect on both strength and impact toughness, should be appropriately control its content. And third, Nb and Ti micro-alloying, which is particularly improving both strength and impact toughness in pipeline steel. This study is not only provided a basis to improve pipeline steel impact toughness, but also provided the necessary theoretical support for the research and development of higher grade pipeline steel.",
                "call-number": "10.1145/3446999.3447629",
                "collection-title": "ICIT 2020",
                "container-title": "2020 The 8th International Conference on Information Technology: IoT and Smart City",
                "DOI": "10.1145/3446999.3447629",
                "event-place": "Xi&apos;an, China",
                "ISBN": "9781450388559",
                "keyword": "big data, strength, alloying element, steel, impact toughness",
                "number-of-pages": "6",
                "page": "183–188",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Alloy Content on Mechanical Properties Research Based on Industrial Big Data Analysis in Microalloyed Steel",
                "URL": "https://doi.org/10.1145/3446999.3447629"
            }
        },
        {
            "10.1145/3047273.3047274": {
                "id": "10.1145/3047273.3047274",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Shrivastava",
                        "given": "Swapnil"
                    },
                    {
                        "family": "Pal",
                        "given": "Supriya N."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            3,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            3,
                            7
                        ]
                    ]
                },
                "abstract": "In the recent times we have been seeing a fundamental shift from Enterprise Applications towards large scale Enterprise Service Ecosystems. Enterprise Service Ecosystems are developed by modularizing and bundling of individual business rules and functions in the form of services. These services are loosely coupled, distributed and heterogeneous components which orchestrate amongst themselves in a seamless manner. Ecosystem components record the events that are related to the activities performed by them. These components could span across Data Centre, Cloud Infrastructure and Internet of Things. Aadhaar Authentication Ecosystem and e-Governance Service Exchange are examples of Enterprise Service Ecosystems which recently emerged in national e-Governance scenario. A Big Data Analytics Framework for comprehensive mining and analyzing event data of Enterprise Service Ecosystems is proposed in this paper. The offered framework facilitates interesting real time analytics (e.g. Process Conformance Checking, Bottleneck Detection) as well as performing offline analytics (e.g. Process Discovery). The application of the proposed framework for real time analytics is explained using Aadhaar (Unique Identity) Authentication Ecosystem case study.",
                "call-number": "10.1145/3047273.3047274",
                "collection-title": "ICEGOV '17",
                "container-title": "Proceedings of the 10th International Conference on Theory and Practice of Electronic Governance",
                "DOI": "10.1145/3047273.3047274",
                "event-place": "New Delhi AA, India",
                "ISBN": "9781450348256",
                "keyword": "Graph Analytics, Event Data, Enterprise Service Ecosystem, Big Data Analytics, Complex Event Processing, Aadhaar Authentication Ecosystem, e-Governance, Process Mining",
                "number-of-pages": "7",
                "page": "5–11",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A Big Data Analytics Framework for Enterprise Service Ecosystems in an e-Governance Scenario",
                "URL": "https://doi.org/10.1145/3047273.3047274"
            }
        },
        {
            "10.1145/3090057": {
                "id": "10.1145/3090057",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "El-Mawass",
                        "given": "Nour"
                    },
                    {
                        "family": "Alaboodi",
                        "given": "Saad"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            9,
                            28
                        ]
                    ]
                },
                "call-number": "10.1145/3090057",
                "collection-number": "4",
                "container-title": "J. Data and Information Quality",
                "DOI": "10.1145/3090057",
                "ISSN": "1936-1955",
                "issue": "1",
                "keyword": "supervised learning, online social networks, social spam detection, Reproducibility, machine learning",
                "number": "Article 4",
                "number-of-pages": "4",
                "page": "1–4",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "March 2017",
                "title": "Data Quality Challenges in Social Spam Research",
                "URL": "https://doi.org/10.1145/3090057",
                "volume": "9"
            }
        },
        {
            "10.5555/2648668.2648699": {
                "id": "10.5555/2648668.2648699",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Yan"
                    },
                    {
                        "family": "Wang",
                        "given": "Kun"
                    },
                    {
                        "family": "Guo",
                        "given": "Qi"
                    },
                    {
                        "family": "Li",
                        "given": "Xin"
                    },
                    {
                        "family": "Zhang",
                        "given": "Xiaochen"
                    },
                    {
                        "family": "Chen",
                        "given": "Guancheng"
                    },
                    {
                        "family": "Liu",
                        "given": "Tao"
                    },
                    {
                        "family": "Li",
                        "given": "Jian"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            9,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            9,
                            4
                        ]
                    ]
                },
                "abstract": "MapReduce plays an critical role in finding insights in Big Data. The performance optimization of MapReduce programs is challenging because it requires a comprehensive understanding of the whole system including both hardware layers (processors, storages, networks and etc), and software stacks (operating systems, JVM, runtime, applications and etc). However, most of the existing performance tuning and optimization are based on empirical and heuristic attempts. It remains a blank on how to build a systematical framework which breaks the boundary of multiple layers for performance optimization.In this paper, we propose a performance evaluation framework by correlating performance metrics from different layers, which provides insights to efficiently pinpoint the performance issue. This framework is composed of a series of predefined patterns. Each pattern indicates one or more potential issues. The behavior of a MapReduce program is mapped to the corresponding resource utilization. The framework provides a holistic approach which allows users at different levels of experience to conduct MapReduce program performance optimization.We use Terasort benchmark running on a 10-node Power7R2 cluster as a real case to show how this framework improves the performance. By this framework, we finally get the Terasort result improved from 47 mins to less than 8 mins. In addition to the best practice on performance tuning, several key findings are summarized as valuable workload analysis for JVM, MapReduce runtime and application design.",
                "call-number": "10.5555/2648668.2648699",
                "collection-title": "ISLPED '13",
                "container-title": "Proceedings of the 2013 International Symposium on Low Power Electronics and Design",
                "event-place": "Beijing, China",
                "ISBN": "9781479912353",
                "number-of-pages": "6",
                "page": "126–131",
                "publisher": "IEEE Press",
                "title": "Breaking the boundary for whole-system performance optimization of big data"
            }
        },
        {
            "10.1145/3055219.3055234": {
                "id": "10.1145/3055219.3055234",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sethi",
                        "given": "Tavpritesh"
                    },
                    {
                        "family": "Nagori",
                        "given": "Aditya"
                    },
                    {
                        "family": "Bhatnagar",
                        "given": "Ambika"
                    },
                    {
                        "family": "Gupta",
                        "given": "Priyanka"
                    },
                    {
                        "family": "Fletcher",
                        "given": "Richard"
                    },
                    {
                        "family": "Lodha",
                        "given": "Rakesh"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            3,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            3,
                            7
                        ]
                    ]
                },
                "abstract": "The potential for whole body thermal patterns in diagnosis of hemodynamic perfusion disturbances in critical care as well as community settings is unexplored. In this study we have combined an in-house digitized Big-data resource from ICU settings with Infra-red thermography to derive novel inferences about the tele-diagnostic potential of IR thermography in diagnosis of shock and perfusion disturbances. While Data-science and Big-data are expected to revolutionize the next generation medicine and healthcare, the scientific efforts towards building Big-data resources for enhancing patient safety and healthcare governance are missing, especially in developing countries. We addressed this challenge and describe our experience on deployment of Big-data warehousing and data-analytics software using lean pipelines developed using open-source technologies and their utility in deriving knowledge and high utility patterns from Affordable Infrared Thermography. These knowledge frameworks and potentially translatable technology were developed in the Pediatric Intensive Care environment through extensive cross-talk between expert clinicians and data-scientists. In this work, we first demonstrate the successful creation of a unique Pediatric ICU resource of over 60,000 hours of continuous multivariate monitoring data followed by validation of the potential of whole body IR thermography in diagnosis of hemodynamic compromise. These patterns were validated through linear mixed models, a state-of-the-art statistical method for longitudinal data. The validated technology is affordable, and can be coupled to smartphones thus providing a huge potential in tele-medicine and electronic governance in healthcare and has the potential to be deployed in a tele-medicine setting with capturing of whole body temperature patterns by Accredited Social Health Activist (ASHA) workers. Therefore, this can enable early diagnosis of critical conditions such as sepsis and shock that are commonly associated with epidemics such as Dengue hemorrhagic fever in developing countries such as India. These images can be remotely shared with expert physicians and data-analysts via telemedicine thus aiding decisions in the Critical Care as well as Community settings.",
                "call-number": "10.1145/3055219.3055234",
                "collection-title": "ICEGOV '17",
                "container-title": "Proceedings of the Special Collection on eGovernment Innovations in India",
                "DOI": "10.1145/3055219.3055234",
                "event-place": "New Delhi AA, India",
                "ISBN": "9781450349307",
                "keyword": "Intensive Care Units, Smartphones, Clinical Decision Support, Open Source Technologies, Telemedicine, Thermal Imaging, Big-data Pipelines, Affordable, Community Care, Child health",
                "number-of-pages": "6",
                "page": "64–69",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Validating the Tele-diagnostic Potential of Affordable Thermography in a Big-data Data-enabled ICU",
                "URL": "https://doi.org/10.1145/3055219.3055234"
            }
        },
        {
            "10.1145/3254563": {
                "id": "10.1145/3254563",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Pollard",
                        "given": "Tom"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            20
                        ]
                    ]
                },
                "call-number": "10.1145/3254563",
                "collection-title": "ACM-BCB '17",
                "container-title": "Proceedings of the 8th ACM International Conference on Bioinformatics, Computational Biology,and Health Informatics",
                "DOI": "10.1145/3254563",
                "event-place": "Boston, Massachusetts, USA",
                "ISBN": "9781450347228",
                "page": "",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Session details: Session 20: Big Data in Bioinformatics II",
                "URL": "https://doi.org/10.1145/3254563"
            }
        },
        {
            "10.1145/3465631.3465664": {
                "id": "10.1145/3465631.3465664",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yu",
                        "given": "Xiaomu"
                    },
                    {
                        "family": "Yin",
                        "given": "Yuelin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            8,
                            19
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            8,
                            19
                        ]
                    ]
                },
                "abstract": "NOTICE OF RETRACTION: While investigating potential publication-related misconduct in connection with the ICIMTech 2021 Conference Proceedings, serious concerns were raised that cast doubt on the integrity of the peer-review process and all papers published in the Proceedings of this Conference. The integrity of the entire Conference has been called into question. As a result, of its investigation, ACM has decided to retract the Entire Conference Proceedings and all related papers from the ACM Digital Library.None of the papers from this Proceeding should be cited in the literature because of the questionable integrity of the peer review process for this Conference.",
                "call-number": "10.1145/3465631.3465664",
                "collection-number": "33",
                "collection-title": "ICIMTECH 21",
                "container-title": "The Sixth International Conference on Information Management and Technology",
                "DOI": "10.1145/3465631.3465664",
                "event-place": "Jakarta, Indonesia",
                "ISBN": "9781450385015",
                "number": "Article 33",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Application Strategies of Medical Big Data in Health Economic Management",
                "URL": "https://doi.org/10.1145/3465631.3465664"
            }
        },
        {
            "10.1145/3410566.3410591": {
                "id": "10.1145/3410566.3410591",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Gillet",
                        "given": "Annabelle"
                    },
                    {
                        "family": "Leclercq",
                        "given": "Éric"
                    },
                    {
                        "family": "Savonnet",
                        "given": "Marinette"
                    },
                    {
                        "family": "Cullot",
                        "given": "Nadine"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            8,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            8,
                            12
                        ]
                    ]
                },
                "abstract": "Polystores are of primary importance to tackle the diversity and the volume of Big Data, as they propose to store data according to specific use cases. Nevertheless, analytics frameworks often lack a uniform interface allowing to fully access and take advantage of the various models offered by the polystore. It also should be ensured that the typing of the algebraic expressions built with data manipulation operators can be checked and that schema can be inferred before starting to execute the operators (type-safe).Tensors are good candidates for supporting a pivot data model. They are powerful abstract mathematical objects which can embed complex relationships between entities and that are used in major analytics frameworks. However, they are far away from data models, and lack high level operators to manipulate their content, resulting in bad coding habits and less maintainability, and sometimes poor performances.With TDM (Tensor Data Model), we propose to join the best of both worlds, to take advantage of modeling capabilities of tensors by adding schema and data manipulation operators to them. We developed an implementation in Scala using Spark, providing users with a type-safe and schema inference mechanism that guarantees the technical and functional correctness of composed expressions on tensors at compile time. We show that this extension does not induce overhead and allows to outperform Spark query optimizer using bind join.",
                "call-number": "10.1145/3410566.3410591",
                "collection-number": "13",
                "collection-title": "IDEAS '20",
                "container-title": "Proceedings of the 24th Symposium on International Database Engineering & Applications",
                "DOI": "10.1145/3410566.3410591",
                "event-place": "Seoul, Republic of Korea",
                "ISBN": "9781450375030",
                "keyword": "tensor, high performance data analytics, polystore, query language",
                "number": "Article 13",
                "number-of-pages": "10",
                "page": "1–10",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Empowering big data analytics with polystore and strongly typed functional queries",
                "URL": "https://doi.org/10.1145/3410566.3410591"
            }
        },
        {
            "10.1145/3456887.3459688": {
                "id": "10.1145/3456887.3459688",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Hui",
                        "given": "Zhu"
                    },
                    {
                        "family": "Zhaoming",
                        "given": "Li"
                    },
                    {
                        "family": "Xuecong",
                        "given": "Cao"
                    },
                    {
                        "family": "Sisi",
                        "given": "Chen"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            5,
                            25
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            5,
                            25
                        ]
                    ]
                },
                "abstract": "In the era of big data, the centralization and subdivision of data provide abundant data resources for the financial management analysis of enterprises, but how to stand out from the financial data analysis depends on the innovation consciousness of enterprises. As an important part of enterprise management, financial management should also make changes to meet the development needs of big data. The financial management of e-commerce enterprises often deals with financial and non-financial data. The rise of big data provides powerful information technology support for the financial management of e-commerce enterprises, which enables enterprises to fully explore, analyze and process the information needed by finance. Based on multiple influencing factors, this paper starts with the necessity of innovation in financial management of e-commerce enterprises, and expounds the influence of big data on traditional financial management of enterprises, and also brings ideas and countermeasures for innovation of financial management mode for some enterprises.",
                "call-number": "10.1145/3456887.3459688",
                "collection-title": "CIPAE 2021",
                "container-title": "2021 2nd International Conference on Computers, Information Processing and Advanced Education",
                "DOI": "10.1145/3456887.3459688",
                "event-place": "Ottawa, ON, Canada",
                "ISBN": "9781450389969",
                "keyword": "financial management, E-commerce enterprises, Big data",
                "number-of-pages": "5",
                "page": "1407–1411",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on financial management mode of e-commerce enterprises based on multi influencing factors from the perspective of big data",
                "URL": "https://doi.org/10.1145/3456887.3459688"
            }
        },
        {
            "10.1145/3128572.3140452": {
                "id": "10.1145/3128572.3140452",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Caliskan",
                        "given": "Aylin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            11,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            11,
                            3
                        ]
                    ]
                },
                "abstract": "My research involves the heavy use of machine learning and natural language processing in novel ways to interpret big data, develop privacy and security attacks, and gain insights about humans and society through these methods. I do not use machine learning only as a tool but I also analyze machine learning models? internal representations to investigate how the artificial intelligence perceives the world. This work [3] has been recently featured in Science where I showed that societal bias exists at the construct level of machine learning models, namely semantic space word embeddings which are dictionaries for machines to understand language. When I use machine learning as a tool to uncover privacy and security problems, I characterize and quantify human behavior in language, including programming languages, by coming up with a linguistic fingerprint for each individual. By extracting linguistic features from natural language or programming language texts of humans, I show that humans have unique linguistic fingerprints since they all learn language on an individual basis. Based on this finding, I can de-anonymize humans that have written certain text, source code, or even executable binaries of compiled code [2, 4, 5]. This is a serious privacy threat for individuals that would like to remain anonymous, such as activists, programmers in oppressed regimes, or malware authors. Nevertheless, being able to identify authors of malicious code enhances security. On the other hand, identifying authors can be used to resolve copyright disputes or detect plagiarism. The methods in this realm [1] have been used to identify so called doppelgängers to link the accounts that belong to the same identities across platforms, especially underground forums that are business platforms for cyber criminals. By analyzing machine learning models? internal representation and linguistic human fingerprints, I am able to uncover facts about the world, society, and the use of language, which have implications for privacy, security, and fairness in machine learning.",
                "call-number": "10.1145/3128572.3140452",
                "collection-title": "AISec '17",
                "container-title": "Proceedings of the 10th ACM Workshop on Artificial Intelligence and Security",
                "DOI": "10.1145/3128572.3140452",
                "event-place": "Dallas, Texas, USA",
                "ISBN": "9781450352024",
                "keyword": "invited keynote",
                "number-of-pages": "1",
                "page": "1",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Beyond Big Data: What Can We Learn from AI Models? Invited Keynote",
                "URL": "https://doi.org/10.1145/3128572.3140452"
            }
        },
        {
            "10.1145/3513135": {
                "id": "10.1145/3513135",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Santoro",
                        "given": "Donatello"
                    },
                    {
                        "family": "Thirumuruganathan",
                        "given": "Saravanan"
                    },
                    {
                        "family": "Papotti",
                        "given": "Paolo"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            8,
                            1
                        ]
                    ]
                },
                "abstract": "This editorial summarizes the content of the Special Issue on Deep Learning for Data Quality of the Journal of Data and Information Quality (JDIQ).",
                "call-number": "10.1145/3513135",
                "collection-number": "14",
                "container-title": "J. Data and Information Quality",
                "DOI": "10.1145/3513135",
                "ISSN": "1936-1955",
                "issue": "3",
                "keyword": "data labeling, schema matching, Deep learning",
                "number": "Article 14",
                "number-of-pages": "3",
                "page": "1–3",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "September 2022",
                "title": "Editorial: Special Issue on Deep Learning for Data Quality",
                "URL": "https://doi.org/10.1145/3513135",
                "volume": "14"
            }
        },
        {
            "10.1145/2839509.2844631": {
                "id": "10.1145/2839509.2844631",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Fields",
                        "given": "Deborah A."
                    },
                    {
                        "family": "Quirke",
                        "given": "Lisa"
                    },
                    {
                        "family": "Amely",
                        "given": "Janell"
                    },
                    {
                        "family": "Maughan",
                        "given": "Jason"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            2,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            2,
                            17
                        ]
                    ]
                },
                "abstract": "In this paper we explore how to assess novice youths' learning of programming in an open-ended, project-based learning environment. Our goal is to combine analysis of frequent, automated snapshots of programming (e.g., \"big\" data) within the \"thick\" social context of kids? learning for deeper insights into their programming trajectories. This paper focuses on the first stage of this endeavor: the development of exploratory quantitative measures of youths? learning of computer science concepts. Analyses focus on kids? learning in a series of three Scratch Camps where 64 campers aged 10-13 used Scratch 2.0 to make a series of creative projects over 30 hours in five days. In the discussion we consider the highlights of the insights-and blind spots-of each data source with regard to youths' learning.",
                "call-number": "10.1145/2839509.2844631",
                "collection-title": "SIGCSE '16",
                "container-title": "Proceedings of the 47th ACM Technical Symposium on Computing Science Education",
                "DOI": "10.1145/2839509.2844631",
                "event-place": "Memphis, Tennessee, USA",
                "ISBN": "9781450336857",
                "keyword": "computer science education, novice programmers, big data, constructionism, assessment, scratch",
                "number-of-pages": "6",
                "page": "150–155",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Combining Big Data and Thick Data Analyses for Understanding Youth Learning Trajectories in a Summer Coding Camp",
                "URL": "https://doi.org/10.1145/2839509.2844631"
            }
        },
        {
            "10.1145/3415958.3433072": {
                "id": "10.1145/3415958.3433072",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Shahoud",
                        "given": "Shadi"
                    },
                    {
                        "family": "Khalloof",
                        "given": "Hatem"
                    },
                    {
                        "family": "Winter",
                        "given": "Moritz"
                    },
                    {
                        "family": "Duepmeier",
                        "given": "Clemens"
                    },
                    {
                        "family": "Hagenmeyer",
                        "given": "Veit"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            11,
                            2
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            11,
                            2
                        ]
                    ]
                },
                "abstract": "For a given specific machine learning task, very often several machine learning algorithms and their right configurations are tested in a trial-and-error approach, until an adequate solution is found. This wastes human resources for constructing multiple models, requires a data analytics expert and is time-consuming, since a variety of learning algorithms are proposed in literature and the non-expert users do not know which one to use in order to obtain good performance results. Meta learning addresses these problems and supports non-expert users by recommending a promising learning algorithm based on meta features computed from a given dataset. In the present paper, a new generic microservice-based framework for realizing the concept of meta learning in Big Data environments is introduced. This framework makes use of a powerful Big Data software stack, container visualization, modern web technologies and a microservice architecture for a fully manageable and highly scalable solution. In this demonstration and for evaluation purpose, time series model selection is taken into account. The performance and usability of the new framework is evaluated on state-of-the-art machine learning algorithms for time series forecasting: it is shown that the proposed microservice-based meta learning framework introduces an excellent performance in assigning the adequate forecasting model for the chosen time series datasets. Moreover, the recommendation of the most appropriate forecasting model results in a well acceptable low overhead demonstrating that the framework can provide an efficient approach to solve the problem of model selection in context of Big Data.",
                "call-number": "10.1145/3415958.3433072",
                "collection-title": "MEDES '20",
                "container-title": "Proceedings of the 12th International Conference on Management of Digital EcoSystems",
                "DOI": "10.1145/3415958.3433072",
                "event-place": "Virtual Event, United Arab Emirates",
                "ISBN": "9781450381154",
                "keyword": "Microservice, Machine Learning, Meta Learning, Web-based Applications, Big Data",
                "number-of-pages": "8",
                "page": "84–91",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A Meta Learning Approach for Automating Model Selection in Big Data Environments using Microservice and Container Virtualization Technologies",
                "URL": "https://doi.org/10.1145/3415958.3433072"
            }
        },
        {
            "10.1145/3365871.3365900": {
                "id": "10.1145/3365871.3365900",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Papst",
                        "given": "Franz"
                    },
                    {
                        "family": "Saukh",
                        "given": "Olga"
                    },
                    {
                        "family": "Römer",
                        "given": "Kay"
                    },
                    {
                        "family": "Grandl",
                        "given": "Florian"
                    },
                    {
                        "family": "Jakovljevic",
                        "given": "Igor"
                    },
                    {
                        "family": "Steininger",
                        "given": "Franz"
                    },
                    {
                        "family": "Mayerhofer",
                        "given": "Martin"
                    },
                    {
                        "family": "Duda",
                        "given": "Jürgen"
                    },
                    {
                        "family": "Egger-Danner",
                        "given": "Christa"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            22
                        ]
                    ]
                },
                "abstract": "Today's herd management undergoes a major transformation triggered by the penetration of cheap sensor solutions into cattle farms, and the promise of predictive analytics to detect animal health issues and product-related problems before they occur. The latter is particularly important to prevent disease spread, ensure animal health, animal welfare and product quality. Sensor businesses entering the market tend to build their solutions as end-to-end pipelines spanning sensors, proprietary algorithms, cloud services, and mobile apps. Since data privacy is an important issue in this industry, as a result, disconnected data silos, heterogeneity of APIs, and lack of common standards limit the value the sensor technologies could provide for herd management. In the last few years, researchers and communities proposed a number of data integration architectures to enable exchange between streams of sensor data. This paper surveys the existing efforts and outlines the opportunities they fail to address by treating sensor data as a black box. We discuss alternative solutions to the problem based on privacy-preserving collaborative learning, and provide a set of scenarios to show their benefits for both farmers and businesses.",
                "call-number": "10.1145/3365871.3365900",
                "collection-number": "27",
                "collection-title": "IoT 2019",
                "container-title": "Proceedings of the 9th International Conference on the Internet of Things",
                "DOI": "10.1145/3365871.3365900",
                "event-place": "Bilbao, Spain",
                "ISBN": "9781450372077",
                "keyword": "privacy-preserving data analysis, data privacy, agriculture",
                "number": "Article 27",
                "number-of-pages": "4",
                "page": "1–4",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Embracing Opportunities of Livestock Big Data Integration with Privacy Constraints",
                "URL": "https://doi.org/10.1145/3365871.3365900"
            }
        },
        {
            "10.1145/3510858.3510965": {
                "id": "10.1145/3510858.3510965",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yao",
                        "given": "Chunyun"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            12,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            12,
                            18
                        ]
                    ]
                },
                "abstract": "With the combination of information technology and economic fields, the amount of data has been greatly increased, and big data has begun to be valued by modern enterprises. As a new IT technology, it has had a huge impact on enterprise management, financial and management models, and business processes. Big data will surely become the basis of enterprise competition and management, and the use of information will have a decisive impact on the operating efficiency of enterprises. Big data sets put forward new requirements for corporate financial management. This article is the research goal of voice assistance and big data financial management based on high-resolution imaging algorithms. This paper establishes the specific process of the speech recognition model and high-resolution imaging algorithm based on the genetic algorithm of big data, and compares the experimental data of this paper with the data obtained from the reference literature and the Internet. Big data puts forward new requirements for financial management. It integrates high-resolution imaging algorithms and voice assistance into financial management based on big data, and studies the academic value and practical application value of financial management based on big data. Combined with actual data practice, it proves the feasibility and practicability of the research direction of this article. According to the experimental research in this article, the voice assistance and big data financial management based on the high-resolution imaging algorithm proposed in this article, adding voice assistance to the financial management can make the financial management run better, and the customers can obtain better data. The changes to the management staff can get management errors in a more timely manner, so that they can be modified in a more timely manner. In the use of genetic algorithms based on big data to optimize speech acquisition and recognition, experimental data shows that the highest recognition rate of optimized speech assistance is 98% close to 100%.",
                "call-number": "10.1145/3510858.3510965",
                "collection-title": "ICASIT 2021",
                "container-title": "2021 International Conference on Aviation Safety and Information Technology",
                "DOI": "10.1145/3510858.3510965",
                "event-place": "Changsha, China",
                "ISBN": "9781450390422",
                "number-of-pages": "5",
                "page": "356–360",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Voice Assistance and Big Data Financial Management Based on High-Resolution Imaging Algorithm",
                "URL": "https://doi.org/10.1145/3510858.3510965"
            }
        },
        {
            "10.1145/3501409.3501637": {
                "id": "10.1145/3501409.3501637",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhang",
                        "given": "Wei"
                    },
                    {
                        "family": "Wang",
                        "given": "Tianjun"
                    },
                    {
                        "family": "Wang",
                        "given": "Hao"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            22
                        ]
                    ]
                },
                "abstract": "Aiming at the problems of cloud communication and storage congestion and computing delay caused by massive heterogeneous distribution data, a hierarchical architecture model of active distribution network based on edge computing was proposed. Firstly, the edge computing framework based on the functional architecture of industrial Internet is proposed, and the internal and external interaction modes of edge computing node data are specifically sorted out. According to the established data interaction modes, the interactive processing mechanism of cloud-edge collaboration is proposed. Then, according to the logical protocol and physical architecture of active distribution network, the hierarchical architecture model of active distribution network based on edge computing is established to collect, interact and monitor the operating status, operating environment and electricity quantity data of distribution equipment. Finally, based on big data technology, the typical application scenarios of edge computing technology in actual power distribution are analyzed, and the efficiency, real-time, security and accuracy of edge computation-based power distribution big data system for local data storage and processing are verified.",
                "call-number": "10.1145/3501409.3501637",
                "collection-title": "EITCE 2021",
                "container-title": "Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering",
                "DOI": "10.1145/3501409.3501637",
                "event-place": "Xiamen, China",
                "ISBN": "9781450384322",
                "keyword": "Data interchange, Edge calculation, Industrial Iot network, Information physical system, Large data distribution data, Main power distribution network, Cloud edge coordination",
                "number-of-pages": "5",
                "page": "1292–1296",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Distribution big data technology of active distribution Network based on edge computing",
                "URL": "https://doi.org/10.1145/3501409.3501637"
            }
        },
        {
            "10.1145/2902961.2902984": {
                "id": "10.1145/2902961.2902984",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kulkarni",
                        "given": "Amey"
                    },
                    {
                        "family": "Abtahi",
                        "given": "Tahmid"
                    },
                    {
                        "family": "Smith",
                        "given": "Emily"
                    },
                    {
                        "family": "Mohsenin",
                        "given": "Tinoosh"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            5,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            5,
                            18
                        ]
                    ]
                },
                "abstract": "Almost 90% of the data available today was created within the last couple of years, thus Big Data set processing is of utmost importance. Many solutions have been investigated to increase processing speed and memory capacity, however I/O bottleneck is still a critical issue. To tackle this issue we adopt Sketching technique to reduce data communications. Reconstruction of the sketched matrix is performed using Orthogonal Matching Pursuit (OMP). Additionally we propose Gradient Descent OMP (GD-OMP) algorithm to reduce hardware complexity. Big data processing at real-time imposes rigid constraints on sketching kernel, hence to further reduce hardware overhead both algorithms are implemented on a low power domain specific many-core platform called Power Efficient Nano Clusters (PENC). GD-OMP algorithm is evaluated for image reconstruction accuracy and the PENC many-core architecture. Implementation results show that for large matrix sizes GD-OMP algorithm is 1.3x faster and consumes 1.4x less energy than OMP algorithm implementations. Compared to GPU and Quad-Core CPU implementations the PENC many-core reconstructs 5.4x and 9.8x faster respectively for large signal sizes with higher sparsity.",
                "call-number": "10.1145/2902961.2902984",
                "collection-title": "GLSVLSI '16",
                "container-title": "Proceedings of the 26th edition on Great Lakes Symposium on VLSI",
                "DOI": "10.1145/2902961.2902984",
                "event-place": "Boston, Massachusetts, USA",
                "ISBN": "9781450342742",
                "keyword": "many-core, high performance and reconfigurable architecture, compressive sensing, OMP",
                "number-of-pages": "6",
                "page": "57–62",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Low Energy Sketching Engines on Many-Core Platform for Big Data Acceleration",
                "URL": "https://doi.org/10.1145/2902961.2902984"
            }
        }
    ]
}