{
    "exportedDoiLength": 100,
    "fileName": "acm",
    "style": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<style xmlns=\"http://purl.org/net/xbiblio/csl\" class=\"in-text\" version=\"1.0\" demote-non-dropping-particle=\"sort-only\" default-locale=\"en-US\">\n    <!-- This style was edited with the Visual CSL Editor (http://editor.citationstyles.org/visualEditor/) -->\n    <info>\n        <title>BibTeX ACM citation style</title>\n        <id>http://www.zotero.org/styles/bibtex-acm-citation-style</id>\n        <link href=\"http://www.zotero.org/styles/bibtex-acm-citation-style\" rel=\"self\"/>\n        <link href=\"http://www.bibtex.org/\" rel=\"documentation\"/>\n        <author>\n            <name>Markus Schaffner</name>\n        </author>\n        <contributor>\n            <name>Richard Karnesky</name>\n            <email>karnesky+zotero@gmail.com</email>\n            <uri>http://arc.nucapt.northwestern.edu/Richard_Karnesky</uri>\n        </contributor>\n        <category citation-format=\"author-date\"/>\n        <category field=\"generic-base\"/>\n        <updated>2018-06-11T10:52:49+00:00</updated>\n        <rights license=\"http://creativecommons.org/licenses/by-sa/3.0/\">This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 License</rights>\n    </info>\n    <macro name=\"zotero2bibtexType\">\n        <choose>\n            <if type=\"BILL BOOK GRAPHIC LEGAL_CASE LEGISLATION MOTION_PICTURE SONG\" match=\"any\">\n                <choose>\n                    <if genre=\"rfc\"  match=\"any\">\n                       <text value=\"rfc\"/>\n                    </if>\n                     <else-if  genre=\"bibliography\" match=\"any\">\n                        <text value=\"bibliography\"/>\n                    </else-if>\n                    <else-if  genre=\"play_drama\" match=\"any\">\n                        <text value=\"playdrama\"/>\n                    </else-if>\n                    <else-if  genre=\"proceeding\" match=\"any\">\n                        <text value=\"proceedings\"/>\n                    </else-if>\n                    <else-if  genre=\"tech_brief\" match=\"any\">\n                        <text value=\"tech-brief\"/>\n                    </else-if>\n                    <else>\n                       <text value=\"book\"/>\n                    </else>\n                </choose>\n            </if>\n            <else-if type=\"CHAPTER\" match=\"any\">\n                <text value=\"inbook\"/>\n            </else-if>\n            <else-if type=\"ARTICLE ARTICLE_JOURNAL ARTICLE_MAGAZINE ARTICLE_NEWSPAPER\" match=\"any\">\n                <text value=\"article\"/>\n            </else-if>\n            <else-if type=\"THESIS\" match=\"any\">\n                <choose>\n                    <if variable=\"genre\">\n                        <text variable=\"genre\" text-case=\"lowercase\" strip-periods=\"true\"/>\n                    </if>\n                </choose>\n                <text value=\"thesis\"/>\n            </else-if>\n            <else-if type=\"PAPER_CONFERENCE\" match=\"any\">\n                <text value=\"inproceedings\"/>\n            </else-if>\n            <else-if type=\"REPORT\" match=\"any\">\n                <text value=\"techreport\"/>\n            </else-if>\n            <else-if type=\"DATASET\" match=\"any\">\n                <choose>\n                    <if genre=\"software\"  match=\"any\">\n                       <text value=\"software\"/>\n                    </if>\n                    <else>\n                       <text value=\"dataset\"/>\n                    </else>\n                </choose>\n            </else-if>\n            <else>\n                <text value=\"misc\"/>\n            </else>\n        </choose>\n    </macro>\n    <macro name=\"citeKey\">\n           <text variable=\"call-number\"/>\n    </macro>\n    <macro name=\"editor-short\">\n        <names variable=\"editor\">\n            <name form=\"short\" delimiter=\":\" delimiter-precedes-last=\"always\"/>\n        </names>\n    </macro>\n    <macro name=\"author-short\">\n        <names variable=\"author\">\n            <name form=\"short\" delimiter=\":\" delimiter-precedes-last=\"always\"/>\n        </names>\n    </macro>\n    <macro name=\"issued-year\">\n        <date variable=\"issued\">\n            <date-part name=\"year\"/>\n        </date>\n    </macro>\n    <macro name=\"issued-month\">\n        <choose>\n            <if type=\"ARTICLE\" match=\"any\">\n                <date variable=\"issued\">\n                    <date-part name=\"month\" form=\"short\" strip-periods=\"true\" text-case=\"lowercase\"/>\n                </date>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"issue-date\">\n        <choose>\n            <if type=\"ARTICLE ARTICLE_JOURNAL\" match=\"any\">\n                <choose>\n                    <if variable=\"note\" match=\"none\">\n                        <choose>\n                            <if variable=\"source\">\n                                 <text variable=\"source\"/>\n                            </if>\n                               <else>\n                                 <date date-parts=\"year-month\" form=\"text\" variable=\"issued\"/>\n                               </else>\n                        </choose>\n                    </if>\n                </choose>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"author\">\n        <names variable=\"author\">\n            <name sort-separator=\", \" delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n            <label form=\"long\" text-case=\"capitalize-first\"/>\n        </names>\n    </macro>\n    <macro name=\"editor-translator\">\n        <names variable=\"editor translator\" delimiter=\", \">\n            <name sort-separator=\", \" delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n            <label form=\"long\" text-case=\"capitalize-first\"/>\n        </names>\n    </macro>\n    <macro name=\"title\">\n        <choose>\n            <if genre=\"proceeding\" match=\"any\">\n                <text variable=\"container-title-short\" suffix=\": \"/>\n                <text variable=\"title\" text-case=\"title\"/>\n            </if>\n            <else-if type=\"ARTICLE_JOURNAL\" match=\"none\">\n                <text variable=\"title\" text-case=\"title\"/>\n            </else-if>\n        </choose>\n    </macro>\n    <macro name=\"volume\">\n        <choose>\n            <if type=\"ARTICLE BOOK ARTICLE_JOURNAL\" match=\"any\">\n                <text variable=\"volume\" prefix=\"volume = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"DOI\">\n        <choose>\n            <if type=\"ARTICLE PAPER_CONFERENCE\" match=\"any\">\n                <text variable=\"DOI\" prefix=\"doi = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"abstract\">\n        <if match=\"any\" variable=\"abstract\">\n            <text variable=\"abstract\"/>\n        </if>\n    </macro>\n    <macro name=\"URL\">\n        <text variable=\"URL\" prefix=\"url = {\" suffix=\"}\"/>\n    </macro>\n    <macro name=\"container-title\">\n        <choose>\n            <if type=\"CHAPTER PAPER_CONFERENCE\" match=\"any\">\n                <text variable=\"container-title\" prefix=\"booktitle = {\" suffix=\"}\" text-case=\"title\"/>\n            </if>\n            <else-if type=\"ARTICLE ARTICLE_JOURNAL\" match=\"any\">\n                <text variable=\"container-title\" prefix=\"journal = {\" suffix=\"}\" text-case=\"title\"/>\n            </else-if>\n        </choose>\n    </macro>\n    <macro name=\"pages\">\n        <group delimiter=\",&#10;\">\n            <choose>\n                <if match=\"any\" variable=\"collection-number\">\n                    <text variable=\"collection-number\" prefix=\"articleno = {\" suffix=\"}\"/>\n                </if>\n                <else>\n                    <text variable=\"page\" prefix=\"pages = {\" suffix=\"}\"/>\n                </else>\n            </choose>\n            <text variable=\"number-of-pages\" prefix=\"numpages = {\" suffix=\"}\"/>\n        </group>\n    </macro>\n    <macro name=\"edition\">\n        <text variable=\"edition\"/>\n    </macro>\n    <macro name=\"editor\">\n        <choose>\n            <if match=\"any\" type=\"THESIS\">\n                <names variable=\"editor\" delimiter=\", \" prefix=\"advisor = {\" suffix=\"}\">\n                    <name delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n                </names>\n            </if>\n            <else>\n               <names variable=\"editor\" delimiter=\", \" prefix=\"editor = {\" suffix=\"}\">\n                   <name delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n               </names>\n            </else>\n        </choose>\n    </macro>\n    <macro name=\"keyword\">\n        <choose>\n            <if type=\"ARTICLE PAPER_CONFERENCE DATASET\" match=\"any\">\n                <text variable=\"keyword\" prefix=\"keywords = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <citation et-al-min=\"11\" et-al-use-first=\"10\" disambiguate-add-year-suffix=\"true\" disambiguate-add-names=\"false\" disambiguate-add-givenname=\"false\" collapse=\"year\">\n        <layout delimiter=\"_\">\n            <text macro=\"citeKey\"/>\n        </layout>\n    </citation>\n    <bibliography hanging-indent=\"false\">\n        <layout>\n            <group display=\"right-inline\">\n                <text macro=\"zotero2bibtexType\" prefix=\"@\"/>\n                <group prefix=\"{\" suffix=\"&#10;}\" delimiter=\",&#10;\">\n                    <text macro=\"citeKey\"/>\n                    <text macro=\"author\" prefix=\"author = {\" suffix=\"}\"/>\n                    <text macro=\"editor\"/>\n                    <text macro=\"title\" prefix=\"title = {\" suffix=\"}\"/>\n                    <text macro=\"issued-year\" prefix=\"year = {\" suffix=\"}\"/>\n                    <text macro=\"issue-date\" prefix=\"issue_date = {\" suffix=\"}\"/>\n                    <text variable=\"ISBN\" prefix=\"isbn = {\" suffix=\"}\"/>\n                    <text variable=\"publisher\" prefix=\"publisher = {\" suffix=\"}\"/>\n                    <text variable=\"publisher-place\" prefix=\"address = {\" suffix=\"}\"/>\n                    <text variable=\"chapter-number\" prefix=\"chapter = {\" suffix=\"}\"/>\n                    <text macro=\"edition\" prefix=\"edition = {\" suffix=\"}\"/>\n                    <text macro=\"volume\"/>\n                    <text variable=\"issue\" prefix=\"number = {\" suffix=\"}\"/>\n                    <text variable=\"ISSN\" prefix=\"issn = {\" suffix=\"}\"/>\n                    <text variable=\"archive_location\" prefix=\"archiveLocation = {\" suffix=\"}\"/>\n                    <text macro=\"URL\"/>\n                    <text macro=\"DOI\"/>\n                    <text macro=\"abstract\" prefix=\"abstract = {\" suffix=\"}\"/>\n                    <text variable=\"note\" prefix=\"note = {\" suffix=\"}\"/>\n                    <text macro=\"container-title\"/>\n                    <text macro=\"issued-month\" prefix=\"month = {\" suffix=\"}\"/>\n                    <text macro=\"pages\"/>\n                    <text macro=\"keyword\"/>\n                    <text variable=\"event-place\" prefix=\"location = {\" suffix=\"}\"/>\n                    <choose>\n                        <if type=\"PAPER_CONFERENCE\" match=\"any\">\n                            <text variable=\"collection-title\" prefix=\"series = {\" suffix=\"}\"/>\n                        </if>\n                        <else>\n                            <text variable=\"collection-title\" prefix=\"collection = {\" suffix=\"}\"/>\n                        </else>\n                    </choose>\n                </group>\n            </group>\n        </layout>\n    </bibliography>\n</style>\n",
    "suffix": "bib",
    "locale": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<locale xmlns=\"http://purl.org/net/xbiblio/csl\" version=\"1.0\" xml:lang=\"en-US\">\n  <info>\n    <rights license=\"http://creativecommons.org/licenses/by-sa/3.0/\">This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 License</rights>\n    <updated>2012-07-04T23:31:02+00:00</updated>\n  </info>\n  <style-options punctuation-in-quote=\"true\"\n                 leading-noise-words=\"a,an,the\"\n                 name-as-sort-order=\"ja zh kr my hu vi\"\n                 name-never-short=\"ja zh kr my hu vi\"/>\n  <date form=\"text\">\n    <date-part name=\"month\" suffix=\" \"/>\n    <date-part name=\"day\" suffix=\", \"/>\n    <date-part name=\"year\"/>\n  </date>\n  <date form=\"numeric\">\n    <date-part name=\"month\" form=\"numeric-leading-zeros\" suffix=\"/\"/>\n    <date-part name=\"day\" form=\"numeric-leading-zeros\" suffix=\"/\"/>\n    <date-part name=\"year\"/>\n  </date>\n  <terms>\n    <term name=\"radio-broadcast\">radio broadcast</term>\n    <term name=\"television-broadcast\">television broadcast</term>\n    <term name=\"podcast\">podcast</term>\n    <term name=\"instant-message\">instant message</term>\n    <term name=\"email\">email</term>\n    <term name=\"number-of-volumes\">\n      <single>volume</single>\n      <multiple>volumes</multiple>\n    </term>\n    <term name=\"accessed\">accessed</term>\n    <term name=\"and\">and</term>\n    <term name=\"and\" form=\"symbol\">&amp;</term>\n    <term name=\"and others\">and others</term>\n    <term name=\"anonymous\">anonymous</term>\n    <term name=\"anonymous\" form=\"short\">anon.</term>\n    <term name=\"at\">at</term>\n    <term name=\"available at\">available at</term>\n    <term name=\"by\">by</term>\n    <term name=\"circa\">circa</term>\n    <term name=\"circa\" form=\"short\">c.</term>\n    <term name=\"cited\">cited</term>\n    <term name=\"edition\">\n      <single>edition</single>\n      <multiple>editions</multiple>\n    </term>\n    <term name=\"edition\" form=\"short\">ed.</term>\n    <term name=\"et-al\">et al.</term>\n    <term name=\"forthcoming\">forthcoming</term>\n    <term name=\"from\">from</term>\n    <term name=\"ibid\">ibid.</term>\n    <term name=\"in\">in</term>\n    <term name=\"in press\">in press</term>\n    <term name=\"internet\">internet</term>\n    <term name=\"interview\">interview</term>\n    <term name=\"letter\">letter</term>\n    <term name=\"no date\">no date</term>\n    <term name=\"no date\" form=\"short\">n.d.</term>\n    <term name=\"online\">online</term>\n    <term name=\"presented at\">presented at the</term>\n    <term name=\"reference\">\n      <single>reference</single>\n      <multiple>references</multiple>\n    </term>\n    <term name=\"reference\" form=\"short\">\n      <single>ref.</single>\n      <multiple>refs.</multiple>\n    </term>\n    <term name=\"retrieved\">retrieved</term>\n    <term name=\"scale\">scale</term>\n    <term name=\"version\">version</term>\n\n    <!-- ANNO DOMINI; BEFORE CHRIST -->\n    <term name=\"ad\">AD</term>\n    <term name=\"bc\">BC</term>\n\n    <!-- PUNCTUATION -->\n    <term name=\"open-quote\">“</term>\n    <term name=\"close-quote\">”</term>\n    <term name=\"open-inner-quote\">‘</term>\n    <term name=\"close-inner-quote\">’</term>\n    <term name=\"page-range-delimiter\">–</term>\n\n    <!-- ORDINALS -->\n    <term name=\"ordinal\">th</term>\n    <term name=\"ordinal-01\">st</term>\n    <term name=\"ordinal-02\">nd</term>\n    <term name=\"ordinal-03\">rd</term>\n    <term name=\"ordinal-11\">th</term>\n    <term name=\"ordinal-12\">th</term>\n    <term name=\"ordinal-13\">th</term>\n\n    <!-- LONG ORDINALS -->\n    <term name=\"long-ordinal-01\">first</term>\n    <term name=\"long-ordinal-02\">second</term>\n    <term name=\"long-ordinal-03\">third</term>\n    <term name=\"long-ordinal-04\">fourth</term>\n    <term name=\"long-ordinal-05\">fifth</term>\n    <term name=\"long-ordinal-06\">sixth</term>\n    <term name=\"long-ordinal-07\">seventh</term>\n    <term name=\"long-ordinal-08\">eighth</term>\n    <term name=\"long-ordinal-09\">ninth</term>\n    <term name=\"long-ordinal-10\">tenth</term>\n\n    <!-- LONG LOCATOR FORMS -->\n    <term name=\"book\">\n      <single>book</single>\n      <multiple>books</multiple>\n    </term>\n    <term name=\"chapter\">\n      <single>chapter</single>\n      <multiple>chapters</multiple>\n    </term>\n    <term name=\"column\">\n      <single>column</single>\n      <multiple>columns</multiple>\n    </term>\n    <term name=\"figure\">\n      <single>figure</single>\n      <multiple>figures</multiple>\n    </term>\n    <term name=\"folio\">\n      <single>folio</single>\n      <multiple>folios</multiple>\n    </term>\n    <term name=\"issue\">\n      <single>number</single>\n      <multiple>numbers</multiple>\n    </term>\n    <term name=\"line\">\n      <single>line</single>\n      <multiple>lines</multiple>\n    </term>\n    <term name=\"note\">\n      <single>note</single>\n      <multiple>notes</multiple>\n    </term>\n    <term name=\"opus\">\n      <single>opus</single>\n      <multiple>opera</multiple>\n    </term>\n    <term name=\"page\">\n      <single>page</single>\n      <multiple>pages</multiple>\n    </term>\n    <term name=\"paragraph\">\n      <single>paragraph</single>\n      <multiple>paragraph</multiple>\n    </term>\n    <term name=\"part\">\n      <single>part</single>\n      <multiple>parts</multiple>\n    </term>\n    <term name=\"section\">\n      <single>section</single>\n      <multiple>sections</multiple>\n    </term>\n    <term name=\"sub verbo\">\n      <single>sub verbo</single>\n      <multiple>sub verbis</multiple>\n    </term>\n    <term name=\"verse\">\n      <single>verse</single>\n      <multiple>verses</multiple>\n    </term>\n    <term name=\"volume\">\n      <single>volume</single>\n      <multiple>volumes</multiple>\n    </term>\n\n    <!-- SHORT LOCATOR FORMS -->\n    <term name=\"book\" form=\"short\">bk.</term>\n    <term name=\"chapter\" form=\"short\">chap.</term>\n    <term name=\"column\" form=\"short\">col.</term>\n    <term name=\"figure\" form=\"short\">fig.</term>\n    <term name=\"folio\" form=\"short\">f.</term>\n    <term name=\"issue\" form=\"short\">no.</term>\n    <term name=\"line\" form=\"short\">l.</term>\n    <term name=\"note\" form=\"short\">n.</term>\n    <term name=\"opus\" form=\"short\">op.</term>\n    <term name=\"page\" form=\"short\">\n      <single>p.</single>\n      <multiple>pp.</multiple>\n    </term>\n    <term name=\"paragraph\" form=\"short\">para.</term>\n    <term name=\"part\" form=\"short\">pt.</term>\n    <term name=\"section\" form=\"short\">sec.</term>\n    <term name=\"sub verbo\" form=\"short\">\n      <single>s.v.</single>\n      <multiple>s.vv.</multiple>\n    </term>\n    <term name=\"verse\" form=\"short\">\n      <single>v.</single>\n      <multiple>vv.</multiple>\n    </term>\n    <term name=\"volume\" form=\"short\">\n      <single>vol.</single>\n      <multiple>vols.</multiple>\n    </term>\n\n    <!-- SYMBOL LOCATOR FORMS -->\n    <term name=\"paragraph\" form=\"symbol\">\n      <single>¶</single>\n      <multiple>¶¶</multiple>\n    </term>\n    <term name=\"section\" form=\"symbol\">\n      <single>§</single>\n      <multiple>§§</multiple>\n    </term>\n\n    <!-- LONG ROLE FORMS -->\n    <term name=\"director\">\n      <single>director</single>\n      <multiple>directors</multiple>\n    </term>\n    <term name=\"editor\">\n      <single>editor</single>\n      <multiple>editors</multiple>\n    </term>\n    <term name=\"editorial-director\">\n      <single>editor</single>\n      <multiple>editors</multiple>\n    </term>\n    <term name=\"illustrator\">\n      <single>illustrator</single>\n      <multiple>illustrators</multiple>\n    </term>\n    <term name=\"translator\">\n      <single>translator</single>\n      <multiple>translators</multiple>\n    </term>\n    <term name=\"editortranslator\">\n      <single>editor &amp; translator</single>\n      <multiple>editors &amp; translators</multiple>\n    </term>\n\n    <!-- SHORT ROLE FORMS -->\n    <term name=\"director\" form=\"short\">\n      <single>dir.</single>\n      <multiple>dirs.</multiple>\n    </term>\n    <term name=\"editor\" form=\"short\">\n      <single>ed.</single>\n      <multiple>eds.</multiple>\n    </term>\n    <term name=\"editorial-director\" form=\"short\">\n      <single>ed.</single>\n      <multiple>eds.</multiple>\n    </term>\n    <term name=\"illustrator\" form=\"short\">\n      <single>ill.</single>\n      <multiple>ills.</multiple>\n    </term>\n    <term name=\"translator\" form=\"short\">\n      <single>tran.</single>\n      <multiple>trans.</multiple>\n    </term>\n    <term name=\"editortranslator\" form=\"short\">\n      <single>ed. &amp; tran.</single>\n      <multiple>eds. &amp; trans.</multiple>\n    </term>\n\n    <!-- VERB ROLE FORMS -->\n    <term name=\"director\" form=\"verb\">directed by</term>\n    <term name=\"editor\" form=\"verb\">edited by</term>\n    <term name=\"editorial-director\" form=\"verb\">edited by</term>\n    <term name=\"illustrator\" form=\"verb\">illustrated by</term>\n    <term name=\"interviewer\" form=\"verb\">interview by</term>\n    <term name=\"recipient\" form=\"verb\">to</term>\n    <term name=\"reviewed-author\" form=\"verb\">by</term>\n    <term name=\"translator\" form=\"verb\">translated by</term>\n    <term name=\"editortranslator\" form=\"verb\">edited &amp; translated by</term>\n\n    <!-- SHORT VERB ROLE FORMS -->\n    <term name=\"container-author\" form=\"verb-short\">by</term>\n    <term name=\"director\" form=\"verb-short\">dir.</term>\n    <term name=\"editor\" form=\"verb-short\">ed.</term>\n    <term name=\"editorial-director\" form=\"verb-short\">ed.</term>\n    <term name=\"illustrator\" form=\"verb-short\">illus.</term>\n    <term name=\"translator\" form=\"verb-short\">trans.</term>\n    <term name=\"editortranslator\" form=\"verb-short\">ed. &amp; trans.</term>\n\n    <!-- LONG MONTH FORMS -->\n    <term name=\"month-01\">January</term>\n    <term name=\"month-02\">February</term>\n    <term name=\"month-03\">March</term>\n    <term name=\"month-04\">April</term>\n    <term name=\"month-05\">May</term>\n    <term name=\"month-06\">June</term>\n    <term name=\"month-07\">July</term>\n    <term name=\"month-08\">August</term>\n    <term name=\"month-09\">September</term>\n    <term name=\"month-10\">October</term>\n    <term name=\"month-11\">November</term>\n    <term name=\"month-12\">December</term>\n\n    <!-- SHORT MONTH FORMS -->\n    <term name=\"month-01\" form=\"short\">Jan.</term>\n    <term name=\"month-02\" form=\"short\">Feb.</term>\n    <term name=\"month-03\" form=\"short\">Mar.</term>\n    <term name=\"month-04\" form=\"short\">Apr.</term>\n    <term name=\"month-05\" form=\"short\">May</term>\n    <term name=\"month-06\" form=\"short\">Jun.</term>\n    <term name=\"month-07\" form=\"short\">Jul.</term>\n    <term name=\"month-08\" form=\"short\">Aug.</term>\n    <term name=\"month-09\" form=\"short\">Sep.</term>\n    <term name=\"month-10\" form=\"short\">Oct.</term>\n    <term name=\"month-11\" form=\"short\">Nov.</term>\n    <term name=\"month-12\" form=\"short\">Dec.</term>\n\n    <!-- SEASONS -->\n    <term name=\"season-01\">Spring</term>\n    <term name=\"season-02\">Summer</term>\n    <term name=\"season-03\">Autumn</term>\n    <term name=\"season-04\">Winter</term>\n  </terms>\n</locale>\n",
    "contentType": "Application/x-bibtex",
    "items": [
        {
            "10.1145/2791347.2791380": {
                "id": "10.1145/2791347.2791380",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zakerzadeh",
                        "given": "Hessam"
                    },
                    {
                        "family": "Aggarwal",
                        "given": "Charu C."
                    },
                    {
                        "family": "Barker",
                        "given": "Ken"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            29
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            29
                        ]
                    ]
                },
                "abstract": "The problem of privacy-preserving data mining has been studied extensively in recent years because of its importance as a key enabler in the sharing of massive data sets. Most of the work in privacy has focussed on issues involving the quality of privacy preservation and utility, though there has been little focus on the issue of scalability in privacy preservation. The reason for this is that anonymization has generally been seen as a batch and one-time process in the context of data sharing. However, in recent years, the sizes of data sets have grown tremendously to a point where the effective application of the current algorithms is becoming increasingly difficult. Furthermore, the transient nature of recent data sets has resulted in an increased need for the repeated application of such methods on the newer data sets which have been collected. Repeated application demands even greater computational efficiency in order to be practical. For example, an algorithm with quadratic complexity is unlikely to be implementable in reasonable time over terabyte scale data sets. A bigger issue is that larger data sets are likely to be addressed by distributed frameworks such as MapReduce. In such frameworks, one has to address the additional issue of minimizing data transfer across different nodes, which is the bottleneck. In this paper, we discuss the first approach towards privacy-preserving data mining of very massive data sets using MapReduce. We study two most widely-used privacy models k-anonymity and l-diversity for anonymization, and present experimental results illustrating the effectiveness of the approach.",
                "call-number": "10.1145/2791347.2791380",
                "collection-number": "26",
                "collection-title": "SSDBM '15",
                "container-title": "Proceedings of the 27th International Conference on Scientific and Statistical Database Management",
                "DOI": "10.1145/2791347.2791380",
                "event-place": "La Jolla, California",
                "ISBN": "9781450337090",
                "number": "Article 26",
                "number-of-pages": "11",
                "page": "1–11",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Privacy-preserving big data publishing",
                "URL": "https://doi.org/10.1145/2791347.2791380"
            }
        },
        {
            "10.1145/3175684.3175717": {
                "id": "10.1145/3175684.3175717",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Xue",
                        "given": "Jiarui"
                    },
                    {
                        "family": "Chen",
                        "given": "Xiangzhou"
                    },
                    {
                        "family": "Ding",
                        "given": "Huixia"
                    },
                    {
                        "family": "He",
                        "given": "Xiao"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            12,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            12,
                            20
                        ]
                    ]
                },
                "abstract": "This paper focuses on the research of all kinds of data in the power grid business system, and carries on the research of intelligent analysis technology. It focuses on breaking the technical difficulties of intelligent and efficient analysis and mining, distributed multi-stream real-time processing, developing large-scale stock data for power and high-frequency incremental data efficient analysis system prototype, for wide-area distributed multi-stream real-time computing, from the data quick access to valuable information to solve the problems in the grid business system to improve the overall business performance, to achieve support power Data real-time processing and other technology applications.",
                "call-number": "10.1145/3175684.3175717",
                "collection-title": "BDIOT2017",
                "container-title": "Proceedings of the International Conference on Big Data and Internet of Thing",
                "DOI": "10.1145/3175684.3175717",
                "event-place": "London, United Kingdom",
                "ISBN": "9781450354301",
                "keyword": "data flow, data information, distributed, intelligence",
                "number-of-pages": "5",
                "page": "43–47",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on Real Time Processing and Intelligent Analysis Technology of Power Big Data",
                "URL": "https://doi.org/10.1145/3175684.3175717"
            }
        },
        {
            "10.1145/3224207.3224220": {
                "id": "10.1145/3224207.3224220",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bhuiyan",
                        "given": "Md Zakirul Alam"
                    },
                    {
                        "family": "Zaman",
                        "given": "Aliuz"
                    },
                    {
                        "family": "Wang",
                        "given": "Tian"
                    },
                    {
                        "family": "Wang",
                        "given": "Guojun"
                    },
                    {
                        "family": "Tao",
                        "given": "Hai"
                    },
                    {
                        "family": "Hassan",
                        "given": "Mohammad Mehedi"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            12
                        ]
                    ]
                },
                "abstract": "The increase in reported incidents of security breaches that compromise privacy of individuals requires us to question the current model used to collect patient information. What we have learned from bitcoin and the underlying blockchain technology is that there are ways for us to protect this information by using a distributed ledger. In this paper, we review and propose a solution that can be used to manage individual health data as well as cross-institutional sharing of this information. The solution will increase clinical effectiveness and an increase in research when the data is shared with researchers. The proposed system solution based on blockchain technology that includes providers, hospitals and clinic, insurance companies, and patients. All along the ownership of the data would belong to the individual or the patient. In the solution, we suggest to adopt a private blockchain solution where all participants are known and trusted, which allows for privacy and security of the data.",
                "call-number": "10.1145/3224207.3224220",
                "collection-title": "ICDPA 2018",
                "container-title": "Proceedings of the International Conference on Data Processing and Applications",
                "DOI": "10.1145/3224207.3224220",
                "event-place": "Guangdong, China",
                "ISBN": "9781450364188",
                "keyword": "big data, privacy, healthcare, Blockchain, patent data",
                "number-of-pages": "7",
                "page": "62–68",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Blockchain and Big Data to Transform the Healthcare",
                "URL": "https://doi.org/10.1145/3224207.3224220"
            }
        },
        {
            "10.1145/3012286": {
                "id": "10.1145/3012286",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Amato",
                        "given": "Flora"
                    },
                    {
                        "family": "Moscato",
                        "given": "Vincenzo"
                    },
                    {
                        "family": "Picariello",
                        "given": "Antonio"
                    },
                    {
                        "family": "Colace",
                        "given": "Francesco"
                    },
                    {
                        "family": "Santo",
                        "given": "Massimo De"
                    },
                    {
                        "family": "Schreiber",
                        "given": "Fabio A."
                    },
                    {
                        "family": "Tanca",
                        "given": "Letizia"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            4,
                            14
                        ]
                    ]
                },
                "abstract": "Information and Communication Technologies have radically changed the modern Cultural Heritage scenery: Simple traditional Information Systems supporting the management of cultural artifacts have left the place to complex systems that expose rich information extracted from heterogeneous data sources—like Sensor Networks, Social Networks, Digital Libraries, Multimedia Collections, Web Data Service, and so on—by means of sophisticated applications that enhance the users’ experience. In this article, we describe SCRABS, a Smart Context-awaRe Browsing assistant for cultural EnvironmentS. SCRABS has been developed during the Cultural Heritage Information Systems national project and promoted by DATABENC, the Cultural Heritage Technological District of the Campania Region, in Italy. SCRABS has been designed on top of a Big Data technological stack as the result of a multidisciplinary project carried out by a heterogeneous team of computer scientists, archeologists, architects, and experts in humanities. We describe the main ideas that support the system, showing its use in some real application scenarios located in the Paestum Archeologica Sites.",
                "call-number": "10.1145/3012286",
                "collection-number": "6",
                "container-title": "J. Comput. Cult. Herit.",
                "DOI": "10.1145/3012286",
                "ISSN": "1556-4673",
                "issue": "1",
                "keyword": "cultural heritage, Big data, multimedia",
                "number": "Article 6",
                "number-of-pages": "23",
                "page": "1–23",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "April 2017",
                "title": "Big Data Meets Digital Cultural Heritage: Design and Implementation of SCRABS, A Smart Context-awaRe Browsing Assistant for Cultural EnvironmentS",
                "URL": "https://doi.org/10.1145/3012286",
                "volume": "10"
            }
        },
        {
            "10.1145/2786451.2786482": {
                "id": "10.1145/2786451.2786482",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Weber",
                        "given": "Matthew S."
                    },
                    {
                        "family": "Nguyen",
                        "given": "Hai"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            28
                        ]
                    ]
                },
                "abstract": "This article analyzes the issue of degradation of data accuracy in large-scale longitudinal data sets. Recent research points to a number of issues with large-scale data, including problems of reliability, accuracy and quality over time. Simultaneously, large-scale data is increasingly being utilized in the social sciences. As scholars work to produce theoretically grounded research utilized \"small-scale\" methods, it is important for researchers to better understand the critical issues associated with the analysis of large-scale data. In order to illustrate the issues associated with this type of research, a case study analysis of archival Internet data is presented focusing on the issues of degradation of data accuracy over time. Suggestions for future studies are given.",
                "call-number": "10.1145/2786451.2786482",
                "collection-number": "6",
                "collection-title": "WebSci '15",
                "container-title": "Proceedings of the ACM Web Science Conference",
                "DOI": "10.1145/2786451.2786482",
                "event-place": "Oxford, United Kingdom",
                "ISBN": "9781450336727",
                "keyword": "Keywords are your own designated keywords",
                "number": "Article 6",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data? Big Issues Degradation in Longitudinal Data and Implications for Social Sciences",
                "URL": "https://doi.org/10.1145/2786451.2786482"
            }
        },
        {
            "10.1145/3265689.3265721": {
                "id": "10.1145/3265689.3265721",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Pan",
                        "given": "Zhiwen"
                    },
                    {
                        "family": "Ji",
                        "given": "Wen"
                    },
                    {
                        "family": "Chen",
                        "given": "Yiqiang"
                    },
                    {
                        "family": "Dai",
                        "given": "Lianjun"
                    },
                    {
                        "family": "Zhang",
                        "given": "Jun"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            7,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            7,
                            28
                        ]
                    ]
                },
                "abstract": "The disability datasets is the datasets which contains the information of disabled populations. By analyzing these datasets, professionals who work with disabled populations can have a better understanding of how to make working plans and policies, so that they support the populations in a better way. In this paper, we proposed a big data management and mining approach for disability datasets. The contributions of this paper are follows: 1) our proposed approach can improve the quality of disability data by estimating miss attribute values and detecting anomaly and low-quality data instances. 2) Our proposed approach can explore useful patterns which reflect the correlation, association and interactional between the disability data attributes. Experiments are conducted at the end to evaluate the performance of our approach.",
                "call-number": "10.1145/3265689.3265721",
                "collection-number": "32",
                "collection-title": "ICCSE'18",
                "container-title": "Proceedings of the 3rd International Conference on Crowd Science and Engineering",
                "DOI": "10.1145/3265689.3265721",
                "event-place": "Singapore, Singapore",
                "ISBN": "9781450365871",
                "keyword": "Disability Dataset, Data Management, Disability Population, Data Mining, Decision support systems, Big data analytics",
                "number": "Article 32",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data Management and Analytics for Disability Datasets",
                "URL": "https://doi.org/10.1145/3265689.3265721"
            }
        },
        {
            "10.1145/3307681.3325410": {
                "id": "10.1145/3307681.3325410",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Fox",
                        "given": "Geoffrey C."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            6,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            6,
                            17
                        ]
                    ]
                },
                "abstract": "High-Performance Computing (HPC) and Cyberinfrastructure have played a leadership role in computational science even since the start of the NSF computing centers program. Thirty years ago parallel computing was a centerpiece of computer science research. Naively Big Data surely requires HPC to be processed, and transformational Big Data technology such as Hadoop and Spark exploit parallelism to success. Nevertheless, the HPC community does not appear to be thriving as a leader in Data Science while parallel computing is no longer a centerpiece. Some reasons for this are the dominant presence of Industry in technology futures and the universal fascination with Artificial Intelligence and Machine Learning. Maybe the pendulum will swing back a bit, but I expect the \"AI first\" philosophy to dominate in the foreseeable future. Thus I describe a future where HPC thrives in collaboration with Industry and AI. In particular, I discuss the promise of MLforHPC (AI for systems) and HPCforML (systems for AI).",
                "call-number": "10.1145/3307681.3325410",
                "collection-title": "HPDC '19",
                "container-title": "Proceedings of the 28th International Symposium on High-Performance Parallel and Distributed Computing",
                "DOI": "10.1145/3307681.3325410",
                "event-place": "Phoenix, AZ, USA",
                "ISBN": "9781450366700",
                "keyword": "big data, HPC, data science, computational science",
                "number-of-pages": "1",
                "page": "145",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Perspectives on High-Performance Computing in a Big Data World",
                "URL": "https://doi.org/10.1145/3307681.3325410"
            }
        },
        {
            "10.1145/2699026.2699116": {
                "id": "10.1145/2699026.2699116",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kuzu",
                        "given": "Mehmet"
                    },
                    {
                        "family": "Islam",
                        "given": "Mohammad Saiful"
                    },
                    {
                        "family": "Kantarcioglu",
                        "given": "Murat"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            3,
                            2
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            3,
                            2
                        ]
                    ]
                },
                "abstract": "Nowadays, huge amount of documents are increasingly transferred to the remote servers due to the appealing features of cloud computing. On the other hand, privacy and security of the sensitive information in untrusted cloud environment is a big concern. To alleviate such concerns, encryption of sensitive data before its transfer to the cloud has become an important risk mitigation option. Encrypted storage provides protection at the expense of a significant increase in the data management complexity. For effective management, it is critical to provide efficient selective document retrieval capability on the encrypted collection. In fact, considerable amount of searchable symmetric encryption schemes have been designed in the literature to achieve this task. However, with the emergence of big data everywhere, available approaches are insufficient to address some crucial real-world problems such as scalability.In this study, we focus on practical aspects of a secure keyword search mechanism over encrypted data. First, we propose a provably secure distributed index along with a parallelizable retrieval technique that can easily scale to big data. Second, we integrate authorization into the search scheme to limit the information leakage in multi-user setting where users are allowed to access only particular documents. Third, we offer efficient updates on the distributed secure index. In addition, we conduct extensive empirical analysis on a real dataset to illustrate the efficiency of the proposed practical techniques.",
                "call-number": "10.1145/2699026.2699116",
                "collection-title": "CODASPY '15",
                "container-title": "Proceedings of the 5th ACM Conference on Data and Application Security and Privacy",
                "DOI": "10.1145/2699026.2699116",
                "event-place": "San Antonio, Texas, USA",
                "ISBN": "9781450331913",
                "keyword": "searchable encryption, security, privacy",
                "number-of-pages": "8",
                "page": "271–278",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Distributed Search over Encrypted Big Data",
                "URL": "https://doi.org/10.1145/2699026.2699116"
            }
        },
        {
            "10.1109/SEAMS.2017.20": {
                "id": "10.1109/SEAMS.2017.20",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Schmid",
                        "given": "Sanny"
                    },
                    {
                        "family": "Gerostathopoulos",
                        "given": "Ilias"
                    },
                    {
                        "family": "Prehofer",
                        "given": "Christian"
                    },
                    {
                        "family": "Bures",
                        "given": "Tomas"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            20
                        ]
                    ]
                },
                "abstract": "In this paper, we focus on self-adaptation in large-scale software-intensive distributed systems. The main problem in making such systems self-adaptive is that their adaptation needs to consider the current situation in the whole system. However, developing a complete and accurate model of such systems at design time is very challenging. To address this, we present a novel approach where the system model consists only of the essential input and output parameters. Furthermore, Big Data analytics is used to guide self-adaptation based on a continuous stream of operational data. We provide a concrete model problem and a reference implementation of it that can be used as a case study for evaluating different self-adaptation techniques pertinent to complex large-scale distributed systems. We also provide an extensible tool for endorsing an arbitrary system with self-adaptation based on analysis of operational data coming from the system. To illustrate the tool, we apply it on the model problem.",
                "call-number": "10.1109/SEAMS.2017.20",
                "collection-title": "SEAMS '17",
                "container-title": "Proceedings of the 12th International Symposium on Software Engineering for Adaptive and Self-Managing Systems",
                "DOI": "10.1109/SEAMS.2017.20",
                "event-place": "Buenos Aires, Argentina",
                "ISBN": "9781538615508",
                "keyword": "big data analytics, model problem, self-adaptation",
                "number-of-pages": "7",
                "page": "102–108",
                "publisher": "IEEE Press",
                "title": "Self-adaptation based on big data analytics: a model problem and tool",
                "URL": "https://doi.org/10.1109/SEAMS.2017.20"
            }
        },
        {
            "10.1145/3374587.3374650": {
                "id": "10.1145/3374587.3374650",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Shen",
                        "given": "Shaoyi"
                    },
                    {
                        "family": "Li",
                        "given": "Bin"
                    },
                    {
                        "family": "Li",
                        "given": "Situo"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            12,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            12,
                            6
                        ]
                    ]
                },
                "abstract": "A data revolution has been leading by big data, which have the extremely profound influence on the economic, social development and public life. This paper introduces the meaning of big data, and discusses the innovation and opportunity of enterprise under the perspective of big data. According to the information architecture, this paper supplies the basic construction of enterprise big data analysis platform, and suggests the strategy of application, which have certain realistic directive significance.",
                "call-number": "10.1145/3374587.3374650",
                "collection-title": "CSAI2019",
                "container-title": "Proceedings of the 2019 3rd International Conference on Computer Science and Artificial Intelligence",
                "DOI": "10.1145/3374587.3374650",
                "event-place": "Normal, IL, USA",
                "ISBN": "9781450376273",
                "keyword": "Construction, Distributed, Data asset, Shared, Analysis of big data",
                "number-of-pages": "5",
                "page": "54–58",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Construction and Application of Big Data Analysis Platform for Enterprise",
                "URL": "https://doi.org/10.1145/3374587.3374650"
            }
        },
        {
            "10.1145/3383923.3383964": {
                "id": "10.1145/3383923.3383964",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Xu",
                        "given": "Qingzheng"
                    },
                    {
                        "family": "Wang",
                        "given": "Na"
                    },
                    {
                        "family": "Tian",
                        "given": "Balin"
                    },
                    {
                        "family": "Xing",
                        "given": "Lipeng"
                    },
                    {
                        "family": "Bai",
                        "given": "Wenhua"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            2,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            2,
                            11
                        ]
                    ]
                },
                "abstract": "The advent of the era of big data provides some new ideas for the reform and development of higher education. In this paper, the importance of educational big data is analyzed from six aspects: improving the effectiveness of teaching and learning, promoting scientific decision-making in education, completing the quality monitoring system, facilitating comprehensive evaluation of education quality, promoting the popularization and personalization of education, and improving personalized teaching. Then, some challenges faced in the application process of education big data are analyzed, including thinking mode, data sharing, data technology, talent support, and data security and privacy. Based on them, several feasible countermeasures are proposed from the aspects of enhancing data awareness, realizing open sharing, accelerating professional talent training and strengthening privacy protection. At last, some research directions of educational big data are put forward.",
                "call-number": "10.1145/3383923.3383964",
                "collection-title": "ICEIT 2020",
                "container-title": "Proceedings of the 2020 9th International Conference on Educational and Information Technology",
                "DOI": "10.1145/3383923.3383964",
                "event-place": "Oxford, United Kingdom",
                "ISBN": "9781450375085",
                "keyword": "challenges, higher education, Big data, countermeasures",
                "number-of-pages": "4",
                "page": "215–218",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Challenges and Countermeasures of Education in the Era of Big Data",
                "URL": "https://doi.org/10.1145/3383923.3383964"
            }
        },
        {
            "10.1145/3019612.3019700": {
                "id": "10.1145/3019612.3019700",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Taherkordi",
                        "given": "Amir"
                    },
                    {
                        "family": "Eliassen",
                        "given": "Frank"
                    },
                    {
                        "family": "Horn",
                        "given": "Geir"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            4,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            4,
                            3
                        ]
                    ]
                },
                "abstract": "The large-scale deployments of Internet of Things (IoT) systems have introduced several new challenges in terms of processing their data. The massive amount of IoT-generated data requires design solutions to speed up data processing, scale up with the data volume and improve data adaptability and extensibility. Beyond existing techniques for IoT data collection, filtering, and analytics, innovative service computing technologies are required for provisioning data-centric and scalable IoT services. This paper presents a service-oriented design model and framework for realizing scalable and efficient acquisition, processing and integration of data-centric IoT services. In this approach, data-centric IoT services are organized in a service integrating tree structure, adhering to the architecture of many large-scale IoT systems, including recent fog-based IoT computing models. A service node in the tree is called a Big Service and acts as an integrator, collecting data from lower level Big Services, processing them, and delivering the result to higher level IoT Big Services. The service tree thereby encapsulates required data processing functions in a hierarchical manner in order to achieve scalable and real-time data collection and processing. We have implemented the IoT Big Services framework leveraging a popular cloud-based service and data platform called Firebase, and evaluated its performance in terms of real-time requirements.",
                "call-number": "10.1145/3019612.3019700",
                "collection-title": "SAC '17",
                "container-title": "Proceedings of the Symposium on Applied Computing",
                "DOI": "10.1145/3019612.3019700",
                "event-place": "Marrakech, Morocco",
                "ISBN": "9781450344869",
                "keyword": "internet of things, big data, big services",
                "number-of-pages": "7",
                "page": "485–491",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "From IoT big data to IoT big services",
                "URL": "https://doi.org/10.1145/3019612.3019700"
            }
        },
        {
            "10.1145/2815782.2815793": {
                "id": "10.1145/2815782.2815793",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Malaka",
                        "given": "Iman"
                    },
                    {
                        "family": "Brown",
                        "given": "Irwin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            9,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            9,
                            28
                        ]
                    ]
                },
                "abstract": "The purpose of this interpretive study was to explore the challenges to the adoption of Big Data Analytics (BDA) in organisations. The Technology-Organisation-Environment (TOE) model was used to guide the study. Data was collected from a large telecommunication organization in South Africa. Seven participants, from both Information Technology (IT) and business were interviewed to gain a holistic overview of challenges towards the adoption of BDA. An inductive approach was used for analysis. Findings revealed technological challenges to the adoption of BDA as being Data Integration; Data Privacy; Return on Investment; Data Quality; Cost; Data Integrity; and Performance and Scalability. From the organizational perspective, the major challenges were Ownership and Control; Skills Shortages; Business Focus and Prioritisation; Training and Exposure; Silos; and Unclear Processes. From the environmental context there were no major challenges highlighted. Organisational challenges were deemed to be the major inhibitors to adoption of BDA",
                "call-number": "10.1145/2815782.2815793",
                "collection-number": "27",
                "collection-title": "SAICSIT '15",
                "container-title": "Proceedings of the 2015 Annual Research Conference on South African Institute of Computer Scientists and Information Technologists",
                "DOI": "10.1145/2815782.2815793",
                "event-place": "Stellenbosch, South Africa",
                "ISBN": "9781450336833",
                "keyword": "Technology Adoption, Big Data Analytics, South Africa, Big Data",
                "number": "Article 27",
                "number-of-pages": "9",
                "page": "1–9",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Challenges to the Organisational Adoption of Big Data Analytics: A Case Study in the South African Telecommunications Industry",
                "URL": "https://doi.org/10.1145/2815782.2815793"
            }
        },
        {
            "10.1145/2331042.2331047": {
                "id": "10.1145/2331042.2331047",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Bhambhri",
                        "given": "Anjul"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            9,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/2331042.2331047",
                "container-title": "XRDS",
                "DOI": "10.1145/2331042.2331047",
                "ISSN": "1528-4972",
                "issue": "1",
                "number-of-pages": "1",
                "page": "9",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "Fall 2012",
                "title": "Six tips for students interested in big data analytics",
                "URL": "https://doi.org/10.1145/2331042.2331047",
                "volume": "19"
            }
        },
        {
            "10.1145/3141248": {
                "id": "10.1145/3141248",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Cappiello",
                        "given": "C."
                    },
                    {
                        "family": "Cerletti",
                        "given": "C."
                    },
                    {
                        "family": "Fratto",
                        "given": "C."
                    },
                    {
                        "family": "Pernici",
                        "given": "B."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            1,
                            15
                        ]
                    ]
                },
                "abstract": "Data quality has gained momentum among organizations upon the realization that poor data quality might cause failures and/or inefficiencies, thus compromising business processes and application results. However, enterprises often adopt data quality assessment and improvement methods based on practical and empirical approaches without conducting a rigorous analysis of the data quality issues and outcome of the enacted data quality improvement practices. In particular, data quality management, especially the identification of the data quality dimensions to be monitored and improved, is performed by knowledge workers on the basis of their skills and experience. Control methods are therefore designed on the basis of expected and evident quality problems; thus, these methods may not be effective in dealing with unknown and/or unexpected problems. This article aims to provide a methodology, based on fault injection, for validating the data quality actions used by organizations. We show how it is possible to check whether the adopted techniques properly monitor the real issues that may damage business processes. At this stage, we focus on scoring processes, i.e., those in which the output represents the evaluation or ranking of a specific object. We show the effectiveness of our proposal by means of a case study in the financial risk management area.",
                "call-number": "10.1145/3141248",
                "collection-number": "11",
                "container-title": "J. Data and Information Quality",
                "DOI": "10.1145/3141248",
                "ISSN": "1936-1955",
                "issue": "2",
                "keyword": "assessment, Data quality, decision support, decision processes",
                "number": "Article 11",
                "number-of-pages": "27",
                "page": "1–27",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "June 2017",
                "title": "Validating Data Quality Actions in Scoring Processes",
                "URL": "https://doi.org/10.1145/3141248",
                "volume": "9"
            }
        },
        {
            "10.1145/2168931.2168932": {
                "id": "10.1145/2168931.2168932",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Wakkary",
                        "given": "Ron"
                    },
                    {
                        "family": "Stolterman",
                        "given": "Erik"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            5,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/2168931.2168932",
                "container-title": "interactions",
                "DOI": "10.1145/2168931.2168932",
                "ISSN": "1072-5520",
                "issue": "3",
                "number-of-pages": "1",
                "page": "5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "May + June 2012",
                "title": "WELCOME Interacting with big data",
                "URL": "https://doi.org/10.1145/2168931.2168932",
                "volume": "19"
            }
        },
        {
            "10.1145/3134271.3134300": {
                "id": "10.1145/3134271.3134300",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhang",
                        "given": "Yong'an"
                    },
                    {
                        "family": "Zhang",
                        "given": "Yuxiaodan"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            7,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            7,
                            23
                        ]
                    ]
                },
                "abstract": "Based on literatures relevant to application of big data included in the Web of Science database as the data sources, this paper used CiteSpace as the research tool to visualize the distribution of keywords, evolution of hot spots and evolution rules. After that, it analyzed the hot spots, contexts, tool technologies and application fields of application of big data, so as to reveal the current situation of researches. The study indicates that existing researches involve a wide range of disciplines and technology is still the center of current researches. At present, the majority of the studies all focused on the field of management, network, information, medicine, health, environment, energy and etc. Overall, technology is still the important part in current research on application of big data. Technical tools, such as data mining, algorithms, cloud computing, mapreduce, hadoop, machine learning all provide strong supports for the practical application of big data.",
                "call-number": "10.1145/3134271.3134300",
                "collection-title": "ICBIM 2017",
                "container-title": "Proceedings of the International Conference on Business and Information Management",
                "DOI": "10.1145/3134271.3134300",
                "event-place": "Bei Jing, China",
                "ISBN": "9781450352765",
                "keyword": "CiteSpace, Application, Knowledge map, Big data",
                "number-of-pages": "5",
                "page": "126–130",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on Evolution and Visualization Analysis of Application of Big Data",
                "URL": "https://doi.org/10.1145/3134271.3134300"
            }
        },
        {
            "10.1145/3041021.3054141": {
                "id": "10.1145/3041021.3054141",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chen",
                        "given": "Kuan-Ting"
                    },
                    {
                        "family": "Luo",
                        "given": "Jiebo"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            4,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            4,
                            3
                        ]
                    ]
                },
                "abstract": "With the prevalence of e-commence websites and the ease of online shopping, consumers are embracing huge amounts of various options in products. Undeniably, shopping is one of the most essential activities in our society and studying consumer's shopping behavior is important for the industry as well as sociology and psychology. Indisputable, one of the most popular e-commerce categories is clothing business. There arises the needs for analysis of popular and attractive clothing features which could further boost many emerging applications, such as clothing recommendation and advertising. In this work, we design a novel system that consists of three major components: 1) exploring and organizing a large-scale clothing dataset from a online shopping website, 2) pruning and extracting images of best-selling products in clothing item data and user transaction history, and 3) utilizing a machine learning based approach to discovering fine-grained clothing attributes as the representative and discriminative characteristics of popular clothing style elements. Through the experiments over a large-scale online clothing shopping dataset, we demonstrate the effectiveness of our proposed system, and obtain useful insights on clothing consumption trends and profitable clothing features.",
                "call-number": "10.1145/3041021.3054141",
                "collection-title": "WWW '17 Companion",
                "container-title": "Proceedings of the 26th International Conference on World Wide Web Companion",
                "DOI": "10.1145/3041021.3054141",
                "event-place": "Perth, Australia",
                "ISBN": "9781450349147",
                "keyword": "clothing features, big data, online shopping, image analysis, data mining",
                "number-of-pages": "8",
                "page": "15–22",
                "publisher": "International World Wide Web Conferences Steering Committee",
                "publisher-place": "Republic and Canton of Geneva, CHE",
                "title": "When Fashion Meets Big Data: Discriminative Mining of Best Selling Clothing Features",
                "URL": "https://doi.org/10.1145/3041021.3054141"
            }
        },
        {
            "10.1109/CCGRID.2017.55": {
                "id": "10.1109/CCGRID.2017.55",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Caíno-Lores",
                        "given": "Silvina"
                    },
                    {
                        "family": "Isaila",
                        "given": "Florin"
                    },
                    {
                        "family": "Carretero",
                        "given": "Jesús"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            14
                        ]
                    ]
                },
                "abstract": "Nowadays there is a raising interest in bridging the gap between Big Data application models and data-intensive HPC. This work explores the effects that Big Data-inspired paradigms could have in current scientific applications through the evaluation of a real-world application from the hydrology domain. This evaluation led to experience that portrayed the key aspects of the HPC and Big Data paradigms that made them successful in their respective worlds. With this information, we established a research roadmap to build a platform suitable for HPC hybrid applications, with a focus on efficient data management and fault-tolerance.",
                "call-number": "10.1109/CCGRID.2017.55",
                "collection-title": "CCGrid '17",
                "container-title": "Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing",
                "DOI": "10.1109/CCGRID.2017.55",
                "event-place": "Madrid, Spain",
                "ISBN": "9781509066100",
                "keyword": "high-performance computing, big data, data management, data-intensive computing, scientific computing",
                "number-of-pages": "4",
                "page": "719–722",
                "publisher": "IEEE Press",
                "title": "Data-Aware Support for Hybrid HPC and Big Data Applications",
                "URL": "https://doi.org/10.1109/CCGRID.2017.55"
            }
        },
        {
            "10.1145/1536616.1536632": {
                "id": "10.1145/1536616.1536632",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Jacobs",
                        "given": "Adam"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2009,
                            8,
                            1
                        ]
                    ]
                },
                "abstract": "Scale up your datasets enough and your apps come undone. What are the typical problems and where do the bottlenecks surface?",
                "call-number": "10.1145/1536616.1536632",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/1536616.1536632",
                "ISSN": "0001-0782",
                "issue": "8",
                "number-of-pages": "9",
                "page": "36–44",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "August 2009",
                "title": "The pathologies of big data",
                "URL": "https://doi.org/10.1145/1536616.1536632",
                "volume": "52"
            }
        },
        {
            "10.1145/2617660": {
                "id": "10.1145/2617660",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Wright",
                        "given": "Alex"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            7,
                            1
                        ]
                    ]
                },
                "abstract": "Next-generation scientific instruments are forcing researchers to question the limits of massively parallel computing.",
                "call-number": "10.1145/2617660",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/2617660",
                "ISSN": "0001-0782",
                "issue": "7",
                "number-of-pages": "3",
                "page": "13–15",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "July 2014",
                "title": "Big data meets big science",
                "URL": "https://doi.org/10.1145/2617660",
                "volume": "57"
            }
        },
        {
            "10.1109/CCGRID.2018.00052": {
                "id": "10.1109/CCGRID.2018.00052",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Al-Jaroodi",
                        "given": "Jameela"
                    },
                    {
                        "family": "Mohamed",
                        "given": "Nader"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            1
                        ]
                    ]
                },
                "abstract": "A smart city has recently become an aspiration for many cities around the world. These cities are looking to apply the smart city concept to improve sustainability, quality of life for residents, and economic development. The smart city concept depends on employing a wide range of advanced technologies to improve the performance of various services and activities such as transportation, energy, healthcare, and education, while at the same time improve the city's resources utilization and initiate new business opportunities. One of the promising technologies to support such efforts is the big data technology. Effective and intelligent use of big data accumulated over time in various sectors can offer many advantages to enhance decision making in smart cities. In this paper we identify the different types of decision making processes involved in smart cities. Then we propose a service-oriented architecture to support big data analytics for decision making in smart cities. This architecture allows for integrating different technologies such as fog and cloud computing to support different types of analytics and decision-making operations needed to effectively utilize available big data. It provides different functions and capabilities to use big data and provide smart capabilities as services that the architecture supports. As a result, different big data applications will be able to access and use these services for varying proposes within the smart city.",
                "call-number": "10.1109/CCGRID.2018.00052",
                "collection-title": "CCGrid '18",
                "container-title": "Proceedings of the 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing",
                "DOI": "10.1109/CCGRID.2018.00052",
                "event-place": "Washington, District of Columbia",
                "ISBN": "9781538658154",
                "keyword": "service-oriented architecture, smart city, fog computing, big data, cloud computing, middleware",
                "number-of-pages": "8",
                "page": "633–640",
                "publisher": "IEEE Press",
                "title": "Service-oriented architecture for big data analytics in smart cities",
                "URL": "https://doi.org/10.1109/CCGRID.2018.00052"
            }
        },
        {
            "10.1145/3505745.3505749": {
                "id": "10.1145/3505745.3505749",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "An",
                        "given": "Qing"
                    },
                    {
                        "family": "Chen",
                        "given": "Xijiang"
                    },
                    {
                        "family": "Tang",
                        "given": "Suixin"
                    },
                    {
                        "family": "Deng",
                        "given": "Qian"
                    },
                    {
                        "family": "Liu",
                        "given": "Fenggang"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            25
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            9,
                            25
                        ]
                    ]
                },
                "abstract": "Based on the in-depth discussion of the uncertain influencing factors of dangerous chemicals in the process of road transportation, the historical data of dangerous chemicals road transportation accidents are sorted out, and the variable consistency dominance rough set theory (VC-DRSA) is proposed to quantitatively analyze the importance of uncertain factors of environmental risk in dangerous chemicals transportation, Furthermore, it reveals the causal relationship between risk factors and risks and its irreducible rules, which provides a certain theoretical basis for alleviating and preventing the risk of road transportation of dangerous chemicals",
                "call-number": "10.1145/3505745.3505749",
                "collection-title": "ICBDR 2021",
                "container-title": "2021 the 5th International Conference on Big Data Research (ICBDR)",
                "DOI": "10.1145/3505745.3505749",
                "event-place": "Tokyo, Japan",
                "ISBN": "9781450384339",
                "keyword": "variable consistency dominance relation, risk analysis, Hazardous chemicals, uncertain factors, rough set theory (VC-DRSA)",
                "number-of-pages": "5",
                "page": "23–27",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Risk Monitoring analysis of dangerous chemical transportation on highway based on big Data",
                "URL": "https://doi.org/10.1145/3505745.3505749"
            }
        },
        {
            "10.1145/3501409.3501593": {
                "id": "10.1145/3501409.3501593",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Diao",
                        "given": "Yanhua"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            10,
                            22
                        ]
                    ]
                },
                "abstract": "In the practical application of existing big data tourism prediction, there are some practical problems, such as complicated data sources and difficult fusion, low prediction accuracy and poor guiding practice effect. In view of this situation, this paper intends to build a tourism big data index prediction model suitable for the characteristics of tourism development through core data extraction, multi-source data fusion, complex data modeling and other key technologies. With the help of the improved tourism prediction model based on multi-source big data fusion technology, the tourist flow and consumption characteristics of Shandong province are more accurately identified and predicted. It can provide help for optimizing public service of tourism, strengthening early warning of tourist flow and improving marketing strategy of tourist destination. This study innovatively supplements the effective integration theory of multi-source tourism big data and the organic integration theory of big data and traditional sampling survey data. At the same time, the relevant methods of tourism big data forecasting model are extended.",
                "call-number": "10.1145/3501409.3501593",
                "collection-title": "EITCE 2021",
                "container-title": "Proceedings of the 2021 5th International Conference on Electronic Information Technology and Computer Engineering",
                "DOI": "10.1145/3501409.3501593",
                "event-place": "Xiamen, China",
                "ISBN": "9781450384322",
                "keyword": "Tourism prediction, Multi-source big data, Data fusion technology",
                "number-of-pages": "7",
                "page": "1030–1036",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Tourism Prediction based on Multi-source Big Data Fusion Technology",
                "URL": "https://doi.org/10.1145/3501409.3501593"
            }
        },
        {
            "10.1145/2345316.2345322": {
                "id": "10.1145/2345316.2345322",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Lopez",
                        "given": "Xavier"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            7,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            7,
                            1
                        ]
                    ]
                },
                "abstract": "Today's business and government organizations are challenged when trying to manage and analyze information from enterprise databases, streaming servers, social media and open source. This is compounded by the complexity of integrating diverse data types (relational, text, spatial, images, spreadsheets) and their representations (customers, products, suppliers, events, and locations) - all of which need to be understood and re-purposed in different contexts. Identifying meaningful patterns across these different information sources is non-trivial. Moreover, conventional IT tools, such as conventional data warehousing and business intelligence alone, are insufficient at handling the volumes, velocity and variety of content at hand. A new framework and associated tools are needed. Dr. Lopez outlines how data scientists and analysts are applying Spatial and Semantic Web concepts to make sense of this Big Data stream. He will describe new approaches oriented toward search, discovery, linking, and analyzing information on the Web, and throughout the enterprise. The role of Map Reduce is described, as is importance of engineered systems to simplify the creation and configuration of Big Data environments. The key take away is use of spatial and linked open data concepts to enhance content alignment, interoperability, discovery and analytics in the Big Data stream.",
                "call-number": "10.1145/2345316.2345322",
                "collection-number": "5",
                "collection-title": "COM.Geo '12",
                "container-title": "Proceedings of the 3rd International Conference on Computing for Geospatial Research and Applications",
                "DOI": "10.1145/2345316.2345322",
                "event-place": "Washington, D.C., USA",
                "ISBN": "9781450311137",
                "number": "Article 5",
                "number-of-pages": "1",
                "page": "1",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data and advanced spatial analytics",
                "URL": "https://doi.org/10.1145/2345316.2345322"
            }
        },
        {
            "10.1145/3478432.3499100": {
                "id": "10.1145/3478432.3499100",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhu",
                        "given": "Hongwei"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            3,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            3,
                            3
                        ]
                    ]
                },
                "abstract": "Data quality is important to analytics; data preparation usually involves data cleaning and is often the most time-consuming part of analytics projects. When the topic is left to the discretion of individual courses in an analytics program, students often end up with light exposure to the topic. Instead, a course on data quality in analytics has been designed and implemented. Organized in eight modules, the first part of the course covers data preparation and preprocessing. This prepares students with the ability to tackle real datasets in other analytics courses. The second part covers analytics for data quality where algorithms for detecting and resolving data quality issues are covered. The third part addresses large scale and engineering issues of analytics practice where data collection needs to be managed and data quality tasks must be part of the pipeline.",
                "call-number": "10.1145/3478432.3499100",
                "collection-title": "SIGCSE 2022",
                "container-title": "Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V. 2",
                "DOI": "10.1145/3478432.3499100",
                "event-place": "Providence, RI, USA",
                "ISBN": "9781450390712",
                "keyword": "data quality, curriculum, data analytics, data preparation",
                "number-of-pages": "1",
                "page": "1106",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A Course on Data Quality in Analytics",
                "URL": "https://doi.org/10.1145/3478432.3499100"
            }
        },
        {
            "10.1145/2641398": {
                "id": "10.1145/2641398",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Lehikoinen",
                        "given": "Juha"
                    },
                    {
                        "family": "Koistinen",
                        "given": "Ville"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/2641398",
                "container-title": "interactions",
                "DOI": "10.1145/2641398",
                "ISSN": "1072-5520",
                "issue": "5",
                "number-of-pages": "4",
                "page": "38–41",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "September + October 2014",
                "title": "In big data we trust?",
                "URL": "https://doi.org/10.1145/2641398",
                "volume": "21"
            }
        },
        {
            "10.1145/2345316.2345329": {
                "id": "10.1145/2345316.2345329",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Pino",
                        "given": "Robinson E."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            7,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            7,
                            1
                        ]
                    ]
                },
                "abstract": "The ever growing necessity for Big Data processing within the industry, government, and specially within defense applications causes the need and requirement for the fast development of new technologies. In addition, the protection of Big Data can be a serious problem because security is commonly an afterthought during technology development, and the exponentially increasing rate at which new data is generated presents many challenges. Although conventional Turing computation has been remarkably successful, it does not scale well and is failing to adapt to novel application domains in cyberspace. Fortunately, Turing formalism for computation represents only a subset of all possible computational possibilities. Unconventional computing - the quest for new algorithms and physical implementations of novel computing paradigms based on and inspired by principles of information processing in physical and biological systems - may help to solve some of the information overflow problems facing the Defense community. These and other topics will be covered by our diverse panel of experts.",
                "call-number": "10.1145/2345316.2345329",
                "collection-number": "10",
                "collection-title": "COM.Geo '12",
                "container-title": "Proceedings of the 3rd International Conference on Computing for Geospatial Research and Applications",
                "DOI": "10.1145/2345316.2345329",
                "event-place": "Washington, D.C., USA",
                "ISBN": "9781450311137",
                "number": "Article 10",
                "number-of-pages": "1",
                "page": "1",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Cloud/big data computing for defense",
                "URL": "https://doi.org/10.1145/2345316.2345329"
            }
        },
        {
            "10.1145/3193063.3193069": {
                "id": "10.1145/3193063.3193069",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Cheng",
                        "given": "Susu"
                    },
                    {
                        "family": "Zhao",
                        "given": "Haijun"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            2,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            2,
                            26
                        ]
                    ]
                },
                "abstract": "The major premise of big data circulation is to identify the ownership of data resource. This paper summed some feasible techniques and methods for confirming big data property which are data citation technology, data provenance technology, data reversible hiding technology, computer forensic technology and block chain technology. The ownership of information property which from different sizes, different formats and different storage condition on distributed heterogeneous platforms can be confirmed by comprehensive application of these techniques and methods based on the coupling interface between them in the practice of big data.",
                "call-number": "10.1145/3193063.3193069",
                "collection-title": "ICIIT 2018",
                "container-title": "Proceedings of the 2018 International Conference on Intelligent Information Technology",
                "DOI": "10.1145/3193063.3193069",
                "event-place": "Ha Noi, Viet Nam",
                "ISBN": "9781450363785",
                "keyword": "Big Data, Method for confirming information property rights, Information property index, Confirmation of Information Property",
                "number-of-pages": "6",
                "page": "59–64",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "An Overview of Techniques for Confirming Big Data Property Rights",
                "URL": "https://doi.org/10.1145/3193063.3193069"
            }
        },
        {
            "10.1145/3205977.3205998": {
                "id": "10.1145/3205977.3205998",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Colombo",
                        "given": "Pietro"
                    },
                    {
                        "family": "Ferrari",
                        "given": "Elena"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            6,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            6,
                            7
                        ]
                    ]
                },
                "abstract": "Data security and privacy issues are magnified by the volume, the variety, and the velocity of Big Data and by the lack, up to now, of a standard data model and related data manipulation language. In this paper, we focus on one of the key data security services, that is, access control, by highlighting the differences with traditional data management systems and describing a set of requirements that any access control solution for Big Data platforms may fulfill. We then describe the state of the art and discuss open research issues.",
                "call-number": "10.1145/3205977.3205998",
                "collection-title": "SACMAT '18",
                "container-title": "Proceedings of the 23nd ACM on Symposium on Access Control Models and Technologies",
                "DOI": "10.1145/3205977.3205998",
                "event-place": "Indianapolis, Indiana, USA",
                "ISBN": "9781450356664",
                "keyword": "big data, access control, privacy, NOSQL data management systems",
                "number-of-pages": "8",
                "page": "185–192",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Access Control in the Era of Big Data: State of the Art and Research Directions",
                "URL": "https://doi.org/10.1145/3205977.3205998"
            }
        },
        {
            "10.1145/2675743.2771878": {
                "id": "10.1145/2675743.2771878",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhang",
                        "given": "Tianning"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            24
                        ]
                    ]
                },
                "abstract": "Event-driven enterprise IT architectures are typically based on message broker systems. Most broker systems focus on functional decoupling, and on the fast and reliable delivery of events towards event consumers. Such consumer-centricity eases the development and deployment of consumers applications. However, especially within a web-based big data enterprise we typically have relatively small number of stable producers that is based on the core enterprise business model, and a higher, dynamic number of highly heterogeneous consumers. With the consumer-centric view of event messaging, problems with some consumers can easily lead to the congestion or service degradation of the whole messaging system, and can affect the operations of the producers or other critical consumers. To avoid such non-functional tight coupling, we propose in this paper a producer-centric architecture for messaging backbone in a big data enterprise. Within this architecture the broker infrastructure concentrates on the event production activities and pushes the delivery functionalities towards the consumer clients and applications. In this way we can achieve a higher level of SOA loose coupling, higher reliability and higher maintainability of the enterprise infrastructure.",
                "call-number": "10.1145/2675743.2771878",
                "collection-title": "DEBS '15",
                "container-title": "Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems",
                "DOI": "10.1145/2675743.2771878",
                "event-place": "Oslo, Norway",
                "ISBN": "9781450332866",
                "keyword": "event messaging, kafka, reliability, producer-centricity, big data, event backbone, redis, NoSQL",
                "number-of-pages": "8",
                "page": "226–233",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Reliable event messaging in big data enterprises: looking for the balance between producers and consumers",
                "URL": "https://doi.org/10.1145/2675743.2771878"
            }
        },
        {
            "10.1145/3415958.3433077": {
                "id": "10.1145/3415958.3433077",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Suleykin",
                        "given": "Alexander"
                    },
                    {
                        "family": "Bakhtadze",
                        "given": "Natalya"
                    },
                    {
                        "family": "Panfilov",
                        "given": "Peter"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            11,
                            2
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            11,
                            2
                        ]
                    ]
                },
                "abstract": "In this paper, Big-Data Driven Digital Ecosystem Framework (BDDDEF) for Online Predictive Control Systems is created. The proposed framework consists of different Agents, where each Agent is a distributed and virtual service. In our work, we provide solutions to the Big Data challenges in building Digital Ecosystems for Online Control including high volumes, velocity and variety of data, and the need for low data latency. We propose to use BDDDEF for building robust, reliable, fault-tolerant, scalable and high-loaded data pipelines for Online Predictive Control Systems. We review Big Data Main Systems for Online Predictive Control Architecture, review the literature for Digital Ecosystems design for Control Systems Online, design and describe main features, main architectural components and functional architecture of the framework, and finally, propose new Predictive Control methodology for Online Predictions.",
                "call-number": "10.1145/3415958.3433077",
                "collection-title": "MEDES '20",
                "container-title": "Proceedings of the 12th International Conference on Management of Digital EcoSystems",
                "DOI": "10.1145/3415958.3433077",
                "event-place": "Virtual Event, United Arab Emirates",
                "ISBN": "9781450381154",
                "keyword": "Message-oriented middleware, Predictive control, Digital ecosystem framework, Inmemory computing, Big Data",
                "number-of-pages": "4",
                "page": "92–95",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big-Data Driven Digital Ecosystem Framework for Online Predictive Control",
                "URL": "https://doi.org/10.1145/3415958.3433077"
            }
        },
        {
            "10.1145/3357292.3357302": {
                "id": "10.1145/3357292.3357302",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kun-fa",
                        "given": "Li"
                    },
                    {
                        "family": "Jing-chun",
                        "given": "Chen"
                    },
                    {
                        "family": "Yan-xi",
                        "given": "Wang"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            23
                        ]
                    ]
                },
                "abstract": "With the development of technology in the era of digital big data in the network and the promotion of network technology, big data is simultaneously integrated into different industry sectors to achieve Internet performance management, and enhance the new perspective of enterprise human resources performance management activities. Today's Internet, cloud computing, Internet of Things and other industrial technologies have undergone repeated changes, showing an unprecedented picture. At present, the subjective awareness of enterprise human resources performance management is too strong, lack of objective data understanding, and the theoretical framework of big data human resource management is not fully applied. This paper reconstructs the data system from four aspects: data source, collection, integration and analysis. Innovate the human resources performance management method from the system to provide more scientific and specific ideas for human resource performance management.",
                "call-number": "10.1145/3357292.3357302",
                "collection-title": "IMMS 2019",
                "container-title": "Proceedings of the 2019 2nd International Conference on Information Management and Management Sciences",
                "DOI": "10.1145/3357292.3357302",
                "event-place": "Chengdu, China",
                "ISBN": "9781450371445",
                "keyword": "human resources, performance management, Big data",
                "number-of-pages": "6",
                "page": "12–17",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data Informatization Applied to Optimization of Human Resource Performance Management",
                "URL": "https://doi.org/10.1145/3357292.3357302"
            }
        },
        {
            "10.1145/3421537": {
                "id": "10.1145/3421537",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2020
                        ]
                    ]
                },
                "abstract": "On behalf of the conference committees, it is my pleasure to address a warm welcome to all delegates to participate in2020 the 4th International Conference on Big Data and Internet of Things(BDIOT2020). This conference is technically sponsored by University of Macau, La trobe University and Universita Di Pisa, and also attracts some media partners.",
                "call-number": "10.1145/3421537",
                "container-title-short": "BDIOT 2020",
                "event-place": "Singapore, Singapore",
                "genre": "proceeding",
                "ISBN": "9781450375504",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2020 the 4th International Conference on Big Data and Internet of Things"
            }
        },
        {
            "10.1145/3332301": {
                "id": "10.1145/3332301",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Barika",
                        "given": "Mutaz"
                    },
                    {
                        "family": "Garg",
                        "given": "Saurabh"
                    },
                    {
                        "family": "Zomaya",
                        "given": "Albert Y."
                    },
                    {
                        "family": "Wang",
                        "given": "Lizhe"
                    },
                    {
                        "family": "Moorsel",
                        "given": "Aad Van"
                    },
                    {
                        "family": "Ranjan",
                        "given": "Rajiv"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            9,
                            13
                        ]
                    ]
                },
                "abstract": "Interest in processing big data has increased rapidly to gain insights that can transform businesses, government policies, and research outcomes. This has led to advancement in communication, programming, and processing technologies, including cloud computing services and technologies such as Hadoop, Spark, and Storm. This trend also affects the needs of analytical applications, which are no longer monolithic but composed of several individual analytical steps running in the form of a workflow. These big data workflows are vastly different in nature from traditional workflows. Researchers are currently facing the challenge of how to orchestrate and manage the execution of such workflows. In this article, we discuss in detail orchestration requirements of these workflows as well as the challenges in achieving these requirements. We also survey current trends and research that supports orchestration of big data workflows and identify open research challenges to guide future developments in this area.",
                "call-number": "10.1145/3332301",
                "collection-number": "95",
                "container-title": "ACM Comput. Surv.",
                "DOI": "10.1145/3332301",
                "ISSN": "0360-0300",
                "issue": "5",
                "keyword": "research taxonomy, workflow orchestration, approaches, cloud computing, Big data, and techniques",
                "number": "Article 95",
                "number-of-pages": "41",
                "page": "1–41",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "September 2020",
                "title": "Orchestrating Big Data Analysis Workflows in the Cloud: Research Challenges, Survey, and Future Directions",
                "URL": "https://doi.org/10.1145/3332301",
                "volume": "52"
            }
        },
        {
            "10.1145/2258056.2258058": {
                "id": "10.1145/2258056.2258058",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Shekhar",
                        "given": "Shashi"
                    },
                    {
                        "family": "Gunturi",
                        "given": "Viswanath"
                    },
                    {
                        "family": "Evans",
                        "given": "Michael R."
                    },
                    {
                        "family": "Yang",
                        "given": "KwangSoo"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            5,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            5,
                            20
                        ]
                    ]
                },
                "abstract": "Increasingly, location-aware datasets are of a size, variety, and update rate that exceeds the capability of spatial computing technologies. This paper addresses the emerging challenges posed by such datasets, which we call Spatial Big Data (SBD). SBD examples include trajectories of cellphones and GPS devices, vehicle engine measurements, temporally detailed road maps, etc. SBD has the potential to transform society via next-generation routing services such as eco-routing. However, the envisaged SBD-based next-generation routing services pose several significant challenges for current routing techniques. SBD magnifies the impact of partial information and ambiguity of traditional routing queries specified by a start location and an end location. In addition, SBD challenges the assumption that a single algorithm utilizing a specific dataset is appropriate for all situations. The tremendous diversity of SBD sources substantially increases the diversity of solution methods. Newer algorithms may emerge as new SBD becomes available, creating the need for a flexible architecture to rapidly integrate new datasets and associated algorithms.",
                "call-number": "10.1145/2258056.2258058",
                "collection-title": "MobiDE '12",
                "container-title": "Proceedings of the Eleventh ACM International Workshop on Data Engineering for Wireless and Mobile Access",
                "DOI": "10.1145/2258056.2258058",
                "event-place": "Scottsdale, Arizona",
                "ISBN": "9781450314428",
                "keyword": "spatial big data, data mining, mobility services",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Spatial big-data challenges intersecting mobility and cloud computing",
                "URL": "https://doi.org/10.1145/2258056.2258058"
            }
        },
        {
            "10.1145/3372938": {
                "id": "10.1145/3372938",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2019
                        ]
                    ]
                },
                "call-number": "10.1145/3372938",
                "container-title-short": "BDIoT'19",
                "event-place": "Rabat, Morocco",
                "genre": "proceeding",
                "ISBN": "9781450372404",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 4th International Conference on Big Data and Internet of Things"
            }
        },
        {
            "10.1145/3423603.3424049": {
                "id": "10.1145/3423603.3424049",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Aissa",
                        "given": "Mohamed Mehdi Ben"
                    },
                    {
                        "family": "Sfaxi",
                        "given": "Lilia"
                    },
                    {
                        "family": "Robbana",
                        "given": "Riadh"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            10,
                            15
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            10,
                            15
                        ]
                    ]
                },
                "abstract": "Information is one of the most important factors in business success, hence the importance of the Business Intelligence (BI) domain in order to simplify the decision making and make it more relevant. Decisional systems have been used for several years to help decision-makers access, analyze and extract value from the data that their organisation accumulated through the years. The success gained by these types of systems caused the establishment of a well-known architecture and development chain, and the proliferation of tools and methodologies that have proven their value. Nonetheless, in some use cases, the classical decisional architecture shows some shortcomings. In fact, the traditional storage and processing models in Business Intelligence systems are not sufficient anymore when confronted with data that becomes more and more massive, varied and with a high velocity. This is where Big Data solutions can be of great use. In fact, these solutions have proven their efficiency when dealing with enormous constantly increasing amounts of data with a changing schema. Our goal in this article is to show the various manners to integrate big data solutions into the decisional world, and to help architects choose which architecture corresponds better to their needs, by taking into consideration the environmental, technical and functional constraints they are faced with.",
                "call-number": "10.1145/3423603.3424049",
                "collection-number": "12",
                "collection-title": "DTUC '20",
                "container-title": "Proceedings of the 2nd International Conference on Digital Tools & Uses Congress",
                "DOI": "10.1145/3423603.3424049",
                "event-place": "Virtual Event, Tunisia",
                "ISBN": "9781405377539",
                "keyword": "data lake, decision tree for decisional architectures, software architecture, data warehouse, decisional systems, big data, OLAP, business intelligence",
                "number": "Article 12",
                "number-of-pages": "9",
                "page": "1–9",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Decisional architectures from business intelligence to big data: challenges and opportunities",
                "URL": "https://doi.org/10.1145/3423603.3424049"
            }
        },
        {
            "10.1145/3535735.3535742": {
                "id": "10.1145/3535735.3535742",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Xin"
                    },
                    {
                        "family": "Li",
                        "given": "Yongkui"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            4,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            4,
                            14
                        ]
                    ]
                },
                "abstract": "One of the core connotations of smart classroom is personalization, which abandons the neat and uniform knowledge transfer mode of traditional classroom. After analyzing the advantages and disadvantages of online and offline teaching mode, we focus on the principle and application of big data technology . The lecturer has made innovative designs in teaching mode, teaching content and curriculum evaluation system. It is true to change standardized teaching into personalized teaching that respects learning individuals and promotes students' knowledge construction and literacy improvement . We are teaching students according to their aptitude. At the same time, adhere to the people-oriented teaching concept and use data to guide teaching, but not too much rely on data, change the way of thinking, and transform teaching from industrialized production to agricultural deep-rooted and meticulous work to create good teaching ecological environment.",
                "call-number": "10.1145/3535735.3535742",
                "collection-title": "ICIEI '22",
                "container-title": "Proceedings of the 7th International Conference on Information and Education Innovations",
                "DOI": "10.1145/3535735.3535742",
                "event-place": "Belgrade, Serbia",
                "ISBN": "9781450396196",
                "keyword": "multidimensional evaluation, Big data technology, mixture teaching",
                "number-of-pages": "6",
                "page": "41–46",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Explore and practice of online and offline mixed teaching based on SPOC — uses the big data major as an example",
                "URL": "https://doi.org/10.1145/3535735.3535742"
            }
        },
        {
            "10.1145/3167918.3167924": {
                "id": "10.1145/3167918.3167924",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Al-Mansoori",
                        "given": "Ahmed"
                    },
                    {
                        "family": "Yu",
                        "given": "Shui"
                    },
                    {
                        "family": "Xiang",
                        "given": "Yong"
                    },
                    {
                        "family": "Sood",
                        "given": "Keshav"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            1,
                            29
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            1,
                            29
                        ]
                    ]
                },
                "abstract": "Big data is the term which denotes data with features such as voluminous data, a variety of data and streaming data as well. Processing big data became essential for enterprises to garner general intelligence and avoid biased conclusions. Due to these features, big data processing is considered to be a challenging task. Big data Processing should rely on a robust network. Cloud computing offers a suitable environment for these processes. However, it is more challenging when we move big data to the cloud, as managing the cloud resources is the main issue. Software Defined Network (SDN) has a potential solution to this issue. In this paper, first, we survey the present state of the art of SDN, cloud computing, and Big data Stream processing (BDSP). Then, we discuss SDN in the context of Big Data Stream Processing in Cloud environment. Finally, critical issues and research opportunity are discussed.",
                "call-number": "10.1145/3167918.3167924",
                "collection-number": "12",
                "collection-title": "ACSW '18",
                "container-title": "Proceedings of the Australasian Computer Science Week Multiconference",
                "DOI": "10.1145/3167918.3167924",
                "event-place": "Brisband, Queensland, Australia",
                "ISBN": "9781450354363",
                "keyword": "cost optimization, resource optimization, big data, cloud computing, SDN, big data stream processing",
                "number": "Article 12",
                "number-of-pages": "11",
                "page": "1–11",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A survey on big data stream processing in SDN supported cloud environment",
                "URL": "https://doi.org/10.1145/3167918.3167924"
            }
        },
        {
            "10.1145/2684822.2685326": {
                "id": "10.1145/2684822.2685326",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Franklin",
                        "given": "Michael"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            2,
                            2
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            2,
                            2
                        ]
                    ]
                },
                "abstract": "The Berkeley AMPLab is creating a new approach to data analytics. Launching in early 2011, the lab aims to seamlessly integrate the three main resources available for making sense of data at scale: Algorithms (machine learning and statistical techniques), Machines (in the form of scalable clusters and elastic cloud computing), and People (both individually as analysts and in crowds). The lab is realizing its ideas through the development of a freely-available Open Source software stack called BDAS: the Berkeley Data Analytics Stack. In the four years the lab has been in operation, we've released major components of BDAS. Several of these components have gained significant traction in industry and elsewhere: the Mesos cluster resource manager, the Spark in-memory computation framework, and the Shark query processing system. BDAS features prominently in many industry discussions of the future of the Big Data analytics ecosystem -- a rare degree of impact for an ongoing academic project. Given this initial success, the lab is continuing on its research path, moving \"up the stack\" to better integrate and support advanced analytics and to make people a full-fledged resource for making sense of data. In this talk, I'll first outline the motivation and insights behind our research approach and describe how we have organized to address the cross-disciplinary nature of Big Data challenges. I will then describe the current state of BDAS with an emphasis on our newest efforts, including some or all of: the GraphX graph processing system, the Velox and MLBase machine learning platforms, and the SampleClean framework for hybrid human/computer data cleaning. Finally I will present our current views of how all the pieces will fit together to form a system that can adaptively bring the right resources to bear on a given data-driven question to meet time, cost and quality requirements throughout the analytics lifecycle.",
                "call-number": "10.1145/2684822.2685326",
                "collection-title": "WSDM '15",
                "container-title": "Proceedings of the Eighth ACM International Conference on Web Search and Data Mining",
                "DOI": "10.1145/2684822.2685326",
                "event-place": "Shanghai, China",
                "ISBN": "9781450333177",
                "keyword": "big data",
                "number-of-pages": "2",
                "page": "1–2",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Making Sense of Big Data with the Berkeley Data Analytics Stack",
                "URL": "https://doi.org/10.1145/2684822.2685326"
            }
        },
        {
            "10.1145/3330431.3330447": {
                "id": "10.1145/3330431.3330447",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Rakhimova",
                        "given": "Diana"
                    },
                    {
                        "family": "Turganbayeva",
                        "given": "Aliya"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            6,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            6,
                            6
                        ]
                    ]
                },
                "abstract": "In paper are considered existing algorithms for automatically isolating the bases for a number of natural languages and possible ways of synthesizing a normal form of a word for the Kazakh language. In paper are described the complete system of endings of the Kazakh language. The article presents the classification of affixes Kazakh language. The paper proposes a new approach to constructing a lemmatization algorithm for the Kazakh language on the basis of a complete set of endings of the Kazakh language. The lemmatization algorithm will be used for Kazakh language information retrieval to finding specific words in the documents by stemming base of word.",
                "call-number": "10.1145/3330431.3330447",
                "collection-number": "16",
                "collection-title": "ICEMIS '19",
                "container-title": "Proceedings of the 5th International Conference on Engineering and MIS",
                "DOI": "10.1145/3330431.3330447",
                "event-place": "Astana, Kazakhstan",
                "ISBN": "9781450372121",
                "keyword": "information, algorithm, language, retrieval, big data, Kazakh, lemmatization",
                "number": "Article 16",
                "number-of-pages": "4",
                "page": "1–4",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Lemmatization of big data in the Kazakh language",
                "URL": "https://doi.org/10.1145/3330431.3330447"
            }
        },
        {
            "10.1145/2436256.2436263": {
                "id": "10.1145/2436256.2436263",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Hoffmann",
                        "given": "Leah"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            4,
                            1
                        ]
                    ]
                },
                "abstract": "As computational tools open up new ways of understanding history, historians and computer scientists are working together to explore the possibilities.",
                "call-number": "10.1145/2436256.2436263",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/2436256.2436263",
                "ISSN": "0001-0782",
                "issue": "4",
                "number-of-pages": "3",
                "page": "21–23",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "April 2013",
                "title": "Looking back at big data",
                "URL": "https://doi.org/10.1145/2436256.2436263",
                "volume": "56"
            }
        },
        {
            "10.5555/2693848.2694145": {
                "id": "10.5555/2693848.2694145",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Wilschut",
                        "given": "Tim"
                    },
                    {
                        "family": "Adan",
                        "given": "Ivo J. B. F."
                    },
                    {
                        "family": "Stokkermans",
                        "given": "Joep"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            12,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            12,
                            7
                        ]
                    ]
                },
                "abstract": "Big data analytics is at the brink of changing the landscape in NXP Semiconductors Back End manufacturing operations. Numerous IT tools, implemented over the last decade, collect gigabytes of data daily, though the potential value of this data still remains to be explored. In this paper, the software tool called Heads Up is presented. Heads Up intelligently scans, filters, and explores the data with use of simulation. The software provides real-time relevant information, which is of high value in daily, as well as long term, production management. The software tool has been introduced at the NXP high volume manufacturing plant GuangDong China, where it is about to shift the paradigm on manufacturing operations.",
                "call-number": "10.5555/2693848.2694145",
                "collection-title": "WSC '14",
                "container-title": "Proceedings of the 2014 Winter Simulation Conference",
                "event-place": "Savannah, Georgia",
                "number-of-pages": "12",
                "page": "2364–2375",
                "publisher": "IEEE Press",
                "title": "Big data in daily manufacturing operations"
            }
        },
        {
            "10.1145/3377170.3377180": {
                "id": "10.1145/3377170.3377180",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Liu",
                        "given": "Qinxian"
                    },
                    {
                        "family": "Hyun",
                        "given": "Youyung"
                    },
                    {
                        "family": "Hosoya",
                        "given": "Ryuichi"
                    },
                    {
                        "family": "Kamioka",
                        "given": "Taro"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            12,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            12,
                            20
                        ]
                    ]
                },
                "abstract": "Nowadays, organizations have been faced with the rapidly changing environment; thus, in order to survive in such volatile business environment, agility which is the ability to sense opportunities and defend threats has become a critical issue. Big data analytics (BDA) has been known to positively influence the agility; however, to our knowledge, the impact of BDA use on agility has not been studied abundantly in relation to the perspective of team cognition. To fill this research gap, we developed a new construct called orientation of interactive team cognition (OITC) based on the interactive team cognition (ITC) theory. After analyzing the survey data from 173 respondents, our paper found that OITC plays a positive role in moderating the relationship between the use of BDA and agility.",
                "call-number": "10.1145/3377170.3377180",
                "collection-title": "ICIT 2019",
                "container-title": "Proceedings of the 2019 7th International Conference on Information Technology: IoT and Smart City",
                "DOI": "10.1145/3377170.3377180",
                "event-place": "Shanghai, China",
                "ISBN": "9781450376631",
                "keyword": "Big data analytics, orientation of interactive team cognition, agility, performance",
                "number-of-pages": "6",
                "page": "34–39",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "How Big Data Analytics Impacts Agility: The Moderation Effect of Orientation of Interactive Team Cognition",
                "URL": "https://doi.org/10.1145/3377170.3377180"
            }
        },
        {
            "10.1145/3314074.3314097": {
                "id": "10.1145/3314074.3314097",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kachaoui",
                        "given": "Jabrane"
                    },
                    {
                        "family": "Belangour",
                        "given": "Abdessamad"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            3,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            3,
                            28
                        ]
                    ]
                },
                "abstract": "Since data is at the heart of information systems, new technologies and approaches dealing with storing, processing and analyzing data have proliferated. Data Warehouses are among the most known approaches that tackle data storing and processing. However, they reached their limits in dealing with large quantities of data as those of Big Data. Consequently, a new concept which is an evolution of Data Warehouse known as \"Data Lake\" is emerging. This paper presents a detailed analysis that compares Data Lake and Data Warehouse key concepts. It sheds lights on the aspects and characteristics for the sake of revealing similarities and differences. It also emphasizes the complementary of the two technologies by showing the most appropriate use case of each of them.",
                "call-number": "10.1145/3314074.3314097",
                "collection-number": "22",
                "collection-title": "SMC '19",
                "container-title": "Proceedings of the New Challenges in Data Sciences: Acts of the Second Conference of the Moroccan Classification Society",
                "DOI": "10.1145/3314074.3314097",
                "event-place": "Kenitra, Morocco",
                "ISBN": "9781450361293",
                "keyword": "Big Data, Repository, Distributed databases, Data Mart, Ad Hoc, NoSQL, Data Lake, Data Warehouse, Hadoop",
                "number": "Article 22",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Challenges and Benefits of Deploying Big Data Storage Solution",
                "URL": "https://doi.org/10.1145/3314074.3314097"
            }
        },
        {
            "10.1145/2818869.2818904": {
                "id": "10.1145/2818869.2818904",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yuan",
                        "given": "Yu-Lan"
                    },
                    {
                        "family": "Ho",
                        "given": "Chaang-Iuan"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            7
                        ]
                    ]
                },
                "abstract": "Big data is an important part of modern information management, providing new strategies for Destination Marketing Organizations (DMOs) for DMOs to gather large amount of data from tourists and stakeholders. DMOs that have the domain knowledge to analyze these data can take the opportunities presented by Big Data. This work describes the opportunities and challenges presented to DMOs in use of Big Data.",
                "call-number": "10.1145/2818869.2818904",
                "collection-number": "60",
                "collection-title": "ASE BD&amp;SI '15",
                "container-title": "Proceedings of the ASE BigData & SocialInformatics 2015",
                "DOI": "10.1145/2818869.2818904",
                "event-place": "Kaohsiung, Taiwan",
                "ISBN": "9781450337359",
                "keyword": "Big Data, Challenges, Destination Management Organization, Opportunities",
                "number": "Article 60",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Rethinking the Destination Marketing Organization Management in the Big Data Era",
                "URL": "https://doi.org/10.1145/2818869.2818904"
            }
        },
        {
            "10.14778/2735461.2735465": {
                "id": "10.14778/2735461.2735465",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Graefe",
                        "given": "Goetz"
                    },
                    {
                        "family": "Volos",
                        "given": "Haris"
                    },
                    {
                        "family": "Kimura",
                        "given": "Hideaki"
                    },
                    {
                        "family": "Kuno",
                        "given": "Harumi"
                    },
                    {
                        "family": "Tucek",
                        "given": "Joseph"
                    },
                    {
                        "family": "Lillibridge",
                        "given": "Mark"
                    },
                    {
                        "family": "Veitch",
                        "given": "Alistair"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            1
                        ]
                    ]
                },
                "abstract": "When a working set fits into memory, the overhead imposed by the buffer pool renders traditional databases non-competitive with in-memory designs that sacrifice the benefits of a buffer pool. However, despite the large memory available with modern hardware, data skew, shifting workloads, and complex mixed workloads make it difficult to guarantee that a working set will fit in memory. Hence, some recent work has focused on enabling in-memory databases to protect performance when the working data set almost fits in memory. Contrary to those prior efforts, we enable buffer pool designs to match in-memory performance while supporting the \"big data\" workloads that continue to require secondary storage, thus providing the best of both worlds. We introduce here a novel buffer pool design that adapts pointer swizzling for references between system objects (as opposed to application objects), and uses it to practically eliminate buffer pool overheads for memoryresident data. Our implementation and experimental evaluation demonstrate that we achieve graceful performance degradation when the working set grows to exceed the buffer pool size, and graceful improvement when the working set shrinks towards and below the memory and buffer pool sizes.",
                "call-number": "10.14778/2735461.2735465",
                "container-title": "Proc. VLDB Endow.",
                "DOI": "10.14778/2735461.2735465",
                "ISSN": "2150-8097",
                "issue": "1",
                "number-of-pages": "12",
                "page": "37–48",
                "publisher": "VLDB Endowment",
                "source": "September 2014",
                "title": "In-memory performance for big data",
                "URL": "https://doi.org/10.14778/2735461.2735465",
                "volume": "8"
            }
        },
        {
            "10.1145/3151759.3151780": {
                "id": "10.1145/3151759.3151780",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Hirchoua",
                        "given": "Badr"
                    },
                    {
                        "family": "Ouhbi",
                        "given": "Brahim"
                    },
                    {
                        "family": "Frikh",
                        "given": "Bouchra"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            12,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            12,
                            4
                        ]
                    ]
                },
                "abstract": "In many companies data is used as a source for creating knowledge in their sphere of business. Therefore this paper presents a knowledge capitalization framework in big data context. Based on the technology derived from distributed systems, our research concerns the design and development of a knowledge engineering framework in big data context. It can be integrated in any knowledge management system. The proposed framework is based on four layers: we start by extracting hidden topics, using the LDA approach in batch processing to handle the complexity of multi knowledge domains and to keep the semantic relations between knowledge entities. Then we use clustering mechanisms to pick the best combination between topics from different sources. As a result, we get, in every distributed site, the related topics (knowledge), in order to facilitate the research and access, to get the useful knowledge in real time processing.",
                "call-number": "10.1145/3151759.3151780",
                "collection-title": "iiWAS '17",
                "container-title": "Proceedings of the 19th International Conference on Information Integration and Web-based Applications & Services",
                "DOI": "10.1145/3151759.3151780",
                "event-place": "Salzburg, Austria",
                "ISBN": "9781450352994",
                "keyword": "machine learning, data intelligence, topic modeling, knowledge capitalization, big data computing",
                "number-of-pages": "9",
                "page": "40–48",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A new knowledge capitalization framework in big data context",
                "URL": "https://doi.org/10.1145/3151759.3151780"
            }
        },
        {
            "10.1145/2623330.2630819": {
                "id": "10.1145/2623330.2630819",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Eagle",
                        "given": "Nathan"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            24
                        ]
                    ]
                },
                "abstract": "Petabytes of data about human movements, transactions and communication patterns are being generated by everyday technologies such as mobile phones & credit cards. This unprecedented volume of information facilitates a novel set of research questions applicable to a wide range of development issues. In collaboration involving 237 mobile phone operators across 102 countries, Jana's mobile technology platform can instantly poll and compensate 3.48 billion active mobile subscriptions. This talk will discuss how insights gained from living in Kenya became the genesis of a technology company currently working with global clients in over 50 countries, including P&G, Google, Unilever, Danone, General Mills, Nestle, Johnson & Johnson, Microsoft, the World Bank, and the United Nations. After providing an overview of the mobile and social media landscapes in emerging markets, we discuss a system that implements polls & mobile subscription compensation. The presentation will conclude by emphasizing the value of consumer data in underserved and understudied regions of the world.",
                "call-number": "10.1145/2623330.2630819",
                "collection-title": "KDD '14",
                "container-title": "Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining",
                "DOI": "10.1145/2623330.2630819",
                "event-place": "New York, New York, USA",
                "ISBN": "9781450329569",
                "keyword": "mobile technology, social media, emerging markets, polling systems",
                "number-of-pages": "1",
                "page": "1522",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data for social good",
                "URL": "https://doi.org/10.1145/2623330.2630819"
            }
        },
        {
            "10.1145/269012.269021": {
                "id": "10.1145/269012.269021",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Tayi",
                        "given": "Giri Kumar"
                    },
                    {
                        "family": "Ballou",
                        "given": "Donald P."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            1998,
                            2,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/269012.269021",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/269012.269021",
                "ISSN": "0001-0782",
                "issue": "2",
                "number-of-pages": "4",
                "page": "54–57",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "Feb. 1998",
                "title": "Examining data quality",
                "URL": "https://doi.org/10.1145/269012.269021",
                "volume": "41"
            }
        },
        {
            "10.1145/3377571.3377600": {
                "id": "10.1145/3377571.3377600",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zihaoran",
                        "given": "Wang"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            1,
                            10
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            1,
                            10
                        ]
                    ]
                },
                "abstract": "Big data \"killing\" as a new manifestation of price discrimination in the era of big data refers to the service provider as a party with information superiority, using the large amount of customer information flow to distinguish the pricing of each individual consumer. Consumer surplus value may be captured, which seriously reduces the level of consumer welfare. Internet companies with monopoly status such as Amazon, Didi, and Orbitz have all been expelled to adopt a pricing strategy of big data. However, the existing literature mainly discusses how to regulate big data at the legal level, and there is less discussion about big data killing itself as a kind of primary price discrimination phenomenon. This article aims to address the following two questions: 1) What is the motivation behind the vendor's big data killing strategy? 2) How to regulate from the perspective of network economics for big data killing? In the discussion of the first problem, using the mathematical modeling method to start the profit maximization by the monopolist, the local aggregation coefficient in the network is used to describe the risk of the manufacturer adopting the big data killing strategy, so that it is not adopted. The profit of the killing strategy and the expected profit of adopting the killing strategy are the motivation of the manufacturer to adopt the big data killing strategy. In the discussion of the second question, taking the comparison between the expected profit of the killing strategy and the profit under normal operation as the starting point, explore how to use the degree of communication between consumers and rationally introduce the competitive market to smash the big data. Conduct regulation. Finally, this paper studies the interdisciplinary issue and provides the relevant government departments with the idea of regulating big data killing strategies under the perspective of network economics.",
                "call-number": "10.1145/3377571.3377600",
                "collection-title": "IC4E 2020",
                "container-title": "Proceedings of the 2020 11th International Conference on E-Education, E-Business, E-Management, and E-Learning",
                "DOI": "10.1145/3377571.3377600",
                "event-place": "Osaka, Japan",
                "ISBN": "9781450372947",
                "keyword": "full price discrimination, clustering coefficient, consumer surplus, Big data killing",
                "number-of-pages": "5",
                "page": "407–411",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research on Motivation and Regulation of Big Data \"Slaughter\" Behavior",
                "URL": "https://doi.org/10.1145/3377571.3377600"
            }
        },
        {
            "10.1145/2967938.2967957": {
                "id": "10.1145/2967938.2967957",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Jia",
                        "given": "Zhen"
                    },
                    {
                        "family": "Xue",
                        "given": "Chao"
                    },
                    {
                        "family": "Chen",
                        "given": "Guancheng"
                    },
                    {
                        "family": "Zhan",
                        "given": "Jianfeng"
                    },
                    {
                        "family": "Zhang",
                        "given": "Lixin"
                    },
                    {
                        "family": "Lin",
                        "given": "Yonghua"
                    },
                    {
                        "family": "Hofstee",
                        "given": "Peter"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            9,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            9,
                            11
                        ]
                    ]
                },
                "abstract": "Much research work devotes to tuning big data analytics in modern data centers, since %the truth that even a small percentage of performance improvement immediately translates to huge cost savings because of the large scale. Simultaneous multithreading (SMT) receives great interest from data center communities, as it has the potential to boost performance of big data analytics by increasing the processor resources utilization. For example, the emerging processor architectures like POWER8 support up to 8-way multithreading. However, as different big data workloads have disparate architectural characteristics, how to identify the most efficient SMT configuration to achieve the best performance is challenging in terms of both complex application behaviors and processor architectures. In this paper, we specifically focus on auto-tuning SMT configuration for Spark-based big data workloads on POWE-R8. However, our methodology could be generalized and extended to other programming software stacks and other architectures.We propose a prediction-based dynamic SMT threading (PBDST) framework to adjust the thread count in SMT cores on POWER8 processors by using versatile machine learning algorithms.Its innovation lies in adopting online SMT configuration predictions derived from micro-architecture level profiling, to regulate the thread counts that could achieve nearly optimal performance. Moreover it is implemented at Spark software stack layer and transparent to user applications. After evaluating a large set of machine learning algorithms, we choose the most efficient ones to perform online predictions. The experimental results demonstrate that our approach can achieve up to 56.3% performance improvement and an average performance gain of 16.2% in comparison with the default configuration---the maximum SMT configuration---SMT8 on our system.",
                "call-number": "10.1145/2967938.2967957",
                "collection-title": "PACT '16",
                "container-title": "Proceedings of the 2016 International Conference on Parallel Architectures and Compilation",
                "DOI": "10.1145/2967938.2967957",
                "event-place": "Haifa, Israel",
                "ISBN": "9781450341219",
                "keyword": "spark big data, dynamic smt tuning, power8",
                "number-of-pages": "14",
                "page": "387–400",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Auto-tuning Spark Big Data Workloads on POWER8: Prediction-Based Dynamic SMT Threading",
                "URL": "https://doi.org/10.1145/2967938.2967957"
            }
        },
        {
            "10.1145/3361758": {
                "id": "10.1145/3361758",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2019
                        ]
                    ]
                },
                "abstract": "We like to start by first acknowledging the traditional custodians of the lands, where La Trobe University campuses are located in Victoria. We recognize their continuing connection to land, waters and culture and we pay our respects to their Elders past, present and emerging.",
                "call-number": "10.1145/3361758",
                "container-title-short": "BDIOT 2019",
                "event-place": "Melbourn, VIC, Australia",
                "genre": "proceeding",
                "ISBN": "9781450372466",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 3rd International Conference on Big Data and Internet of Things"
            }
        },
        {
            "10.1145/3341069.3341079": {
                "id": "10.1145/3341069.3341079",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Weigang",
                        "given": "Gao"
                    },
                    {
                        "family": "Guiming",
                        "given": "Chen"
                    },
                    {
                        "family": "Xiang",
                        "given": "Zheng"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            6,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            6,
                            22
                        ]
                    ]
                },
                "abstract": "With the development of computer and information technology, the era of big data has arrived, and entered the military field comprehensively. To improve the ability to develop and use big data has become a strategic project that affecting the victory of war. This paper takes the elaboration of the relevant connotation of big data as the traction, analyzes the urgency of the application of big data to the management of military equipment costs, points out the key problems of big data in the management of military equipment costs and proposes corresponding solutions.",
                "call-number": "10.1145/3341069.3341079",
                "collection-title": "HPCCT 2019",
                "container-title": "Proceedings of the 2019 3rd High Performance Computing and Cluster Technologies Conference",
                "DOI": "10.1145/3341069.3341079",
                "event-place": "Guangzhou, China",
                "ISBN": "9781450371858",
                "keyword": "big data, equipment, cost",
                "number-of-pages": "4",
                "page": "177–180",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Analysis on the Application of Big Data in Military Equipment Expense Management",
                "URL": "https://doi.org/10.1145/3341069.3341079"
            }
        },
        {
            "10.1145/2168931.2168943": {
                "id": "10.1145/2168931.2168943",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Fisher",
                        "given": "Danyel"
                    },
                    {
                        "family": "DeLine",
                        "given": "Rob"
                    },
                    {
                        "family": "Czerwinski",
                        "given": "Mary"
                    },
                    {
                        "family": "Drucker",
                        "given": "Steven"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            5,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/2168931.2168943",
                "container-title": "interactions",
                "DOI": "10.1145/2168931.2168943",
                "ISSN": "1072-5520",
                "issue": "3",
                "number-of-pages": "10",
                "page": "50–59",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "May + June 2012",
                "title": "Interactions with big data analytics",
                "URL": "https://doi.org/10.1145/2168931.2168943",
                "volume": "19"
            }
        },
        {
            "10.5555/3233397.3233441": {
                "id": "10.5555/3233397.3233441",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Gheid",
                        "given": "Zakaria"
                    },
                    {
                        "family": "Challal",
                        "given": "Yacine"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            12,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            12,
                            7
                        ]
                    ]
                },
                "abstract": "Big data systems are gathering more and more information in order to discover new values through data analytics and depth insights. However, mining sensitive personal information breaches privacy and degrades services' reputation. Accordingly, many research works have been proposed to address the privacy issues of data analytics, but almost seem to be not suitable in big data context either in data types they support or in computation time efficiency. In this paper we propose a novel privacy-preserving cosine similarity computation protocol that will support both binary and numerical data types within an efficient computation time, and we prove its adequacy for big data high volume, high variety and high velocity.",
                "call-number": "10.5555/3233397.3233441",
                "collection-title": "UCC '15",
                "container-title": "Proceedings of the 8th International Conference on Utility and Cloud Computing",
                "event-place": "Limassol, Cyprus",
                "ISBN": "9780769556970",
                "keyword": "big data, cosine similarity, data analytics, privacy",
                "number-of-pages": "9",
                "page": "281–289",
                "publisher": "IEEE Press",
                "title": "An efficient and privacy-preserving similarity evaluation for big data analytics"
            }
        },
        {
            "10.1145/2897010.2897014": {
                "id": "10.1145/2897010.2897014",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Fredericks",
                        "given": "Erik M."
                    },
                    {
                        "family": "Hariri",
                        "given": "Reihaneh H."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            5,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            5,
                            14
                        ]
                    ]
                },
                "abstract": "Massive datasets are quickly becoming a concern for many industries. For example, many web-based applications must be able to handle petabytes worth of transactions on a daily basis, and moreover, be able to quickly and efficiently act upon data that exists in each transaction. As a result, providing testing capabilities for such applications becomes a challenge of scale. We argue that existing approaches, such as automated test suite generation, may not necessarily scale without assistance. To this end, we discuss open issues and possible solutions specific to testing big data applications.",
                "call-number": "10.1145/2897010.2897014",
                "collection-title": "SBST '16",
                "container-title": "Proceedings of the 9th International Workshop on Search-Based Software Testing",
                "DOI": "10.1145/2897010.2897014",
                "event-place": "Austin, Texas",
                "ISBN": "9781450341660",
                "keyword": "big data, search-based software testing, test suite generation",
                "number-of-pages": "2",
                "page": "41–42",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Extending search-based software testing techniques to big data applications",
                "URL": "https://doi.org/10.1145/2897010.2897014"
            }
        },
        {
            "10.1145/3491396.3506516": {
                "id": "10.1145/3491396.3506516",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Wang",
                        "given": "Chunxiao"
                    },
                    {
                        "family": "Zhao",
                        "given": "Zhigang"
                    },
                    {
                        "family": "Zhang",
                        "given": "Jian"
                    },
                    {
                        "family": "Huo",
                        "given": "Jidong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            12,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            12,
                            28
                        ]
                    ]
                },
                "abstract": "In order to support the dynamic perception neural network of underground space and the intelligent brain of the city, according to the characteristics of multi-source, multi-category, multidimensional and multi-quantity of geological data, this paper studies the large data storage system which integrates multi-source acquisition and converged storage and intelligent processing to solve the problems of wide range, long time, multidimensional source and diverse processing of underground space information. This system promotes the combination of sensor network, big data and other technologies with the urban underground space perception industry, realizes the digitalization and intellectualization of various underground space information, improves the planning, risk assessment and disaster prediction of underground space, and provides support for the comprehensive development and utilization of underground space.",
                "call-number": "10.1145/3491396.3506516",
                "collection-title": "ACM ICEA '21",
                "container-title": "Proceedings of the 2021 ACM International Conference on Intelligent Computing and its Emerging Applications",
                "DOI": "10.1145/3491396.3506516",
                "event-place": "Jinan, China",
                "ISBN": "9781450391603",
                "keyword": "Underground space information, Big data storage system, Big data",
                "number-of-pages": "6",
                "page": "234–239",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research of Big Data Storage System Based on Underground Space Information",
                "URL": "https://doi.org/10.1145/3491396.3506516"
            }
        },
        {
            "10.1145/2484028.2494492": {
                "id": "10.1145/2484028.2494492",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Smith",
                        "given": "John R."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            7,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            7,
                            28
                        ]
                    ]
                },
                "abstract": "In this talk we present a perspective across multiple industry problems, including safety and security, medical, Web, social and mobile media, and motivate the need for large-scale analysis and retrieval of multimedia data. We describe a multi-layer architecture that incorporates capabilities for audio-visual feature extraction, machine learning and semantic modeling and provides a powerful framework for learning and classifying contents of multimedia data. We discuss the role semantic ontologies for representing audio-visual concepts and relationships, which are essential for training semantic classifiers. We discuss the importance of using faceted classification schemes in particular for organizing multimedia semantic concepts in order to achieve effective learning and retrieval. We also show how training and scoring of multimedia semantics can be implemented on big data distributed computing platforms to address both massive-scale analysis and low-latency processing. We describe multiple efforts at IBM on image and video analysis and retrieval, including IBM Multimedia Analysis and Retrieval System (IMARS), and show recent results for semantic-based classification and retrieval. We conclude with future directions for improving analysis of multimedia through interactive and curriculum-based techniques for multimedia semantics-based learning and retrieval.",
                "call-number": "10.1145/2484028.2494492",
                "collection-title": "SIGIR '13",
                "container-title": "Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval",
                "DOI": "10.1145/2484028.2494492",
                "event-place": "Dublin, Ireland",
                "ISBN": "9781450320344",
                "keyword": "multimedia information retrieval, video analysis, semantic modeling, machine learning, content-based search",
                "number-of-pages": "2",
                "page": "1–2",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Riding the multimedia big data wave",
                "URL": "https://doi.org/10.1145/2484028.2494492"
            }
        },
        {
            "10.1145/2601074": {
                "id": "10.1145/2601074",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "CACM Staff"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            1
                        ]
                    ]
                },
                "abstract": "New techniques are designed to translate \"invisible numbers\" into visible images.",
                "call-number": "10.1145/2601074",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/2601074",
                "ISSN": "0001-0782",
                "issue": "6",
                "number-of-pages": "3",
                "page": "19–21",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "June 2014",
                "title": "Visualizations make big data meaningful",
                "URL": "https://doi.org/10.1145/2601074",
                "volume": "57"
            }
        },
        {
            "10.1145/1012453.1012465": {
                "id": "10.1145/1012453.1012465",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Cappiello",
                        "given": "Cinzia"
                    },
                    {
                        "family": "Francalanci",
                        "given": "Chiara"
                    },
                    {
                        "family": "Pernici",
                        "given": "Barbara"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2004,
                            6,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2004,
                            6,
                            18
                        ]
                    ]
                },
                "abstract": "The quality of data is often defined as \"fitness for use\", i.e., the ability of a data collection to meet user requirements. The assessment of data quality dimensions should consider the degree to which data satisfy users' needs. User expectations are clearly related to the selected services and at the same time a service can have different characteristics depending on the type of user that accesses it. The data quality assessment process has to consider both aspects and, consequently, select a suitable evaluation function to obtain a correct interpretation of results. This paper proposes a model that ties the assessment phase to user requirements. Multichannel information systems are considered as an example to show the applicability of the proposed model.",
                "call-number": "10.1145/1012453.1012465",
                "collection-title": "IQIS '04",
                "container-title": "Proceedings of the 2004 international workshop on Information quality in information systems",
                "DOI": "10.1145/1012453.1012465",
                "event-place": "Paris, France",
                "ISBN": "1581139020",
                "keyword": "data quality, user requirements, quality assessment",
                "number-of-pages": "6",
                "page": "68–73",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Data quality assessment from the user's perspective",
                "URL": "https://doi.org/10.1145/1012453.1012465"
            }
        },
        {
            "10.1145/3331453.3362052": {
                "id": "10.1145/3331453.3362052",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Shu",
                        "given": "Jiangbo"
                    },
                    {
                        "family": "Peng",
                        "given": "Liyuan"
                    },
                    {
                        "family": "Hu",
                        "given": "Qianqian"
                    },
                    {
                        "family": "Tan",
                        "given": "Fengxia"
                    },
                    {
                        "family": "Ge",
                        "given": "Xiong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            22
                        ]
                    ]
                },
                "abstract": "With the continuous improvement of the information construction of colleges and universities, the daily life and learning behaviors of college students are recorded and stored by major business systems, and they are accumulated, which has initially formed a large-scale and multi-type student personal big data environment.This paper mainly classifies and summarizes the students' data from the three aspects of student basic information, campus learning and campus life. It focuses on the feature extraction and index mining of students' campus consumption, curriculum and performance data, and constructs the student's personal big data behavior analysis model. In-depth analysis and mining of student consumption behavior data to explore students' dietary rules and consumption level. Through data analysis, the following rules were found: 1)The total number of students eating at school decreases year by year, and the breakfast rate decreases year by year; 2) Freshmen are one hour ahead of the \"peak period\" of breakfast meals for the whole group;3) The students' academic scores are highly correlated with the meal rate, breakfast meal rate and eating consumption level, and are less correlated with variables such as window selection stability, etc. 4) The more regular the student's diet, the more stable the level of consumption, and the higher the level of learning effort, the better the student's academic performance.",
                "call-number": "10.1145/3331453.3362052",
                "collection-number": "28",
                "collection-title": "CSAE 2019",
                "container-title": "Proceedings of the 3rd International Conference on Computer Science and Application Engineering",
                "DOI": "10.1145/3331453.3362052",
                "event-place": "Sanya, China",
                "ISBN": "9781450362948",
                "keyword": "Student personal big data, Correlation analysis, Education big data, Behavior analysis",
                "number": "Article 28",
                "number-of-pages": "7",
                "page": "1–7",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Analysis of Behavioral Characteristics Based on Student's Personal Big Data",
                "URL": "https://doi.org/10.1145/3331453.3362052"
            }
        },
        {
            "10.5555/3375069.3375113": {
                "id": "10.5555/3375069.3375113",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Jain",
                        "given": "Shashwat"
                    },
                    {
                        "family": "Khandelwal",
                        "given": "Manish"
                    },
                    {
                        "family": "Katkar",
                        "given": "Ashutosh"
                    },
                    {
                        "family": "Nygate",
                        "given": "Joseph"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            11,
                            30
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            10,
                            31
                        ]
                    ]
                },
                "abstract": "Managing QoS in a telecommunications network is a complex process. Effective network design and sizing in conjunction with load balancing, access control and traffic prioritization need to be orchestrated to optimize CAPEX investment, maximize network utilization and ensure that performance metrics and SLAs are met. This work shows how big data analytics were used to improve the management of QoS in an SDN by performing multi-dimensional analysis of Key Performance Indicators (KPIs) and applying machine learning algorithms to discover new correlations, perform root cause analysis and predict traffic congestion.",
                "call-number": "10.5555/3375069.3375113",
                "collection-title": "CNSM 2016",
                "container-title": "Proceedings of the 12th Conference on International Conference on Network and Service Management",
                "event-place": "Montreal, Quebec, Canada",
                "ISBN": "9783901882852",
                "keyword": "tSDN, QoS, Performance Management, data movement, Big Data",
                "number-of-pages": "5",
                "page": "302–306",
                "publisher": "International Federation for Information Processing",
                "publisher-place": "Laxenburg, AUT",
                "title": "Applying Big Data Technologies to Manage QoS in an SDN"
            }
        },
        {
            "10.1145/3234825.3234843": {
                "id": "10.1145/3234825.3234843",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Xin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            6,
                            30
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            6,
                            30
                        ]
                    ]
                },
                "abstract": "In recent years, big data has been infiltrating into all sectors of our society. Big data technology has brought revolutionary impact to every field, and is becoming the driving force and booster of disruptive innovation in all walks of life. Based on the application of big data in wisdom- lifelong education, this paper studies the impact of big data era on the development of lifelong education.First, the literature analysis software \"CiteSpace\" was used to explore the status of life education research at home and abroad. Through the study, it was found that the era of big data has brought a profound impact on the development of lifelong education. The main manifestation is that online education in the era of big data brings opportunities to reduce education costs and achieve educational equity. The conclusion is that we can make full use of the opportunity of big data education development.",
                "call-number": "10.1145/3234825.3234843",
                "collection-title": "ICIEI '18",
                "container-title": "Proceedings of the 3rd International Conference on Information and Education Innovations",
                "DOI": "10.1145/3234825.3234843",
                "event-place": "London, United Kingdom",
                "ISBN": "9781450364409",
                "keyword": "education revolution, teaching students in accordance with their aptitude, big data, cloud computing, wisdom education, life-long education",
                "number-of-pages": "5",
                "page": "35–39",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Research of Wisdom and Lifelong Education Based on Big Data",
                "URL": "https://doi.org/10.1145/3234825.3234843"
            }
        },
        {
            "10.1145/2487575.2506178": {
                "id": "10.1145/2487575.2506178",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sun",
                        "given": "Jimeng"
                    },
                    {
                        "family": "Reddy",
                        "given": "Chandan K."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            8,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            8,
                            11
                        ]
                    ]
                },
                "abstract": "Large amounts of heterogeneous medical data have become available in various healthcare organizations (payers, providers, pharmaceuticals). Those data could be an enabling resource for deriving insights for improving care delivery and reducing waste. The enormity and complexity of these datasets present great challenges in analyses and subsequent applications to a practical clinical environment. In this tutorial, we introduce the characteristics and related mining challenges on dealing with big medical data. Many of those insights come from medical informatics community, which is highly related to data mining but focuses on biomedical specifics. We survey various related papers from data mining venues as well as medical informatics venues to share with the audiences key problems and trends in healthcare analytics research, with different applications ranging from clinical text mining, predictive modeling, survival analysis, patient similarity, genetic data analysis, and public health. The tutorial will include several case studies dealing with some of the important healthcare applications.",
                "call-number": "10.1145/2487575.2506178",
                "collection-title": "KDD '13",
                "container-title": "Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining",
                "DOI": "10.1145/2487575.2506178",
                "event-place": "Chicago, Illinois, USA",
                "ISBN": "9781450321747",
                "number-of-pages": "1",
                "page": "1525",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data analytics for healthcare",
                "URL": "https://doi.org/10.1145/2487575.2506178"
            }
        },
        {
            "10.1145/2460999.2461024": {
                "id": "10.1145/2460999.2461024",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bosu",
                        "given": "Michael Franklin"
                    },
                    {
                        "family": "MacDonell",
                        "given": "Stephen G."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            4,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            4,
                            14
                        ]
                    ]
                },
                "abstract": "Context: The utility of prediction models in empirical software engineering (ESE) is heavily reliant on the quality of the data used in building those models. Several data quality challenges such as noise, incompleteness, outliers and duplicate data points may be relevant in this regard. Objective: We investigate the reporting of three potentially influential elements of data quality in ESE studies: data collection, data pre-processing, and the identification of data quality issues. This enables us to establish how researchers view the topic of data quality and the mechanisms that are being used to address it. Greater awareness of data quality should inform both the sound conduct of ESE research and the robust practice of ESE data collection and processing. Method: We performed a targeted literature review of empirical software engineering studies covering the period January 2007 to September 2012. A total of 221 relevant studies met our inclusion criteria and were characterized in terms of their consideration and treatment of data quality. Results: We obtained useful insights as to how the ESE community considers these three elements of data quality. Only 23 of these 221 studies reported on all three elements of data quality considered in this paper. Conclusion: The reporting of data collection procedures is not documented consistently in ESE studies. It will be useful if data collection challenges are reported in order to improve our understanding of why there are problems with software engineering data sets and the models developed from them. More generally, data quality should be given far greater attention by the community. The improvement of data sets through enhanced data collection, pre-processing and quality assessment should lead to more reliable prediction models, thus improving the practice of software engineering.",
                "call-number": "10.1145/2460999.2461024",
                "collection-title": "EASE '13",
                "container-title": "Proceedings of the 17th International Conference on Evaluation and Assessment in Software Engineering",
                "DOI": "10.1145/2460999.2461024",
                "event-place": "Porto de Galinhas, Brazil",
                "ISBN": "9781450318488",
                "keyword": "literature review, data sets, empirical software engineering, data quality",
                "number-of-pages": "6",
                "page": "171–176",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Data quality in empirical software engineering: a targeted review",
                "URL": "https://doi.org/10.1145/2460999.2461024"
            }
        },
        {
            "10.1145/2663715": {
                "id": "10.1145/2663715",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2014
                        ]
                    ]
                },
                "abstract": "The 1st International Workshop on Privacy and Security of Big Data (PSBD 2014) focuses the attention on privacy and security research issues in the context of Big Data, a vibrant and challenging research context which is playing a leading role in the Database research community. Indeed, while Big Data is gaining the attention from the research community, also driven by some relevant technological innovations (like Clouds) as well as novel paradigms (like social networks), the issues of privacy and security of Big Data represent a fundamental problem in this research context, due to the fact Big Data are typically published online for supporting knowledge management and fruition processes and, in addition to this, such data are usually handled by multiple owners, with possible secure multi-part computation issues. Some of the hot topics in the context privacy and security of Big Data include: (i) privacy and security of Big Data integration and exchange; (ii) privacy and security of Big Data in data-intensive Cloud computing; (iii) system architectures in support of privacy and security of Big Data, e.g., GPUs: (iv) privacy and security issues of Big Data querying and analysis. These topics are first-class aspects to be addressed and investigated by PSBD 2014.These proceedings contain the papers selected for presentation at the workshop. We received 12 submissions from countries in North America, Europe and Asia. After careful review, the program committee selected 5 papers for presentation at the workshop. The accepted papers were presented in 2 sessions: scalable privacy-preserving and security-control methods for Big Data processing, user-oriented and data-oriented privacy methods for Big Data processing. A panel discussed advanced aspects of privacy and security of Big Data. We hope that these proceedings will serve as a valuable reference for researchers and practitioners focusing on privacy and security of Big Data.",
                "call-number": "10.1145/2663715",
                "container-title-short": "PSBD '14",
                "event-place": "Shanghai, China",
                "genre": "proceeding",
                "ISBN": "9781450315838",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the First International Workshop on Privacy and Secuirty of Big Data"
            }
        },
        {
            "10.1145/2808797.2808841": {
                "id": "10.1145/2808797.2808841",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "O'Halloran",
                        "given": "Sharyn"
                    },
                    {
                        "family": "Maskey",
                        "given": "Sameer"
                    },
                    {
                        "family": "McAllister",
                        "given": "Geraldine"
                    },
                    {
                        "family": "Park",
                        "given": "David K."
                    },
                    {
                        "family": "Chen",
                        "given": "Kaiping"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            8,
                            25
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            8,
                            25
                        ]
                    ]
                },
                "abstract": "The development of computational data science techniques in natural language processing (NLP) and machine learning (ML) algorithms to analyze large and complex textual information opens new avenues to study intricate processes, such as government regulation of financial markets, at a scale unimaginable even a few years ago. This paper develops scalable NLP and ML algorithms (classification, clustering and ranking methods) that automatically classify laws into various codes/labels, rank feature sets based on use case, and induce best structured representation of sentences for various types of computational analysis. The results provide standardized coding labels of policies to assist regulators to better understand how key policy features impact financial markets.",
                "call-number": "10.1145/2808797.2808841",
                "collection-title": "ASONAM '15",
                "container-title": "Proceedings of the 2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2015",
                "DOI": "10.1145/2808797.2808841",
                "event-place": "Paris, France",
                "ISBN": "9781450338547",
                "keyword": "big data, political economics, machine learning, natural language processing, financial regulation",
                "number-of-pages": "7",
                "page": "1118–1124",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data and the Regulation of Financial Markets",
                "URL": "https://doi.org/10.1145/2808797.2808841"
            }
        },
        {
            "10.1145/2818869.2818884": {
                "id": "10.1145/2818869.2818884",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Wu",
                        "given": "Chun-Hsin"
                    },
                    {
                        "family": "Hsu",
                        "given": "Pu"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            7
                        ]
                    ]
                },
                "abstract": "Efficiency and reliability are critical to the performance of big data computing. Hadoop is one of the most popular cloud platforms to support big data analysis. To improve data availability, the Hadoop distributed file system usually stores blocks of files in triplicate, but it incurs high storage costs and high information-leakage risks. In this paper we propose a new cost-effective approach in xHDFS: paired blocks from two machines are erasure-coded to generate redundant blocks that are intelligently managed. We evaluate that xHDFS can effectively improve the reliability of cloud storage and tolerate network or site failures with lower storage costs.",
                "call-number": "10.1145/2818869.2818884",
                "collection-number": "2",
                "collection-title": "ASE BD&amp;SI '15",
                "container-title": "Proceedings of the ASE BigData & SocialInformatics 2015",
                "DOI": "10.1145/2818869.2818884",
                "event-place": "Kaohsiung, Taiwan",
                "ISBN": "9781450337359",
                "keyword": "Big Data Computing, Remote Backup, Reliability, Hadoop, Erasure Codes, Cloud Storage, Cloud File Systems",
                "number": "Article 2",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Cost-Effective and Reliable Cloud Storage for Big Data",
                "URL": "https://doi.org/10.1145/2818869.2818884"
            }
        },
        {
            "10.1145/3368756.3369096": {
                "id": "10.1145/3368756.3369096",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Samir",
                        "given": "Tetouani"
                    },
                    {
                        "family": "Abdelsamad",
                        "given": "Chouar"
                    },
                    {
                        "family": "ElAlami",
                        "given": "Jamila"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            2
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            10,
                            2
                        ]
                    ]
                },
                "abstract": "Recent advances in information and communication technologies (ICT) have contributed to the evolution of the supply chain and logistics sector. Indeed, the analysis of massive data (Big Data) coming from smart-products makes it possible to extract enormous values for the decision-making of strategic choice: commercial or technical. But this also causes research problems because of the speed of data transmission, the huge volume, and the non-homogeneous types of data. This work provides an overview of the analysis of Big-Data (BD) from the Internet of Things (IoT) in new Logistics. This article begins with a discussion of the needs and challenges of the Internet of Things (IoT) and Big Data (BD) analysis in logistics. Then, major data analysis technologies are examined and discussed. In addition, this article also describes future directions in this promising area.",
                "call-number": "10.1145/3368756.3369096",
                "collection-number": "109",
                "collection-title": "SCA '19",
                "container-title": "Proceedings of the 4th International Conference on Smart City Applications",
                "DOI": "10.1145/3368756.3369096",
                "event-place": "Casablanca, Morocco",
                "ISBN": "9781450362894",
                "keyword": "Logistics 4.0, internet of things, big data analytics",
                "number": "Article 109",
                "number-of-pages": "4",
                "page": "1–4",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data analysis from the smart-logistics for smart-cities",
                "URL": "https://doi.org/10.1145/3368756.3369096"
            }
        },
        {
            "10.1145/3338906.3338939": {
                "id": "10.1145/3338906.3338939",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bagherzadeh",
                        "given": "Mehdi"
                    },
                    {
                        "family": "Khatchadourian",
                        "given": "Raffi"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            12
                        ]
                    ]
                },
                "abstract": "Software developers are increasingly required to write big data code. However, they find big data software development challenging. To help these developers it is necessary to understand big data topics that they are interested in and the difficulty of finding answers for questions in these topics. In this work, we conduct a large-scale study on Stackoverflow to understand the interest and difficulties of big data developers. To conduct the study, we develop a set of big data tags to extract big data posts from Stackoverflow; use topic modeling to group these posts into big data topics; group similar topics into categories to construct a topic hierarchy; analyze popularity and difficulty of topics and their correlations; and discuss implications of our findings for practice, research and education of big data software development and investigate their coincidence with the findings of previous work.",
                "call-number": "10.1145/3338906.3338939",
                "collection-title": "ESEC/FSE 2019",
                "container-title": "Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering",
                "DOI": "10.1145/3338906.3338939",
                "event-place": "Tallinn, Estonia",
                "ISBN": "9781450355728",
                "keyword": "Big data topics, Big data topic popularity, Big data topic difficulty, Big data topic hierarchy, Stackoverflow",
                "number-of-pages": "11",
                "page": "432–442",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Going big: a large-scale study on what big data developers ask",
                "URL": "https://doi.org/10.1145/3338906.3338939"
            }
        },
        {
            "10.5555/2460396.2460415": {
                "id": "10.5555/2460396.2460415",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sadiq",
                        "given": "Shazia"
                    },
                    {
                        "family": "Yeganeh",
                        "given": "Naiem Khodabandehloo"
                    },
                    {
                        "family": "Indulska",
                        "given": "Marta"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2011,
                            1,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2011,
                            1,
                            17
                        ]
                    ]
                },
                "abstract": "Data Quality is a cross-disciplinary and often domain specific problem due to the importance of fitness for use in the definition of data quality metrics. It has been the target of research and development for over 4 decades by business analysts, solution architects, database experts and statisticians to name a few. However, the changing landscape of data quality challenges indicate the need for holistic solutions. As a first step towards bridging any gaps between the various research communities, we undertook a comprehensive literature study of data quality research published in the last two decades. In this study we considered a broad range of Information System (IS) and Computer Science (CS) publication (conference and journal) outlets. The main aims of the study were to understand the current landscape of data quality research, to create better awareness of (lack of) synergies between various research communities, and, subsequently, to direct attention towards holistic solutions. In this paper, we present a summary of the findings from the study, that include a taxonomy of data quality problems, identification of the top themes, outlets and main trends in data quality research, as well as a detailed thematic analysis that outlines the overlaps and distinctions between the focus of IS and CS publications.",
                "call-number": "10.5555/2460396.2460415",
                "collection-title": "ADC '11",
                "container-title": "Proceedings of the Twenty-Second Australasian Database Conference - Volume 115",
                "event-place": "Perth, Australia",
                "ISBN": "9781920682958",
                "keyword": "literature survey, research framework, data quality",
                "number-of-pages": "10",
                "page": "153–162",
                "publisher": "Australian Computer Society, Inc.",
                "publisher-place": "AUS",
                "title": "20 years of data quality research: themes, trends and synergies"
            }
        },
        {
            "10.1145/3406601.3406628": {
                "id": "10.1145/3406601.3406628",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chalumporn",
                        "given": "Gantaphon"
                    },
                    {
                        "family": "Hewett",
                        "given": "Rattikorn"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            7,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            7,
                            1
                        ]
                    ]
                },
                "abstract": "In data-driven society, health data can lead to profound impacts on public safety policies, epidemic modeling, and advancement of health science and medicine. This paper presents an approach to automatically elucidating useful information from \"Big\" health data. In particular, we analyze manufactured cosmetic products containing chemicals that are known or suspected to cause cancer, birth defects, or developmental and reproductive harm. Our analysis is based on the Apriori algorithm, the heart of the popular Association Rule Mining to discover associations among sets of influencing factors. However, with rapid growth of huge amount of data, including ours, existing data analytics algorithms designed for in-memory data are not adequate. Most Big data analytics algorithms are implemented on MapReduce framework for execution in parallel and distributed environments. Unlike traditional implementation, our approach employs an opportunistic MapReduce-based Apriori algorithm to fully exploit parallelism. The paper describes the algorithm and presents our findings, from 113, 179 data instances, both in terms of the execution times and the discovered associations among product profiles. For a support threshold of 10% (5%,), 20 (53) association rules are obtained with an improved execution time over that of the traditional MapReduce-based algorithm by 14.6% (40.3%) on the average over three machines.",
                "call-number": "10.1145/3406601.3406628",
                "collection-number": "23",
                "collection-title": "IAIT2020",
                "container-title": "Proceedings of the 11th International Conference on Advances in Information Technology",
                "DOI": "10.1145/3406601.3406628",
                "event-place": "Bangkok, Thailand",
                "ISBN": "9781450377591",
                "keyword": "Big Data Algorithms, MapReduce, Association rules mining",
                "number": "Article 23",
                "number-of-pages": "9",
                "page": "1–9",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Health Data Analytics with an Opportunistic Big Data Algorithm",
                "URL": "https://doi.org/10.1145/3406601.3406628"
            }
        },
        {
            "10.1145/3444757.3485107": {
                "id": "10.1145/3444757.3485107",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Anisetti",
                        "given": "Marco"
                    },
                    {
                        "family": "Ardagna",
                        "given": "Claudio A."
                    },
                    {
                        "family": "Braghin",
                        "given": "Chiara"
                    },
                    {
                        "family": "Damiani",
                        "given": "Ernesto"
                    },
                    {
                        "family": "Polimeno",
                        "given": "Antongiacomo"
                    },
                    {
                        "family": "Balestrucci",
                        "given": "Alessandro"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            11,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            11,
                            1
                        ]
                    ]
                },
                "abstract": "The conflict between the need of protecting and sharing data is hampering the spread of big data applications. Security and privacy assurance is required to protect data owners, while data access and sharing are fundamental to implement smart big data solutions. In this context, access control systems can assume a central role in balancing data protection and data sharing. However, existing access control solutions are not general and scalable enough to address the software and technological complexity of big data ecosystems, being unable to support such a dynamic and collaborative environment. In this paper, we propose an access control system that enforces access to data in a distributed, multi-party big data environment. It is based on data annotations and secure data transformations performed at ingestion time. We show the feasibility of our approach in the smart city domain using an Apache-based big data engine.",
                "call-number": "10.1145/3444757.3485107",
                "collection-title": "MEDES '21",
                "container-title": "Proceedings of the 13th International Conference on Management of Digital EcoSystems",
                "DOI": "10.1145/3444757.3485107",
                "event-place": "Virtual Event, Tunisia",
                "ISBN": "9781450383141",
                "keyword": "Data Ingestion, Access Control, Data Transformation, Big Data",
                "number-of-pages": "8",
                "page": "71–78",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Dynamic and Scalable Enforcement of Access Control Policies for Big Data",
                "URL": "https://doi.org/10.1145/3444757.3485107"
            }
        },
        {
            "10.1145/2649387.2660821": {
                "id": "10.1145/2649387.2660821",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Biswas",
                        "given": "Abhishek"
                    },
                    {
                        "family": "Gauthier",
                        "given": "David"
                    },
                    {
                        "family": "Ranjan",
                        "given": "Desh"
                    },
                    {
                        "family": "Zubair",
                        "given": "Mohammad"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            20
                        ]
                    ]
                },
                "abstract": "The selection of an appropriate assembler is important to obtain best assembly of a fragment dataset, avoid misassembles and minimize further finishing effort. It is known that the assembly quality of assemblers is dependent on the input data parameters such as DNA fragmentation parameters and genome sequence structure. To the best of our knowledge no large scale systematic effort has been made in quantifying the quality of the assembly generated by various assemblers over a range of input parameters. The correlation between input parameters and assembler quality can be used to define the characteristics of an assembler and design an optimal assembler selection algorithm. The critical barrier is the computational challenge of assembling simulated high-throughput sequence libraries of thousands of genomes with input parameters varied to cover the spectrum of values obtained from major sequencers available to biologists today. We present a study to show that a quantifiable correlation can be drawn between their input and output characteristics for four major open-source assemblers. Based on our result we propose a simple model to estimate the quality of assemblies generated by these assemblers for given input parameters.",
                "call-number": "10.1145/2649387.2660821",
                "collection-title": "BCB '14",
                "container-title": "Proceedings of the 5th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics",
                "DOI": "10.1145/2649387.2660821",
                "event-place": "Newport Beach, California",
                "ISBN": "9781450328944",
                "keyword": "big data, assembly quality model, assembler characteristics, genome fragmentation parameters",
                "number-of-pages": "8",
                "page": "653–660",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data challenges for estimating genome assembler quality",
                "URL": "https://doi.org/10.1145/2649387.2660821"
            }
        },
        {
            "10.5555/1274453.1274459": {
                "id": "10.5555/1274453.1274459",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Gomes",
                        "given": "Pedro"
                    },
                    {
                        "family": "Farinha",
                        "given": "José"
                    },
                    {
                        "family": "Trigueiros",
                        "given": "Maria José"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2007,
                            1,
                            30
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2007,
                            1,
                            30
                        ]
                    ]
                },
                "abstract": "The importance of metadata has been broadly referred in the last years, mainly in the field of data warehousing and decision support systems. Contemporarily, in the adjacent field of data quality, several approaches and tools have been set out for the purpose of data profiling and cleaning. However, little effort has been made in order to formally specify metrics and techniques for data quality in a structured way. As a matter of fact, little relevance has been assigned to metadata regarding data quality and data cleaning issues. This paper aims at filling this gap, proposing a conceptual metamodel for data quality and cleaning, both applicable to operational and data warehousing contexts. The presented metadata model is integrated with OMG's CWM, offering a possible extension of this standard toward data quality.",
                "call-number": "10.5555/1274453.1274459",
                "collection-title": "APCCM '07",
                "container-title": "Proceedings of the fourth Asia-Pacific conference on Comceptual modelling - Volume 67",
                "event-place": "Ballarat, Australia",
                "ISBN": "192068285X",
                "keyword": "CWM, standards, metadata, data cleaning, metamodel, data quality, data warehouses",
                "number-of-pages": "10",
                "page": "17–26",
                "publisher": "Australian Computer Society, Inc.",
                "publisher-place": "AUS",
                "title": "A data quality metamodel extension to CWM"
            }
        },
        {
            "10.1145/3297662.3365797": {
                "id": "10.1145/3297662.3365797",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Musto",
                        "given": "Jiri"
                    },
                    {
                        "family": "Dahanayake",
                        "given": "Ajantha"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            11,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            11,
                            12
                        ]
                    ]
                },
                "abstract": "Data quality is an important aspect in many fields. In citizen science application databases, data quality is often found lacking, which is why there needs to be a method of integrating data quality into the design. This paper tackles the problem by dividing data quality into separate characteristics according to the ISO / IEC 25012 standard. These characteristics are integrated into a conceptual model of the system and data model for citizen science applications. Furthermore, the paper describes a way to measure data quality using the data quality characteristics. The models and measuring methods are theoretical and can be adapted into case specific designs.",
                "call-number": "10.1145/3297662.3365797",
                "collection-title": "MEDES '19",
                "container-title": "Proceedings of the 11th International Conference on Management of Digital EcoSystems",
                "DOI": "10.1145/3297662.3365797",
                "event-place": "Limassol, Cyprus",
                "ISBN": "9781450362382",
                "keyword": "Citizen science, Data Quality requirements, Conceptual model, Data quality, Data Quality Characteristics",
                "number-of-pages": "8",
                "page": "166–173",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Integrating data quality requirements to citizen science application design",
                "URL": "https://doi.org/10.1145/3297662.3365797"
            }
        },
        {
            "10.1145/2331042.2331050": {
                "id": "10.1145/2331042.2331050",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Bonino",
                        "given": "Dario"
                    },
                    {
                        "family": "De Russis",
                        "given": "Luigi"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            9,
                            1
                        ]
                    ]
                },
                "abstract": "To conciliate application logic concerns with event handling performance, we introduce the spChains processing framework.",
                "call-number": "10.1145/2331042.2331050",
                "container-title": "XRDS",
                "DOI": "10.1145/2331042.2331050",
                "ISSN": "1528-4972",
                "issue": "1",
                "number-of-pages": "4",
                "page": "83–86",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "Fall 2012",
                "title": "Mastering real-time big data with stream processing chains",
                "URL": "https://doi.org/10.1145/2331042.2331050",
                "volume": "19"
            }
        },
        {
            "10.1145/3302424.3303988": {
                "id": "10.1145/3302424.3303988",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bruno",
                        "given": "Rodrigo"
                    },
                    {
                        "family": "Patricio",
                        "given": "Duarte"
                    },
                    {
                        "family": "Simão",
                        "given": "José"
                    },
                    {
                        "family": "Veiga",
                        "given": "Luis"
                    },
                    {
                        "family": "Ferreira",
                        "given": "Paulo"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            3,
                            25
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            3,
                            25
                        ]
                    ]
                },
                "abstract": "Latency sensitive services such as credit-card fraud detection and website targeted advertisement rely on Big Data platforms which run on top of memory managed runtimes, such as the Java Virtual Machine (JVM). These platforms, however, suffer from unpredictable and unacceptably high pause times due to inadequate memory management decisions (e.g., allocating objects with very different lifetimes next to each other, resulting in severe memory fragmentation). This leads to frequent and long application pause times, breaking Service Level Agreements (SLAs). This problem has been previously identified, and results show that current memory management techniques are ill-suited for applications that hold in memory massive amounts of long-lived objects (which is the case for a wide spectrum of Big Data applications).Previous works reduce such application pauses by allocating objects in off-heap, in special allocation regions/generations, or by using ultra-low latency Garbage Collectors (GC). However, all these solutions either require a combination of programmer effort and knowledge, source code access, offline profiling (with clear negative impacts on programmer's productivity), or impose a significant impact on application throughput and/or memory to reduce application pauses.We propose ROLP, a Runtime Object Lifetime Profiler that profiles application code at runtime and helps pretenuring GC algorithms allocating objects with similar lifetimes close to each other so that the overall fragmentation, GC effort, and application pauses are reduced. ROLP is implemented for the OpenJDK 8 and was evaluated with a recently proposed open-source pretenuring collector (NG2C). Results show long tail latencies reductions of up to 51% for Lucene, 85% for GraphChi, and 69% for Cassandra. This is achieved with negligible throughput (< 6%) and memory overhead, with no programmer effort, and no source code access.",
                "call-number": "10.1145/3302424.3303988",
                "collection-number": "28",
                "collection-title": "EuroSys '19",
                "container-title": "Proceedings of the Fourteenth EuroSys Conference 2019",
                "DOI": "10.1145/3302424.3303988",
                "event-place": "Dresden, Germany",
                "ISBN": "9781450362818",
                "keyword": "Profiling, Tail Latency, Garbage Collection, Big Data, Pretenuring",
                "number": "Article 28",
                "number-of-pages": "16",
                "page": "1–16",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Runtime Object Lifetime Profiler for Latency Sensitive Big Data Applications",
                "URL": "https://doi.org/10.1145/3302424.3303988"
            }
        },
        {
            "10.1145/1077501.1077519": {
                "id": "10.1145/1077501.1077519",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Pon",
                        "given": "Raymond K."
                    },
                    {
                        "family": "Cárdenas",
                        "given": "Alfonso F."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2005,
                            6,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2005,
                            6,
                            17
                        ]
                    ]
                },
                "abstract": "In the field of sensor networks, data integration and collaboration, and intelligence gathering efforts, information on the quality of data sources are important but are often not available. We describe a technique to rank data sources by observing and comparing their behavior (i.e., the data produced by data sources) to rank. Intuitively, our measure characterizes data sources that agree with accurate or high-quality data sources as likely accurate. Furthermore, our measure includes a temporal component that takes into account a data source's past accuracy in evaluating its current accuracy. Initial experimental results based on simulation data to support our hypothesis demonstrate high precision and recall on identifying the most accurate data sources.",
                "call-number": "10.1145/1077501.1077519",
                "collection-title": "IQIS '05",
                "container-title": "Proceedings of the 2nd international workshop on Information quality in information systems",
                "DOI": "10.1145/1077501.1077519",
                "event-place": "Baltimore, Maryland",
                "ISBN": "1595931600",
                "number-of-pages": "7",
                "page": "105–111",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Data quality inference",
                "URL": "https://doi.org/10.1145/1077501.1077519"
            }
        },
        {
            "10.1145/2559206.2580093": {
                "id": "10.1145/2559206.2580093",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Eagle",
                        "given": "Nathan"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            4,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            4,
                            26
                        ]
                    ]
                },
                "abstract": "Petabytes of data about human movements, transactions, and communication patterns are continuously being generated by everyday technologies such as mobile phones and credit cards. This unprecedented volume of information facilitates a novel set of research questions applicable to a wide range of development issues.In a collaboration involving 237 mobile operators across 102 countries, Jana's mobile technology platform can instantly poll and compensate 3.48 billion active mobile subscriptions. This talk will discuss how insights gained from living in Kenya became the genesis of a technology company currently working with global clients in over 50 countries, including P&G, Google, Unilever, Danone, General Mills, Nestle, Johnson & Johnson, Microsoft, the World Bank, and the United Nations. After providing an overview of the mobile and social media landscapes in emerging markets, it will conclude by emphasizing the value of consumer data in underserved and understudied regions of the world.",
                "call-number": "10.1145/2559206.2580093",
                "collection-title": "CHI EA '14",
                "container-title": "CHI '14 Extended Abstracts on Human Factors in Computing Systems",
                "DOI": "10.1145/2559206.2580093",
                "event-place": "Toronto, Ontario, Canada",
                "ISBN": "9781450324748",
                "keyword": "keynote/invited talk",
                "number-of-pages": "2",
                "page": "11–12",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data for social good",
                "URL": "https://doi.org/10.1145/2559206.2580093"
            }
        },
        {
            "10.1145/3220228.3220236": {
                "id": "10.1145/3220228.3220236",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Saraee",
                        "given": "Mo"
                    },
                    {
                        "family": "Silva",
                        "given": "Charith"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            4,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            4,
                            20
                        ]
                    ]
                },
                "abstract": "Geospatial Big Data analytics are changing the way that businesses operate in many industries. Although a good number of research works have reported in the literature on geospatial data analytics and real-time data processing of large spatial data streams, only a few have addressed the full geospatial big data analytics project lifecycle and geospatial data science project lifecycle. Big data analysis differs from traditional data analysis primarily due to the volume, velocity and variety characteristics of the data being processed. One of a motivation of introducing new framework is to address these big data analysis challenges. Geospatial data science projects differ from most traditional data analysis projects because they could be complex and in need of advanced technologies in comparison to the traditional data analysis projects. For this reason, it is essential to have a process to govern the project and ensure that the project participants are competent enough to carry on the process. To this end, this paper presents, new geospatial big data mining and machine learning framework for geospatial data acquisition, data fusion, data storing, managing, processing, analysing, visualising and modelling and evaluation. Having a good process for data analysis and clear guidelines for comprehensive analysis is always a plus point for any data science project. It also helps to predict required time and resources early in the process to get a clear idea of the business problem to be solved.",
                "call-number": "10.1145/3220228.3220236",
                "collection-title": "ICGDA '18",
                "container-title": "Proceedings of the International Conference on Geoinformatics and Data Analysis",
                "DOI": "10.1145/3220228.3220236",
                "event-place": "Prague, Czech Republic",
                "ISBN": "9781450364454",
                "keyword": "big data, data mining, data science, machine learning, geospatial big data",
                "number-of-pages": "5",
                "page": "98–102",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A new data science framework for analysing and mining geospatial big data",
                "URL": "https://doi.org/10.1145/3220228.3220236"
            }
        },
        {
            "10.1145/2505515.2514697": {
                "id": "10.1145/2505515.2514697",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Murphy",
                        "given": "Kevin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            10,
                            27
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            10,
                            27
                        ]
                    ]
                },
                "abstract": "We are drowning in big data, but a lot of it is hard to interpret. For example, Google indexes about 40B webpages, but these are just represented as bags of words, which don't mean much to a computer. To get from \"strings to things\", Google introduced the Knowledge Graph (KG), which is a database of facts about entities (people, places, movies, etc.) and their relations (nationality, geo-containment, actor roles, etc). KG is based on Freebase, but supplements it with various other structured data sources. Although KG is very large (about 500M nodes/ entities, and 30B edges/ relations), it is still very incomplete. For example, 94% of the people are missing their place of birth, and 78\\% have no known nationality - these are examples of missing links in the graph. In addition, we are missing many nodes (corresponding to new entities), as well as new types of nodes and edges (corresponding to extensions to the schema). In this talk, I will survey some of the efforts we are engaged in to try to \"grow\" KG automatically using machine learning methods. In particular, I will summarize our work on the problems of entity linkage, relation extraction, and link prediction, using data extracted from natural language text as well as tabular data found on the web.",
                "call-number": "10.1145/2505515.2514697",
                "collection-title": "CIKM '13",
                "container-title": "Proceedings of the 22nd ACM international conference on Information & Knowledge Management",
                "DOI": "10.1145/2505515.2514697",
                "event-place": "San Francisco, California, USA",
                "ISBN": "9781450322638",
                "keyword": "information extraction, knowledge bases, machine learning",
                "number-of-pages": "2",
                "page": "1917–1918",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "From big data to big knowledge",
                "URL": "https://doi.org/10.1145/2505515.2514697"
            }
        },
        {
            "10.1145/3436286": {
                "id": "10.1145/3436286",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2020
                        ]
                    ]
                },
                "call-number": "10.1145/3436286",
                "container-title-short": "ISBDAI '20",
                "event-place": "Johannesburg, South Africa",
                "genre": "proceeding",
                "ISBN": "9781450376457",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2020 2nd International Conference on Big Data and Artificial Intelligence"
            }
        },
        {
            "10.1109/CCGRID.2018.00097": {
                "id": "10.1109/CCGRID.2018.00097",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Makrani",
                        "given": "Hosein Mohammadi"
                    },
                    {
                        "family": "Rafatirad",
                        "given": "Setareh"
                    },
                    {
                        "family": "Houmansadr",
                        "given": "Amir"
                    },
                    {
                        "family": "Homayoun",
                        "given": "Houman"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            1
                        ]
                    ]
                },
                "abstract": "The emergence of big data frameworks requires computational and memory resources that can naturally scale to manage massive amounts of diverse data. It is currently unclear whether big data frameworks such as Hadoop, Spark, and MPI will require high bandwidth and large capacity memory to cope with this change. The primary purpose of this study is to answer this question through empirical analysis of different memory configurations available for commodity server and to assess the impact of these configurations on the performance Hadoop and Spark frameworks, and MPI based applications. Our results show that neither DRAM capacity, frequency, nor the number of channels play a critical role on the performance of all studied Hadoop as well as most studied Spark applications. However, our results reveal that iterative tasks (e.g. machine learning) in Spark and MPI are benefiting from a high bandwidth and large capacity memory.",
                "call-number": "10.1109/CCGRID.2018.00097",
                "collection-title": "CCGrid '18",
                "container-title": "Proceedings of the 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing",
                "DOI": "10.1109/CCGRID.2018.00097",
                "event-place": "Washington, District of Columbia",
                "ISBN": "9781538658154",
                "keyword": "performance, memory, big data, hadoop, Spark",
                "number-of-pages": "8",
                "page": "653–660",
                "publisher": "IEEE Press",
                "title": "Main-memory requirements of big data applications on commodity server platform",
                "URL": "https://doi.org/10.1109/CCGRID.2018.00097"
            }
        },
        {
            "10.1145/3481056.3481108": {
                "id": "10.1145/3481056.3481108",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yanzheng",
                        "given": "Wang"
                    },
                    {
                        "family": "Xiaohong",
                        "given": "Wang"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            7,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            7,
                            23
                        ]
                    ]
                },
                "abstract": "Big data in education plays a pivotal role in university course learning at present, and it is also the trend of future education development.This paper introduces the application functions of big data in the teaching and learning of university subjects: the effective data analysis of big data in education, the resource-sharing function of big data in education, and the the evaluation of a variety of students' schoolwork.At the same time, this paper studies the development and application of intelligent platform based on big data, discusses the construction and application of automatic writing evaluation system based on \"big data\" and \"artificial intelligence\" technology.",
                "call-number": "10.1145/3481056.3481108",
                "collection-title": "ICEMT 2021",
                "container-title": "2021 5th International Conference on Education and Multimedia Technology",
                "DOI": "10.1145/3481056.3481108",
                "event-place": "Kyoto, Japan",
                "ISBN": "9781450390224",
                "keyword": "education, big data, curriculum learning, application and development, data analysis",
                "number-of-pages": "4",
                "page": "1–4",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Application and Development of Educational Big Data in University Course Learning",
                "URL": "https://doi.org/10.1145/3481056.3481108"
            }
        },
        {
            "10.1145/2694730": {
                "id": "10.1145/2694730",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2015
                        ]
                    ]
                },
                "abstract": "It is our great pleasure to welcome you to the 2015 ACM Workshop on Performance Analysis of Big Data Systems -- PABS'15 in conjunction with ICPE2015.The main objective of the workshop is to discuss the performance challenges imposed by big data systems and the different state-of-the-art solutions proposed to overcome these challenges. The workshop aims at providing a platform for scientific researchers, academicians and practitioners to discuss techniques, models, benchmarks, tools and experiences while dealing with performance issues in big data systems.The program committee reviewed 4 and accepted 2 full technical papers with acceptance rate as 50%.We welcome attendees to attend the keynote, invited talk and paper presentations. These valuable and insightful talks can and will guide us to a better understanding of the future: Accelerating Big Data Processing on Modern Clusters, Prof. D.K. Panda (Ohio State University, USA)Experimentation as a Tool for the Performance Evaluation of Big Data Systems, Prof. Amy W. Apon (Clemson University, USA)",
                "call-number": "10.1145/2694730",
                "container-title-short": "PABS '15",
                "event-place": "Austin, Texas, USA",
                "genre": "proceeding",
                "ISBN": "9781450333382",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 1st Workshop on Performance Analysis of Big Data Systems"
            }
        },
        {
            "10.1145/3277139.3277155": {
                "id": "10.1145/3277139.3277155",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sarker",
                        "given": "Md Nazirul Islam"
                    },
                    {
                        "family": "Hossin",
                        "given": "Md Altab"
                    },
                    {
                        "family": "Frimpong",
                        "given": "Adasa Nkrumah Kofi"
                    },
                    {
                        "family": "Xiaohua",
                        "given": "Yin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            8,
                            25
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            8,
                            25
                        ]
                    ]
                },
                "abstract": "Big data has a potential to transform traditional government system to data-driven e-government system by utilizing modern analytical techniques. The aim of this article is to explore the applicability of big data for ensuring e-government. An extensive literature review has been administered using various levels of scales and indicators. Literature survey shows that a number of models have been developed to explain e-governance but systematic research on the suitability of big data for e-government is still lacking. This article argues that big data can help the information resource management system of the government for improving transparency and reducing corruption, fastest public service delivery, reducing public hassle, providing easy access to public services, reducing error and reducing poverty through e-services, e-management, e-democracy, and e-commerce. This article further argues that big data has a significant role in cost-effective service delivery to citizens, policy coherence, access to public services, participation and engagement, representation, access to information, open government and corruption control. The finding suggests that big data technologies should be implemented in every public-sector organization by minimizing technological challenges and threats, ensuring the privacy of citizen's information, maximizing utilization of data and promoting information management capacity.",
                "call-number": "10.1145/3277139.3277155",
                "collection-title": "IMMS '18",
                "container-title": "Proceedings of the 2018 International Conference on Information Management & Management Science",
                "DOI": "10.1145/3277139.3277155",
                "event-place": "Chengdu, China",
                "ISBN": "9781450364867",
                "keyword": "administration, public agency, big data, IRM, governance, e-government",
                "number-of-pages": "6",
                "page": "99–104",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Promoting information resource management for e-government through big data approach",
                "URL": "https://doi.org/10.1145/3277139.3277155"
            }
        },
        {
            "10.1145/3194206.3194229": {
                "id": "10.1145/3194206.3194229",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zhichao",
                        "given": "Xu"
                    },
                    {
                        "family": "Jiandong",
                        "given": "Zhao"
                    },
                    {
                        "family": "Huan",
                        "given": "Huang"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            3,
                            9
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            3,
                            9
                        ]
                    ]
                },
                "abstract": "With the advent of the Internet + era in the field of Tech big data, the big data of Tech big data has a large amount of data and various characteristics. It is an important means to carry out research on the big data of Tech big data to realize the combination and mining of efficient multi-source foreign technology data. However, at present, the big data of Tech big data are divided into disciplines and different formats, which are difficult to realize the intersection of effective scientific and technological information and realize data sharing. This paper puts forward a kind of big data combined with Tech big data and mining technology based on the Hadoop framework.It includes a unified collection and preprocessing method of big data of Tech big data and the design of storage and management platform for data sources. It is based on Map/Reduce Tech big data parallelization computing model and system.Its correlation with important scientific data mining services.The framework has good practicability and expansibility.",
                "call-number": "10.1145/3194206.3194229",
                "collection-title": "ICIAI '18",
                "container-title": "Proceedings of the 2nd International Conference on Innovation in Artificial Intelligence",
                "DOI": "10.1145/3194206.3194229",
                "event-place": "Shanghai, China",
                "ISBN": "9781450363457",
                "keyword": "tech big data, combination, Hadoop, mining",
                "number-of-pages": "5",
                "page": "59–63",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Based on Hadoop's tech big data combination and mining technology framework",
                "URL": "https://doi.org/10.1145/3194206.3194229"
            }
        },
        {
            "10.1145/3150919.3150925": {
                "id": "10.1145/3150919.3150925",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Ramirez",
                        "given": "Andres"
                    },
                    {
                        "family": "Rahnemoonfar",
                        "given": "Maryam"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            11,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            11,
                            7
                        ]
                    ]
                },
                "abstract": "A hyperspectral image provides a multidimensional data consisting of hundreds of spectral dimensions. Even though having an abundance of spectral might seem favorable, classification of hyperspectral data tends to collide with the curse of dimensionality. Therefore, reducing the number of dimensions before classification is always favorable. For this research, the feature extraction method will consist of a nonlinear manifold learning technique named locally linear embedding (LLE). Additionally, another problem that we attempt to overcome is the high computational time required to run manifold learning methods. In order to help overcome this problem, this research compares one implementation of LLE against an improved version that runs much quicker than the original version.",
                "call-number": "10.1145/3150919.3150925",
                "collection-title": "BigSpatial'17",
                "container-title": "Proceedings of the 6th ACM SIGSPATIAL Workshop on Analytics for Big Geospatial Data",
                "DOI": "10.1145/3150919.3150925",
                "event-place": "Redondo Beach, CA, USA",
                "ISBN": "9781450354943",
                "keyword": "Hyperspectral, Big-data, Locally Linear Embedding",
                "number-of-pages": "5",
                "page": "37–41",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Improved Locally Linear Embedding for Big-data Classification",
                "URL": "https://doi.org/10.1145/3150919.3150925"
            }
        },
        {
            "10.1145/2970276.2970325": {
                "id": "10.1145/2970276.2970325",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Li",
                        "given": "Nan"
                    },
                    {
                        "family": "Lei",
                        "given": "Yu"
                    },
                    {
                        "family": "Khan",
                        "given": "Haider Riaz"
                    },
                    {
                        "family": "Liu",
                        "given": "Jingshu"
                    },
                    {
                        "family": "Guo",
                        "given": "Yun"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            8,
                            25
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            8,
                            25
                        ]
                    ]
                },
                "abstract": "Big data applications (e.g., Extract, Transform, and Load (ETL) applications) are designed to handle great volumes of data. However, processing such great volumes of data is time-consuming. There is a need to construct small yet effective test data sets during agile development of big data applications. In this paper, we apply a combinatorial test data generation approach to two real-world ETL applications at Medidata. In our approach, we first create Input Domain Models (IDMs) automatically by analyzing the original data source and incorporating constraints manually derived from requirements. Next, the IDMs are used to create test data sets that achieve t-way coverage, which has shown to be very effective in detecting software faults. The generated test data sets also satisfy all the constraints identified in the first step. To avoid creating IDMs from scratch when there is a change to the original data source or constraints, our approach extends the original IDMs with additional information. The new IDMs, which we refer to as Adaptive IDMs (AIDMs), are updated by comparing the changes against the additional information, and are then used to generate new test data sets. We implement our approach in a tool, called comBinatorial bIg daTa Test dAta Generator (BIT-TAG). Our experience shows that combinatorial testing can be effectively applied to big data applications. In particular, the test data sets created using our approach for the two ETL applications are only a small fraction of the original data source, but we were able to detect all the faults found with the original data source.",
                "call-number": "10.1145/2970276.2970325",
                "collection-title": "ASE 2016",
                "container-title": "Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering",
                "DOI": "10.1145/2970276.2970325",
                "event-place": "Singapore, Singapore",
                "ISBN": "9781450338455",
                "keyword": "Combinatorial Testing, Input Domain Model, Test Data Generation, Adaptive Input Domain Model, Big Data Testing",
                "number-of-pages": "11",
                "page": "637–647",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Applying combinatorial test data generation to big data applications",
                "URL": "https://doi.org/10.1145/2970276.2970325"
            }
        },
        {
            "10.1145/2616498.2616525": {
                "id": "10.1145/2616498.2616525",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sondhi",
                        "given": "Sukrit"
                    },
                    {
                        "family": "Arora",
                        "given": "Ritu"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            7,
                            13
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            7,
                            13
                        ]
                    ]
                },
                "abstract": "The term 'Big Data' defines large datasets that are difficult to use and manage through conventional software tools. Legal Electronic Discovery (e-Discovery) is a business domain which has massive consumption of Big Data, where electronic records such as e-mail, documents, databases and social media postings are processed in order to discover evidence that may be pertinent to legal/compliance needs, litigation or other investigations. Numerous vendors exist in the market to provide organizations with services such as data collection, digital forensics and electronic discovery. High-end instrumentation and modern information technologies are creating data at an ever increasing rate. The challenges associated with managing the large datasets are related to the capture, storage, search, sharing, analytics, and visualization of the data. Big Data also offers unprecedented opportunities in other fields, ranging from astronomy and biology to marketing and e-commerce. This paper presents lessons learnt from the legal e-Discovery domain that can be adapted to process Big Data effectively on HPC resources, thereby benefitting the various disciplines of science, engineering and business that are grappling with a deluge of Big Data challenges and opportunities.",
                "call-number": "10.1145/2616498.2616525",
                "collection-number": "8",
                "collection-title": "XSEDE '14",
                "container-title": "Proceedings of the 2014 Annual Conference on Extreme Science and Engineering Discovery Environment",
                "DOI": "10.1145/2616498.2616525",
                "event-place": "Atlanta, GA, USA",
                "ISBN": "9781450328937",
                "keyword": "parallel programming, predictive analytics, Big Data, e-Discovery",
                "number": "Article 8",
                "number-of-pages": "2",
                "page": "1–2",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Applying Lessons from e-Discovery to Process Big Data using HPC",
                "URL": "https://doi.org/10.1145/2616498.2616525"
            }
        },
        {
            "10.1145/2500873": {
                "id": "10.1145/2500873",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Kim",
                        "given": "Gang-Hoon"
                    },
                    {
                        "family": "Trimi",
                        "given": "Silvana"
                    },
                    {
                        "family": "Chung",
                        "given": "Ji-Hyong"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            3,
                            1
                        ]
                    ]
                },
                "abstract": "In the same way businesses use big data to pursue profits, governments use it to promote the public good.",
                "call-number": "10.1145/2500873",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/2500873",
                "ISSN": "0001-0782",
                "issue": "3",
                "number-of-pages": "8",
                "page": "78–85",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "March 2014",
                "title": "Big-data applications in the government sector",
                "URL": "https://doi.org/10.1145/2500873",
                "volume": "57"
            }
        },
        {
            "10.1145/3129292.3129296": {
                "id": "10.1145/3129292.3129296",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Costa",
                        "given": "Constantinos"
                    },
                    {
                        "family": "Chatzimilioudis",
                        "given": "Georgios"
                    },
                    {
                        "family": "Zeinalipour-Yazti",
                        "given": "Demetrios"
                    },
                    {
                        "family": "Mokbel",
                        "given": "Mohamed F."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            28
                        ]
                    ]
                },
                "abstract": "A telecommunication company (telco) is traditionally only perceived as the entity that provides telecommunication services, such as telephony and data communication access to users. However, the IP backbone infrastructure of such entities spanning densely urban spaces and widely rural areas, provides nowadays a unique opportunity to collect immense amounts of mobility data that can provide valuable insights for road traffic management and avoidance. In this paper we outline the components of the Traffic-TBD (Traffic Telco Big Data) architecture, which aims to become an innovative road traffic analytic and prediction system with the following desiderata: i) provide micro-level traffic modeling and prediction that goes beyond the current state provided by Internet-based navigation enterprises utilizing crowdsourcing; ii) retain the location privacy boundaries of users inside their mobile network operator, to avoid the risks of exposing location data to third-party mobile applications; and iii) be available with minimal costs and using existing infrastructure (i.e., cell towers and TBD data streams are readily available inside a telco). Road traffic understanding, management and analytics can minimize the number of road accidents, optimize fuel and energy consumption, avoid unexpected delays, contribute to a macroscopic spatio-temporal understanding of traffic in cities but also to \"smart\" societies through applications in city planning, public transportation, logistics and fleet management for enterprises, startups and governmental bodies.",
                "call-number": "10.1145/3129292.3129296",
                "collection-number": "5",
                "collection-title": "BIRTE '17",
                "container-title": "Proceedings of the International Workshop on Real-Time Business Intelligence and Analytics",
                "DOI": "10.1145/3129292.3129296",
                "event-place": "Munich, Germany",
                "ISBN": "9781450354257",
                "keyword": "Road Traic, Big Data, Telco, Data Analytics",
                "number": "Article 5",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Towards Real-Time Road Traffic Analytics using Telco Big Data",
                "URL": "https://doi.org/10.1145/3129292.3129296"
            }
        },
        {
            "10.5555/3018100.3018105": {
                "id": "10.5555/3018100.3018105",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yang",
                        "given": "Xi"
                    },
                    {
                        "family": "Lehman",
                        "given": "Tom"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            11,
                            13
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            11,
                            13
                        ]
                    ]
                },
                "abstract": "Advanced hybrid cloud services aim to serve big data applications by bridging multi-provider high performance cloud resources including direct connects, hypervisor bypassing VM interfaces, on premise clusters, parallel storage and high speed inter-cloud networks. We present a new \"full-stack model driven orchestration\" paradigm to integrate these diverse resources through semantic modeling and provide complex high-end services through dynamic orchestrated workflows. We also present architectural design of a real-world orchestration system, VersaStack, that implements the paradigm as well as a case study for providing full-scale advanced hybrid cloud services in practice.",
                "call-number": "10.5555/3018100.3018105",
                "collection-title": "DataCloud '16",
                "container-title": "Proceedings of the 7th International Workshop on Data-Intensive Computing in the Cloud",
                "event-place": "Salt Lake City, Utah",
                "ISBN": "9781509061587",
                "keyword": "advanced hybrid cloud, semantic modeling, big data, service orchestration",
                "number-of-pages": "5",
                "page": "32–36",
                "publisher": "IEEE Press",
                "title": "Model driven advanced hybrid cloud services for big data: paradigm and practice"
            }
        },
        {
            "10.1145/2818302.2818308": {
                "id": "10.1145/2818302.2818308",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Nguyen",
                        "given": "Khanh"
                    },
                    {
                        "family": "Fang",
                        "given": "Lu"
                    },
                    {
                        "family": "Xu",
                        "given": "Guoqing"
                    },
                    {
                        "family": "Demsky",
                        "given": "Brian"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            10,
                            4
                        ]
                    ]
                },
                "abstract": "Most real-world Big Data systems are written in managed languages. These systems suffer from severe memory problems due to the massive volumes of objects created to process input data. Allocating and deallocating a sea of objects puts a severe strain on the garbage collector, leading to excessive GC efforts and/or out-of-memory crashes. Region-based memory management has been recently shown to be effective to reduce GC costs for Big Data systems. However, all existing region-based techniques require significant user annotations, resulting in limited usefulness and practicality. This paper reports an ongoing project, aiming to design and implement a novel speculative region-based technique that requires only minimum user involvement. In our system, objects are allocated speculatively into their respective regions and promoted into the heap if needed. We develop an object promotion algorithm that scans regions for only a small number of times, which will hopefully lead to significantly improved memory management efficiency. We also present an OpenJDK-based implementation plan and an evaluation plan.",
                "call-number": "10.1145/2818302.2818308",
                "collection-title": "PLOS '15",
                "container-title": "Proceedings of the 8th Workshop on Programming Languages and Operating Systems",
                "DOI": "10.1145/2818302.2818308",
                "event-place": "Monterey, California",
                "ISBN": "9781450339421",
                "keyword": "region-based memory management, language, big data systems, performance optimization, managed languages",
                "number-of-pages": "6",
                "page": "27–32",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Speculative region-based memory management for big data systems",
                "URL": "https://doi.org/10.1145/2818302.2818308"
            }
        },
        {
            "10.1145/3006299": {
                "id": "10.1145/3006299",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2016
                        ]
                    ]
                },
                "abstract": "Rapid advances in digital sensors, networks, storage, and computation along with their availability at low cost is leading to the creation of huge collections of data---dubbed \"Big Data.\" As a result, a Big Data computing paradigm has emerged, enabling new insights that can change the way business, science, and governments deliver services to their consumers, and can impact society as a whole. BDCAT provides an international forum for researchers and practitioners to present and discuss new discoveries, developments, and results, as well as the latest trends in big data computing, technologies, and applications.",
                "call-number": "10.1145/3006299",
                "container-title-short": "BDCAT '16",
                "event-place": "Shanghai, China",
                "genre": "proceeding",
                "ISBN": "9781450346177",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 3rd IEEE/ACM International Conference on Big Data Computing, Applications and Technologies"
            }
        },
        {
            "10.1145/3017680.3022386": {
                "id": "10.1145/3017680.3022386",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Nagar",
                        "given": "Anurag"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            3,
                            8
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            3,
                            8
                        ]
                    ]
                },
                "abstract": "This lightning talk will focus on our experience of developing and managing large undergraduate and graduate Big Data courses. The demand for trained professionals in the field of Big Data technologies is huge, and there is urgent need to develop and update courses in this area. One of the biggest hurdles for many schools is establishment, maintenance, and constant update of high performance computing infrastructure. Further, the technology landscape for Big Data is constantly evolving, and newer technologies, such as Apache Spark, require significant expenditure to set up and upgrade at the cluster level. Traditional infrastructure at most higher educational institutions is insufficient for this, and is also not able to scale up to meet the expectations of large class sizes and multiple simultaneous sessions. In this lightening talk, we will share our experience of running large undergraduate and graduate Big Data courses using open source infrastructure. Some of this infrastructure is cloud based, while others require students to create virtualized environment on their personal computers. Both types of resources are freely available, easy to setup, and provide students with enough computational power to run most academic tasks and projects. We will provide specific examples of using such technologies for common tasks, such as setting up a distributed file system, running MapReduce algorithms on large datasets, performing large scale machine learning and graph mining using Apache Spark, and maintaining a high availability Cassandra instance.",
                "call-number": "10.1145/3017680.3022386",
                "collection-title": "SIGCSE '17",
                "container-title": "Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education",
                "DOI": "10.1145/3017680.3022386",
                "event-place": "Seattle, Washington, USA",
                "ISBN": "9781450346986",
                "keyword": "big data teaching, distributed computing teaching, infrastructure for teaching big data",
                "number-of-pages": "2",
                "page": "700–701",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Developing Big Data Curriculum with Open Source Infrastructure (Abstract Only)",
                "URL": "https://doi.org/10.1145/3017680.3022386"
            }
        },
        {
            "10.1145/3246336": {
                "id": "10.1145/3246336",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chen",
                        "given": "Lei"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            23
                        ]
                    ]
                },
                "call-number": "10.1145/3246336",
                "collection-title": "SIGMOD'13 PhD Symposium",
                "container-title": "Proceedings of the 2013 SIGMOD/PODS Ph.D. symposium",
                "DOI": "10.1145/3246336",
                "event-place": "New York, New York, USA",
                "ISBN": "9781450321556",
                "page": "",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Session details: Towards big data",
                "URL": "https://doi.org/10.1145/3246336"
            }
        }
    ]
}