{
    "exportedDoiLength": 100,
    "fileName": "acm",
    "style": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<style xmlns=\"http://purl.org/net/xbiblio/csl\" class=\"in-text\" version=\"1.0\" demote-non-dropping-particle=\"sort-only\" default-locale=\"en-US\">\n    <!-- This style was edited with the Visual CSL Editor (http://editor.citationstyles.org/visualEditor/) -->\n    <info>\n        <title>BibTeX ACM citation style</title>\n        <id>http://www.zotero.org/styles/bibtex-acm-citation-style</id>\n        <link href=\"http://www.zotero.org/styles/bibtex-acm-citation-style\" rel=\"self\"/>\n        <link href=\"http://www.bibtex.org/\" rel=\"documentation\"/>\n        <author>\n            <name>Markus Schaffner</name>\n        </author>\n        <contributor>\n            <name>Richard Karnesky</name>\n            <email>karnesky+zotero@gmail.com</email>\n            <uri>http://arc.nucapt.northwestern.edu/Richard_Karnesky</uri>\n        </contributor>\n        <category citation-format=\"author-date\"/>\n        <category field=\"generic-base\"/>\n        <updated>2018-06-11T10:52:49+00:00</updated>\n        <rights license=\"http://creativecommons.org/licenses/by-sa/3.0/\">This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 License</rights>\n    </info>\n    <macro name=\"zotero2bibtexType\">\n        <choose>\n            <if type=\"BILL BOOK GRAPHIC LEGAL_CASE LEGISLATION MOTION_PICTURE SONG\" match=\"any\">\n                <choose>\n                    <if genre=\"rfc\"  match=\"any\">\n                       <text value=\"rfc\"/>\n                    </if>\n                     <else-if  genre=\"bibliography\" match=\"any\">\n                        <text value=\"bibliography\"/>\n                    </else-if>\n                    <else-if  genre=\"play_drama\" match=\"any\">\n                        <text value=\"playdrama\"/>\n                    </else-if>\n                    <else-if  genre=\"proceeding\" match=\"any\">\n                        <text value=\"proceedings\"/>\n                    </else-if>\n                    <else-if  genre=\"tech_brief\" match=\"any\">\n                        <text value=\"tech-brief\"/>\n                    </else-if>\n                    <else>\n                       <text value=\"book\"/>\n                    </else>\n                </choose>\n            </if>\n            <else-if type=\"CHAPTER\" match=\"any\">\n                <text value=\"inbook\"/>\n            </else-if>\n            <else-if type=\"ARTICLE ARTICLE_JOURNAL ARTICLE_MAGAZINE ARTICLE_NEWSPAPER\" match=\"any\">\n                <text value=\"article\"/>\n            </else-if>\n            <else-if type=\"THESIS\" match=\"any\">\n                <choose>\n                    <if variable=\"genre\">\n                        <text variable=\"genre\" text-case=\"lowercase\" strip-periods=\"true\"/>\n                    </if>\n                </choose>\n                <text value=\"thesis\"/>\n            </else-if>\n            <else-if type=\"PAPER_CONFERENCE\" match=\"any\">\n                <text value=\"inproceedings\"/>\n            </else-if>\n            <else-if type=\"REPORT\" match=\"any\">\n                <text value=\"techreport\"/>\n            </else-if>\n            <else-if type=\"DATASET\" match=\"any\">\n                <choose>\n                    <if genre=\"software\"  match=\"any\">\n                       <text value=\"software\"/>\n                    </if>\n                    <else>\n                       <text value=\"dataset\"/>\n                    </else>\n                </choose>\n            </else-if>\n            <else>\n                <text value=\"misc\"/>\n            </else>\n        </choose>\n    </macro>\n    <macro name=\"citeKey\">\n           <text variable=\"call-number\"/>\n    </macro>\n    <macro name=\"editor-short\">\n        <names variable=\"editor\">\n            <name form=\"short\" delimiter=\":\" delimiter-precedes-last=\"always\"/>\n        </names>\n    </macro>\n    <macro name=\"author-short\">\n        <names variable=\"author\">\n            <name form=\"short\" delimiter=\":\" delimiter-precedes-last=\"always\"/>\n        </names>\n    </macro>\n    <macro name=\"issued-year\">\n        <date variable=\"issued\">\n            <date-part name=\"year\"/>\n        </date>\n    </macro>\n    <macro name=\"issued-month\">\n        <choose>\n            <if type=\"ARTICLE\" match=\"any\">\n                <date variable=\"issued\">\n                    <date-part name=\"month\" form=\"short\" strip-periods=\"true\" text-case=\"lowercase\"/>\n                </date>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"issue-date\">\n        <choose>\n            <if type=\"ARTICLE ARTICLE_JOURNAL\" match=\"any\">\n                <choose>\n                    <if variable=\"note\" match=\"none\">\n                        <choose>\n                            <if variable=\"source\">\n                                 <text variable=\"source\"/>\n                            </if>\n                               <else>\n                                 <date date-parts=\"year-month\" form=\"text\" variable=\"issued\"/>\n                               </else>\n                        </choose>\n                    </if>\n                </choose>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"author\">\n        <names variable=\"author\">\n            <name sort-separator=\", \" delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n            <label form=\"long\" text-case=\"capitalize-first\"/>\n        </names>\n    </macro>\n    <macro name=\"editor-translator\">\n        <names variable=\"editor translator\" delimiter=\", \">\n            <name sort-separator=\", \" delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n            <label form=\"long\" text-case=\"capitalize-first\"/>\n        </names>\n    </macro>\n    <macro name=\"title\">\n        <choose>\n            <if genre=\"proceeding\" match=\"any\">\n                <text variable=\"container-title-short\" suffix=\": \"/>\n                <text variable=\"title\" text-case=\"title\"/>\n            </if>\n            <else-if type=\"ARTICLE_JOURNAL\" match=\"none\">\n                <text variable=\"title\" text-case=\"title\"/>\n            </else-if>\n        </choose>\n    </macro>\n    <macro name=\"volume\">\n        <choose>\n            <if type=\"ARTICLE BOOK ARTICLE_JOURNAL\" match=\"any\">\n                <text variable=\"volume\" prefix=\"volume = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"DOI\">\n        <choose>\n            <if type=\"ARTICLE PAPER_CONFERENCE\" match=\"any\">\n                <text variable=\"DOI\" prefix=\"doi = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <macro name=\"abstract\">\n        <if match=\"any\" variable=\"abstract\">\n            <text variable=\"abstract\"/>\n        </if>\n    </macro>\n    <macro name=\"URL\">\n        <text variable=\"URL\" prefix=\"url = {\" suffix=\"}\"/>\n    </macro>\n    <macro name=\"container-title\">\n        <choose>\n            <if type=\"CHAPTER PAPER_CONFERENCE\" match=\"any\">\n                <text variable=\"container-title\" prefix=\"booktitle = {\" suffix=\"}\" text-case=\"title\"/>\n            </if>\n            <else-if type=\"ARTICLE ARTICLE_JOURNAL\" match=\"any\">\n                <text variable=\"container-title\" prefix=\"journal = {\" suffix=\"}\" text-case=\"title\"/>\n            </else-if>\n        </choose>\n    </macro>\n    <macro name=\"pages\">\n        <group delimiter=\",&#10;\">\n            <choose>\n                <if match=\"any\" variable=\"collection-number\">\n                    <text variable=\"collection-number\" prefix=\"articleno = {\" suffix=\"}\"/>\n                </if>\n                <else>\n                    <text variable=\"page\" prefix=\"pages = {\" suffix=\"}\"/>\n                </else>\n            </choose>\n            <text variable=\"number-of-pages\" prefix=\"numpages = {\" suffix=\"}\"/>\n        </group>\n    </macro>\n    <macro name=\"edition\">\n        <text variable=\"edition\"/>\n    </macro>\n    <macro name=\"editor\">\n        <choose>\n            <if match=\"any\" type=\"THESIS\">\n                <names variable=\"editor\" delimiter=\", \" prefix=\"advisor = {\" suffix=\"}\">\n                    <name delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n                </names>\n            </if>\n            <else>\n               <names variable=\"editor\" delimiter=\", \" prefix=\"editor = {\" suffix=\"}\">\n                   <name delimiter=\" and \" delimiter-precedes-last=\"always\" name-as-sort-order=\"all\"/>\n               </names>\n            </else>\n        </choose>\n    </macro>\n    <macro name=\"keyword\">\n        <choose>\n            <if type=\"ARTICLE PAPER_CONFERENCE DATASET\" match=\"any\">\n                <text variable=\"keyword\" prefix=\"keywords = {\" suffix=\"}\"/>\n            </if>\n        </choose>\n    </macro>\n    <citation et-al-min=\"11\" et-al-use-first=\"10\" disambiguate-add-year-suffix=\"true\" disambiguate-add-names=\"false\" disambiguate-add-givenname=\"false\" collapse=\"year\">\n        <layout delimiter=\"_\">\n            <text macro=\"citeKey\"/>\n        </layout>\n    </citation>\n    <bibliography hanging-indent=\"false\">\n        <layout>\n            <group display=\"right-inline\">\n                <text macro=\"zotero2bibtexType\" prefix=\"@\"/>\n                <group prefix=\"{\" suffix=\"&#10;}\" delimiter=\",&#10;\">\n                    <text macro=\"citeKey\"/>\n                    <text macro=\"author\" prefix=\"author = {\" suffix=\"}\"/>\n                    <text macro=\"editor\"/>\n                    <text macro=\"title\" prefix=\"title = {\" suffix=\"}\"/>\n                    <text macro=\"issued-year\" prefix=\"year = {\" suffix=\"}\"/>\n                    <text macro=\"issue-date\" prefix=\"issue_date = {\" suffix=\"}\"/>\n                    <text variable=\"ISBN\" prefix=\"isbn = {\" suffix=\"}\"/>\n                    <text variable=\"publisher\" prefix=\"publisher = {\" suffix=\"}\"/>\n                    <text variable=\"publisher-place\" prefix=\"address = {\" suffix=\"}\"/>\n                    <text variable=\"chapter-number\" prefix=\"chapter = {\" suffix=\"}\"/>\n                    <text macro=\"edition\" prefix=\"edition = {\" suffix=\"}\"/>\n                    <text macro=\"volume\"/>\n                    <text variable=\"issue\" prefix=\"number = {\" suffix=\"}\"/>\n                    <text variable=\"ISSN\" prefix=\"issn = {\" suffix=\"}\"/>\n                    <text variable=\"archive_location\" prefix=\"archiveLocation = {\" suffix=\"}\"/>\n                    <text macro=\"URL\"/>\n                    <text macro=\"DOI\"/>\n                    <text macro=\"abstract\" prefix=\"abstract = {\" suffix=\"}\"/>\n                    <text variable=\"note\" prefix=\"note = {\" suffix=\"}\"/>\n                    <text macro=\"container-title\"/>\n                    <text macro=\"issued-month\" prefix=\"month = {\" suffix=\"}\"/>\n                    <text macro=\"pages\"/>\n                    <text macro=\"keyword\"/>\n                    <text variable=\"event-place\" prefix=\"location = {\" suffix=\"}\"/>\n                    <choose>\n                        <if type=\"PAPER_CONFERENCE\" match=\"any\">\n                            <text variable=\"collection-title\" prefix=\"series = {\" suffix=\"}\"/>\n                        </if>\n                        <else>\n                            <text variable=\"collection-title\" prefix=\"collection = {\" suffix=\"}\"/>\n                        </else>\n                    </choose>\n                </group>\n            </group>\n        </layout>\n    </bibliography>\n</style>\n",
    "suffix": "bib",
    "locale": "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<locale xmlns=\"http://purl.org/net/xbiblio/csl\" version=\"1.0\" xml:lang=\"en-US\">\n  <info>\n    <rights license=\"http://creativecommons.org/licenses/by-sa/3.0/\">This work is licensed under a Creative Commons Attribution-ShareAlike 3.0 License</rights>\n    <updated>2012-07-04T23:31:02+00:00</updated>\n  </info>\n  <style-options punctuation-in-quote=\"true\"\n                 leading-noise-words=\"a,an,the\"\n                 name-as-sort-order=\"ja zh kr my hu vi\"\n                 name-never-short=\"ja zh kr my hu vi\"/>\n  <date form=\"text\">\n    <date-part name=\"month\" suffix=\" \"/>\n    <date-part name=\"day\" suffix=\", \"/>\n    <date-part name=\"year\"/>\n  </date>\n  <date form=\"numeric\">\n    <date-part name=\"month\" form=\"numeric-leading-zeros\" suffix=\"/\"/>\n    <date-part name=\"day\" form=\"numeric-leading-zeros\" suffix=\"/\"/>\n    <date-part name=\"year\"/>\n  </date>\n  <terms>\n    <term name=\"radio-broadcast\">radio broadcast</term>\n    <term name=\"television-broadcast\">television broadcast</term>\n    <term name=\"podcast\">podcast</term>\n    <term name=\"instant-message\">instant message</term>\n    <term name=\"email\">email</term>\n    <term name=\"number-of-volumes\">\n      <single>volume</single>\n      <multiple>volumes</multiple>\n    </term>\n    <term name=\"accessed\">accessed</term>\n    <term name=\"and\">and</term>\n    <term name=\"and\" form=\"symbol\">&amp;</term>\n    <term name=\"and others\">and others</term>\n    <term name=\"anonymous\">anonymous</term>\n    <term name=\"anonymous\" form=\"short\">anon.</term>\n    <term name=\"at\">at</term>\n    <term name=\"available at\">available at</term>\n    <term name=\"by\">by</term>\n    <term name=\"circa\">circa</term>\n    <term name=\"circa\" form=\"short\">c.</term>\n    <term name=\"cited\">cited</term>\n    <term name=\"edition\">\n      <single>edition</single>\n      <multiple>editions</multiple>\n    </term>\n    <term name=\"edition\" form=\"short\">ed.</term>\n    <term name=\"et-al\">et al.</term>\n    <term name=\"forthcoming\">forthcoming</term>\n    <term name=\"from\">from</term>\n    <term name=\"ibid\">ibid.</term>\n    <term name=\"in\">in</term>\n    <term name=\"in press\">in press</term>\n    <term name=\"internet\">internet</term>\n    <term name=\"interview\">interview</term>\n    <term name=\"letter\">letter</term>\n    <term name=\"no date\">no date</term>\n    <term name=\"no date\" form=\"short\">n.d.</term>\n    <term name=\"online\">online</term>\n    <term name=\"presented at\">presented at the</term>\n    <term name=\"reference\">\n      <single>reference</single>\n      <multiple>references</multiple>\n    </term>\n    <term name=\"reference\" form=\"short\">\n      <single>ref.</single>\n      <multiple>refs.</multiple>\n    </term>\n    <term name=\"retrieved\">retrieved</term>\n    <term name=\"scale\">scale</term>\n    <term name=\"version\">version</term>\n\n    <!-- ANNO DOMINI; BEFORE CHRIST -->\n    <term name=\"ad\">AD</term>\n    <term name=\"bc\">BC</term>\n\n    <!-- PUNCTUATION -->\n    <term name=\"open-quote\">“</term>\n    <term name=\"close-quote\">”</term>\n    <term name=\"open-inner-quote\">‘</term>\n    <term name=\"close-inner-quote\">’</term>\n    <term name=\"page-range-delimiter\">–</term>\n\n    <!-- ORDINALS -->\n    <term name=\"ordinal\">th</term>\n    <term name=\"ordinal-01\">st</term>\n    <term name=\"ordinal-02\">nd</term>\n    <term name=\"ordinal-03\">rd</term>\n    <term name=\"ordinal-11\">th</term>\n    <term name=\"ordinal-12\">th</term>\n    <term name=\"ordinal-13\">th</term>\n\n    <!-- LONG ORDINALS -->\n    <term name=\"long-ordinal-01\">first</term>\n    <term name=\"long-ordinal-02\">second</term>\n    <term name=\"long-ordinal-03\">third</term>\n    <term name=\"long-ordinal-04\">fourth</term>\n    <term name=\"long-ordinal-05\">fifth</term>\n    <term name=\"long-ordinal-06\">sixth</term>\n    <term name=\"long-ordinal-07\">seventh</term>\n    <term name=\"long-ordinal-08\">eighth</term>\n    <term name=\"long-ordinal-09\">ninth</term>\n    <term name=\"long-ordinal-10\">tenth</term>\n\n    <!-- LONG LOCATOR FORMS -->\n    <term name=\"book\">\n      <single>book</single>\n      <multiple>books</multiple>\n    </term>\n    <term name=\"chapter\">\n      <single>chapter</single>\n      <multiple>chapters</multiple>\n    </term>\n    <term name=\"column\">\n      <single>column</single>\n      <multiple>columns</multiple>\n    </term>\n    <term name=\"figure\">\n      <single>figure</single>\n      <multiple>figures</multiple>\n    </term>\n    <term name=\"folio\">\n      <single>folio</single>\n      <multiple>folios</multiple>\n    </term>\n    <term name=\"issue\">\n      <single>number</single>\n      <multiple>numbers</multiple>\n    </term>\n    <term name=\"line\">\n      <single>line</single>\n      <multiple>lines</multiple>\n    </term>\n    <term name=\"note\">\n      <single>note</single>\n      <multiple>notes</multiple>\n    </term>\n    <term name=\"opus\">\n      <single>opus</single>\n      <multiple>opera</multiple>\n    </term>\n    <term name=\"page\">\n      <single>page</single>\n      <multiple>pages</multiple>\n    </term>\n    <term name=\"paragraph\">\n      <single>paragraph</single>\n      <multiple>paragraph</multiple>\n    </term>\n    <term name=\"part\">\n      <single>part</single>\n      <multiple>parts</multiple>\n    </term>\n    <term name=\"section\">\n      <single>section</single>\n      <multiple>sections</multiple>\n    </term>\n    <term name=\"sub verbo\">\n      <single>sub verbo</single>\n      <multiple>sub verbis</multiple>\n    </term>\n    <term name=\"verse\">\n      <single>verse</single>\n      <multiple>verses</multiple>\n    </term>\n    <term name=\"volume\">\n      <single>volume</single>\n      <multiple>volumes</multiple>\n    </term>\n\n    <!-- SHORT LOCATOR FORMS -->\n    <term name=\"book\" form=\"short\">bk.</term>\n    <term name=\"chapter\" form=\"short\">chap.</term>\n    <term name=\"column\" form=\"short\">col.</term>\n    <term name=\"figure\" form=\"short\">fig.</term>\n    <term name=\"folio\" form=\"short\">f.</term>\n    <term name=\"issue\" form=\"short\">no.</term>\n    <term name=\"line\" form=\"short\">l.</term>\n    <term name=\"note\" form=\"short\">n.</term>\n    <term name=\"opus\" form=\"short\">op.</term>\n    <term name=\"page\" form=\"short\">\n      <single>p.</single>\n      <multiple>pp.</multiple>\n    </term>\n    <term name=\"paragraph\" form=\"short\">para.</term>\n    <term name=\"part\" form=\"short\">pt.</term>\n    <term name=\"section\" form=\"short\">sec.</term>\n    <term name=\"sub verbo\" form=\"short\">\n      <single>s.v.</single>\n      <multiple>s.vv.</multiple>\n    </term>\n    <term name=\"verse\" form=\"short\">\n      <single>v.</single>\n      <multiple>vv.</multiple>\n    </term>\n    <term name=\"volume\" form=\"short\">\n      <single>vol.</single>\n      <multiple>vols.</multiple>\n    </term>\n\n    <!-- SYMBOL LOCATOR FORMS -->\n    <term name=\"paragraph\" form=\"symbol\">\n      <single>¶</single>\n      <multiple>¶¶</multiple>\n    </term>\n    <term name=\"section\" form=\"symbol\">\n      <single>§</single>\n      <multiple>§§</multiple>\n    </term>\n\n    <!-- LONG ROLE FORMS -->\n    <term name=\"director\">\n      <single>director</single>\n      <multiple>directors</multiple>\n    </term>\n    <term name=\"editor\">\n      <single>editor</single>\n      <multiple>editors</multiple>\n    </term>\n    <term name=\"editorial-director\">\n      <single>editor</single>\n      <multiple>editors</multiple>\n    </term>\n    <term name=\"illustrator\">\n      <single>illustrator</single>\n      <multiple>illustrators</multiple>\n    </term>\n    <term name=\"translator\">\n      <single>translator</single>\n      <multiple>translators</multiple>\n    </term>\n    <term name=\"editortranslator\">\n      <single>editor &amp; translator</single>\n      <multiple>editors &amp; translators</multiple>\n    </term>\n\n    <!-- SHORT ROLE FORMS -->\n    <term name=\"director\" form=\"short\">\n      <single>dir.</single>\n      <multiple>dirs.</multiple>\n    </term>\n    <term name=\"editor\" form=\"short\">\n      <single>ed.</single>\n      <multiple>eds.</multiple>\n    </term>\n    <term name=\"editorial-director\" form=\"short\">\n      <single>ed.</single>\n      <multiple>eds.</multiple>\n    </term>\n    <term name=\"illustrator\" form=\"short\">\n      <single>ill.</single>\n      <multiple>ills.</multiple>\n    </term>\n    <term name=\"translator\" form=\"short\">\n      <single>tran.</single>\n      <multiple>trans.</multiple>\n    </term>\n    <term name=\"editortranslator\" form=\"short\">\n      <single>ed. &amp; tran.</single>\n      <multiple>eds. &amp; trans.</multiple>\n    </term>\n\n    <!-- VERB ROLE FORMS -->\n    <term name=\"director\" form=\"verb\">directed by</term>\n    <term name=\"editor\" form=\"verb\">edited by</term>\n    <term name=\"editorial-director\" form=\"verb\">edited by</term>\n    <term name=\"illustrator\" form=\"verb\">illustrated by</term>\n    <term name=\"interviewer\" form=\"verb\">interview by</term>\n    <term name=\"recipient\" form=\"verb\">to</term>\n    <term name=\"reviewed-author\" form=\"verb\">by</term>\n    <term name=\"translator\" form=\"verb\">translated by</term>\n    <term name=\"editortranslator\" form=\"verb\">edited &amp; translated by</term>\n\n    <!-- SHORT VERB ROLE FORMS -->\n    <term name=\"container-author\" form=\"verb-short\">by</term>\n    <term name=\"director\" form=\"verb-short\">dir.</term>\n    <term name=\"editor\" form=\"verb-short\">ed.</term>\n    <term name=\"editorial-director\" form=\"verb-short\">ed.</term>\n    <term name=\"illustrator\" form=\"verb-short\">illus.</term>\n    <term name=\"translator\" form=\"verb-short\">trans.</term>\n    <term name=\"editortranslator\" form=\"verb-short\">ed. &amp; trans.</term>\n\n    <!-- LONG MONTH FORMS -->\n    <term name=\"month-01\">January</term>\n    <term name=\"month-02\">February</term>\n    <term name=\"month-03\">March</term>\n    <term name=\"month-04\">April</term>\n    <term name=\"month-05\">May</term>\n    <term name=\"month-06\">June</term>\n    <term name=\"month-07\">July</term>\n    <term name=\"month-08\">August</term>\n    <term name=\"month-09\">September</term>\n    <term name=\"month-10\">October</term>\n    <term name=\"month-11\">November</term>\n    <term name=\"month-12\">December</term>\n\n    <!-- SHORT MONTH FORMS -->\n    <term name=\"month-01\" form=\"short\">Jan.</term>\n    <term name=\"month-02\" form=\"short\">Feb.</term>\n    <term name=\"month-03\" form=\"short\">Mar.</term>\n    <term name=\"month-04\" form=\"short\">Apr.</term>\n    <term name=\"month-05\" form=\"short\">May</term>\n    <term name=\"month-06\" form=\"short\">Jun.</term>\n    <term name=\"month-07\" form=\"short\">Jul.</term>\n    <term name=\"month-08\" form=\"short\">Aug.</term>\n    <term name=\"month-09\" form=\"short\">Sep.</term>\n    <term name=\"month-10\" form=\"short\">Oct.</term>\n    <term name=\"month-11\" form=\"short\">Nov.</term>\n    <term name=\"month-12\" form=\"short\">Dec.</term>\n\n    <!-- SEASONS -->\n    <term name=\"season-01\">Spring</term>\n    <term name=\"season-02\">Summer</term>\n    <term name=\"season-03\">Autumn</term>\n    <term name=\"season-04\">Winter</term>\n  </terms>\n</locale>\n",
    "contentType": "Application/x-bibtex",
    "items": [
        {
            "10.1145/2612733.2612779": {
                "id": "10.1145/2612733.2612779",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Harrison",
                        "given": "Teresa M."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            18
                        ]
                    ]
                },
                "abstract": "\"Big data\" has emerged as a compelling topic for e-government practitioners who have the opportunity to develop strategies for exploiting the data streams they currently possess or can access in an effort to make government organizations smarter and more responsive to their constituencies. This panel brings together researchers who are exploring big data analytic capabilities and opportunities in government organizations as well as the technical, organizational and ethical constraints that government practitioners are likely to face.",
                "call-number": "10.1145/2612733.2612779",
                "collection-title": "dg.o '14",
                "container-title": "Proceedings of the 15th Annual International Conference on Digital Government Research",
                "DOI": "10.1145/2612733.2612779",
                "event-place": "Aguascalientes, Mexico",
                "ISBN": "9781450329019",
                "keyword": "social networks, Mexico, political science, big data, auditors, text analytics, communication, census data, policy informatics, natural language processing",
                "number-of-pages": "3",
                "page": "306–308",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Building government's capacity for big data analysis",
                "URL": "https://doi.org/10.1145/2612733.2612779"
            }
        },
        {
            "10.1145/3472163.3472195": {
                "id": "10.1145/3472163.3472195",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sahri",
                        "given": "Soror"
                    },
                    {
                        "family": "Moussa",
                        "given": "Rim"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            7,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            7,
                            14
                        ]
                    ]
                },
                "abstract": "Big data systems are becoming mainstream for big data management either for batch processing or real-time processing. In order to extract insights from data, quality issues are very important to address, particularly. A veracity assessment model is consequently needed. In this paper, we propose a model which ties quality of datasets and quality of query resultsets. We particularly examine quality issues raised by a given dataset, order attributes along their fitness for use and correlate veracity metrics to business queries. We validate our work using the open dataset NYC taxi’ trips.",
                "call-number": "10.1145/3472163.3472195",
                "collection-title": "IDEAS '21",
                "container-title": "Proceedings of the 25th International Database Engineering & Applications Symposium",
                "DOI": "10.1145/3472163.3472195",
                "event-place": "Montreal, QC, Canada",
                "ISBN": "9781450389914",
                "keyword": "Big data, Veracity",
                "number-of-pages": "9",
                "page": "157–165",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Customized Eager-Lazy Data Cleansing for Satisfactory Big Data Veracity",
                "URL": "https://doi.org/10.1145/3472163.3472195"
            }
        },
        {
            "10.1145/2351316.2351322": {
                "id": "10.1145/2351316.2351322",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yang",
                        "given": "Hang"
                    },
                    {
                        "family": "Fong",
                        "given": "Simon"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            8,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            8,
                            12
                        ]
                    ]
                },
                "abstract": "How to extract meaningful information from big data has been a popular open problem. Decision tree, which has a high degree of knowledge interpretation, has been favored in many real world applications. However noisy values commonly exist in high-speed data streams, e.g. real-time online data feeds that are prone to interference. When processing big data, it is hard to implement pre-processing and sampling in full batches. To solve this tradeoff, this paper proposes a new incremental decision tree algorithm so called incrementally optimized very fast decision tree (iOVFDT). The experiment evaluates the proposed algorithm in comparison to existing methods under noisy data streams environment. Result shows iOVFDT has outperformance on the aspects of higher accuracy and smaller model size.",
                "call-number": "10.1145/2351316.2351322",
                "collection-title": "BigMine '12",
                "container-title": "Proceedings of the 1st International Workshop on Big Data, Streams and Heterogeneous Source Mining: Algorithms, Systems, Programming Models and Applications",
                "DOI": "10.1145/2351316.2351322",
                "event-place": "Beijing, China",
                "ISBN": "9781450315470",
                "keyword": "incremental optimization, optimized very fast decision tree, data stream mining, decision tree classification",
                "number-of-pages": "9",
                "page": "36–44",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Incrementally optimized decision tree for noisy big data",
                "URL": "https://doi.org/10.1145/2351316.2351322"
            }
        },
        {
            "10.1145/3512731.3534211": {
                "id": "10.1145/3512731.3534211",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Hamza",
                        "given": "Rafik"
                    },
                    {
                        "family": "Dao",
                        "given": "Minh-Son"
                    },
                    {
                        "family": "Ito",
                        "given": "Sadanori"
                    },
                    {
                        "family": "Koji",
                        "given": "Zettsu"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            6,
                            27
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            6,
                            27
                        ]
                    ]
                },
                "abstract": "Big Data applications can revolutionize any platform by facilitating the analysis of large amounts of information. However, the biggest challenge associated with Big Data is overcoming the intellectual property barriers associated with the use of this data, especially in cross-database applications. Although intellectual property provisions have been formulated to limit inappropriate use and manage access to Big Data, it is difficult to make this trade-off and overcome the challenges of Big Data. This paper explores the limits of intellectual property rights in Big Data applications. The advent of Big Data requires an alternative conceptual framework along with security policies and regulations. The profound issues of copyright on cross-database platforms are highlighted in this paper, as well as the paradigm shift from ownership to control of access to and use of Big Data, especially on cross-database platforms. We also present a real-world case study of the underlying technologies of cross-data analytics (xdata.nict.jp). The xData platform aims to coordinate competing social, personal, and industrial interests in data to ensure fair access while minimizing legal and ethical threats. Finally, we discuss the idea of using blockchain-enabled smart contracts to protect intellectual property rights on cross-data platforms and highlight some important aspects of copyright issues, highlighting key issues and current open challenges.",
                "call-number": "10.1145/3512731.3534211",
                "collection-title": "ICDAR '22",
                "container-title": "Proceedings of the 3rd ACM Workshop on Intelligent Cross-Data Analysis and Retrieval",
                "DOI": "10.1145/3512731.3534211",
                "event-place": "Newark, NJ, USA",
                "ISBN": "9781450392419",
                "keyword": "big data, security policy, industrial application, intellectual property",
                "number-of-pages": "8",
                "page": "50–57",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Towards Intellectual Property Rights Protection in Big Data",
                "URL": "https://doi.org/10.1145/3512731.3534211"
            }
        },
        {
            "10.1145/3386415.3386964": {
                "id": "10.1145/3386415.3386964",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chen",
                        "given": "Lijun"
                    },
                    {
                        "family": "Pan",
                        "given": "Zhengjun"
                    },
                    {
                        "family": "Yuan",
                        "given": "Lina"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            12,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            12,
                            6
                        ]
                    ]
                },
                "abstract": "In the past few years, the rapidly developing technology in the field of information technology is \"big data\". Clustering is one of the key tasks in a wide range of areas dealing with large amounts of data. This survey introduces various clustering methods used for effective big data clustering. Therefore, this review paper reviewed 15 research papers, which proposed various methods for effective big data clustering, such as k-means clustering, k-means variant clustering, fuzzy c-means clustering, possibility c-means clustering, collaborative filtering and optimization based clustering. In addition, detailed analysis is carried out by referring to the implementation tools used, the data sets used and the big data clustering framework adopted. Then, an effective solution must be developed to go beyond the existing technology to the special management of big data. Finally, the research problems and gaps of various big data clustering technologies are proposed to enable researchers to start with better big data clustering.",
                "call-number": "10.1145/3386415.3386964",
                "collection-number": "17",
                "collection-title": "ICITEE-2019",
                "container-title": "Proceedings of the 2nd International Conference on Information Technologies and Electrical Engineering",
                "DOI": "10.1145/3386415.3386964",
                "event-place": "Zhuzhou, Hunan, China",
                "ISBN": "9781450372930",
                "keyword": "Cluster, C-mean, Map, K-mean, Reduce, Big data",
                "number": "Article 17",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Study on Clustering Computing Methods of Big Data",
                "URL": "https://doi.org/10.1145/3386415.3386964"
            }
        },
        {
            "10.1145/3322431.3326330": {
                "id": "10.1145/3322431.3326330",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kantarcioglu",
                        "given": "Murat"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            5,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            5,
                            28
                        ]
                    ]
                },
                "abstract": "Recent cyber attacks have shown that the leakage/stealing of big data may result in enormous monetary loss and damage to organizational reputation, and increased identity theft risks for individuals. Furthermore, in the age of big data, protecting the security and privacy of stored data is paramount for maintaining public trust, and getting the full value from the collected data. In this talk, we first discuss the unique security and privacy challenges arise due to big data and the NoSQL systems designed to analyze big data. Also we discuss our proposed SecureDL system that is built on top of existing NoSQL databases such as Hadoop and Spark and designed as a data access broker where each request submitted by a user app is automatically captured. These captured requests are logged, analyzed and then modified (if needed) to conform with security and privacy policies (e.g.,[5]), and submitted to underlying NoSQL database. Furthermore, SecureDL can allow organizations to audit their big data usage to prevent data misuse and comply with various privacy regulations[2]. SecureDL is totally transparent from the user point of view and does not require any change to the user's code and/or the underlying NoSQL database systems. Therefore, it can be deployed on existing NoSQL databases.Later on, we discuss how to add additional security layer for protecting big data using encryption techniques (e.g., [1, 3, 4]). Especially, we discuss our work on leveraging the modern hardware based trusted execution environments (TEEs) such as Intel SGX for secure encrypted data processing. We also discuss how to provide a simple, secure and high level language based framework that is suitable for enabling generic data analytics for non-security experts who do not have security concepts such as \"oblivious execution''. Our proposed framework allows data scientists to perform the data analytic tasks with TEEs using a Python/Matlab like high level language; and automatically compiles programs written in our language to optimal execution code by managing issues such as optimal data block sizes for I/O, vectorized computations to simplify much of the data processing, and optimal ordering of operations for certain tasks. Using these design choices, we show how to provide guarantees for efficient and secure big data analytics over encrypted data.",
                "call-number": "10.1145/3322431.3326330",
                "collection-title": "SACMAT '19",
                "container-title": "Proceedings of the 24th ACM Symposium on Access Control Models and Technologies",
                "DOI": "10.1145/3322431.3326330",
                "event-place": "Toronto ON, Canada",
                "ISBN": "9781450367530",
                "keyword": "encrypted data processing, intrusion detection, security, access control, privacy, nosql databases",
                "number-of-pages": "2",
                "page": "1–2",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Securing Big Data: New Access Control Challenges and Approaches",
                "URL": "https://doi.org/10.1145/3322431.3326330"
            }
        },
        {
            "10.1145/3003733.3003767": {
                "id": "10.1145/3003733.3003767",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Petrou",
                        "given": "Charilaos"
                    },
                    {
                        "family": "Paraskevas",
                        "given": "Michael"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            11,
                            10
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            11,
                            10
                        ]
                    ]
                },
                "abstract": "Big data science has been developed into a topic that attracts attention from industry, academia and governments. The main objective in Big Data science is to recognize and extract meaningful information from huge amounts of heterogeneous data and unstructured data (which constitute 95% of big data). Signal Processing (SP) techniques and related statistical learning (SL) tools such as Principal Component Analysis (PCA), R-PCA (Robust PCA), Compressive Sampling (CS), convex optimization (CO), stochastic approximation (SA), kernel based learning (KBL) tasks are used for robustness, compression and dimensionality reduction in Big Data arising challenges. This review paper introduces Big Data related SP techniques and presents applications of this emerging field.",
                "call-number": "10.1145/3003733.3003767",
                "collection-number": "52",
                "collection-title": "PCI '16",
                "container-title": "Proceedings of the 20th Pan-Hellenic Conference on Informatics",
                "DOI": "10.1145/3003733.3003767",
                "event-place": "Patras, Greece",
                "ISBN": "9781450347891",
                "keyword": "statistical learning tools, signal processing techniques, convex optimization, big data, stochastic approximation",
                "number": "Article 52",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Signal Processing Techniques Restructure The Big Data Era",
                "URL": "https://doi.org/10.1145/3003733.3003767"
            }
        },
        {
            "10.1145/2935753": {
                "id": "10.1145/2935753",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Berti-Equille",
                        "given": "Laure"
                    },
                    {
                        "family": "Ba",
                        "given": "Mouhamadou Lamine"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            8,
                            17
                        ]
                    ]
                },
                "call-number": "10.1145/2935753",
                "collection-number": "12",
                "container-title": "J. Data and Information Quality",
                "DOI": "10.1145/2935753",
                "ISSN": "1936-1955",
                "issue": "3",
                "keyword": "fact checking, data fusion, information extraction, data quality, Truth discovery",
                "number": "Article 12",
                "number-of-pages": "3",
                "page": "1–3",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "September 2016",
                "title": "Veracity of Big Data: Challenges of Cross-Modal Truth Discovery",
                "URL": "https://doi.org/10.1145/2935753",
                "volume": "7"
            }
        },
        {
            "10.1145/3150919.3150923": {
                "id": "10.1145/3150919.3150923",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Wang",
                        "given": "Shaohua"
                    },
                    {
                        "family": "Zhong",
                        "given": "Yang"
                    },
                    {
                        "family": "Lu",
                        "given": "Hao"
                    },
                    {
                        "family": "Wang",
                        "given": "Erqi"
                    },
                    {
                        "family": "Yun",
                        "given": "Weiying"
                    },
                    {
                        "family": "Cai",
                        "given": "Wenwen"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            11,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            11,
                            7
                        ]
                    ]
                },
                "abstract": "With the rapid development of geospatial data acquisition and processing technology, the scale of spatial data is expanding. Mass production applications put forward higher requirements for the performance of geospatial data analysis. In this study, we developed a geospatial big data analytics engine based on SuperMap iObject for Java and Apache Spark. The geospatial big data analytics engine can increase the RDD representation ability of spatial data. The spatial indexing can make the spatial calculation on the nodes of the Spark cluster distributed and efficient. The experimental results show that compared with the traditional algorithm, the geospatial big data analytics engine for Spark has better execution efficiency.",
                "call-number": "10.1145/3150919.3150923",
                "collection-title": "BigSpatial'17",
                "container-title": "Proceedings of the 6th ACM SIGSPATIAL Workshop on Analytics for Big Geospatial Data",
                "DOI": "10.1145/3150919.3150923",
                "event-place": "Redondo Beach, CA, USA",
                "ISBN": "9781450354943",
                "keyword": "SuperMap GIS, distributed computing, Spark, Geospatial big data, Cross-platform GIS",
                "number-of-pages": "4",
                "page": "42–45",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Geospatial Big Data Analytics Engine for Spark",
                "URL": "https://doi.org/10.1145/3150919.3150923"
            }
        },
        {
            "10.5555/3192424.3192613": {
                "id": "10.5555/3192424.3192613",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yu",
                        "given": "Yuan-Chih"
                    },
                    {
                        "family": "Tsai",
                        "given": "Dwen-Ren"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            8,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            8,
                            18
                        ]
                    ]
                },
                "abstract": "The power of big data gives us an unprecedented chance to understand, analyze, and recreate the world, while open data ensures that power be shared and widely exploited. Open and big data has become the emerging topics for researchers and governments. Thus, the related privacy issues also become an emerging urgent problem. In this work, we propose a conceptual framework of privacy weaving pipeline dedicated for producing open and big data while preserving privacy. Within the processing pipeline, each step of the process flow considers the privacy assurance to manipulate datasets. However, the complexity of process flow is the same as normal data pipeline. The experimental prototype confirms the feasibility of framework design. We hope this work will facilitate the development of open and big data industry.",
                "call-number": "10.5555/3192424.3192613",
                "collection-title": "ASONAM '16",
                "container-title": "Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining",
                "event-place": "Davis, California",
                "ISBN": "9781509028467",
                "keyword": "open data, privacy breach, big data, data pipeline",
                "number-of-pages": "2",
                "page": "997–998",
                "publisher": "IEEE Press",
                "title": "A privacy weaving pipeline for open big data"
            }
        },
        {
            "10.1145/3168390.3168425": {
                "id": "10.1145/3168390.3168425",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Samosir",
                        "given": "Ridha Sefina"
                    },
                    {
                        "family": "Hendric",
                        "given": "Harco Leslie"
                    },
                    {
                        "family": "Gaol",
                        "given": "Ford Lumban"
                    },
                    {
                        "family": "Abdurachman",
                        "given": "Edi"
                    },
                    {
                        "family": "Soewito",
                        "given": "Benfano"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            12,
                            5
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            12,
                            5
                        ]
                    ]
                },
                "abstract": "Big data is defined as a very large data set (volume), velocity and variety. Big data analytics systems must be supports for parallel processing and large storage. The problem of this research is how to identify measurement metric based on big data analytics system characteristic. One device that support big data platform is Hadoop. Measurement is a process for assigning values or symbols to the attributes of an entity. The purpose of measurement is to distinguish between entities one to another. Indicator for software measurement represented with a metric. The aim of this research is to proposes some measurement metric for big data analytics system. This research using UML exactly a class diagram in system modelling to identify the measurement metric. Both of dynamic and static metric is proposed as solution to measure big data analytics system. Result for this researh are some measurement ndicator both of dynamic and static metric based on class diagram for big data analytics.",
                "call-number": "10.1145/3168390.3168425",
                "collection-title": "CSAI 2017",
                "container-title": "Proceedings of the 2017 International Conference on Computer Science and Artificial Intelligence",
                "DOI": "10.1145/3168390.3168425",
                "event-place": "Jakarta, Indonesia",
                "ISBN": "9781450353922",
                "keyword": "Measurement, Big Data Analytics, Software, Metric",
                "number-of-pages": "5",
                "page": "265–269",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Measurement Metric Proposed For Big Data Analytics System",
                "URL": "https://doi.org/10.1145/3168390.3168425"
            }
        },
        {
            "10.1145/3239283.3239322": {
                "id": "10.1145/3239283.3239322",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Liu",
                        "given": "Zhuang"
                    },
                    {
                        "family": "Gong",
                        "given": "Lin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            7,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            7,
                            20
                        ]
                    ]
                },
                "abstract": "With the arrival of the intelligent era, Big Data will play an increasingly important role in all aspects of product design. In the product design stage, comprehensive evaluations such as product quality assessment and social demand exploration are directly associated with various data and information. The advantages of big data in data mining and model prediction can be used to provide new ideas for process optimization and problem improvement of design innovation. Based on this situation, this paper proposes a big data framework based on Hadoop for product design. The framework contains the complete flow of big data analysis, and these processes are efficiently connected with good efficiency and practicality. This paper selects the data sets of product quality design and product demand design respectively, mining the design factors in the product design process through data mining technology, thus providing new ideas for product design.",
                "call-number": "10.1145/3239283.3239322",
                "collection-title": "DSIT '18",
                "container-title": "Proceedings of the 2018 International Conference on Data Science and Information Technology",
                "DOI": "10.1145/3239283.3239322",
                "event-place": "Singapore, Singapore",
                "ISBN": "9781450365215",
                "keyword": "Hadoop, product design, data mining, big data",
                "number-of-pages": "6",
                "page": "105–110",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Study on big data framework for product design",
                "URL": "https://doi.org/10.1145/3239283.3239322"
            }
        },
        {
            "10.1145/3524383.3533248": {
                "id": "10.1145/3524383.3533248",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Liu",
                        "given": "Sheng"
                    },
                    {
                        "family": "Hou",
                        "given": "Liutong"
                    },
                    {
                        "family": "Chen",
                        "given": "Xiuying"
                    },
                    {
                        "family": "Tang",
                        "given": "Xuanhe"
                    },
                    {
                        "family": "He",
                        "given": "Yuzi"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            2,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            2,
                            26
                        ]
                    ]
                },
                "abstract": "With the deep integration of the new generation of information technology and the real economy, what impact will digital management capabilities have on manufacturing companies? Using data from the China Employer-Employee Survey (CEES), this article examines the impact of digital management capabilities on the innovation performance of manufacturing companies. The results show that the enhancement of digital management capabilities can significantly promote the innovation performance of manufacturing enterprises, and this effect is robust. Dimensional regression results show that the availability of data in the decision-making process, the degree of data dependence in the decision-making process, the diversity of corporate data collection entities, and the frequency of use of work process data can significantly promote corporate innovation performance, while the influence of the frequency of data using in the decision-making process and the frequency of data use in the decision-making process and the frequency of using statistical methods to predict on the innovation performance of manufacturing enterprises is not obvious. Sub-sample regression results show that the effect of digital management capabilities on the innovation performance of manufacturing enterprises is heterogeneous. Specifically, when the company is characterized as with a long life span, with a large scale, with the type of family business, with a high proportion of CEOs who owned a college degree or above, with a high number of years of education for middle and senior managers, with a board of directors or a party organization, with a location of the eastern region or in the areas of a high concentration of financial services and R&D services, the effect of digital management capabilities on innovation performance is more obvious. Therefore, this article provides evidence for revealing the microeconomic effects of industrial digital development and promoting the reform of innovation management in manufacturing enterprises.",
                "call-number": "10.1145/3524383.3533248",
                "collection-title": "ICBDE '22",
                "container-title": "Proceedings of the 5th International Conference on Big Data and Education",
                "DOI": "10.1145/3524383.3533248",
                "event-place": "Shanghai, China",
                "ISBN": "9781450395793",
                "keyword": "manufacturing enterprises, innovation performance, digital management capabilities, big data, artificial intelligence",
                "number-of-pages": "6",
                "page": "455–460",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Digital Management Capability and Innovation of Manufacturing Enterprises in the Era of Big Data",
                "URL": "https://doi.org/10.1145/3524383.3533248"
            }
        },
        {
            "10.1145/3378904": {
                "id": "10.1145/3378904",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2020
                        ]
                    ]
                },
                "abstract": "Big data is an emerging paradigm applied to datasets whose size is beyond the ability of commonly used software tools to capture, manage, and process the data within a tolerable elapsed time. Such datasets are often from various sources (Variety) yet unstructured such as social media, sensors, scientific applications, surveillance, video and image archives, Internet texts and documents, Internet search indexing, medical records, business transactions and web logs; and are of large size (Volume) with fast data in/out (Velocity). 2020 2nd International Conference on Big Data Engineering and Technology is one of the premier events to network and learn from colleagues and other leading international scientific voices from across the world, who is actively engaged in advancing research and raising awareness of the many challenges in the diverse field of Big Data Engineering and Technology.",
                "call-number": "10.1145/3378904",
                "container-title-short": "BDET 2020",
                "event-place": "Singapore, China",
                "genre": "proceeding",
                "ISBN": "9781450376839",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2020 2nd International Conference on Big Data Engineering and Technology"
            }
        },
        {
            "10.1145/3301551.3301566": {
                "id": "10.1145/3301551.3301566",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Hyun",
                        "given": "Youyung"
                    },
                    {
                        "family": "Hosoya",
                        "given": "Ryuichi"
                    },
                    {
                        "family": "Kamioka",
                        "given": "Taro"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            12,
                            29
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            12,
                            29
                        ]
                    ]
                },
                "abstract": "Big data analytics (BDA) is becoming a key way for leading companies to outperform their peers by utilizing big data and better understanding its business environment. However, there is evidence that many firms are facing difficulties in deploying BDA effectively into their business processes because of data silos, the rigid separation of data across divisions. In order to overcome data silos and capture the full potential of big data, it is considered important to create a corporate culture that encourages communication and sharing of data across departments. Therefore, to identify an appropriate corporate culture that supports BDA deployment in the context of big data, our research introduces BDA orientation which facilitates data flow across separate divisions and values business decisions based on insights gained from BDA. Drawing on resource-based view (RBV) and upper echelon theory, our research model examines the impact of BDA orientation on the deployment of BDA. Also, this study investigates the role of BDA orientation that mediates the effects of top management team initiative and BDA infrastructure on BDA deployment. To test our proposed model, an online survey was administered for a quantitative analysis and data from 166 Japanese upper-level managers were collected. Our findings confirm the significant impact of BDA orientation on BDA deployment, and the mediating role of BDA orientation in the suggested relationships above.",
                "call-number": "10.1145/3301551.3301566",
                "collection-title": "ICIT 2018",
                "container-title": "Proceedings of the 6th International Conference on Information Technology: IoT and Smart City",
                "DOI": "10.1145/3301551.3301566",
                "event-place": "Hong Kong, Hong Kong",
                "ISBN": "9781450366298",
                "keyword": "big data analytics orientation, Big data, BDA deployment",
                "number-of-pages": "7",
                "page": "42–48",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The Implications of Big Data Analytics Orientation upon Deployment",
                "URL": "https://doi.org/10.1145/3301551.3301566"
            }
        },
        {
            "10.1145/2479724.2479764": {
                "id": "10.1145/2479724.2479764",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Harrison",
                        "given": "Teresa M."
                    },
                    {
                        "family": "Hrdinova",
                        "given": "Jana"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            17
                        ]
                    ]
                },
                "abstract": "In this plenary panel, speakers from academia and government consider the technical, scientific, and organizational implications of Big Data and offer observations about what it means for research and practice related to e-government.",
                "call-number": "10.1145/2479724.2479764",
                "collection-title": "dg.o '13",
                "container-title": "Proceedings of the 14th Annual International Conference on Digital Government Research",
                "DOI": "10.1145/2479724.2479764",
                "event-place": "Quebec, Canada",
                "ISBN": "9781450320573",
                "keyword": "large-scale data systems, research data alliance, social media, data analytics, data integration, data stewardship, performance and benchmarking of big data systems, big data, scientific data management, security, privacy",
                "number-of-pages": "2",
                "page": "263–264",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The complexities of \"big data\": the opportunities and challenges for e-government",
                "URL": "https://doi.org/10.1145/2479724.2479764"
            }
        },
        {
            "10.1145/3451400.3451414": {
                "id": "10.1145/3451400.3451414",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Ren",
                        "given": "Weixin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            2,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            2,
                            3
                        ]
                    ]
                },
                "abstract": "Affected by the outbreak of COVID-19, the employment pressure of college graduates is increasing. The employment problem of graduates is a livelihood issue which is highly valued by social community. The arrival of big data era has a profound impact on the employment situation analysis, policy formulation, employment service and guidance, and college graduates’ career development. Therefore, to explore the impact of the epidemic on the employment situation of graduates, this paper takes college graduates of the University of Electronic Science and Technology of China as the survey object, and uses questionnaires to investigate the employment status of college graduates under the background of the COVID-19. Starting from the three dimensions of the government, universities, and individual college graduates, to analyze the employment status and problems of graduates, and to explore ways to use big data to promote employment of college graduates under the influence of the COVID-19. This is of great significance for alleviating employment pressure and improving the quality of employment.",
                "call-number": "10.1145/3451400.3451414",
                "collection-title": "ICBDE 2021",
                "container-title": "2021 4th International Conference on Big Data and Education",
                "DOI": "10.1145/3451400.3451414",
                "event-place": "London, United Kingdom",
                "ISBN": "9781450389389",
                "keyword": "Big data, graduate employment, COVID-19",
                "number-of-pages": "4",
                "page": "88–91",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A Study on College Graduates' Employment Problem in The Context of Big Data Based on the Event of COVID-19",
                "URL": "https://doi.org/10.1145/3451400.3451414"
            }
        },
        {
            "10.1145/3396452.3396458": {
                "id": "10.1145/3396452.3396458",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Su",
                        "given": "Ying"
                    },
                    {
                        "family": "Zhang",
                        "given": "Yong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            4,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            4,
                            1
                        ]
                    ]
                },
                "abstract": "In this paper, we propose an automatic construction method of subject knowledge graph for educational applications. The subject knowledge graph is constructed based on educational big data by using a bootstrapping strategy to gradually expand knowledge points and connections between them. In this paper two different datasets are used. One is the subject teaching resources such as syllabuses, teaching plans, textbooks and etc., which is used to automatically construct the core of subject knowledge graph so as to reduce the dependence on the manual annotation. Meanwhile the high-quality of subject teaching resources is the guarantee of accuracy of the knowledge graph core. The other dataset is the massive Internet encyclopedia texts, which is used to expand and complete the subject knowledge graph. As to algorithm, this paper utilizes the BERT-BiLSTM-CRF model to automatically identify the subject knowledge points, and then evaluates the relationship between the knowledge points by calculating their semantic similarity, PMI and Normalized Google Distance between them. The experimental results show that BERT-BiLSTM-CRF outperforms the baselines significantly, and the three kinds of relationship evaluation models have achieved good results. Finally, computer science and physics science are taken as examples to construct the subject knowledge graphs successfully, which show the effectiveness of our method.",
                "call-number": "10.1145/3396452.3396458",
                "collection-title": "ICBDE '20",
                "container-title": "Proceedings of the 2020 The 3rd International Conference on Big Data and Education",
                "DOI": "10.1145/3396452.3396458",
                "event-place": "London, United Kingdom",
                "ISBN": "9781450374989",
                "keyword": "BERT-BILSTM-CRF, knowledge graph, intelligent education, normalized google distance, point mutual information",
                "number-of-pages": "7",
                "page": "30–36",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Automatic Construction of Subject Knowledge Graph based on Educational Big Data",
                "URL": "https://doi.org/10.1145/3396452.3396458"
            }
        },
        {
            "10.1145/2938503.2938540": {
                "id": "10.1145/2938503.2938540",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "McClatchey",
                        "given": "Richard"
                    },
                    {
                        "family": "Branson",
                        "given": "Andrew"
                    },
                    {
                        "family": "Shamdasani",
                        "given": "Jetendr"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            7,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            7,
                            11
                        ]
                    ]
                },
                "abstract": "One essential requirement for supporting analytics for Big Medical Data systems is the provision of a suitable level of traceability to data or processes ('Items') in large volumes of data. Systems should be designed from the outset to support usage of such Items across the spectrum of medical use and over time in order to promote traceability, to simplify maintenance and to assist analytics. The philosophy proposed in this paper is to design medical data systems using a 'description-driven' approach in which meta-data and the description of medical items are saved alongside the data, simplifying item re-use over time and thereby enabling the traceability of these items over time and their use in analytics. Details are given of a big data system in neuroimaging to demonstrate aspects of provenance data capture, collaborative analysis and longitudinal information traceability. Evidence is presented that the description-driven approach leads to simplicity of design and ease of maintenance following the adoption of a unified approach to Item management.",
                "call-number": "10.1145/2938503.2938540",
                "collection-title": "IDEAS '16",
                "container-title": "Proceedings of the 20th International Database Engineering & Applications Symposium",
                "DOI": "10.1145/2938503.2938540",
                "event-place": "Montreal, QC, Canada",
                "ISBN": "9781450341189",
                "keyword": "provenance data, traceability, Big Data, Description-driven systems, medical analytics",
                "number-of-pages": "6",
                "page": "386–391",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Provenance Support for Biomedical Big Data Analytics",
                "URL": "https://doi.org/10.1145/2938503.2938540"
            }
        },
        {
            "10.1145/3503928.3503929": {
                "id": "10.1145/3503928.3503929",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Barzan Abdalla",
                        "given": "Hemn"
                    },
                    {
                        "family": "Mustafa",
                        "given": "Nasser"
                    },
                    {
                        "family": "Ihnaini",
                        "given": "Baha"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            11,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            11,
                            12
                        ]
                    ]
                },
                "abstract": "In many health care domains, big data has arrived. How to manage and use big data better has become the focus of all walks of life. Many data sources provide the repeated fault data—the repeated fault data forming the delay of processing time and storage capacity. Big data includes properties like volume, velocity, variety, variability, value, complexity, and performance put forward more challenges. Most healthcare domains face the problem of testing for structured and unstructured data validation in big data. It provides low-quality data and delays in response. In testing process is delay and not provide the correct response. In Proposed, pre-testing and post-testing are used for big data testing. In pre-testing, classify fault data from different data sources. After Classification to group big data using SVM algorithms such as Text, Image, Audio, and Video file. In post-testing, to implement the pre-processing, remove the zero file size, unrelated file extension, and de-duplication after pre-processing to implement the Map-reduce algorithm to find out the big data efficiently. This process reduces the pre-processing time, reduces the server energy, and increases the processing time. To remove the fault data before pre-processing means to increase the processing time and data storage.",
                "call-number": "10.1145/3503928.3503929",
                "collection-title": "ICISE 2021",
                "container-title": "2021 the 6th International Conference on Information Systems Engineering",
                "DOI": "10.1145/3503928.3503929",
                "event-place": "Shanghai, China",
                "ISBN": "9781450385220",
                "keyword": "Pre-Processing, Fault data detection, Classification using SVM, Map-reduce, Big Data",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data: Finding Frequencies of Faulty Multimedia Data",
                "URL": "https://doi.org/10.1145/3503928.3503929"
            }
        },
        {
            "10.1145/3206505.3206556": {
                "id": "10.1145/3206505.3206556",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kammer",
                        "given": "Dietrich"
                    },
                    {
                        "family": "Keck",
                        "given": "Mandy"
                    },
                    {
                        "family": "Gründer",
                        "given": "Thomas"
                    },
                    {
                        "family": "Groh",
                        "given": "Rainer"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            29
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            5,
                            29
                        ]
                    ]
                },
                "abstract": "With the internet, massively heterogeneous data sources need to be understood and classified to provide suitable services to users such as content observation, data exploration, e-commerce, or adaptive learning environments. The key to providing these services is applying machine learning (ML) in order to generate structures via clustering and classification. Due to the intricate processes involved in ML, visual tools are needed to support designing and evaluating the ML pipelines. In this contribution, we propose a comprehensive tool that facilitates the analysis and design of ML-based clustering algorithms using multiple visualization features such as semantic zoom, glyphs, and histograms.",
                "call-number": "10.1145/3206505.3206556",
                "collection-number": "66",
                "collection-title": "AVI '18",
                "container-title": "Proceedings of the 2018 International Conference on Advanced Visual Interfaces",
                "DOI": "10.1145/3206505.3206556",
                "event-place": "Castiglione della Pescaia, Grosseto, Italy",
                "ISBN": "9781450356169",
                "keyword": "visualization, glyphs, machine learning, big data landscapes, clustering",
                "number": "Article 66",
                "number-of-pages": "3",
                "page": "1–3",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data landscapes: improving the visualization of machine learning-based clustering algorithms",
                "URL": "https://doi.org/10.1145/3206505.3206556"
            }
        },
        {
            "10.1145/2783258.2789989": {
                "id": "10.1145/2783258.2789989",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yang",
                        "given": "Tianbao"
                    },
                    {
                        "family": "Lin",
                        "given": "Qihang"
                    },
                    {
                        "family": "Jin",
                        "given": "Rong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            8,
                            10
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            8,
                            10
                        ]
                    ]
                },
                "abstract": "As the scale and dimensionality of data continue to grow in many applications of data analytics (e.g., bioinformatics, finance, computer vision, medical informatics), it becomes critical to develop efficient and effective algorithms to solve numerous machine learning and data mining problems. This tutorial will focus on simple yet practically effective techniques and algorithms for big data analytics. In the first part, we plan to present the state-of-the-art large-scale optimization algorithms, including various stochastic gradient descent methods, stochastic coordinate descent methods and distributed optimization algorithms, for solving various machine learning problems. In the second part, we will focus on randomized approximation algorithms for learning from large-scale data. We will discuss i) randomized algorithms for low-rank matrix approximation; ii) approximation techniques for solving kernel learning problems; iii) randomized reduction methods for addressing the high-dimensional challenge. Along with the description of algorithms, we will also present some empirical results to facilitate understanding of different algorithms and comparison between them.",
                "call-number": "10.1145/2783258.2789989",
                "collection-title": "KDD '15",
                "container-title": "Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
                "DOI": "10.1145/2783258.2789989",
                "event-place": "Sydney, NSW, Australia",
                "ISBN": "9781450336642",
                "keyword": "machine learning, optimization, randomized approximation, randomized reduction",
                "number-of-pages": "1",
                "page": "2327",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data Analytics: Optimization and Randomization",
                "URL": "https://doi.org/10.1145/2783258.2789989"
            }
        },
        {
            "10.1145/2632320.2632325": {
                "id": "10.1145/2632320.2632325",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Grillenberger",
                        "given": "Andreas"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            7,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            7,
                            28
                        ]
                    ]
                },
                "abstract": "The topics data management and data analysis are currently discussed in various contexts, e.g. in Computer Science but also in daily life and society. The recent developments in this field, which are often summarized under the term Big Data, did not only lead to the emergence of new database models, but also comprise new threats, e.g. for data privacy. These topics include many aspects that are important for everyone, but they only gain in relevance slowly in higher education and hardly in secondary education. Hence, I will evaluate data management as a topic for secondary education, with a view on the long-lasting concepts and aspects in this field.",
                "call-number": "10.1145/2632320.2632325",
                "collection-title": "ICER '14",
                "container-title": "Proceedings of the tenth annual conference on International computing education research",
                "DOI": "10.1145/2632320.2632325",
                "event-place": "Glasgow, Scotland, United Kingdom",
                "ISBN": "9781450327558",
                "keyword": "data management, daily life, big data, data analysis, databases, data privacy, secondary schools, nosql",
                "number-of-pages": "2",
                "page": "147–148",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data and data management: a topic for secondary computing education",
                "URL": "https://doi.org/10.1145/2632320.2632325"
            }
        },
        {
            "10.1145/2676723.2693616": {
                "id": "10.1145/2676723.2693616",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bart",
                        "given": "Austin Cory"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            2,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            2,
                            24
                        ]
                    ]
                },
                "abstract": "As Computational Thinking becomes pervasive in undergraduate programs, new students must be educated in meaningful, authentic contexts that they find both motivating and relatable. I propose working with big data as a novel context for introductory programming, authentic given its importance in diverse fields such as agriculture, history, and more. Big data is considered difficult to use because of its inherent technical obstacles. To overcome these difficulties, I introduce a new project: CORGIS - a \"Collection of Real-time, Giant, Interesting, Situated Datasets\". The CORGIS project comprises a collection of libraries that provide an interface to big data for students, architectures for rapidly enabling new datasets, and a web-based textbook platform for disseminating relevant course materials. This textbook features an online block-based programming environment, real-time collaborative text editing, and continuous server-side storage. In this poster, I describe the educational theory guiding this work, the novel technolgy created and deployed, and the initial, promising results.",
                "call-number": "10.1145/2676723.2693616",
                "collection-title": "SIGCSE '15",
                "container-title": "Proceedings of the 46th ACM Technical Symposium on Computer Science Education",
                "DOI": "10.1145/2676723.2693616",
                "event-place": "Kansas City, Missouri, USA",
                "ISBN": "9781450329668",
                "keyword": "Big data, Computational Thinking, Motivation, CORGIS",
                "number-of-pages": "1",
                "page": "719",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Situating Computational Thinking with Big Data: Pedagogy and Technology (Abstract Only)",
                "URL": "https://doi.org/10.1145/2676723.2693616"
            }
        },
        {
            "10.1109/CCGrid.2015.85": {
                "id": "10.1109/CCGrid.2015.85",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chen",
                        "given": "Peng"
                    },
                    {
                        "family": "Plale",
                        "given": "Beth"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            5,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            5,
                            4
                        ]
                    ]
                },
                "abstract": "Provenance captured from E-Science experimentation is often large and complex, for instance, from agent-based simulations that have tens of thousands of heterogeneous components interacting over extended time periods. The subject of study of my dissertation is the use of E-Science provenance at scale. My initial research studied the visualization of large provenance graphs and proposed an abstract representation of provenance that supports useful data mining. Recent work involves analyzing large provenance data generated from agent-based simulations on a single machine. In continuation, I propose stream processing techniques to support the continuous and realtime analysis of data provenance, which is captured from agent based simulations on HPC and thus has unprecedented volume and complexity.",
                "call-number": "10.1109/CCGrid.2015.85",
                "collection-title": "CCGRID '15",
                "container-title": "Proceedings of the 15th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing",
                "DOI": "10.1109/CCGrid.2015.85",
                "event-place": "Shenzhen, China",
                "ISBN": "9781479980062",
                "keyword": "mining, big data, visualization, data provenance, stream processing",
                "number-of-pages": "4",
                "page": "797–800",
                "publisher": "IEEE Press",
                "title": "Big data provenance analysis and visualization",
                "URL": "https://doi.org/10.1109/CCGrid.2015.85"
            }
        },
        {
            "10.1145/2612733.2619954": {
                "id": "10.1145/2612733.2619954",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Villaseñor",
                        "given": "Elio"
                    },
                    {
                        "family": "Estrada",
                        "given": "Hugo"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            18
                        ]
                    ]
                },
                "abstract": "Today, governmental entities are embracing new trends in information technology. One of the technological developments that generate more excitement is Big Data; because this technology let us analyze the huge amount of information produced by the government and is useful for decisions making. On the other hand, the Future Internet platform of the European Community (FI- WARE) is one of the most powerful trends around the world and has aroused more interest in governments. This technology is based on a set of Generic Enablers (GE) for various applications, including Big Data. The FI-WARE is a platform under construction and knowing how this process performed is essential to join in this monumental effort and take advantages of its benefits. This document presents the results of the application of text and data mining techniques as well as informetric mapping to gain understanding regarding the development of Big Data technology present in the FI- WARE.",
                "call-number": "10.1145/2612733.2619954",
                "collection-title": "dg.o '14",
                "container-title": "Proceedings of the 15th Annual International Conference on Digital Government Research",
                "DOI": "10.1145/2612733.2619954",
                "event-place": "Aguascalientes, Mexico",
                "ISBN": "9781450329019",
                "keyword": "big data, FI-ware, generic enablers, informetric analysis",
                "number-of-pages": "2",
                "page": "348–349",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Informetric mapping of \"big data\" in FI-WARE",
                "URL": "https://doi.org/10.1145/2612733.2619954"
            }
        },
        {
            "10.1145/3148055.3148079": {
                "id": "10.1145/3148055.3148079",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Chen",
                        "given": "Shouwei"
                    },
                    {
                        "family": "Rodero",
                        "given": "Ivan"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            12,
                            5
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            12,
                            5
                        ]
                    ]
                },
                "abstract": "As data analytics applications become increasingly important in a wide range of domains, the ability to develop large-scale and sustainable platforms and software infrastructure to support these applications has significant potential to drive research and innovation in both science and business domains. This paper characterizes performance and power-related behavior trends and tradeoffs of the two predominant frameworks for Big Data analytics (i.e., Apache Hadoop and Spark) for a range of representative applications. It also evaluates system design knobs, such as storage and network technologies and power capping techniques. Experimental results from empirical executions provide meaningful data points for exploring the potential of software-defined infrastructure for Big Data processing systems through simulation. The results provide better understanding of the design space to build multi-criteria application-centric models as well as show significant advantages of software-defined infrastructure in terms of execution time, energy and cost. It motivates further research focused on in-memory processing formulations regarding systems with deeper memory hierarchies and software-defined infrastructure.",
                "call-number": "10.1145/3148055.3148079",
                "collection-title": "BDCAT '17",
                "container-title": "Proceedings of the Fourth IEEE/ACM International Conference on Big Data Computing, Applications and Technologies",
                "DOI": "10.1145/3148055.3148079",
                "event-place": "Austin, Texas, USA",
                "ISBN": "9781450355490",
                "keyword": "big data processing frameworks, characterization and tradeoffs, software-defined infrastructure",
                "number-of-pages": "10",
                "page": "199–208",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Understanding Behavior Trends of Big Data Frameworks in Ongoing Software-Defined Cyber-Infrastructure",
                "URL": "https://doi.org/10.1145/3148055.3148079"
            }
        },
        {
            "10.1145/2699414": {
                "id": "10.1145/2699414",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Reed",
                        "given": "Daniel A."
                    },
                    {
                        "family": "Dongarra",
                        "given": "Jack"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            25
                        ]
                    ]
                },
                "abstract": "Scientific discovery and engineering innovation requires unifying traditionally separated high-performance computing and big data analytics.",
                "call-number": "10.1145/2699414",
                "container-title": "Commun. ACM",
                "DOI": "10.1145/2699414",
                "ISSN": "0001-0782",
                "issue": "7",
                "number-of-pages": "13",
                "page": "56–68",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "July 2015",
                "title": "Exascale computing and big data",
                "URL": "https://doi.org/10.1145/2699414",
                "volume": "58"
            }
        },
        {
            "10.1145/2320765.2320830": {
                "id": "10.1145/2320765.2320830",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Held",
                        "given": "Johannes"
                    },
                    {
                        "family": "Lenz",
                        "given": "Richard"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            3,
                            30
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            3,
                            30
                        ]
                    ]
                },
                "abstract": "In order to enable proper system and integration testing, it is often necessary to have huge test data inventories, reflecting the heterogeneous live system. Although the maintenance of large data stores can be guided by advice obtained from data quality evaluations, this technique can be only partly applied to test data inventories. Assessing test data quality is difficult, as the well-known data quality dimensions are not applicable in an easy fashion. For example, an otherwise good value of 100% for correctness would not allow to store erroneous test data items. The need for data quality dimensions dedicated to assessing test data quality can't be satisfied by well-known data quality dimensions. In this paper, we present our thesis approach to identify and validate new quality dimensions applicable for test data quality and develop quantification methods. We propose proximity to reality and degree of coverage as two new test data quality dimension and sketch quantification approach to measures, specifically suited for test data.",
                "call-number": "10.1145/2320765.2320830",
                "collection-title": "EDBT-ICDT '12",
                "container-title": "Proceedings of the 2012 Joint EDBT/ICDT Workshops",
                "DOI": "10.1145/2320765.2320830",
                "event-place": "Berlin, Germany",
                "ISBN": "9781450311434",
                "keyword": "test data quality, data quality dimensions, testing",
                "number-of-pages": "6",
                "page": "233–238",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Towards measuring test data quality",
                "URL": "https://doi.org/10.1145/2320765.2320830"
            }
        },
        {
            "10.1145/3134302.3134335": {
                "id": "10.1145/3134302.3134335",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Petrova-Antonova",
                        "given": "Dessislava"
                    },
                    {
                        "family": "Georgieva",
                        "given": "Olga"
                    },
                    {
                        "family": "Ilieva",
                        "given": "Sylvia"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            6,
                            23
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            6,
                            23
                        ]
                    ]
                },
                "abstract": "Big Data is attracting increasing amount of attention among academy, industry and citizens. It poses both opportunities and challenges for society as a whole. In order to gain value from Big Data, it needs to be processed and analysed in an appropriate way, and the results have to be presented in a visual manner as to be able to effectively support decision making. Following the current trends in Big Data, this paper aims to prove the value-creation of Big Data by proposing a new data model in the field of the primary and secondary education in Bulgaria. It follows the Big Data Value Chain concept in order to group the schools depending on the concentration of students with learning deficits and risk of premature leaving the education system. The primary purpose of the proposed Data Model is to drive decisions by turning information into intelligence.",
                "call-number": "10.1145/3134302.3134335",
                "collection-title": "CompSysTech'17",
                "container-title": "Proceedings of the 18th International Conference on Computer Systems and Technologies",
                "DOI": "10.1145/3134302.3134335",
                "event-place": "Ruse, Bulgaria",
                "ISBN": "9781450352345",
                "keyword": "Education, Data model, Big Data, Decision support, Big Data Value Chain",
                "number-of-pages": "8",
                "page": "88–95",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Modelling of Educational Data Following Big Data Value Chain",
                "URL": "https://doi.org/10.1145/3134302.3134335"
            }
        },
        {
            "10.1145/3006299.3006317": {
                "id": "10.1145/3006299.3006317",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Razaq",
                        "given": "Abdul"
                    },
                    {
                        "family": "Tianfield",
                        "given": "Huaglory"
                    },
                    {
                        "family": "Barrie",
                        "given": "Peter"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            12,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            12,
                            6
                        ]
                    ]
                },
                "abstract": "We present a novel Cyber Security analytics framework. We demonstrate a comprehensive cyber security monitoring system to construct cyber security correlated events with feature selection to anticipate behaviour based on various sensors.",
                "call-number": "10.1145/3006299.3006317",
                "collection-title": "BDCAT '16",
                "container-title": "Proceedings of the 3rd IEEE/ACM International Conference on Big Data Computing, Applications and Technologies",
                "DOI": "10.1145/3006299.3006317",
                "event-place": "Shanghai, China",
                "ISBN": "9781450346177",
                "keyword": "advanced persistent threats, process auditing, IDS/IPS, security analytics, event correlation, SIEM",
                "number-of-pages": "7",
                "page": "187–193",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A big data analytics based approach to anomaly detection",
                "URL": "https://doi.org/10.1145/3006299.3006317"
            }
        },
        {
            "10.1145/3358505.3358512": {
                "id": "10.1145/3358505.3358512",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Demchenko",
                        "given": "Yuri"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            8,
                            28
                        ]
                    ]
                },
                "abstract": "This paper presents experiences of development and teaching courses on Big Data Infrastructure Technologies for Data Analytics (BDIT4DA) as a part of the general Data Science curricula. The authors built the discussed course based on the EDISON Data Science Framework (EDSF), in particular, Data Science Body of Knowledge (DS-BoK) related to Data Science Engineering knowledge area group (KAG-DSENG). The paper provides overview of the cloud based platforms and tools for Big Data Analytics and stresses importance of including into curriculum the practical work with clouds for future graduates or specialists workplace adaptability. The paper discusses a relationship between the DSENG BoK and Big Data technologies and platforms, in particular Hadoop based applications and tools for data analytics that should be promoted through all course activities: lectures, practical activities and self-study.",
                "call-number": "10.1145/3358505.3358512",
                "collection-title": "ICCBDC 2019",
                "container-title": "Proceedings of the 2019 3rd International Conference on Cloud and Big Data Computing",
                "DOI": "10.1145/3358505.3358512",
                "event-place": "Oxford, United Kingdom",
                "ISBN": "9781450371650",
                "keyword": "Hadoop ecosystem, EDISON Data Science Framework (EDSF), Cloud Computing, Big Data Infrastructure Technologies, Data Science Engineering, Data Science Body of Knowledge (DS-BoK)",
                "number-of-pages": "5",
                "page": "60–64",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data Platforms and Tools for Data Analytics in the Data Science Engineering Curriculum",
                "URL": "https://doi.org/10.1145/3358505.3358512"
            }
        },
        {
            "10.5555/2735522.2735573": {
                "id": "10.5555/2735522.2735573",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Mohammadi",
                        "given": "Mohammad Mahdi"
                    },
                    {
                        "family": "Raahemi",
                        "given": "Bijan"
                    },
                    {
                        "family": "Cheraghchi",
                        "given": "Fatemeh"
                    },
                    {
                        "family": "Obidallah",
                        "given": "Wael"
                    },
                    {
                        "family": "Bigdeli",
                        "given": "Elnaz"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            11,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            11,
                            3
                        ]
                    ]
                },
                "abstract": "The exponential growth of data, especially over the internet; leads to the dramatic rise of unstructured and semi-structured data, in addition to the traditional (structured) data. Since relational databases and associated tools were designed to interact with structured data, companies such as Google and Yahoo were facing challenges dealing with the unstructured and semi-structured data. When the volume of data goes beyond the processing capacity of the existing algorithms, it is considered as Big Data. Hadoop is a popular technology for analyzing Big data. There are tools available on Hadoop platform to assist analysts create complex queries and run machine learning algorithms in a parallel and distributed fashion. The goal of this workshop is to provide the participants with hands-on experiences on analyzing Big data, installing Hadoop on Linux-based machines (PCs equipped with Ubuntu OS), and running examples on Hadoop framework.",
                "call-number": "10.5555/2735522.2735573",
                "collection-title": "CASCON '14",
                "container-title": "Proceedings of 24th Annual International Conference on Computer Science and Software Engineering",
                "event-place": "Markham, Ontario, Canada",
                "number-of-pages": "3",
                "page": "323–325",
                "publisher": "IBM Corp.",
                "publisher-place": "USA",
                "title": "Big data analytics using hadoop"
            }
        },
        {
            "10.5555/2740769.2740789": {
                "id": "10.5555/2740769.2740789",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Wu",
                        "given": "Zhaohui"
                    },
                    {
                        "family": "Wu",
                        "given": "Jian"
                    },
                    {
                        "family": "Khabsa",
                        "given": "Madian"
                    },
                    {
                        "family": "Williams",
                        "given": "Kyle"
                    },
                    {
                        "family": "Chen",
                        "given": "Hung-Hsuan"
                    },
                    {
                        "family": "Huang",
                        "given": "Wenyi"
                    },
                    {
                        "family": "Tuarob",
                        "given": "Suppawong"
                    },
                    {
                        "family": "Choudhury",
                        "given": "Sagnik Ray"
                    },
                    {
                        "family": "Ororbia",
                        "given": "Alexander"
                    },
                    {
                        "family": "Mitra",
                        "given": "Prasenjit"
                    },
                    {
                        "family": "Giles",
                        "given": "C. Lee"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            8
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            8
                        ]
                    ]
                },
                "abstract": "We introduce a big data platform that provides various services for harvesting scholarly information and enabling efficient scholarly applications. The core architecture of the platform is built on a secured private cloud, crawls data using a scholarly focused crawler that leverages a dynamic scheduler, processes by utilizing a map reduce based crawl-extraction-ingestion (CEI) workflow, and is stored in distributed repositories and databases. Services such as scholarly data harvesting, information extraction, and user information and log data analytics are integrated into the platform and provided by an OAI and RESTful API. We also introduce a set of scholarly applications built on top of this platform including citation recommendation and collaborator discovery.",
                "call-number": "10.5555/2740769.2740789",
                "collection-title": "JCDL '14",
                "container-title": "Proceedings of the 14th ACM/IEEE-CS Joint Conference on Digital Libraries",
                "event-place": "London, United Kingdom",
                "ISBN": "9781479955695",
                "keyword": "scholarly big data, big data, information extraction",
                "number-of-pages": "10",
                "page": "117–126",
                "publisher": "IEEE Press",
                "title": "Towards building a scholarly big data platform: challenges, lessons and opportunities"
            }
        },
        {
            "10.1145/2612733.2612780": {
                "id": "10.1145/2612733.2612780",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Harrison",
                        "given": "Teresa M."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            18
                        ]
                    ]
                },
                "abstract": "\"Big data\" has captured the imagination of e-government researchers as the source of potential advances in government innovation, strategy, and policy, and as the basis for entirely new approaches to research investigations across the disciplines. Digital data is everywhere, and, it is thought, considerable value may be obtained in analyzing the digital traces generated by internet users as they traverse social, political, economic and material spaces. However, once past the seminal anecdotes (e.g, estimates of flu outbreaks based on Google searches), generating knowledge from big data presents complexities along with its potentials. In this panel, we bring together researchers to share their experiences with big data projects in e-government, considering the research questions they are asking, the opportunities and complications they are encountering, and the new strategies or responses they are creating in response.",
                "call-number": "10.1145/2612733.2612780",
                "collection-title": "dg.o '14",
                "container-title": "Proceedings of the 15th Annual International Conference on Digital Government Research",
                "DOI": "10.1145/2612733.2612780",
                "event-place": "Aguascalientes, Mexico",
                "ISBN": "9781450329019",
                "keyword": "social media, social networks, political science, automated linguistic analysis, communication, 2008 financial crisis, project X haren, big data, policy informatics, Facebook",
                "number-of-pages": "2",
                "page": "309–310",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Using big data for digital government research",
                "URL": "https://doi.org/10.1145/2612733.2612780"
            }
        },
        {
            "10.1145/3419634": {
                "id": "10.1145/3419634",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Bansal",
                        "given": "Maggi"
                    },
                    {
                        "family": "Chana",
                        "given": "Inderveer"
                    },
                    {
                        "family": "Clarke",
                        "given": "Siobhán"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            12,
                            6
                        ]
                    ]
                },
                "abstract": "Driven by the core technologies, i.e., sensor-based autonomous data acquisition and the cloud-based big data analysis, IoT automates the actuation of data-driven intelligent actions on the connected objects. This automation enables numerous useful real-life use-cases, such as smart transport, smart living, smart cities, and so on. However, recent industry surveys reflect that data-related challenges are responsible for slower growth of IoT in recent years. For this reason, this article presents a systematic and comprehensive survey on IoT Big Data (IoTBD) with the aim to identify the uncharted challenges for IoTBD. This article analyzes the state-of-the-art academic works in IoT and big data management across various domains and proposes a taxonomy for IoTBD management. Then, the survey explores the IoT portfolio of major cloud vendors and provides a classification of vendor services for the integration of IoT and IoTBD on their cloud platforms. After that, the survey identifies the IoTBD challenges in terms of 13 V’s challenges and envisions IoTBD as “Big Data 2.0.” Then the survey provides comprehensive analysis of recent works that address IoTBD challenges by highlighting their strengths and weaknesses to assess the recent trends and future research directions. Finally, the survey concludes with discussion on open research issues for IoTBD.",
                "call-number": "10.1145/3419634",
                "collection-number": "131",
                "container-title": "ACM Comput. Surv.",
                "DOI": "10.1145/3419634",
                "ISSN": "0360-0300",
                "issue": "6",
                "keyword": "cloud computing in IoT, big data 2.0, V’s challenges for IoT big data, IoT big data, IoT big data survey, cloud IoT services",
                "number": "Article 131",
                "number-of-pages": "59",
                "page": "1–59",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "November 2021",
                "title": "A Survey on IoT Big Data: Current Status, 13 V’s Challenges, and Future Directions",
                "URL": "https://doi.org/10.1145/3419634",
                "volume": "53"
            }
        },
        {
            "10.1145/3184407.3184420": {
                "id": "10.1145/3184407.3184420",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Ardagna",
                        "given": "Danilo"
                    },
                    {
                        "family": "Barbierato",
                        "given": "Enrico"
                    },
                    {
                        "family": "Evangelinou",
                        "given": "Athanasia"
                    },
                    {
                        "family": "Gianniti",
                        "given": "Eugenio"
                    },
                    {
                        "family": "Gribaudo",
                        "given": "Marco"
                    },
                    {
                        "family": "Pinto",
                        "given": "Túlio B. M."
                    },
                    {
                        "family": "Guimarães",
                        "given": "Anna"
                    },
                    {
                        "family": "Couto da Silva",
                        "given": "Ana Paula"
                    },
                    {
                        "family": "Almeida",
                        "given": "Jussara M."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            3,
                            30
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            3,
                            30
                        ]
                    ]
                },
                "abstract": "Data heterogeneity and irregularity are key characteristics of big data applications that often overwhelm the existing software and hardware infrastructures. In such context, the exibility and elasticity provided by the cloud computing paradigm over a natural approach to cost-effectively adapting the allocated resources to the application's current needs. Yet, the same characteristics impose extra challenges to predicting the performance of cloud-based big data applications, a central step in proper management and planning. This paper explores two modeling approaches for performance prediction of cloud-based big data applications. We evaluate a queuing-based analytical model and a novel fast ad-hoc simulator in various scenarios based on different applications and infrastructure setups. Our results show that our approaches can predict average application execution times with 26% relative error in the very worst case and about 12% on average. Moreover, our simulator provides performance estimates 70 times faster than state of the art simulation tools.",
                "call-number": "10.1145/3184407.3184420",
                "collection-title": "ICPE '18",
                "container-title": "Proceedings of the 2018 ACM/SPEC International Conference on Performance Engineering",
                "DOI": "10.1145/3184407.3184420",
                "event-place": "Berlin, Germany",
                "ISBN": "9781450350952",
                "keyword": "approximate methods, big data, spark, performance modeling, simulation",
                "number-of-pages": "8",
                "page": "192–199",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Performance Prediction of Cloud-Based Big Data Applications",
                "URL": "https://doi.org/10.1145/3184407.3184420"
            }
        },
        {
            "10.1145/3400903.3409117": {
                "id": "10.1145/3400903.3409117",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Cuzzocrea",
                        "given": "Alfredo"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            7,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            7,
                            7
                        ]
                    ]
                },
                "abstract": "Clustering is an essential task of the whole pattern recognition process, and it can serve under several roles, for instance in terms of data pre-processing tool for better (i.e., more accurate) pattern recognition analysis and mining. In this vest, a critical applicative setting is represented by applying pattern recognition tools over emerging big data. Here, clustering specially plays a challenging role within the context of this conceptual mining framework, and, under a larger vision, it can act as pre-processing task for general big data clustering problems. In this paper, we first focus on state-of-the-art solutions for big data clustering in the specific pattern recognition context, by highlighting benefits and limitations. Then, we focus the attention on the problem of effectively and efficiently clustering big data via innovative multidimensional metaphors, thus achieving the definition of so-called multidimensional clustering over big data. In this so-delineated research setting, based on the well-known challenges of big data management (e.g., volume, velocity, variety, and veracity), we provide critical review and discussion, complemented by a rich set of research directions, development perspectives and emerging trends of the investigated topics, as contextualized in the reference big-data-analytics scientific area.",
                "call-number": "10.1145/3400903.3409117",
                "collection-number": "32",
                "collection-title": "SSDBM 2020",
                "container-title": "32nd International Conference on Scientific and Statistical Database Management",
                "DOI": "10.1145/3400903.3409117",
                "event-place": "Vienna, Austria",
                "ISBN": "9781450388146",
                "keyword": "Big Data Clustering, Multidimensional Clustering over Big Data, Big Data, Big Data Analytics",
                "number": "Article 32",
                "number-of-pages": "6",
                "page": "1–6",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Multidimensional Clustering over Big Data: Models, Issues, Analysis, Emerging Trends",
                "URL": "https://doi.org/10.1145/3400903.3409117"
            }
        },
        {
            "10.1145/2859889.2883586": {
                "id": "10.1145/2859889.2883586",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Zibitsker",
                        "given": "Boris"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            3,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            3,
                            12
                        ]
                    ]
                },
                "abstract": "Today's fast-paced businesses have to make business decisions in real-time. That creates pressure on IT leaders to develop near real-time Big Data and Data Warehouse applications that apply advance analytics against large volumes of data to deliver recommendations fast. Hardware and software used to build Big Data infrastructure is cheap, but management of complex environments is not easy In this presentation we will review role of Performance Assurance incorporating Descriptive, Diagnostic, Predictive, Prescriptive and Control Analytics during each phase of the Application and Data life cycle. We will review challenges and Performance Assurance solutions for Big Data Batch and Real Time applications based on YARN, Map/Reduce, Kafka, Spark/Storm and Cassandra Apache projects",
                "call-number": "10.1145/2859889.2883586",
                "collection-title": "ICPE '16 Companion",
                "container-title": "Companion Publication for ACM/SPEC on International Conference on Performance Engineering",
                "DOI": "10.1145/2859889.2883586",
                "event-place": "Delft, The Netherlands",
                "ISBN": "9781450341479",
                "number-of-pages": "1",
                "page": "31",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data Applications Performance Assurance",
                "URL": "https://doi.org/10.1145/2859889.2883586"
            }
        },
        {
            "10.1145/3372454.3372479": {
                "id": "10.1145/3372454.3372479",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Guo",
                        "given": "Yiming"
                    },
                    {
                        "family": "Xia",
                        "given": "Zhijie"
                    },
                    {
                        "family": "Zhang",
                        "given": "Zhisheng"
                    },
                    {
                        "family": "Sun",
                        "given": "Mengze"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            11,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            11,
                            20
                        ]
                    ]
                },
                "abstract": "Plasma Enhanced Chemical Vapor Deposition (PECVD) is a critical process in the processing of solar cells. Large quantities of the process data are collected from different sensors during the PECVD process, which are high-dimensional and highly correlated. Most existing research only focus on the analysis of single sensor data instead of multi-sensor data. However, the information contained in single sensor data is incomplete. In this paper, the method of Convolutional Neural Networks (CNN) is adopted to analysis multi-sensor big data form PECVD process. The regression model between the multi-sensor data and the quality of solar cells is established for quality prediction. The impact of various types of hyper-parameters on the performance of the model is analyzed, and the predictive performance of the model is optimized by adjusting the hyper-parameters. The performance of the proposed method is compared with existing methods in a real-world case study.",
                "call-number": "10.1145/3372454.3372479",
                "collection-title": "ICBDR 2019",
                "container-title": "Proceedings of the 2019 3rd International Conference on Big Data Research",
                "DOI": "10.1145/3372454.3372479",
                "event-place": "Cergy-Pontoise, France",
                "ISBN": "9781450372015",
                "keyword": "CNN, Quality prediction, Multi-sensor data, Big data, PECVD",
                "number-of-pages": "6",
                "page": "24–29",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A Multi-sensor Big Data fusion Method in Quality Prediction of the Plasma Enhanced Chemical Vapor Deposition Process",
                "URL": "https://doi.org/10.1145/3372454.3372479"
            }
        },
        {
            "10.1145/2447481.2447491": {
                "id": "10.1145/2447481.2447491",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Ayhan",
                        "given": "Samet"
                    },
                    {
                        "family": "Pesce",
                        "given": "Johnathan"
                    },
                    {
                        "family": "Comitz",
                        "given": "Paul"
                    },
                    {
                        "family": "Gerberick",
                        "given": "Gary"
                    },
                    {
                        "family": "Bliesner",
                        "given": "Steve"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            11,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            11,
                            6
                        ]
                    ]
                },
                "abstract": "In this paper, we describe a novel analytics system that enables query processing and predictive analytics over streams of aviation data. As part of an Internal Research and Development project, Boeing Research and Technology (BR&T) Advanced Air Traffic Management (AATM) built a system that makes predictions based upon descriptive patterns of archived aviation data. Boeing AATM has been receiving live Aircraft Situation Display to Industry (ASDI) data and archiving it for over two years. At the present time, there is not an easy mechanism to perform analytics on the data. The incoming ASDI data is large, compressed, and requires correlation with other flight data before it can be analyzed.The service exposes this data once it has been uncompressed, correlated, and stored in a data warehouse for further analysis using a variety of descriptive, predictive, and possibly prescriptive analytics tools. The service is being built partially in response to requests from Boeing Commercial Aviation (BCA) for analysis of capacity and flow in the US National Airspace System (NAS). The service utilizes a custom tool for correlating the raw ASDI feed, IBM Warehouse with DB2 for data management, WebSphere Message Broker for real-time message brokering, SPSS Modeler for statistical analysis, and Cognos BI for front-end business intelligence (BI) visualization. This paper describes a scalable service architecture, implementation and the value it adds to the aviation domain.",
                "call-number": "10.1145/2447481.2447491",
                "collection-title": "BigSpatial '12",
                "container-title": "Proceedings of the 1st ACM SIGSPATIAL International Workshop on Analytics for Big Geospatial Data",
                "DOI": "10.1145/2447481.2447491",
                "event-place": "Redondo Beach, California",
                "ISBN": "9781450316927",
                "keyword": "big data, data stream management, data analytics, data warehouse",
                "number-of-pages": "10",
                "page": "81–90",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Predictive analytics with surveillance big data",
                "URL": "https://doi.org/10.1145/2447481.2447491"
            }
        },
        {
            "10.5555/2819289.2819293": {
                "id": "10.5555/2819289.2819293",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Cerqueus",
                        "given": "Thomas"
                    },
                    {
                        "family": "de Almeida",
                        "given": "Eduardo Cunha"
                    },
                    {
                        "family": "Scherzinger",
                        "given": "Stefanie"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            5,
                            16
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            5,
                            16
                        ]
                    ]
                },
                "abstract": "We consider the task of building Big Data software systems, offered as software-as-a-service. These applications are commonly backed by NoSQL data stores that address the proverbial Vs of Big Data processing: NoSQL data stores can handle large volumes of data and many systems do not enforce a global schema, to account for structural variety in data. Thus, software engineers can design the data model on the go, a flexibility that is particularly crucial in agile software development. However, NoSQL data stores commonly do not yet account for the veracity of changes when it comes to changes in the structure of persisted data. Yet this is an inevitable consequence of agile software development. In most NoSQL-based application stacks, schema evolution is completely handled within the application code, usually involving object mapper libraries. Yet simple code refactorings, such as renaming a class attribute at the source code level, can cause data loss or runtime errors once the application has been deployed to production. We address this pain point by contributing type checking rules that we have implemented within an IDE plugin. Our plugin ControVol statically type checks the object mapper class declarations against the code release history. ControVol is thus capable of detecting common yet risky cases of mismatched data and schema, and can even suggest automatic fixes.",
                "call-number": "10.5555/2819289.2819293",
                "collection-title": "BIGDSE '15",
                "container-title": "Proceedings of the First International Workshop on BIG Data Software Engineering",
                "event-place": "Florence, Italy",
                "number-of-pages": "7",
                "page": "4–10",
                "publisher": "IEEE Press",
                "title": "Safely managing data variety in big data software development"
            }
        },
        {
            "10.1145/3335484.3335509": {
                "id": "10.1145/3335484.3335509",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Liao",
                        "given": "Han-Teng"
                    },
                    {
                        "family": "Wang",
                        "given": "Zijia"
                    },
                    {
                        "family": "Wu",
                        "given": "Xue"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            5,
                            10
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            5,
                            10
                        ]
                    ]
                },
                "abstract": "The advancement in Big Data and Artificial Intelligence has posed challenges and opportunities for undergraduate education. It raises several questions regarding what is desirable and viable for preparing undergraduate students for future success. This paper presents the rationales and outcomes of a two-year reform of an undergraduate program of Internet and New Media in China, summarizing the ways in which the curriculum design can incorporate Big Data and Artificial Intelligence education for future Internet product managers and HCI professionals. Using the notion of \"minimum viable products\" to frame the action research of education reform, it first describes the ways in which we identify the job market need for Internet product managers and HCI professionals, and explores the learning pathways, departing from the conventional Internet and New Media programs in China. It then documents the results of the minimum required changes to deliver such a viable learning product and the initial evidence from students that validates the designed learning product. The overall findings demonstrate the usefulness and challenges in preparing students for careers in a data-intensive or data-driven world.",
                "call-number": "10.1145/3335484.3335509",
                "collection-title": "ICBDC '19",
                "container-title": "Proceedings of the 4th International Conference on Big Data and Computing",
                "DOI": "10.1145/3335484.3335509",
                "event-place": "Guangzhou, China",
                "ISBN": "9781450362788",
                "keyword": "Sustainable Design, ICT4D, Knowledge Brokerage, Big Data Education, Ecological Design, Sustainable HCI",
                "number-of-pages": "6",
                "page": "42–47",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Developing a Minimum Viable Product for Big Data and AI Education: Action Research Based on a Two-Year Reform of an Undergraduate Program of Internet and New Media",
                "URL": "https://doi.org/10.1145/3335484.3335509"
            }
        },
        {
            "10.1145/2433396.2433459": {
                "id": "10.1145/2433396.2433459",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Yang",
                        "given": "Qiang"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            2,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            2,
                            4
                        ]
                    ]
                },
                "abstract": "A major challenge in today's world is the Big Data problem, which manifests itself in Web and Mobile domains as rapidly changing and heterogeneous data streams. A data-mining system must be able to cope with the influx of changing data in a continual manner. This calls for Lifelong Machine Learning, which in contrast to the traditional one-shot learning, should be able to identify the learning tasks at hand and adapt to the learning problems in a sustainable manner. A foundation for lifelong machine learning is transfer learning, whereby knowledge gained in a related but different domain may be transferred to benefit learning for a current task. To make effective transfer learning, it is important to maintain a continual and sustainable channel in the life time of a user in which the data are annotated. In this talk, I outline the lifelong machine learning situations, give several examples of transfer learning and applications for lifelong machine learning, and discuss cases of successful extraction of data annotations to meet the Big Data challenge.",
                "call-number": "10.1145/2433396.2433459",
                "collection-title": "WSDM '13",
                "container-title": "Proceedings of the sixth ACM international conference on Web search and data mining",
                "DOI": "10.1145/2433396.2433459",
                "event-place": "Rome, Italy",
                "ISBN": "9781450318693",
                "keyword": "big data, transfer learning, lifelong machine learning",
                "number-of-pages": "2",
                "page": "505–506",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data, lifelong machine learning and transfer learning",
                "URL": "https://doi.org/10.1145/2433396.2433459"
            }
        },
        {
            "10.14778/2824032.2824140": {
                "id": "10.14778/2824032.2824140",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Balazinska",
                        "given": "Magdalena"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            8,
                            1
                        ]
                    ]
                },
                "abstract": "The need for effective tools for big data data management and analytics continues to grow. While the ecosystem of tools is expanding many research problems remain open: they include challenges around efficient processing, flexible analytics, ease of use, and operation as a service. Many new systems and much innovation, however, come from industry (or from academic projects that quickly became big players in industry). An important question for our community is whether industry will solve all the problems or whether there is a place for academic research in big data and what is that place. In this paper, we address this question by looking back at our research on the Nuage, CQMS, Myria, and Data Pricing projects, and the SciDB collaboration.",
                "call-number": "10.14778/2824032.2824140",
                "container-title": "Proc. VLDB Endow.",
                "DOI": "10.14778/2824032.2824140",
                "ISSN": "2150-8097",
                "issue": "12",
                "number-of-pages": "4",
                "page": "2053–2056",
                "publisher": "VLDB Endowment",
                "source": "August 2015",
                "title": "Big data research: will industry solve all the problems?",
                "URL": "https://doi.org/10.14778/2824032.2824140",
                "volume": "8"
            }
        },
        {
            "10.1145/2295136.2295148": {
                "id": "10.1145/2295136.2295148",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bhatti",
                        "given": "Rafae"
                    },
                    {
                        "family": "LaSalle",
                        "given": "Ryan"
                    },
                    {
                        "family": "Bird",
                        "given": "Rob"
                    },
                    {
                        "family": "Grance",
                        "given": "Tim"
                    },
                    {
                        "family": "Bertino",
                        "given": "Elisa"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            6,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            6,
                            20
                        ]
                    ]
                },
                "abstract": "This panel will discuss the interplay between key emerging security trends centered around big data analytics and security. With the explosion of big data and advent of cloud computing, data analytics has not only become prevalent but also a critical business need. Internet applications today consume vast amounts of data collected from heterogeneous big data repositories and provide meaningful insights from it. These include applications for business forecasting, investment and finance, healthcare and well-being, science and hi-tech, to name a few. Security and operational intelligence is one of the critical areas where big data analytics is expected to play a crucial role. Security analytics in a big data environment presents a unique set of challenges, not properly addressed by the existing security incident and event monitoring (or SIEM) systems that typically work with a limited set of traditional data sources (firewall, IDS, etc.) in an enterprise network. A big data environment presents both a great opportunity and a challenge due to the explosion and heterogeneity of the potential data sources that extend the boundary of analytics to social networks, real time streams and other forms of highly contextual data that is characterized by high volume and speed. In addition to meeting infrastructure challenges, there remain additional unaddressed issues, including but not limited to development of self-evolving threat ontologies, integrated network and application layer analytics, and detection of \"low and slow\" attacks. At the same time, security analytics requires a high degree of data assurance, where assurance implies that the data be trustworthy as well as managed in a privacy preserving manner. Our panelists represent individuals from industry, academia, and government who are at the forefront of big data security analytics. They will provide insights into these unique challenges, survey the emerging trends, and lay out a vision for future.",
                "call-number": "10.1145/2295136.2295148",
                "collection-title": "SACMAT '12",
                "container-title": "Proceedings of the 17th ACM symposium on Access Control Models and Technologies",
                "DOI": "10.1145/2295136.2295148",
                "event-place": "Newark, New Jersey, USA",
                "ISBN": "9781450312950",
                "keyword": "analytics, big data, privacy, security",
                "number-of-pages": "2",
                "page": "67–68",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Emerging trends around big data analytics and security: panel",
                "URL": "https://doi.org/10.1145/2295136.2295148"
            }
        },
        {
            "10.1145/3396452": {
                "id": "10.1145/3396452",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2020
                        ]
                    ]
                },
                "abstract": "Due to the outbreak of COVID-19, and considering the participants' healthy, the 2020 3rd International Conference on Big Data and Education (ICBDE 2020) was held successfully online during April 01-03, 2020. Online conference is a good scientific platform for both local and international scientists, managers, business leaders, educators, scholars, engineers and technologists who work in all aspects of Big Data and Education to exchange and share their experiences, new ideas, and discuss the practical challenges encountered and the solutions adopted.",
                "call-number": "10.1145/3396452",
                "container-title-short": "ICBDE '20",
                "event-place": "London, United Kingdom",
                "genre": "proceeding",
                "ISBN": "9781450374989",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2020 The 3rd International Conference on Big Data and Education"
            }
        },
        {
            "10.1109/CCGRID.2017.107": {
                "id": "10.1109/CCGRID.2017.107",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Haroun",
                        "given": "Amir"
                    },
                    {
                        "family": "Mostefaoui",
                        "given": "Ahmed"
                    },
                    {
                        "family": "Dessables",
                        "given": "François"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            5,
                            14
                        ]
                    ]
                },
                "abstract": "Vehicles have become moving sensor platforms collecting huge volumes of data from their various embedded sensors. This data has a great value for automotive manufacturers and vehicles owners. Indeed, connected vehicles data can be used in a large broad of automotive services ranging from safety services to well-being services (e.g. fatigue detection). However, vehicle fleets send big volumes of data that traditional computing and storage approaches are not able to manage efficiently. In this paper, we present the experience of the PSA Group1 on leveraging big data in automotive context. We describe in depth the big data architecture deployed within the PSA Group and the underlaying technologies/products used in each component.",
                "call-number": "10.1109/CCGRID.2017.107",
                "collection-title": "CCGrid '17",
                "container-title": "Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing",
                "DOI": "10.1109/CCGRID.2017.107",
                "event-place": "Madrid, Spain",
                "ISBN": "9781509066100",
                "keyword": "Big Data, Reference Architecture, Connected Vehicles",
                "number-of-pages": "8",
                "page": "921–928",
                "publisher": "IEEE Press",
                "title": "A Big Data Architecture for Automotive Applications: PSA Group Deployment Experience",
                "URL": "https://doi.org/10.1109/CCGRID.2017.107"
            }
        },
        {
            "10.1145/3404512": {
                "id": "10.1145/3404512",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2020
                        ]
                    ]
                },
                "abstract": "At this conference, I served as Conference Program Chair. Prof. Kai Hwang from Chinese University of Hong Kong, China, Prof. Yao Liang from Purdue University School of Science, Indiana University Purdue University, USA and I shared our speeches as keynote speakers. Dr Wei Li from Central Queensland University, Australia, Dr Ka-Chun Wong from City University of Hong Kong, Hong Kong and Dr. Gabriella Casalino from University of Bari, Italy served as the Invited Speakers. They also shared their research during the conference.",
                "call-number": "10.1145/3404512",
                "container-title-short": "BDE 2020",
                "event-place": "Shanghai, China",
                "genre": "proceeding",
                "ISBN": "9781450377225",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2020 2nd International Conference on Big Data Engineering"
            }
        },
        {
            "10.1145/3352700.3352709": {
                "id": "10.1145/3352700.3352709",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Jeřábek",
                        "given": "Kamil"
                    },
                    {
                        "family": "Ryšavý",
                        "given": "Ondřej"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            9,
                            2
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            9,
                            2
                        ]
                    ]
                },
                "abstract": "The increasing amount of traffic flows captured as a part of network monitoring activities makes the analysis more complicated. One of the goals for network traffic analysis is to identify malicious communication. In the paper, we present a new system for big data network flow classification and clustering. The proposed system is based on the popular big data engines such as Apache Spark and Apache Ignite. The conducted experiments demonstrate the feasibility of the proposed approach and show the possible scalability.",
                "call-number": "10.1145/3352700.3352709",
                "collection-number": "9",
                "collection-title": "ECBS '19",
                "container-title": "Proceedings of the 6th Conference on the Engineering of Computer Based Systems",
                "DOI": "10.1145/3352700.3352709",
                "event-place": "Bucharest, Romania",
                "ISBN": "9781450376365",
                "keyword": "Apache Ignite, Big Data, Network flows, Cassandra, Apache Spark",
                "number": "Article 9",
                "number-of-pages": "9",
                "page": "1–9",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data Network Flow Processing Using Apache Spark",
                "URL": "https://doi.org/10.1145/3352700.3352709"
            }
        },
        {
            "10.1145/2481244.2481246": {
                "id": "10.1145/2481244.2481246",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Fan",
                        "given": "Wei"
                    },
                    {
                        "family": "Bifet",
                        "given": "Albert"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            4,
                            30
                        ]
                    ]
                },
                "abstract": "Big Data is a new term used to identify datasets that we can not manage with current methodologies or data mining software tools due to their large size and complexity. Big Data mining is the capability of extracting useful information from these large datasets or streams of data. New mining techniques are necessary due to the volume, variability, and velocity, of such data. The Big Data challenge is becoming one of the most exciting opportunities for the years to come. We present in this issue, a broad overview of the topic, its current status, controversy, and a forecast to the future. We introduce four articles, written by influential scientists in the field, covering the most interesting and state-of-the-art topics on Big Data mining.",
                "call-number": "10.1145/2481244.2481246",
                "container-title": "SIGKDD Explor. Newsl.",
                "DOI": "10.1145/2481244.2481246",
                "ISSN": "1931-0145",
                "issue": "2",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "December 2012",
                "title": "Mining big data: current status, and forecast to the future",
                "URL": "https://doi.org/10.1145/2481244.2481246",
                "volume": "14"
            }
        },
        {
            "10.1145/2588555.2610512": {
                "id": "10.1145/2588555.2610512",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "LeFevre",
                        "given": "Jeff"
                    },
                    {
                        "family": "Sankaranarayanan",
                        "given": "Jagan"
                    },
                    {
                        "family": "Hacigumus",
                        "given": "Hakan"
                    },
                    {
                        "family": "Tatemura",
                        "given": "Junichi"
                    },
                    {
                        "family": "Polyzotis",
                        "given": "Neoklis"
                    },
                    {
                        "family": "Carey",
                        "given": "Michael J."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            18
                        ]
                    ]
                },
                "abstract": "Big data analytical systems, such as MapReduce, perform aggressive materialization of intermediate job results in order to support fault tolerance. When jobs correspond to exploratory queries submitted by data analysts, these materializations yield a large set of materialized views that we propose to treat as an opportunistic physical design. We present a semantic model for UDFs that enables effective reuse of views containing UDFs along with a rewrite algorithm that provably finds the minimum-cost rewrite under certain assumptions. An experimental study on real-world datasets using our prototype based on Hive shows that our approach can result in dramatic performance improvements.",
                "call-number": "10.1145/2588555.2610512",
                "collection-title": "SIGMOD '14",
                "container-title": "Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data",
                "DOI": "10.1145/2588555.2610512",
                "event-place": "Snowbird, Utah, USA",
                "ISBN": "9781450323765",
                "keyword": "query rewriting, big data, opportunistic physical design, opportunistic views, query processing, exploratory analysis, UDFs",
                "number-of-pages": "12",
                "page": "851–862",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Opportunistic physical design for big data analytics",
                "URL": "https://doi.org/10.1145/2588555.2610512"
            }
        },
        {
            "10.1145/2903150.2908078": {
                "id": "10.1145/2903150.2908078",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Homayoun",
                        "given": "Houman"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            5,
                            16
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            5,
                            16
                        ]
                    ]
                },
                "abstract": "Emerging big data analytics applications require a significant amount of server computational power. The costs of building and running a computing server to process big data and the capacity to which we can scale it are driven in large part by those computational resources. However, big data applications share many characteristics that are fundamentally different from traditional desktop, parallel, and scale-out applications. Big data analytics applications rely heavily on specific deep machine learning and data mining algorithms, and are running a complex and deep software stack with various components (e.g. Hadoop, Spark, MPI, Hbase, Impala, MySQL, Hive, Shark, Apache, and MangoDB) that are bound together with a runtime software system and interact significantly with I/O and OS, exhibiting high computational intensity, memory intensity, I/O intensity and control intensity. Current server designs, based on commodity homogeneous processors, will not be the most efficient in terms of performance/watt for this emerging class of applications. In other domains, heterogeneous architectures have emerged as a promising solution to enhance energy-efficiency by allowing each application to run on a core that matches resource needs more closely than a one-size-fits-all core. A heterogeneous architecture integrates cores with various micro-architectures and accelerators to provide more opportunity for efficient workload mapping. In this work, through methodical investigation of power and performance measurements, and comprehensive system level characterization, we demonstrate that a heterogeneous architecture combining high performance big and low power little cores is required for efficient big data analytics applications processing, and in particular in the presence of accelerators and near real-time performance constraints.",
                "call-number": "10.1145/2903150.2908078",
                "collection-title": "CF '16",
                "container-title": "Proceedings of the ACM International Conference on Computing Frontiers",
                "DOI": "10.1145/2903150.2908078",
                "event-place": "Como, Italy",
                "ISBN": "9781450341288",
                "keyword": "heterogeneous architectures, accelerator, power, big data, application characterization, performance",
                "number-of-pages": "6",
                "page": "400–405",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Heterogeneous chip multiprocessor architectures for big data applications",
                "URL": "https://doi.org/10.1145/2903150.2908078"
            }
        },
        {
            "10.1145/3274250.3275113": {
                "id": "10.1145/3274250.3275113",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Xinhua",
                        "given": "E."
                    },
                    {
                        "family": "Zhu",
                        "given": "Binjie"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            7,
                            15
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            7,
                            15
                        ]
                    ]
                },
                "abstract": "Big data service is a promising technology in Internet. Quality of service of big data services is a very important indicator. A service delivery network was presented in this paper to reduce service delays. The web services were distribution to the edge of the network to making it closer to users, so the network delay is small. A services distribution method with QoS guarantee was presented in this paper. Friendly degrees were measured in this method between the servers. According to the friendly degree determine the coverage areas of a copy. It takes up less resource under the premise of QoS guaranteeing.",
                "call-number": "10.1145/3274250.3275113",
                "collection-title": "ICoMS '18",
                "container-title": "Proceedings of the 2018 1st International Conference on Mathematics and Statistics",
                "DOI": "10.1145/3274250.3275113",
                "event-place": "Porto, Portugal",
                "ISBN": "9781450365383",
                "keyword": "Distribution method, Web service, SDN",
                "number-of-pages": "3",
                "page": "89–91",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data Service Delivery Network",
                "URL": "https://doi.org/10.1145/3274250.3275113"
            }
        },
        {
            "10.1145/1839379.1839397": {
                "id": "10.1145/1839379.1839397",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Helfert",
                        "given": "Markus"
                    },
                    {
                        "family": "Hossain",
                        "given": "Fakir"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2010,
                            6,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2010,
                            6,
                            17
                        ]
                    ]
                },
                "abstract": "Many researchers and practitioners have been attracted to improve data quality due to its monumental importance as a key success factor. Mathematical and statistical models have been deployed to information systems to introduce constrain and transaction based mechanisms to prevent data quality related problems. Entire management of the process and roles involved in data generation has also been scrutinized. Vast amount of knowledge base has been progressed in this area; however, most of the approaches are limited from practical perspective. System development process incorporating quality modelling is rarely integrated. Quality related meta data is absent from most information system. Neither process mapping nor data modelling provides sufficient provision to measure quality or certification of data in the information systems. Furthermore, ongoing monitoring of data for quality conformance through a separate process is expensive and time consuming. Recognising this limitation and aiming to provide a practical-orient comprehensive approach, we propose a process centric quality focused system design incorporating data product quality, conformance monitoring and certification. In this paper we focus on the self certification of data quality based on our earlier work on the process centric framework for ongoing data quality monitoring.",
                "call-number": "10.1145/1839379.1839397",
                "collection-title": "CompSysTech '10",
                "container-title": "Proceedings of the 11th International Conference on Computer Systems and Technologies and Workshop for PhD Students in Computing on International Conference on Computer Systems and Technologies",
                "DOI": "10.1145/1839379.1839397",
                "event-place": "Sofia, Bulgaria",
                "ISBN": "9781450302432",
                "keyword": "data quality certification, information manufacturing, information quality, ongoing data product monitoring, quality monitoring",
                "number-of-pages": "6",
                "page": "95–100",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Certifying data quality conformance",
                "URL": "https://doi.org/10.1145/1839379.1839397"
            }
        },
        {
            "10.1145/3409501.3409523": {
                "id": "10.1145/3409501.3409523",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bo",
                        "given": "Yu"
                    },
                    {
                        "family": "Yongke",
                        "given": "Chen"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            7,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            7,
                            3
                        ]
                    ]
                },
                "abstract": "Big data plays an irreplaceable role in China's logistics industry. Enterprises need to reconstruct their logistics management system with the help of big data technology. This paper expounds the application advantages of big data technology in enterprise logistics management, puts forward the contradictions in enterprise logistics management under the background of big data, and explores the application of big data technology in enterprise logistics management from four aspects of safety management system, inventory management mode, logistics distribution management and talent team construction.",
                "call-number": "10.1145/3409501.3409523",
                "collection-title": "HPCCT &amp; BDAI 2020",
                "container-title": "Proceedings of the 2020 4th High Performance Computing and Cluster Technologies Conference & 2020 3rd International Conference on Big Data and Artificial Intelligence",
                "DOI": "10.1145/3409501.3409523",
                "event-place": "Qingdao, China",
                "ISBN": "9781450375603",
                "keyword": "big data, logistics, information",
                "number-of-pages": "3",
                "page": "209–211",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Strengthen the establishment of enterprise logistics management system by means of big data",
                "URL": "https://doi.org/10.1145/3409501.3409523"
            }
        },
        {
            "10.1145/2331042.2331062": {
                "id": "10.1145/2331042.2331062",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Yang",
                        "given": "Edward Z."
                    },
                    {
                        "family": "Simmons",
                        "given": "Robert J."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            9,
                            1
                        ]
                    ]
                },
                "call-number": "10.1145/2331042.2331062",
                "container-title": "XRDS",
                "DOI": "10.1145/2331042.2331062",
                "ISSN": "1528-4972",
                "issue": "1",
                "number-of-pages": "1",
                "page": "69",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "Fall 2012",
                "title": "Profile Jeff Dean Big data at Google",
                "URL": "https://doi.org/10.1145/2331042.2331062",
                "volume": "19"
            }
        },
        {
            "10.5555/2819289": {
                "id": "10.5555/2819289",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2015
                        ]
                    ]
                },
                "abstract": "Big Data is about extracting valuable information from data in order to use it in intelligent ways such as to revolutionize decision-making in businesses, science and society. The continuous and tremendous growth of data volume and velocity combined with easier access to data and the availability of powerful IT systems have led to intensified activities around Big Data.BIGDSE 2015 aims to explore opportunities that Big Data technology offers to software engineering, both in research and practice. In addition, BIGDSE will look at the software engineering challenges imposed by building Big Data software systems. The workshop brings together researchers and practitioners working in the areas of Big Data, software engineering and software analytics to discuss research challenges, recent developments, novel applications and scenarios, as well as methods, techniques, experiences, and tools to leverage and exploit the opportunities offered by Big Data.",
                "call-number": "10.5555/2819289",
                "container-title-short": "BIGDSE '15",
                "event-place": "Florence, Italy",
                "genre": "proceeding",
                "publisher": "IEEE Press",
                "title": "Proceedings of the First International Workshop on BIG Data Software Engineering"
            }
        },
        {
            "10.1145/1526993.1526999": {
                "id": "10.1145/1526993.1526999",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Spaniol",
                        "given": "Marc"
                    },
                    {
                        "family": "Denev",
                        "given": "Dimitar"
                    },
                    {
                        "family": "Mazeika",
                        "given": "Arturas"
                    },
                    {
                        "family": "Weikum",
                        "given": "Gerhard"
                    },
                    {
                        "family": "Senellart",
                        "given": "Pierre"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2009,
                            4,
                            20
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2009,
                            4,
                            20
                        ]
                    ]
                },
                "abstract": "Web archives preserve the history of Web sites and have high long-term value for media and business analysts. Such archives are maintained by periodically re-crawling entire Web sites of interest. From an archivist's point of view, the ideal case to ensure highest possible data quality of the archive would be to \"freeze\" the complete contents of an entire Web site during the time span of crawling and capturing the site. Of course, this is practically infeasible. To comply with the politeness specification of a Web site, the crawler needs to pause between subsequent http requests in order to avoid unduly high load on the site's http server. As a consequence, capturing a large Web site may span hours or even days, which increases the risk that contents collected so far are incoherent with the parts that are still to be crawled. This paper introduces a model for identifying coherent sections of an archive and, thus, measuring the data quality in Web archiving. Additionally, we present a crawling strategy that aims to ensure archive coherence by minimizing the diffusion of Web site captures. Preliminary experiments demonstrate the usefulness of the model and the effectiveness of the strategy.",
                "call-number": "10.1145/1526993.1526999",
                "collection-title": "WICOW '09",
                "container-title": "Proceedings of the 3rd workshop on Information credibility on the web",
                "DOI": "10.1145/1526993.1526999",
                "event-place": "Madrid, Spain",
                "ISBN": "9781605584881",
                "keyword": "temporal coherence, data quality, web archiving",
                "number-of-pages": "8",
                "page": "19–26",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Data quality in web archiving",
                "URL": "https://doi.org/10.1145/1526993.1526999"
            }
        },
        {
            "10.5555/3172795.3172852": {
                "id": "10.5555/3172795.3172852",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Wong",
                        "given": "Serene"
                    },
                    {
                        "family": "Jurisica",
                        "given": "Igor"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            11,
                            6
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            11,
                            6
                        ]
                    ]
                },
                "abstract": "With recent technological advancement, biomedical data is growing rapidly, in terms of volume, quality and depth. This creates many challenges, and in this workshop we focused on how one can turn this data using \"big data analytics\" into knowledge that can be used effectively. One of the main building blocks of this process is diverse networks - typed graphs that provide detailed annotation of relationships among measured entities.",
                "call-number": "10.5555/3172795.3172852",
                "collection-title": "CASCON '17",
                "container-title": "Proceedings of the 27th Annual International Conference on Computer Science and Software Engineering",
                "event-place": "Markham, Ontario, Canada",
                "number-of-pages": "1",
                "page": "338",
                "publisher": "IBM Corp.",
                "publisher-place": "USA",
                "title": "Big data analytics: challenges and applications to health care"
            }
        },
        {
            "10.1145/3338840.3355683": {
                "id": "10.1145/3338840.3355683",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Guleng",
                        "given": "Siri"
                    },
                    {
                        "family": "Wu",
                        "given": "Celimuge"
                    },
                    {
                        "family": "Yoshinaga",
                        "given": "Tsutomu"
                    },
                    {
                        "family": "Ji",
                        "given": "Yusheng"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            9,
                            24
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            9,
                            24
                        ]
                    ]
                },
                "abstract": "Multi-hop broadcast communications are required for vehicular Internet-of-Things applications including intelligent transport systems, autonomous driving, and collision avoidance systems. However, conducing efficient broadcasting in vehicular ad hoc networks (VANETs) is particularly challenging due to the vehicle mobility and various vehicle densities. In this paper, we propose a traffic big data assisted broadcast scheme in VANETs. The proposed scheme uses vehicle traffic big data to estimate vehicle density, and then uses the prediction information to enhance the procedure of multi-hop broadcasting. By enhancing a receiver-oriented broadcast approach with vehicle density prediction, the proposed scheme can provide a high dissemination ratio with low broadcast redundancy. We use real traffic big data to conduct prediction and then generate realistic vehicular network simulations to show the performance of the proposed scheme.",
                "call-number": "10.1145/3338840.3355683",
                "collection-title": "RACS '19",
                "container-title": "Proceedings of the Conference on Research in Adaptive and Convergent Systems",
                "DOI": "10.1145/3338840.3355683",
                "event-place": "Chongqing, China",
                "ISBN": "9781450368438",
                "keyword": "VANETs, traffic big data, broadcast",
                "number-of-pages": "5",
                "page": "236–240",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Traffic big data assisted broadcast in vehicular networks",
                "URL": "https://doi.org/10.1145/3338840.3355683"
            }
        },
        {
            "10.1145/2896825": {
                "id": "10.1145/2896825",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2016
                        ]
                    ]
                },
                "abstract": "Big Data is about extracting valuable information from data in order to use it in intelligent ways such as to revolutionize decision-making in businesses, science and society. Big Data may open up radical new ways and unprecedented opportunities of attacking software engineering problems. Already now forums, forges, blogs, Q&A sites, and social networks, provide a wealth of data that may be analysed to uncover new requirements, provide evidence on usage and development trends of application frameworks, or to perform empirical studies involving real-world software developers. In addition, real-time data collected from mobile and cloud applications may be analysed to detect user trends, preferences, and optimization opportunities.BIGDSE 2016 features contributions and discussions that explore opportunities that Big Data technology offers to software engineering, both in research and practice (\"big data for software engineering\"). BIGDSE also looks at the software engineering challenges imposed by building Big Data software systems (\"software engineering for big data\").",
                "call-number": "10.1145/2896825",
                "container-title-short": "BIGDSE '16",
                "event-place": "Austin, Texas",
                "genre": "proceeding",
                "ISBN": "9781450341523",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Proceedings of the 2nd International Workshop on BIG Data Software Engineering"
            }
        },
        {
            "10.5555/3192424.3192597": {
                "id": "10.5555/3192424.3192597",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Jiang",
                        "given": "Fan"
                    },
                    {
                        "family": "Leung",
                        "given": "Carson K."
                    },
                    {
                        "family": "Pazdor",
                        "given": "Adam G. M."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            8,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            8,
                            18
                        ]
                    ]
                },
                "abstract": "In the current era of big data, high volumes of valuable data can be easily collected and generated. Social networks are examples of generating sources of these big data. Users in these social networks are often linked by some interdependency such as friendship. As these big social networks keep growing, there are situations in which an individual user wants to find popular groups of friends so that he can recommend the same groups to other users. In this paper, we present a big data analytic solution that uses the MapReduce model in mining these big social networks for discovering groups of frequently connected users for friend recommendation. Evaluation results show the efficiency and practicality of our data analytic solution in mining big social networks, discovering popular users, and recommending friends.",
                "call-number": "10.5555/3192424.3192597",
                "collection-title": "ASONAM '16",
                "container-title": "Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining",
                "event-place": "Davis, California",
                "ISBN": "9781509028467",
                "keyword": "social networks, big data, big data mining, friendship, social network analysis",
                "number-of-pages": "2",
                "page": "921–922",
                "publisher": "IEEE Press",
                "title": "Big data mining of social networks for friend recommendation"
            }
        },
        {
            "10.1145/3097983.3105814": {
                "id": "10.1145/3097983.3105814",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Mazumdar",
                        "given": "Mainak"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            13
                        ]
                    ]
                },
                "abstract": "The digital media and TV - which is increasingly digitized, have amassed and generating enormous amount of data. While extremely useful, the big data generated by these platforms poses unique challenges for Data Scientists working on developing measurement framework and metrics. Most practitioners optimize speed and scale at the expense of accuracy, which is critical for any measurement. And, the trade-off between bias and variance is not in consideration. In this paper, we will demonstrate how Nielsen is combining proprietary ground truth data and methodologies with Big Data to address the accuracy and bias/variance challenges. We argue that high quality ground truth or training set is pre-requisite to deploying Big Data for high quality media measurement. To illustrate the point, we will share how Nielsen is combining its proprietary high quality panels with Set Top Box for TV measurement in the U.S.",
                "call-number": "10.1145/3097983.3105814",
                "collection-title": "KDD '17",
                "container-title": "Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
                "DOI": "10.1145/3097983.3105814",
                "event-place": "Halifax, NS, Canada",
                "ISBN": "9781450348874",
                "keyword": "media measurement, digital media, data mining, big data, proprietary data, tv",
                "number-of-pages": "1",
                "page": "23",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Addressing Challenges with Big Data for Media Measurement",
                "URL": "https://doi.org/10.1145/3097983.3105814"
            }
        },
        {
            "10.1145/3418688": {
                "id": "10.1145/3418688",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2020
                        ]
                    ]
                },
                "call-number": "10.1145/3418688",
                "container-title-short": "ICCBD '20",
                "event-place": "Taichung, Taiwan",
                "genre": "proceeding",
                "ISBN": "9781450387866",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "2020 the 3rd International Conference on Computing and Big Data"
            }
        },
        {
            "10.1145/3084381.3084422": {
                "id": "10.1145/3084381.3084422",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Eachempati",
                        "given": "Prajwal"
                    },
                    {
                        "family": "Srivastava",
                        "given": "Praveen Ranjan"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            6,
                            21
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            6,
                            21
                        ]
                    ]
                },
                "abstract": "This paper aims to identify some emerging sectors that apply big-data analytics through a systematic literature review conducted by capturing the existing work done in this subject area by academicians and industry experts worldwide and specifically in India backed by a detailed domain-wise, nation-wise and within India, an institute-wise analysis of the contributions made. Based on the existing work, the need for applying analytics in Banking and Finance is emphasized through the paper and a premise is provided for conducting future research in this domain.",
                "call-number": "10.1145/3084381.3084422",
                "collection-title": "SIGMIS-CPR '17",
                "container-title": "Proceedings of the 2017 ACM SIGMIS Conference on Computers and People Research",
                "DOI": "10.1145/3084381.3084422",
                "event-place": "Bangalore, India",
                "ISBN": "9781450350372",
                "keyword": "business, domains, big-data, databases, finance, scopus, analytics, tools",
                "number-of-pages": "2",
                "page": "177–178",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Systematic Literature Review of Big Data Analytics",
                "URL": "https://doi.org/10.1145/3084381.3084422"
            }
        },
        {
            "10.1145/2463676.2463707": {
                "id": "10.1145/2463676.2463707",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sumbaly",
                        "given": "Roshan"
                    },
                    {
                        "family": "Kreps",
                        "given": "Jay"
                    },
                    {
                        "family": "Shah",
                        "given": "Sam"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            22
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            6,
                            22
                        ]
                    ]
                },
                "abstract": "The use of large-scale data mining and machine learning has proliferated through the adoption of technologies such as Hadoop, with its simple programming semantics and rich and active ecosystem. This paper presents LinkedIn's Hadoop-based analytics stack, which allows data scientists and machine learning researchers to extract insights and build product features from massive amounts of data. In particular, we present our solutions to the ``last mile'' issues in providing a rich developer ecosystem. This includes easy ingress from and egress to online systems, and managing workflows as production processes. A key characteristic of our solution is that these distributed system concerns are completely abstracted away from researchers. For example, deploying data back into the online system is simply a 1-line Pig command that a data scientist can add to the end of their script. We also present case studies on how this ecosystem is used to solve problems ranging from recommendations to news feed updates to email digesting to descriptive analytical dashboards for our members.",
                "call-number": "10.1145/2463676.2463707",
                "collection-title": "SIGMOD '13",
                "container-title": "Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data",
                "DOI": "10.1145/2463676.2463707",
                "event-place": "New York, New York, USA",
                "ISBN": "9781450320375",
                "keyword": "big data, hadoop, machine learning, data mining, offline processing, data pipeline",
                "number-of-pages": "10",
                "page": "1125–1134",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The big data ecosystem at LinkedIn",
                "URL": "https://doi.org/10.1145/2463676.2463707"
            }
        },
        {
            "10.1145/3472163.3472171": {
                "id": "10.1145/3472163.3472171",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Bhardwaj",
                        "given": "Dave"
                    },
                    {
                        "family": "Ormandjieva",
                        "given": "Olga"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            7,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2021,
                            7,
                            14
                        ]
                    ]
                },
                "abstract": "Big Data is becoming a substantial part of the decision-making processes in both industry and academia, especially in areas where Big Data may have a profound impact on businesses and society. However, as more data is being processed, data quality is becoming a genuine issue that negatively affects credibility of the systems we build because of the lack of visibility and transparency of the underlying data. Therefore, Big Data quality measurement is becoming increasingly necessary in assessing whether data can serve its purpose in a particular context (such as Big Data analytics, for example). This research addresses Big Data quality measurement modelling and automation by proposing a novel quality measurement framework for Big Data (MEGA) that objectively assesses the underlying quality characteristics of Big Data (also known as the V's of Big Data) at each step of the Big Data Pipelines. Five of the Big Data V's (Volume, Variety, Velocity, Veracity and Validity) are currently automated by the MEGA framework. In this paper, a new theoretically valid quality measurement model is proposed for an essential quality characteristic of Big Data, called Validity. The proposed measurement information model for Validity of Big Data is a hierarchy of 4 derived measures / indicators and 5 based measures. Validity measurement is illustrated on a running example.",
                "call-number": "10.1145/3472163.3472171",
                "collection-title": "IDEAS '21",
                "container-title": "Proceedings of the 25th International Database Engineering & Applications Symposium",
                "DOI": "10.1145/3472163.3472171",
                "event-place": "Montreal, QC, Canada",
                "ISBN": "9781450389914",
                "keyword": "Representational Theory of Measurement,, Validity, Big Data, Measurement Hierarchical Model, Quality Characteristics (V's)",
                "number-of-pages": "7",
                "page": "285–291",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Rigorous Measurement Model for Validity of Big Data: MEGA Approach",
                "URL": "https://doi.org/10.1145/3472163.3472171"
            }
        },
        {
            "10.1145/2769458.2769484": {
                "id": "10.1145/2769458.2769484",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Theodoropoulos",
                        "given": "Georgios"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            10
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            6,
                            10
                        ]
                    ]
                },
                "abstract": "The emergence of extreme scale computing systems and the data explosion have presented an unprecedented opportunity for the analysis of systems at a rapidly increasing scale, complexity and granularity. This paradigm shift calls for an intermingling of 'what-if' and data analytics approaches, however the worlds of Simulation and Big Data have so far been largely separate. The talk will focus on the interplay between simulation, data and emerging computational platforms, identifying gaps and opportunities and discussing some concrete examples of interacting scalable data infrastructures and agent-based simulations.",
                "call-number": "10.1145/2769458.2769484",
                "collection-title": "SIGSIM PADS '15",
                "container-title": "Proceedings of the 3rd ACM SIGSIM Conference on Principles of Advanced Discrete Simulation",
                "DOI": "10.1145/2769458.2769484",
                "event-place": "London, United Kingdom",
                "ISBN": "9781450335836",
                "keyword": "big data, exascale, agent-based modelling, simulation",
                "number-of-pages": "1",
                "page": "1",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Simulation in the era of Big Data: Trends and Challenges",
                "URL": "https://doi.org/10.1145/2769458.2769484"
            }
        },
        {
            "10.1145/3105831.3105841": {
                "id": "10.1145/3105831.3105841",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Costa",
                        "given": "Carlos"
                    },
                    {
                        "family": "Santos",
                        "given": "Maribel Yasmina"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            7,
                            12
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            7,
                            12
                        ]
                    ]
                },
                "abstract": "Nowadays, the concept of Smart City provides a rich analytical context, highlighting the need to store and process vast amounts of heterogeneous data flowing at different velocities. This data is defined as Big Data, which imposes significant difficulties in traditional data techniques and technologies. Data Warehouses (DWs) have long been recognized as a fundamental enterprise asset, providing fact-based decision support for several organizations. The concept of DW is evolving. Traditionally, Relational Database Management Systems (RDBMSs) are used to store historical data, providing different analytical perspectives regarding several business processes. With the current advancements in Big Data techniques and technologies, the concept of Big Data Warehouse (BDW) emerges to surpass several limitations of traditional DWs. This paper presents a novel approach for designing and implementing BDWs, which has been supporting the SusCity data visualization platform. The BDW is a crucial component of the SusCity research project in the context of Smart Cities, supporting analytical tasks based on data collected in the city of Lisbon.",
                "call-number": "10.1145/3105831.3105841",
                "collection-title": "IDEAS '17",
                "container-title": "Proceedings of the 21st International Database Engineering & Applications Symposium",
                "DOI": "10.1145/3105831.3105841",
                "event-place": "Bristol, United Kingdom",
                "ISBN": "9781450352208",
                "keyword": "Big Data, Data Warehouse, NoSQL, Smart Cities, Big Data Warehousing, Hadoop",
                "number-of-pages": "10",
                "page": "264–273",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The SusCity Big Data Warehousing Approach for Smart Cities",
                "URL": "https://doi.org/10.1145/3105831.3105841"
            }
        },
        {
            "10.1145/2487575.2491135": {
                "id": "10.1145/2487575.2491135",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Neumann",
                        "given": "Chris"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            8,
                            11
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            8,
                            11
                        ]
                    ]
                },
                "abstract": "The brief history of knowledge discovery is filled with products that promised to bring \"BI to the masses\". But how do you build a product that truly bridges the gap between the conceptual simplicity of \"questions and answers\" and the structure needed to query traditional data stores?In this talk, Chris Neumann will discuss how DataHero applied the principles of user-centric design and development over a year and a half to create a product with which more than 95% of new users can get answers on their first attempt. He'll demonstrate the process DataHero uses to determine the best combination of algorithms and user interface concepts needed to create intuitive solutions to potentially complex interactions, including: Determining the structure of files uploaded by usersAccurately identifying data types within filesPresenting users with an optimal visualization for any combination of dataHelping users to ask questions of data when they don't know what to do Chris will also talk about what it's like to start a \"Big Data\" company and how he applied lessons from his time as the first engineer at Aster Data Systems to DataHero.",
                "call-number": "10.1145/2487575.2491135",
                "collection-title": "KDD '13",
                "container-title": "Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining",
                "DOI": "10.1145/2487575.2491135",
                "event-place": "Chicago, Illinois, USA",
                "ISBN": "9781450321747",
                "keyword": "data mining, analytics, big data",
                "number-of-pages": "1",
                "page": "1140",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Using \"big data\" to solve \"small data\" problems",
                "URL": "https://doi.org/10.1145/2487575.2491135"
            }
        },
        {
            "10.1145/2513549.2514739": {
                "id": "10.1145/2513549.2514739",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Plale",
                        "given": "Beth"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2013,
                            10,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2013,
                            10,
                            28
                        ]
                    ]
                },
                "abstract": "Big Data poses challenges for text analysis and natural language processing due to its characteristics of volume, veracity, and velocity of the data. The sheer volume in terms of numbers of documents challenges traditional local repository and index systems for large-scale analysis and mining. Computation, storage and data representation must work together to provide rapid access, search, and mining of the deep knowledge in the large text collection. Text under copyright poses additional barriers to computational access, where analysis has to be separated from human consumption of the original text. Data preprocessing, in most cases, remains a daunting task for big textual data particularly data veracity is questionable due to age of original materials. Data velocity is rate of change of the data but can also be the rate at which changes and corrections are made.The HathiTrust Research Center (HTRC) provides new opportunities for IR, NLP and text mining research. HTRC is the research arm of HathiTrust, a consortium that stewards the digital library of content from research libraries around the country. With close to 11 million volumes in HathiTrust collection, HTRC aims to provide large-scale computational access and analytics to these text resources.With the goal of facilitating scholar's work, HTRC establishes a cyberinfrastructure of software, staff, and services to assist researchers and developers more easily process and mine large scale textual data effectively and efficiently. The primary users of HTRC are digital humanities, informatics, and librarians. They are of different research backgrounds and expertise and thus a variety of tools are made available to them.In the HTRC model of computing, computation moves to the data, and services grow up around the corpus to serve the research community. In this manner, the architecture is cloud-based. Moving algorithms to the data is important because the copyrighted content must be protected, however, a side benefit is that the paradigm frees scholars from worrying about managing a large corpus of data.The text analytics currently supported in HTRC is the SEASR suite of analytical algorithms (www.seasr.org). SEASR algorithms, which are written as workflows, include entity extraction, tag cloud, topic modeling, NaiveBayes, Date Entities to Similie Timeline.In this talk, I introduce the collections, architecture, and text analytics of HTRC, with a focus on the challenges of a BigData corpus and what that means for data storage, access, and large-scale computation.HTRC is building a user community to better understand and support researcher needs. It opens many exciting possibilities for the NLP, text mining, IR types of research: with so large an amount of textual data and many candidate algorithms, with support for researcher contributed algorithms, many interesting research questions emerge and many interesting results are to follow.",
                "call-number": "10.1145/2513549.2514739",
                "collection-title": "UnstructureNLP '13",
                "container-title": "Proceedings of the 2013 international workshop on Mining unstructured big data using natural language processing",
                "DOI": "10.1145/2513549.2514739",
                "event-place": "San Francisco, California, USA",
                "ISBN": "9781450324151",
                "keyword": "hathitrust, text mining and analysis, information retrieval, big data access, nlp",
                "number-of-pages": "2",
                "page": "1–2",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big data opportunities and challenges for IR, text mining and NLP",
                "URL": "https://doi.org/10.1145/2513549.2514739"
            }
        },
        {
            "10.1145/3291801.3291833": {
                "id": "10.1145/3291801.3291833",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Shaorong",
                        "given": "He"
                    },
                    {
                        "family": "Zhifeng",
                        "given": "Xie"
                    },
                    {
                        "family": "Jianbo",
                        "given": "Huang"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            27
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            10,
                            27
                        ]
                    ]
                },
                "abstract": "China film market has become the second largest box office market just after North America today, the Chinese film market is less than 1/5 size of the now, in 10 years ago. The Chinese film market is growing so fast, the reasons research on this phenomenon become a hot spot. In this article, we tried to find the rule of films box office market based on the historical data of China released film. Gaining film market rules will help film-makers understand audience preferences and make decisions on future movie projects. We collected the movies data released in China in recent 15 years which contains box office, and basic information (such as release date, language, type, country, etc.), correspondingly, we also collected the movie audience's com-ments on the internet, more than 100000 comments in total, There is no public movies released in China set provided by a inde-pendent agency until now, According to the obtained data, we analyzed the movies data distribution rules in the month, year, genre, using language, We also visualized the proportion of all films in the rating (from douban.com), and analyzed collectively the quality of domestic released films. We conducted word cloud processing on the comments of the highest box office movie Wolf warriors 2, which demonstrate intuitively the public's discussion on this movie.",
                "call-number": "10.1145/3291801.3291833",
                "collection-title": "ICBDR 2018",
                "container-title": "Proceedings of the 2nd International Conference on Big Data Research",
                "DOI": "10.1145/3291801.3291833",
                "event-place": "Weihai, China",
                "ISBN": "9781450364768",
                "keyword": "visual analysis, data analysis, Movies released in China",
                "number-of-pages": "6",
                "page": "80–85",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Visual Analysis of Big Data Based on Movies Released in China",
                "URL": "https://doi.org/10.1145/3291801.3291833"
            }
        },
        {
            "10.1145/2247596.2247598": {
                "id": "10.1145/2247596.2247598",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Borkar",
                        "given": "Vinayak"
                    },
                    {
                        "family": "Carey",
                        "given": "Michael J."
                    },
                    {
                        "family": "Li",
                        "given": "Chen"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            3,
                            27
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            3,
                            27
                        ]
                    ]
                },
                "abstract": "In this paper we review the history of systems for managing \"Big Data\" as well as today's activities and architectures from the (perhaps biased) perspective of three \"database guys\" who have been watching this space for a number of years and are currently working together on \"Big Data\" problems. Our focus is on architectural issues, and particularly on the components and layers that have been developed recently (in open source and elsewhere) and on how they are being used (or abused) to tackle challenges posed by today's notion of \"Big Data\". Also covered is the approach we are taking in the ASTERIX project at UC Irvine, where we are developing our own set of answers to the questions of the \"right\" components and the \"right\" set of layers for taming the \"Big Data\" beast. We close by sharing our opinions on what some of the important open questions are in this area as well as our thoughts on how the dataintensive computing community might best seek out answers.",
                "call-number": "10.1145/2247596.2247598",
                "collection-title": "EDBT '12",
                "container-title": "Proceedings of the 15th International Conference on Extending Database Technology",
                "DOI": "10.1145/2247596.2247598",
                "event-place": "Berlin, Germany",
                "ISBN": "9781450307901",
                "number-of-pages": "12",
                "page": "3–14",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Inside \"Big Data management\": ogres, onions, or parfaits?",
                "URL": "https://doi.org/10.1145/2247596.2247598"
            }
        },
        {
            "10.14778/2733004.2733015": {
                "id": "10.14778/2733004.2733015",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Yu",
                        "given": "Meng-Chieh"
                    },
                    {
                        "family": "Yu",
                        "given": "Tong"
                    },
                    {
                        "family": "Wang",
                        "given": "Shao-Chen"
                    },
                    {
                        "family": "Lin",
                        "given": "Chih-Jen"
                    },
                    {
                        "family": "Chang",
                        "given": "Edward Y."
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            8,
                            1
                        ]
                    ]
                },
                "abstract": "Sensors on mobile phones and wearables, and in general sensors on IoT (Internet of Things), bring forth a couple of new challenges to big data research. First, the power consumption for analyzing sensor data must be low, since most wearables and portable devices are power-strapped. Second, the velocity of analyzing big data on these devices must be high, otherwise the limited local storage may overflow.This paper presents our hardware-software co-design of a classifier for wearables to detect a person's transportation mode (i.e., still, walking, running, biking, and on a vehicle). We particularly focus on addressing the big-data small-footprint requirement by designing a classifier that is low in both computational complexity and memory requirement. Together with a sensor-hub configuration, we are able to drastically reduce power consumption by 99%, while maintaining competitive mode-detection accuracy. The data used in the paper is made publicly available for conducting research.",
                "call-number": "10.14778/2733004.2733015",
                "container-title": "Proc. VLDB Endow.",
                "DOI": "10.14778/2733004.2733015",
                "ISSN": "2150-8097",
                "issue": "13",
                "keyword": "classification, big data small footprint, context-aware computing, transportation mode, support vector machines, sensor hub",
                "number-of-pages": "12",
                "page": "1429–1440",
                "publisher": "VLDB Endowment",
                "source": "August 2014",
                "title": "Big data small footprint: the design of a low-power classifier for detecting transportation modes",
                "URL": "https://doi.org/10.14778/2733004.2733015",
                "volume": "7"
            }
        },
        {
            "10.1145/2835596.2835614": {
                "id": "10.1145/2835596.2835614",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Liu",
                        "given": "Kuien"
                    },
                    {
                        "family": "Yao",
                        "given": "Yandong"
                    },
                    {
                        "family": "Guo",
                        "given": "Danhuai"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            11,
                            3
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            11,
                            3
                        ]
                    ]
                },
                "abstract": "With the rapid growth of mobile devices and applications, geo-tagged data is becoming increasingly important in emergency management and has become a major workload for big data storage systems. Traditional methods that storing geospatial data in centralized databases suffer from inevitable limitations such like scaling out with the growing size of geospatial data. In order to achieve scalability, a number of solutions on big geospatial data management are proposed in recent years. We can simply classify them into two kinds: extending on distributed databases, or migrating to big-data storage systems. For previous, they mostly adopt the massive parallel processing (MPP) based architecture, in which data are stored and retrieved in a set of independent nodes. Each node can be treated as a traditional databases instance with geospatial extension. For the latter, existing solutions tend to build an additional index layer above general-purpose distributed data stores, e.g., HBASE, CASSANDRA, MangoDB, etc., to support geospatial data while integrating the big-data lineage. However, there are no absolutely perfect data management systems on the earth. Some approaches are desired for execution efficiency while some others are better on fulfilling the programming level need for big data scenarios.In this paper, we analysis the requirements and challenges on geospatial big data storage in emergency management, succeed with discussion with individual perspective from practical cases. The purpose of this paper is not only focused on how to program a geospatial data storage platform but also on how to approve the rationality of geospatial big data system that we plan to build.",
                "call-number": "10.1145/2835596.2835614",
                "collection-number": "5",
                "collection-title": "EM-GIS '15",
                "container-title": "Proceedings of the 1st ACM SIGSPATIAL International Workshop on the Use of GIS in Emergency Management",
                "DOI": "10.1145/2835596.2835614",
                "event-place": "Bellevue, Washington",
                "ISBN": "9781450339704",
                "keyword": "geospatial, perspectives, big data, emergency management",
                "number": "Article 5",
                "number-of-pages": "4",
                "page": "1–4",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "On managing geospatial big-data in emergency management: some perspectives",
                "URL": "https://doi.org/10.1145/2835596.2835614"
            }
        },
        {
            "10.1145/3078564.3078571": {
                "id": "10.1145/3078564.3078571",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Liu",
                        "given": "Xiaoxia"
                    },
                    {
                        "family": "Du",
                        "given": "Yuejin"
                    },
                    {
                        "family": "Sun",
                        "given": "Feiqiang"
                    },
                    {
                        "family": "Zhai",
                        "given": "Lidong"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            8,
                            17
                        ]
                    ]
                },
                "abstract": "In1 recent years, with the rise and development of big data technology, research about big data of education has gradually become a hot research. Big data of education is an important means of modernization educational change based on data acquisition and analysis technology. The major applications of big data in education are educational data mining, learning analysis and educational decision-making and so on [1]. With the combination of big data and education, adaptive learning system [2] gradually into our sight. Adaptive learning system is a system that can provide a personalized learning service for learners. The system can recommended personalized learning path and learning resources according to learners' various characteristics and behavioral tendencies, such as learning style, media tendency, interest, cognitive level and so on. This paper aims to design an adaptive learning system based on the big data in education. The system contains four modules: domain module, student module, adaptive recommendation module and visual display module.",
                "call-number": "10.1145/3078564.3078571",
                "collection-number": "10",
                "collection-title": "ICIE '17",
                "container-title": "Proceedings of the 6th International Conference on Information Engineering",
                "DOI": "10.1145/3078564.3078571",
                "event-place": "Dalian Liaoning, China",
                "ISBN": "9781450352109",
                "keyword": "big data, adaptive learning, data mining",
                "number": "Article 10",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Design of adaptive learning system based on big data",
                "URL": "https://doi.org/10.1145/3078564.3078571"
            }
        },
        {
            "10.5555/2694443.2694450": {
                "id": "10.5555/2694443.2694450",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Borkar",
                        "given": "Vinayak"
                    },
                    {
                        "family": "Carey",
                        "given": "Michael J."
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            12,
                            14
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            12,
                            14
                        ]
                    ]
                },
                "abstract": "The growth of the World Wide Web has led to an astronomical amount of data being generated. More recently, the amount of user-generated content has seen tremendous expansion thanks to social media like Facebook and Twitter. Enterprises, researchers, and even governments consider this data to be an invaluable source of insight into people's behavior, creating a race to analyze as much data as possible. This race has driven virtually everyone, ranging from Web companies to brick and mortar businesses, into a \"Big Data\" frenzy. On the systems side, traditional relational databases have proven to be un-scalable, too expensive, too rigid, and/or too heavy-weight for dealing with current Big Data problems. As a result, there has been an explosion in the number of systems being developed, both within industry as well as in academia, to manage massive amounts of data.",
                "call-number": "10.5555/2694443.2694450",
                "collection-title": "COMAD '12",
                "container-title": "Proceedings of the 18th International Conference on Management of Data",
                "event-place": "Pune, India",
                "number-of-pages": "3",
                "page": "12–14",
                "publisher": "Computer Society of India",
                "publisher-place": "Mumbai, Maharashtra, IND",
                "title": "Big data technologies circa 2012"
            }
        },
        {
            "10.1145/2644866.2644870": {
                "id": "10.1145/2644866.2644870",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Schmitz",
                        "given": "Patrick"
                    },
                    {
                        "family": "Pearce",
                        "given": "Laurie"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            16
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            9,
                            16
                        ]
                    ]
                },
                "abstract": "In this paper, we describe Berkeley Prosopography Services (BPS), a new set of tools for prosopography - the identification of individuals and study of their interactions - in support of humanities research. Prosopography is an example of \"big data\" in the humanities, characterized not by the size of the datasets, but by the way that computational and data-driven methods can transform scholarly workflows. BPS is based upon re-usable infrastructure, supporting generalized web services for corpus management, social network analysis, and visualization. The BPS disambiguation model is a formal implementation of the traditional heuristics used by humanists, and supports plug-in rules for adaptation to a wide range of domain corpora. A workspace model supports exploratory research and collaboration. We contrast the BPS model of configurable heuristic rules to other approaches for automated text analysis, and explain how our model facilitates interpretation by humanist researchers. We describe the significance of the BPS assertion model in which researchers assert conclusions or possibilities, allowing them to override automated inference, to explore ideas in what-if scenarios, and to formally publish and subscribe-to asserted annotations among colleagues, and/or with students. We present an initial evaluation of researchers' experience using the tools to study corpora of cuneiform tablets, and describe plans to expand the application of the tools to a broader range of corpora.",
                "call-number": "10.1145/2644866.2644870",
                "collection-title": "DocEng '14",
                "container-title": "Proceedings of the 2014 ACM symposium on Document engineering",
                "DOI": "10.1145/2644866.2644870",
                "event-place": "Fort Collins, Colorado, USA",
                "ISBN": "9781450329491",
                "keyword": "cyberinfrastructure, digital humanities, prosopography, social network analysis, web-services, annotation, assertions, big data",
                "number-of-pages": "10",
                "page": "179–188",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Humanist-centric tools for big data: berkeley prosopography services",
                "URL": "https://doi.org/10.1145/2644866.2644870"
            }
        },
        {
            "10.1145/3305160.3305211": {
                "id": "10.1145/3305160.3305211",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Sun",
                        "given": "Zhaohao"
                    },
                    {
                        "family": "Huo",
                        "given": "Yanxia"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            1,
                            10
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            1,
                            10
                        ]
                    ]
                },
                "abstract": "Intelligent big data analytics is an emerging paradigm for integrating big data, analytics, and artificial intelligence. The objective of this paper is to provide a managerial framework of intelligent big data analytics. More specifically, this paper proposes a managerial framework of intelligent big data analytics, which consists of intelligent big data analytics as a science, technology, system, service and management for improving business decision making. Then it elaborates intelligent big data analytics for management taking into account main managerial functions: planning, organising, leading and controlling. The proposed approach in this paper might facilitate the research and development of business analytics, big data analytics, business intelligence, artificial intelligence and data science.",
                "call-number": "10.1145/3305160.3305211",
                "collection-title": "ICSIM 2019",
                "container-title": "Proceedings of the 2nd International Conference on Software Engineering and Information Management",
                "DOI": "10.1145/3305160.3305211",
                "event-place": "Bali, Indonesia",
                "ISBN": "9781450366427",
                "keyword": "artificial intelligence, intelligent analytics, management analytics, intelligent big data analytics",
                "number-of-pages": "5",
                "page": "152–156",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "A Managerial Framework for Intelligent Big Data Analytics",
                "URL": "https://doi.org/10.1145/3305160.3305211"
            }
        },
        {
            "10.5555/2602724.2602725": {
                "id": "10.5555/2602724.2602725",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Hendler",
                        "given": "Jim"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            6,
                            1
                        ]
                    ]
                },
                "abstract": "As \"big data\" moves from buzzword to practice, campus departments must increasingly figure out where data science fits into their curricula. Clearly such an interdisciplinary area crosses traditional boundaries ranging from statistics traditionally taught in mathematics or engineering departments, a new method of scientific discovery for biologists and chemists, a new challenge for ethicists and political scientists, and a new realm for design and electronic arts, etc. Within computer science departments, it currently seems to reside in the machine learning and knowledge discovery areas where the metaphor of big data as \"the new oil\" to be mined is pursued. In this talk, however, I opine that just as oil is important for the energy it generates, which powers the technologies of modern life, data is increasingly important for the information it generates, which will power the information applications of the future. We will explore some of these emerging trends, ranging from high performance modeling to the Watson AI system, looking at what we might want to be teaching our students if they are to be leaders in this emerging area.",
                "call-number": "10.5555/2602724.2602725",
                "container-title": "J. Comput. Sci. Coll.",
                "ISSN": "1937-4771",
                "issue": "6",
                "number-of-pages": "2",
                "page": "5–6",
                "publisher": "Consortium for Computing Sciences in Colleges",
                "publisher-place": "Evansville, IN, USA",
                "source": "June 2014",
                "title": "Big data meets computer science",
                "volume": "29"
            }
        },
        {
            "10.5555/2819289.2819298": {
                "id": "10.5555/2819289.2819298",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "DeLine",
                        "given": "Robert"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2015,
                            5,
                            16
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2015,
                            5,
                            16
                        ]
                    ]
                },
                "abstract": "Big Data Analysis is becoming a widespread practice on many software development projects, and statisticians and data analysts are working alongside developers, testers and program managers. Because data science is still an emerging discipline in software projects, there are many opportunities where software engineering researchers can help improve practice. In terms of productivity, data scientists need support for exploratory analysis of large datasets, relief from clerical tasks like data cleaning, and easier paths for live deployment of new analyses. In terms of correctness, data scientists need help in preserving data meaning and provenance, and non-experts need help avoiding analysis errors. In terms of communication and coordination, teams need more approachable ways to discuss uncertainty and risk, and support for data-driven decision making needs to become available to all roles. This position paper describes these open problems and points to ongoing research beginning to tackle them.",
                "call-number": "10.5555/2819289.2819298",
                "collection-title": "BIGDSE '15",
                "container-title": "Proceedings of the First International Workshop on BIG Data Software Engineering",
                "event-place": "Florence, Italy",
                "number-of-pages": "4",
                "page": "26–29",
                "publisher": "IEEE Press",
                "title": "Research opportunities for the big data era of software engineering"
            }
        },
        {
            "10.1145/2345316.2345328": {
                "id": "10.1145/2345316.2345328",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Xue",
                        "given": "Zhiming"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2012,
                            7,
                            1
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2012,
                            7,
                            1
                        ]
                    ]
                },
                "abstract": "The amount of data each organization deals with today has been rapidly growing. However, analyzing large datasets commonly referred to as \"big data\" has been a huge challenge due to lack of suitable tools and adequate computing resources. Why are organizations, both in public sector and private sector, so keen on unlocking business insights from all structured and unstructured data? What is the current state of big data solutions and service providers? How effective are some of the solutions that have been put into real world practices? What is the current state of cloud computing technologies? What impacts have cloud computing technologies available in public clouds and private clouds had on the way organizations addressing big data challenges? How to secure big data in the clouds? What are the future roadmaps for cloud-based big data solutions, especially for geospatial related applications?This panel discussion will include a short presentation or discussion related to big data and cloud computing by each panelist, followed by questions and questions from the audience and the panel.",
                "call-number": "10.1145/2345316.2345328",
                "collection-number": "9",
                "collection-title": "COM.Geo '12",
                "container-title": "Proceedings of the 3rd International Conference on Computing for Geospatial Research and Applications",
                "DOI": "10.1145/2345316.2345328",
                "event-place": "Washington, D.C., USA",
                "ISBN": "9781450311137",
                "number": "Article 9",
                "number-of-pages": "1",
                "page": "1",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Cloud computing & big data computing",
                "URL": "https://doi.org/10.1145/2345316.2345328"
            }
        },
        {
            "10.1007/s00778-014-0357-y": {
                "id": "10.1007/s00778-014-0357-y",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Alexandrov",
                        "given": "Alexander"
                    },
                    {
                        "family": "Bergmann",
                        "given": "Rico"
                    },
                    {
                        "family": "Ewen",
                        "given": "Stephan"
                    },
                    {
                        "family": "Freytag",
                        "given": "Johann-Christoph"
                    },
                    {
                        "family": "Hueske",
                        "given": "Fabian"
                    },
                    {
                        "family": "Heise",
                        "given": "Arvid"
                    },
                    {
                        "family": "Kao",
                        "given": "Odej"
                    },
                    {
                        "family": "Leich",
                        "given": "Marcus"
                    },
                    {
                        "family": "Leser",
                        "given": "Ulf"
                    },
                    {
                        "family": "Markl",
                        "given": "Volker"
                    },
                    {
                        "family": "Naumann",
                        "given": "Felix"
                    },
                    {
                        "family": "Peters",
                        "given": "Mathias"
                    },
                    {
                        "family": "Rheinländer",
                        "given": "Astrid"
                    },
                    {
                        "family": "Sax",
                        "given": "Matthias J."
                    },
                    {
                        "family": "Schelter",
                        "given": "Sebastian"
                    },
                    {
                        "family": "Höger",
                        "given": "Mareike"
                    },
                    {
                        "family": "Tzoumas",
                        "given": "Kostas"
                    },
                    {
                        "family": "Warneke",
                        "given": "Daniel"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            12,
                            1
                        ]
                    ]
                },
                "abstract": "We present Stratosphere, an open-source software stack for parallel data analysis. Stratosphere brings together a unique set of features that allow the expressive, easy, and efficient programming of analytical applications at very large scale. Stratosphere's features include \"in situ\" data processing, a declarative query language, treatment of user-defined functions as first-class citizens, automatic program parallelization and optimization, support for iterative programs, and a scalable and efficient execution engine. Stratosphere covers a variety of \"Big Data\" use cases, such as data warehousing, information extraction and integration, data cleansing, graph analysis, and statistical analysis applications. In this paper, we present the overall system architecture design decisions, introduce Stratosphere through example queries, and then dive into the internal workings of the system's components that relate to extensibility, programming model, optimization, and query execution. We experimentally compare Stratosphere against popular open-source alternatives, and we conclude with a research outlook for the next years.",
                "call-number": "10.1007/s00778-014-0357-y",
                "container-title": "The VLDB Journal",
                "DOI": "10.1007/s00778-014-0357-y",
                "ISSN": "1066-8888",
                "issue": "6",
                "keyword": "Graph processing, Big data, Query Optimization, Text mining, Distributed systems, Parallel databases, Data cleansing, Query processing",
                "number-of-pages": "26",
                "page": "939–964",
                "publisher": "Springer-Verlag",
                "publisher-place": "Berlin, Heidelberg",
                "source": "December  2014",
                "title": "The Stratosphere platform for big data analytics",
                "URL": "https://doi.org/10.1007/s00778-014-0357-y",
                "volume": "23"
            }
        },
        {
            "10.1145/3221269.3221294": {
                "id": "10.1145/3221269.3221294",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Porto",
                        "given": "Fabio"
                    },
                    {
                        "family": "Rittmeyer",
                        "given": "João N."
                    },
                    {
                        "family": "Ogasawara",
                        "given": "Eduardo"
                    },
                    {
                        "family": "Krone-Martins",
                        "given": "Alberto"
                    },
                    {
                        "family": "Valduriez",
                        "given": "Patrick"
                    },
                    {
                        "family": "Shasha",
                        "given": "Dennis"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            7,
                            9
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            7,
                            9
                        ]
                    ]
                },
                "abstract": "Consider a set of points P in space with at least some of the pairwise distances specified. Given this set P, consider the following three kinds of queries against a database D of points : (i) pure constellation query: find all sets S in D of size |P| that exactly match the pairwise distances within P up to an additive error ϵ; (ii) isotropic constellation queries: find all sets S in D of size |P| such that there exists some scale factor f for which the distances between pairs in S exactly match f times the distances between corresponding pairs of P up to an additive ϵ; (iii) non-isotropic constellation queries: find all sets S in D of size |P| such that there exists some scale factor f and for at least some pairs of points, a maximum stretch factor mi,j > 1 such that (f X mi,jXdist(pi, pj))+ϵ > dist(si,sj) > (f X dist(pi, pj)) - ϵ. Finding matches to such queries has applications to spatial data in astronomical, seismic, and any domain in which (approximate, scale-independent) geometrical matching is required. Answering the isotropic and non-isotropic queries is challenging because scale factors and stretch factors may take any of an infinite number of values. This paper proposes practically efficient sequential and distributed algorithms for pure, isotropic, and non-isotropic constellation queries. As far as we know, this is the first work to address isotropic and non-isotropic queries.",
                "call-number": "10.1145/3221269.3221294",
                "collection-number": "21",
                "collection-title": "SSDBM '18",
                "container-title": "Proceedings of the 30th International Conference on Scientific and Statistical Database Management",
                "DOI": "10.1145/3221269.3221294",
                "event-place": "Bozen-Bolzano, Italy",
                "ISBN": "9781450365055",
                "keyword": "big data, distance matching, isotropic, point set registration, geometrical patterns, pattern search, spatial patterns",
                "number": "Article 21",
                "number-of-pages": "12",
                "page": "1–12",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Point pattern search in big data",
                "URL": "https://doi.org/10.1145/3221269.3221294"
            }
        },
        {
            "10.1145/3110025.3119402": {
                "id": "10.1145/3110025.3119402",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Ahmed",
                        "given": "Mohiuddin"
                    },
                    {
                        "family": "Choudhury",
                        "given": "Nazim"
                    },
                    {
                        "family": "Uddin",
                        "given": "Shahadat"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            7,
                            31
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            7,
                            31
                        ]
                    ]
                },
                "abstract": "In the modern financial market, market participants use big data analytics to gain valuable insight on historical market data for better decision making. Complying with the three vs (i.e., velocity, volume and variety) of big data, the financial market is considered as a complex system comprised of many interacting high-frequency traders those make decisions based on the relative strengths of these interactions. Researchers have put substantial scholarly input to deal with these anomalies. From the big data perspective, anomaly detection in financial data has widely been ignored despite many organisations store, process and disseminate financial market data for interested customers to assist them to make informed decision abd create competitive advantages. Considering the presence of anomalies in voluminous data from myriad data sources may generate catastrophic decision through misunderstandings of market behaviour. Therefore, in this study, we applied a standard set of anomaly detection techniques, used in big data based on nearest-neighbours, clustering and statistical approaches, to detect rare anomalies present within the historical daily trading information for five years (i.e., 2009--2013) for each stock listed on the Australian Security Exchange (ASX). We also measured the performance of these anomaly detection techniques using a number of metrics to highlight the best performing algorithm. The experimental results suggest that the LOF(Local Outlier Factor) and CMGOS(Clustering-based Multivariate Gaussian Outlier Score) are the best performing anomaly detection techniques.",
                "call-number": "10.1145/3110025.3119402",
                "collection-title": "ASONAM '17",
                "container-title": "Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017",
                "DOI": "10.1145/3110025.3119402",
                "event-place": "Sydney, Australia",
                "ISBN": "9781450349932",
                "keyword": "Financial Markets, Financial Big Data, Anomaly Detection",
                "number-of-pages": "4",
                "page": "998–1001",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Anomaly Detection on Big Data in Financial Markets",
                "URL": "https://doi.org/10.1145/3110025.3119402"
            }
        },
        {
            "10.1145/3348400.3348414": {
                "id": "10.1145/3348400.3348414",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Karim",
                        "given": "Shakir"
                    },
                    {
                        "family": "Gide",
                        "given": "Ergun"
                    },
                    {
                        "family": "Sandu",
                        "given": "Raj"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2019,
                            6,
                            28
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2019,
                            6,
                            28
                        ]
                    ]
                },
                "abstract": "Big Data is the biggest emerging trend and promise in today's technology-driven world. It is continuing to create a lot of buzz in not only the field of technology, but across the world. It promises substantial involvements, vast changes, modernizations, and integration with and within people's ongoing life. It makes the world more demanding and helps with making prompt and appropriate decisions in real time. This paper aims to provide a comprehensive analysis of the health industry and health care system in Australia that are relevant to the consequences formed by Big Data. This paper primarily uses a secondary research analysis method to provide a wide-ranging investigation into the positive and negative consequences of health issues relevant to Big Data, the architects of those consequences, and those overstated by the consequences. The secondary resources are subject to journal articles, reports, conference proceedings, media articles, corporation-based documents, blogs and other appropriate information. In the future, the investigation will continue by employing Mixed Methodology (Qualitative and Quantitative) in relation to Big Data usage in the Australian Health industry. The paper initially finds that Big Data is an evidence source in health care and provides useful insight into the Australian healthcare system. It is steadily reducing the cost of the Australian healthcare system and improving patients' outcomes in Australia. Big data can not only improve the affairs between public and health enterprises, but can also make life better by increasing efficiency and modernization.",
                "call-number": "10.1145/3348400.3348414",
                "collection-title": "ICMSTTL 2019",
                "container-title": "Proceedings of the 2019 International Conference on Mathematics, Science and Technology Teaching and Learning",
                "DOI": "10.1145/3348400.3348414",
                "event-place": "Sydney, NSW, Australia",
                "ISBN": "9781450371674",
                "keyword": "Big Data (BD), Australian Health Care Services, Health Care System, High Risk and High Cost Patients",
                "number-of-pages": "5",
                "page": "34–38",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "The Impact of Big Data on Health Care Services in Australia: Using Big Data Analytics to Categorise and Deal with Patients",
                "URL": "https://doi.org/10.1145/3348400.3348414"
            }
        },
        {
            "10.1145/3445945": {
                "id": "10.1145/3445945",
                "type": "BOOK",
                "issued": {
                    "date-parts": [
                        [
                            2020
                        ]
                    ]
                },
                "call-number": "10.1145/3445945",
                "container-title-short": "ICBDR 2020",
                "event-place": "Tokyo, Japan",
                "genre": "proceeding",
                "ISBN": "9781450387750",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "2020 the 4th International Conference on Big Data Research (ICBDR'20)"
            }
        },
        {
            "10.1145/3416921.3416936": {
                "id": "10.1145/3416921.3416936",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Gotsev",
                        "given": "Lyubomir"
                    },
                    {
                        "family": "Shoikova",
                        "given": "Elena"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            8,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            8,
                            26
                        ]
                    ]
                },
                "abstract": "The paper aims to reveal the current state of book, video and article production in Big Data Knowledge Domain on particular platforms by examining the capabilities of Application Programming Interface (API) technology in conducting scientific data-driven research. Queries append public records from Google Books, YouTube and IEEE Explore® Digital Library to two research paradigms (sets of data sets): Big Data (incl. Analysis, Engineering, Architecture, Governance, Management, Frameworks) and Big Data interdisciplinary fields (Data Science, Data Mining, Deep Learning, Machine Learning, Artificial Intelligence). Metadata from more than 25 000 conference papers, 2000 books over the past 50 years, and 4 000 videos for the last 12 years, matching the searching criteria, has been stored and analyzed. The outputs are summarized in statistics, forecasting, rating key findings by various attributes: title, author, publisher, research field, category, subject, publication year, description, view count, and a combination of mentioned metadata in cross-tables. Nearly a half of billion video views; a half of million article reference count; a twofold increase in the number of papers in Machine learning over past three years compared to the total number in the same field for entire 1988-2016 period; 1:2:12 overall books-to-videos-to conference papers ratio; 61.3% of last year's video production just in a month (Jan-2020); the earliest found usage of \"Artificial Intelligence\" expression in a printed law document dated 1848 are few curious examples of analysis findings. The paper presents non-commercial research and retrieved data is collected entirely from public records.",
                "call-number": "10.1145/3416921.3416936",
                "collection-title": "ICCBDC '20",
                "container-title": "Proceedings of the 2020 4th International Conference on Cloud and Big Data Computing",
                "DOI": "10.1145/3416921.3416936",
                "event-place": "Virtual, United Kingdom",
                "ISBN": "9781450375382",
                "keyword": "Big Data, Data Analysis, Scientific Publishing, API",
                "number-of-pages": "5",
                "page": "10–14",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "An Analysis of Scientific Production in Big Data Knowledge Domain on Google Books, YouTube and IEEE Explore® Digital Library",
                "URL": "https://doi.org/10.1145/3416921.3416936"
            }
        },
        {
            "10.1145/3524383.3524433": {
                "id": "10.1145/3524383.3524433",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Abdul Jalil",
                        "given": "Nasir"
                    },
                    {
                        "family": "Wong Ei Leen",
                        "given": "Mikkay"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2022,
                            2,
                            26
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2022,
                            2,
                            26
                        ]
                    ]
                },
                "abstract": "Over the last couple of years, Covid-19 has caused an uproar and chaos throughout the world. The occurrence of Covid-19 is an unprecedented event which has led towards a substantial number of lost humans’ lives and mayhem in the economic, social, and most importantly, healthcare systems across the world. In order to gain control of the pandemic, it is extremely pertinent to truly grasp the characteristics and behavior of the coronavirus which can be done by gathering and evaluating related big data. Furthermore, big data analytics tools are known to play an important role in building knowledge which are vital for decision making and precautionary measures. Across the world, it is evident that both government and non-governmental organizations have been working hand-in-hand to deploy big data technology. There is a plethora of data analytics methods available thus, the intention of this work is to assemble available methods which can be applied in the current pandemic.",
                "call-number": "10.1145/3524383.3524433",
                "collection-title": "ICBDE '22",
                "container-title": "Proceedings of the 5th International Conference on Big Data and Education",
                "DOI": "10.1145/3524383.3524433",
                "event-place": "Shanghai, China",
                "ISBN": "9781450395793",
                "keyword": "Machine Learning, IoT based data analytics, Artificial Intelligence, COVID-19, Pandemic, Big Data",
                "number-of-pages": "7",
                "page": "361–367",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Big Data in the Era of Pandemic COVID-19 : Application of IoT based data analytics, Machine Learning and Artificial Intelligence",
                "URL": "https://doi.org/10.1145/3524383.3524433"
            }
        },
        {
            "10.1145/3186549.3186559": {
                "id": "10.1145/3186549.3186559",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Sadiq",
                        "given": "Shazia"
                    },
                    {
                        "family": "Dasu",
                        "given": "Tamraparni"
                    },
                    {
                        "family": "Dong",
                        "given": "Xin Luna"
                    },
                    {
                        "family": "Freire",
                        "given": "Juliana"
                    },
                    {
                        "family": "Ilyas",
                        "given": "Ihab F."
                    },
                    {
                        "family": "Link",
                        "given": "Sebastian"
                    },
                    {
                        "family": "Miller",
                        "given": "Miller J."
                    },
                    {
                        "family": "Naumann",
                        "given": "Felix"
                    },
                    {
                        "family": "Zhou",
                        "given": "Xiaofang"
                    },
                    {
                        "family": "Srivastava",
                        "given": "Divesh"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            2,
                            22
                        ]
                    ]
                },
                "abstract": "We outline a call to action for promoting empiricism in data quality research. The action points result from an analysis of the landscape of data quality research. The landscape exhibits two dimensions of empiricism in data quality research relating to type of metrics and scope of method. Our study indicates the presence of a data continuum ranging from real to synthetic data, which has implications for how data quality methods are evaluated. The dimensions of empiricism and their inter-relationships provide a means of positioning data quality research, and help expose limitations, gaps and opportunities.",
                "call-number": "10.1145/3186549.3186559",
                "container-title": "SIGMOD Rec.",
                "DOI": "10.1145/3186549.3186559",
                "ISSN": "0163-5808",
                "issue": "4",
                "number-of-pages": "9",
                "page": "35–43",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "December 2017",
                "title": "Data Quality: The Role of Empiricism",
                "URL": "https://doi.org/10.1145/3186549.3186559",
                "volume": "46"
            }
        },
        {
            "10.1145/3412497": {
                "id": "10.1145/3412497",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Peng",
                        "given": "Lingxi"
                    },
                    {
                        "family": "Liu",
                        "given": "Haohuai"
                    },
                    {
                        "family": "Nie",
                        "given": "Yangang"
                    },
                    {
                        "family": "Xie",
                        "given": "Ying"
                    },
                    {
                        "family": "Tang",
                        "given": "Xuan"
                    },
                    {
                        "family": "Luo",
                        "given": "Ping"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            11,
                            21
                        ]
                    ]
                },
                "abstract": "Happiness is a hot topic in academic circles. The study of happiness involves many disciplines, such as philosophy, psychology, sociology, and economics. However, there are few studies on the quantitative analysis of the factors affecting happiness. In this article, we used the well-known World Values Survey Wave 6 (WV6) dataset to quantitatively analyze the happiness of 57 countries with Big Data techniques. First, we obtained the seven most important factors by constructing happiness decision trees for each country. Calculating the frequencies of these factors, we obtained the 17 most important indicators for the prediction of happiness in the world. Then, we selected five representative countries, namely, Sweden, Japan, India, China, and the USA, and analyzed the indicators with the random forest method. We identified different patterns of factors that influence happiness in different countries. This study is a successful attempt to apply data mining technology in the social sciences, and the results are of practical significance.",
                "call-number": "10.1145/3412497",
                "collection-number": "5",
                "container-title": "ACM Trans. Asian Low-Resour. Lang. Inf. Process.",
                "DOI": "10.1145/3412497",
                "ISSN": "2375-4699",
                "issue": "1",
                "keyword": "happiness, Big Data, decision tree, feature selection",
                "number": "Article 5",
                "number-of-pages": "12",
                "page": "1–12",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "January 2021",
                "title": "The Transnational Happiness Study with Big Data Technology",
                "URL": "https://doi.org/10.1145/3412497",
                "volume": "20"
            }
        },
        {
            "10.1145/3130218.3130236": {
                "id": "10.1145/3130218.3130236",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Doppa",
                        "given": "Janardhan Rao"
                    },
                    {
                        "family": "Kim",
                        "given": "Ryan Gary"
                    },
                    {
                        "family": "Isakov",
                        "given": "Mihailo"
                    },
                    {
                        "family": "Kinsy",
                        "given": "Michel A."
                    },
                    {
                        "family": "Kwon",
                        "given": "Hyouk Jun"
                    },
                    {
                        "family": "Krishna",
                        "given": "Tushar"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            10,
                            19
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            10,
                            19
                        ]
                    ]
                },
                "abstract": "This work presents a cross-layer design of an adaptive manycore architecture to address the computational needs of emerging big data applications within the technological constraints of power and reliability. From the circuits end, we present links with reconfigurable repeaters that allow single-cycle traversals across multiple hops, creating fast single-cycle paths on demand. At the microarchitecture end, we present a router with bi-directional links, unified virtual channel (VC) structure, and the ability to perform self-monitoring and self-configuration around faults. We present our vision for self-aware manycore architectures and argue that machine learning techniques are very appropriate to efficiently control various configurable on-chip resources in order to realize this vision. We provide concrete learning algorithms for core and NoC reconfiguration; and dynamic power management to improve the performance, energy-efficiency, and reliability over static designs to meet the demands of big data computing. We also discuss future challenges to push the state-of-the-art on fully adaptive manycore architectures.",
                "call-number": "10.1145/3130218.3130236",
                "collection-number": "20",
                "collection-title": "NOCS '17",
                "container-title": "Proceedings of the Eleventh IEEE/ACM International Symposium on Networks-on-Chip",
                "DOI": "10.1145/3130218.3130236",
                "event-place": "Seoul, Republic of Korea",
                "ISBN": "9781450349840",
                "keyword": "Adaptive manycore architectures, Machine learning, Power management, Big data computing, Interconnect networks",
                "number": "Article 20",
                "number-of-pages": "8",
                "page": "1–8",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Adaptive Manycore Architectures for Big Data Computing",
                "URL": "https://doi.org/10.1145/3130218.3130236"
            }
        },
        {
            "10.1145/3422713.3422715": {
                "id": "10.1145/3422713.3422715",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Han",
                        "given": "Bing"
                    },
                    {
                        "family": "Chen",
                        "given": "Zhenxiang"
                    },
                    {
                        "family": "Liu",
                        "given": "Cong"
                    },
                    {
                        "family": "Shang",
                        "given": "Mingyue"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2020,
                            9,
                            18
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2020,
                            9,
                            18
                        ]
                    ]
                },
                "abstract": "In recent years, the number of Android malicious applications has grown rapidly. In the field of network security, the detection of Android malicious applications has been a hot spot. Traditional Android malicious application detection has two methods: dynamic detection and static detection. With the development of network technology, network traffic has increased dramatically, analysis and researchers pay attention to malware detection based on network traffic. As the number of applications increases, application data management becomes particularly important. This paper proposes a method of the collection, store, analysis and visualization of Android applications. This platform provides a simple way to access data, which has broad application prospects.",
                "call-number": "10.1145/3422713.3422715",
                "collection-title": "ICBDT 2020",
                "container-title": "Proceedings of the 2020 3rd International Conference on Big Data Technologies",
                "DOI": "10.1145/3422713.3422715",
                "event-place": "Qingdao, China",
                "ISBN": "9781450387859",
                "keyword": "Data management, Network traffic, Android, Malicious applications",
                "number-of-pages": "5",
                "page": "36–40",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Design and Implementation of Big Data Management Platform for Android Applications",
                "URL": "https://doi.org/10.1145/3422713.3422715"
            }
        },
        {
            "10.1145/2628194.2628251": {
                "id": "10.1145/2628194.2628251",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Liu",
                        "given": "Xiufeng"
                    },
                    {
                        "family": "Iftikhar",
                        "given": "Nadeem"
                    },
                    {
                        "family": "Xie",
                        "given": "Xike"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2014,
                            7,
                            7
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2014,
                            7,
                            7
                        ]
                    ]
                },
                "abstract": "In recent years, real-time processing and analytics systems for big data--in the context of Business Intelligence (BI)--have received a growing attention. The traditional BI platforms that perform regular updates on daily, weekly or monthly basis are no longer adequate to satisfy the fast-changing business environments. However, due to the nature of big data, it has become a challenge to achieve the real-time capability using the traditional technologies. The recent distributed computing technology, MapReduce, provides off-the-shelf high scalability that can significantly shorten the processing time for big data; Its open-source implementation such as Hadoop has become the de-facto standard for processing big data, however, Hadoop has the limitation of supporting real-time updates. The improvements in Hadoop for the real-time capability, and the other alternative real-time frameworks have been emerging in recent years. This paper presents a survey of the open source technologies that support big data processing in a real-time/near real-time fashion, including their system architectures and platforms.",
                "call-number": "10.1145/2628194.2628251",
                "collection-title": "IDEAS '14",
                "container-title": "Proceedings of the 18th International Database Engineering & Applications Symposium",
                "DOI": "10.1145/2628194.2628251",
                "event-place": "Porto, Portugal",
                "ISBN": "9781450326278",
                "keyword": "big data, architectures, survey, real-time, systems",
                "number-of-pages": "6",
                "page": "356–361",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Survey of real-time processing systems for big data",
                "URL": "https://doi.org/10.1145/2628194.2628251"
            }
        },
        {
            "10.1145/3030207.3053670": {
                "id": "10.1145/3030207.3053670",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Singhal",
                        "given": "Rekha"
                    },
                    {
                        "family": "Kunde",
                        "given": "Shruti"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2017,
                            4,
                            17
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2017,
                            4,
                            17
                        ]
                    ]
                },
                "abstract": "Application and/or data migration is a result of limitations in existing system architecture to handle new requirements and the availability of newer, more efficient technology. In any big data architecture, technology migration is staggered across multiple levels and poses functional (related to components of the architecture and underlying infrastructure) and non-functional (QoS) challenges such as availability, reliability and performance guarantees in the target architecture. In this paper, (1) we outline a big data architecture stack and identify research problems arising out of the technology migration in this scenario (2) we propose a smart rule engine system which facilitates the decision making process for the technology to be used at different layers in the architecture during migration.",
                "call-number": "10.1145/3030207.3053670",
                "collection-title": "ICPE '17",
                "container-title": "Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering",
                "DOI": "10.1145/3030207.3053670",
                "event-place": "L&apos;Aquila, Italy",
                "ISBN": "9781450344043",
                "keyword": "migration, big data, performance",
                "number-of-pages": "2",
                "page": "159–160",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Technology Migration Challenges in a Big Data Architecture Stack",
                "URL": "https://doi.org/10.1145/3030207.3053670"
            }
        },
        {
            "10.1145/3299819.3299841": {
                "id": "10.1145/3299819.3299841",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "bt Yusof Ali",
                        "given": "Hazirah Bee"
                    },
                    {
                        "family": "bt Abdullah",
                        "given": "Lili Marziana"
                    },
                    {
                        "family": "Kartiwi",
                        "given": "Mira"
                    },
                    {
                        "family": "Nordin",
                        "given": "Azlin"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2018,
                            12,
                            21
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2018,
                            12,
                            21
                        ]
                    ]
                },
                "abstract": "The alarming rate of big data usage in the cloud makes data exposed easily. Cloud which consists of many servers linked to each other is used for data storage. Having owned by third parties, the security of the cloud needs to be looked at. Risks of storing data in cloud need to be checked further on the severity level. There should be a way to access the risks. Thus, the objective of this paper is to use SLR so that we can have extensive background of literatures on risk assessment for big data in cloud computing environment from the perspective of security, privacy and trust.",
                "call-number": "10.1145/3299819.3299841",
                "collection-title": "AICCC '18",
                "container-title": "Proceedings of the 2018 Artificial Intelligence and Cloud Computing Conference",
                "DOI": "10.1145/3299819.3299841",
                "event-place": "Tokyo, Japan",
                "ISBN": "9781450366236",
                "keyword": "Security, Privacy, Big Data, Trust, Risk Assessment, Cloud",
                "number-of-pages": "5",
                "page": "63–67",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Risk Assessment for Big Data in Cloud: Security, Privacy and Trust",
                "URL": "https://doi.org/10.1145/3299819.3299841"
            }
        },
        {
            "10.1145/1376916.1376940": {
                "id": "10.1145/1376916.1376940",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Fan",
                        "given": "Wenfei"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2008,
                            6,
                            9
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2008,
                            6,
                            9
                        ]
                    ]
                },
                "abstract": "Dependency theory is almost as old as relational databases themselves, and has traditionally been used to improve the quality of schema, among other things. Recently there has been renewed interest in dependencies for improving the quality of data. The increasing demand for data quality technology has also motivated revisions of classical dependencies, to capture more inconsistencies in real-life data, and to match, repair and query the inconsistent data. This paper aims to provide an overview of recent advances in revising classical dependencies for improving data quality.",
                "call-number": "10.1145/1376916.1376940",
                "collection-title": "PODS '08",
                "container-title": "Proceedings of the twenty-seventh ACM SIGMOD-SIGACT-SIGART symposium on Principles of database systems",
                "DOI": "10.1145/1376916.1376940",
                "event-place": "Vancouver, Canada",
                "ISBN": "9781605581521",
                "keyword": "data quality, dependency",
                "number-of-pages": "12",
                "page": "159–170",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Dependencies revisited for improving data quality",
                "URL": "https://doi.org/10.1145/1376916.1376940"
            }
        },
        {
            "10.1145/2905055.2905202": {
                "id": "10.1145/2905055.2905202",
                "type": "PAPER_CONFERENCE",
                "author": [
                    {
                        "family": "Kumar",
                        "given": "Sunil"
                    },
                    {
                        "family": "Shekhar",
                        "given": "Jayant"
                    },
                    {
                        "family": "Gupta",
                        "given": "Himanshu"
                    }
                ],
                "accessed": {
                    "date-parts": [
                        [
                            2022,
                            10,
                            6
                        ]
                    ]
                },
                "issued": {
                    "date-parts": [
                        [
                            2016,
                            3,
                            4
                        ]
                    ]
                },
                "original-date": {
                    "date-parts": [
                        [
                            2016,
                            3,
                            4
                        ]
                    ]
                },
                "abstract": "As we know that digitization is one of boon of 21st century technologies. With the massstorage of digital information and development of internet based technologies like cloud computing, researcher interest has been increased in Big Data and its security. The term Big Data refers to the huge amount of digital information. Actually, Big Data is not a fully new technology; but it is the expansion of data mining technique. In this paper, we propose an agent based security model for cloud big data. The main objective of this security model is to facilitate the IT companies in term of data protection; those are using Cloud Big Data for the analyzing purpose.",
                "call-number": "10.1145/2905055.2905202",
                "collection-number": "142",
                "collection-title": "ICTCS '16",
                "container-title": "Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies",
                "DOI": "10.1145/2905055.2905202",
                "event-place": "Udaipur, India",
                "ISBN": "9781450339629",
                "keyword": "Big Data Security, Cloud Security, Agent Based Security, NoSQL Security",
                "number": "Article 142",
                "number-of-pages": "5",
                "page": "1–5",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "title": "Agent based Security Model for Cloud Big Data",
                "URL": "https://doi.org/10.1145/2905055.2905202"
            }
        },
        {
            "10.1145/3450287": {
                "id": "10.1145/3450287",
                "type": "ARTICLE",
                "author": [
                    {
                        "family": "Zhao",
                        "given": "Liang"
                    }
                ],
                "issued": {
                    "date-parts": [
                        [
                            2021,
                            5,
                            23
                        ]
                    ]
                },
                "abstract": "Events are occurrences in specific locations, time, and semantics that nontrivially impact either our society or the nature, such as earthquakes, civil unrest, system failures, pandemics, and crimes. It is highly desirable to be able to anticipate the occurrence of such events in advance to reduce the potential social upheaval and damage caused. Event prediction, which has traditionally been prohibitively challenging, is now becoming a viable option in the big data era and is thus experiencing rapid growth, also thanks to advances in high performance computers and new Artificial Intelligence techniques. There is a large amount of existing work that focuses on addressing the challenges involved, including heterogeneous multi-faceted outputs, complex (e.g., spatial, temporal, and semantic) dependencies, and streaming data feeds. Due to the strong interdisciplinary nature of event prediction problems, most existing event prediction methods were initially designed to deal with specific application domains, though the techniques and evaluation procedures utilized are usually generalizable across different domains. However, it is imperative yet difficult to cross-reference the techniques across different domains, given the absence of a comprehensive literature survey for event prediction. This article aims to provide a systematic and comprehensive survey of the technologies, applications, and evaluations of event prediction in the big data era. First, systematic categorization and summary of existing techniques are presented, which facilitate domain experts’ searches for suitable techniques and help model developers consolidate their research at the frontiers. Then, comprehensive categorization and summary of major application domains are provided to introduce wider applications to model developers to help them expand the impacts of their research. Evaluation metrics and procedures are summarized and standardized to unify the understanding of model performance among stakeholders, model developers, and domain experts in various application domains. Finally, open problems and future directions are discussed. Additional resources related to event prediction are included in the paper website: http://cs.emory.edu/∼lzhao41/projects/event_prediction_site.html.",
                "call-number": "10.1145/3450287",
                "collection-number": "94",
                "container-title": "ACM Comput. Surv.",
                "DOI": "10.1145/3450287",
                "ISSN": "0360-0300",
                "issue": "5",
                "keyword": "artificial intelligence, Event prediction, big data",
                "number": "Article 94",
                "number-of-pages": "37",
                "page": "1–37",
                "publisher": "Association for Computing Machinery",
                "publisher-place": "New York, NY, USA",
                "source": "June 2022",
                "title": "Event Prediction in the Big Data Era: A Systematic Survey",
                "URL": "https://doi.org/10.1145/3450287",
                "volume": "54"
            }
        }
    ]
}